{
  "root": "/Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor",
  "repo_info": {
    "is_repo": true,
    "commit": "ff9be6fd2e276c9b314628957a52a8548b1cdbc7",
    "branch": "refactoring",
    "author": "Abhinav <abhinavbhardwaj2002@gmail.com>",
    "date": "Fri Oct 10 19:32:48 2025",
    "note": null
  },
  "structure": "├── src\n│   └── rcpack\n│       ├── renderer\n│       │   ├── jsonyaml.py\n│       │   └── markdown.py\n│       ├── __init__.py\n│       ├── __main__.py\n│       ├── cli.py\n│       ├── config_loader.py\n│       ├── discover.py\n│       ├── gitinfo.py\n│       ├── io_utils.py\n│       ├── packager.py\n│       ├── treeview.py\n│       └── utils.py\n├── LICENSE\n├── README.md\n├── pyproject.toml\n├── test-iteration2.json\n├── test-iteration2.yaml\n├── test-output.json\n└── test-yaml.yaml",
  "recent_changes": {},
  "files": {
    "LICENSE": "MIT License\n\nCopyright (c) 2025 Abhinav\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
    "README.md": "# Repo-Contextor\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nA powerful Repository Context Packager CLI tool that analyzes local git repositories and creates comprehensive text files containing repository content optimized for sharing with Large Language Models (LLMs).\n\n## Overview\n\nWhen developers want to get help from ChatGPT, Claude, or other LLMs about their code, they often struggle with how to share their codebase effectively. Common problems include:\n\n- **Lost Context**: Copy-pasting individual files loses important project structure and relationships\n- **Missing Dependencies**: LLMs can't see how files connect or what libraries are used\n- **Incomplete Picture**: Hard to convey the overall architecture and organization\n- **Manual Work**: Time-consuming to gather and format relevant code\n\n**Repo-Contextor** solves this by automatically collecting and formatting repository content into a single, well-structured text file that provides rich context to LLMs, enabling them to give much better assistance with your code.\n\n## Features\n\n- **Git Integration**: Extracts commit SHA, branch, author, and date information\n- **Project Structure**: Generates a clear directory tree visualization\n- **File Content Packaging**: Includes file contents with syntax highlighting\n- **Smart File Discovery**: Recursively scans directories with intelligent filtering\n- **Binary File Detection**: Automatically skips binary files\n- **Error Handling**: Gracefully handles permission errors and provides helpful messages\n- **Multiple Output Formats**: Supports Markdown, JSON, and YAML formats\n- **Flexible Output**: Write to stdout or save to a file\n- **Recent Changes Filter**: Give the files which are updated in last 7days with the time when it was recently modified.\n\n## Installation\n\n### Prerequisites\n\n- Python 3.9 or higher\n- Git (for git repository analysis)\n\n### For End Users\n\n```bash\n# Clone and install\ngit clone https://github.com/yourusername/Repo-Contextor.git\ncd Repo-Contextor\npip install -e .\n```\n\n### For Contributors & Local Development\n\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/Repo-Contextor.git\ncd Repo-Contextor\n\n# Create virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install in development mode\npip install -e .\n```\n\n## Usage\n\n### Basic Examples\n\n```bash\n# Package current directory to terminal\nrepo-contextor .\n\n# Package a specific directory\nrepo-contextor /path/to/your/project\n\n# Save output to a file\nrepo-contextor . -o my-project-context.md\n\n# Generate JSON format\nrepo-contextor . -f json -o context.json\n\n# Generate YAML format\nrepo-contextor . -f yaml -o context.yaml\n\n# Include only files modified in the last 7 days\nrepo-contextor . --recent\n\n# Combine with output file\nrepo-contextor . --recent -o recent-changes.md\n```\n\n### Command Line Options\n\n| Option | Short | Description | Example |\n|--------|-------|-------------|---------|\n| `path` | - | Repository path to analyze (default: current directory) | `repo-contextor /path/to/project` |\n| `--output` | `-o` | Output file path (default: stdout) | `-o context.md` |\n| `--format` | `-f` | Output format: text, json, yaml (default: text) | `-f json` |\n| `--help` | `-h` | Show help message | `-h` |\n| `--recent`  | `-r`  | Include only files modified in the last 7 days    | `repo-contextor . -r -o recent.md` |\n\n### Advanced Examples\n\n```bash\n# Analyze different repository\nrepo-contextor /path/to/other/project -o other-project.md\n\n# Generate JSON for API consumption\nrepo-contextor . -f json -o api-context.json\n\n# Create YAML configuration\nrepo-contextor . -f yaml -o project-config.yaml\n\n# Generate files which are changed recently in 7 days\nrepo-contextor . -r --output recent-changes.txt\n\n```\n## Configuration via TOML\n\nRepo-Contextor supports configuration through a `.repo-contextor.toml` file in the current working directory.  \nThis file allows you to avoid typing the same CLI arguments every time.\n\nExample `.repo-contextor.toml`:\n\n```toml\n# Output file to write results\noutput = \"context.yaml\"\n\n# Output format: text, json, or yaml\nformat = \"yaml\"\n\n# Limit to files modified in the last 7 days\nrecent = true\n\n# Repository path to analyze (default = current directory)\npath = \".\"\n```\n### Rules\n- If the `.repo-contextor.toml` file is **missing**, the tool falls back to defaults.  \n- If the file is **present but invalid TOML**, the tool prints a clear error message and exits with status code 1.  \n- **Unknown keys** in the TOML file are ignored (safe for future extensions).  \n- **Precedence** of settings is:\n  1. Command-line arguments (highest priority)  \n  2. Values from `.repo-contextor.toml`  \n  3. Built-in defaults (lowest priority)\n     \n## Output Format\n\nThe tool generates a structured text file with the following sections:\n\n### 1. Repository Context Header\nProject path and identification\n\n### 2. Git Repository Information\n- Current branch\n- Latest commit SHA\n- Last commit author\n- Last commit date\n\n### 3. Summary Statistics\n- Total number of files processed\n- Total lines of code\n\n### 4. Directory Structure\nClean tree visualization showing project organization\n\n### 5. Recent Changes (if `--recent` is used)\n\n- Lists files modified in the last 7 days.\n- Shows relative file paths along with how long ago each file was modified\n- Helps focus on recently updated parts of the project.\n- Can be combined with `--output` or `--format` to save or change the output type.\n\n\n### 5. File Contents\nEach file's content with:\n- Clear file path headers\n- Appropriate syntax highlighting language tags\n- Complete file contents\n\n## Example Output\n\nWhen you run `repo-contextor .`, the output looks like this:\n\n````markdown\n# Repository Context: /path/to/your/project\n\n## Git Repository Information\n- **Branch**: main\n- **Commit**: a1b2c3d4e5f6789...\n- **Author**: John Doe <john@example.com>\n- **Date**: Fri Sep 12 14:30:15 2025\n\n## Summary\n- **Total Files**: 15\n- **Total Lines**: 1,247\n\n## Directory Structure\n```\n├── src/\n│   ├── main.py\n│   └── utils.py\n├── tests/\n│   └── test_main.py\n├── README.md\n└── requirements.txt\n```\n## Recent Changes\n- src/main.py (modified 2 days ago)\n- src/utils/helpers.py (modified 5 days ago)\n\n## File Contents\n\n### src/main.py\n\n```python\ndef main():\n    print(\"Hello, World!\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### README.md\n\n```markdown\n# My Project\nThis is a sample project.\n```\n\n## Summary\n- Total files: 15\n- Total lines: 1,247\n````\n\n## What Files Are Included\n\nThe tool includes most text files but automatically excludes:\n\n### Excluded Directories\n- `.git`, `.svn`, `.hg` (version control)\n- `__pycache__`, `.pytest_cache` (Python cache)\n- `node_modules`, `.venv`, `venv` (dependencies/environments)\n- `.vscode`, `.idea` (IDE directories)\n- `build`, `dist`, `target` (build directories)\n\n### File Handling Rules\n- **Text files**: All readable text files with common extensions\n- **Binary files**: Automatically detected and skipped\n- **Permission errors**: Skipped with graceful handling\n- **Configuration files**: Includes pyproject.toml, package.json, etc.\n\n### Included File Types\n- Source code: `.py`, `.js`, `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\n- Web files: `.html`, `.css`, `.scss`, `.vue`, `.jsx`, etc.\n- Documentation: `.md`, `.txt`, `.rst`\n- Configuration: `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\n- Scripts: `.sh`, `.bash`, `.zsh`\n\n## Error Handling\n\nThe tool handles errors gracefully:\n\n| Error Type | Behavior |\n|------------|----------|\n| **Permission errors** | Skipped with warning |\n| **Binary files** | Automatically detected and skipped |\n| **Invalid paths** | Clear error messages |\n| **Non-git repositories** | Works fine, shows \"Not a git repository\" |\n| **Unreadable files** | Marked as \"[Binary or unreadable file]\" |\n\n## Development\n\n### Project Structure\n\n```text\nRepo-Contextor/\n├── src/rcpack/              # Main package\n│   ├── __init__.py         # Package initialization\n│   ├── cli.py              # Command-line interface\n│   ├── discover.py         # File discovery logic\n│   ├── gitinfo.py          # Git repository analysis\n│   ├── treeview.py         # Directory tree generation\n│   ├── packager.py         # Main orchestration\n│   ├── io_utils.py         # File I/O utilities\n│   └── renderer/           # Output formatters\n│       ├── markdown.py     # Markdown renderer\n│       └── jsonyaml.py     # JSON/YAML renderers\n├── pyproject.toml          # Project configuration\n├── LICENSE                 # MIT License\n└── README.md              # This documentation\n```\n\n### Running Tests\n\n```bash\n# Test on current repository\nrepo-contextor . -o test-output.md\n\n# Test different formats\nrepo-contextor . -f json | head -20\nrepo-contextor . -f yaml | head -20\n\n# Test specific directory\nrepo-contextor src/ -o src-only.md\n```\n\n### Contributing\n\n1. **Fork the repository**\n2. **Clone your fork:**\n   ```bash\n   git clone https://github.com/yourusername/Repo-Contextor.git\n   cd Repo-Contextor\n   ```\n3. **Install for development:**\n   ```bash\n   python -m venv .venv\n   source .venv/bin/activate\n   pip install -e .\n   ```\n4. **Make your changes and test:**\n   ```bash\n   repo-contextor . -o test.md\n   ```\n5. **Submit a pull request**\n\n### Development Workflow\n\n```bash\n# 1. Setup development environment\ngit clone https://github.com/yourusername/Repo-Contextor.git\ncd Repo-Contextor\npython -m venv .venv\nsource .venv/bin/activate\npip install -e .\n\n# 2. Make changes to the code\n# Edit files in src/rcpack/\n\n# 3. Test your changes\nrepo-contextor . -o test-output.md\n\n# 4. Test different formats\nrepo-contextor . -f json -o test.json\nrepo-contextor . -f yaml -o test.yaml\n\n# 5. Commit and push changes\ngit add .\ngit commit -m \"Add new feature\"\ngit push origin feature-branch\n```\n\n## License\n\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\n\n## Why Repo-Contextor?\n\nThe name \"Repo-Contextor\" combines \"Repository\" + \"Context\" + \"or\", representing the tool's purpose of providing rich context about code repositories in a format that's perfect for LLM interactions.\n\n### Use Cases\n\n- **AI Assistance**: Get better help from ChatGPT, Claude, or GitHub Copilot\n- **Code Reviews**: Share complete project context with team members\n- **Documentation**: Create comprehensive project snapshots\n- **Onboarding**: Help new team members understand project structure\n- **Project Analysis**: Understand repository structure and dependencies\n\n### Perfect for LLMs\n\nThe output format is specifically designed to work well with Large Language Models:\n- Clear section headers for easy parsing\n- Syntax highlighting markers for code blocks\n- Structured metadata (git info, file locations)\n- Complete project context in a single file\n- Multiple output formats (Markdown, JSON, YAML)\n- Optimized for token efficiency\n",
    "pyproject.toml": "[build-system]\nrequires = [\"setuptools>=68\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"rcpack\"\nversion = \"0.1.0\"\ndescription = \"Repository Context Packager CLI for LLMs\"\nreadme = \"README.md\"\nrequires-python = \">=3.9\"\nlicense = { text = \"MIT\" }\ndependencies = [\n    \"PyYAML>=6.0\"\n]\n\n[project.scripts]\nrepo-contextor = \"rcpack.cli:main\"\n",
    "src/rcpack/__init__.py": "\"\"\"Repository Context Packager - CLI tool for creating LLM-optimized repository context.\"\"\"\n\n__version__ = \"0.1.0\"\n__author__ = \"Abhinav\"\n__description__ = \"Repository Context Packager CLI for LLMs\"",
    "src/rcpack/__main__.py": "#!/usr/bin/env python3\n\"\"\"Module entry point to enable `python -m rcpack`.\n\nThis simply delegates to the CLI's main() function.\n\"\"\"\n\nfrom .cli import main\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n",
    "src/rcpack/cli.py": "#!/usr/bin/env python3\n\"\"\"CLI for Repository Context Packager.\"\"\"\n\nfrom .config_loader import load_config\n\nimport argparse\nimport sys\nfrom pathlib import Path\nfrom .gitinfo import get_git_info\nfrom .discover import discover_files\nfrom .treeview import create_tree_view\nfrom .renderer.markdown import render_markdown\nfrom .renderer.jsonyaml import render_json, render_yaml\nfrom .io_utils import write_output\nfrom datetime import datetime, timedelta\n\n\ndef log_verbose(message: str, verbose: bool) -> None:\n    \"\"\"Log a message to stderr if verbose mode is enabled.\"\"\"\n    if verbose:\n        print(message, file=sys.stderr)\n\n\ndef get_rendered_content(format_type: str, repo_path: str, repo_info: dict, tree_text: str, \n                        files_data: dict, total_files: int, total_lines: int, \n                        recent_files_info: dict, file_sizes: dict) -> str:\n    \"\"\"Get rendered content based on the specified format.\"\"\"\n    if format_type == \"json\":\n        return render_json(\n            repo_path, repo_info, tree_text, \n            files_data, total_files, total_lines,\n            recent_files=recent_files_info,\n            file_sizes=file_sizes\n        )\n    elif format_type == \"yaml\":\n        return render_yaml(\n            repo_path, repo_info, tree_text, \n            files_data, total_files, total_lines,\n            recent_files=recent_files_info,\n            file_sizes=file_sizes\n        )\n    else:  # text/markdown\n        return render_markdown(\n            repo_path, repo_info, tree_text, \n            files_data, total_files, total_lines,\n            recent_files=recent_files_info,\n            file_sizes=file_sizes\n        )\n\n\ndef process_file(file_path: Path, repo_path: Path, verbose: bool) -> tuple[str, str, str]:\n    \"\"\"Process a single file and return its data.\n    \n    Returns:\n        tuple: (relative_path_str, content, file_size)\n    \"\"\"\n    relative_path = file_path.relative_to(repo_path)\n    relative_path_str = str(relative_path)\n    \n    log_verbose(f\"Reading file: {relative_path}\", verbose)\n    file_size = file_path.stat().st_size\n    \n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n        return relative_path_str, content, str(file_size)\n    except (UnicodeDecodeError, PermissionError):\n        log_verbose(f\"Skipping binary/unreadable file: {relative_path}\", verbose)\n        file_size = file_path.stat().st_size if file_path.exists() else 0\n        content = f\"[Binary or unreadable file: {file_path.name}]\"\n        return relative_path_str, content, str(file_size)\n    except Exception:\n        log_verbose(f\"Error reading file: {relative_path}\", verbose)\n        raise  # Re-raise to handle in calling code\n\n\ndef handle_output(content: str, output_path: str = None) -> None:\n    \"\"\"Handle output to either file or stdout.\"\"\"\n    if output_path:\n        # Write to file\n        write_output(output_path, content)\n        print(f\"Context package created: {output_path}\")\n    else:\n        # Output to stdout\n        print(content)\n\n\ndef main():\n    parser = argparse.ArgumentParser(\n        description=\"Package repository content for LLM context\"\n    )\n    parser.add_argument(\n        \"path\", \n        nargs=\"?\", \n        default=\".\", \n        help=\"Repository path (default: current directory)\"\n    )\n    parser.add_argument(\n        \"-o\", \"--output\", \n        help=\"Output file path (default: stdout)\"\n    )\n    parser.add_argument(\n        \"-f\", \"--format\", \n        choices=[\"text\", \"json\", \"yaml\"], \n        default=\"text\",\n        help=\"Output format (default: text)\"\n    )\n\n    \"\"\" This will read -r from the console and able to search it with this\"\"\"\n    parser.add_argument(\n    \"-r\", \"--recent\",\n    action=\"store_true\",\n    help=\"Include only files modified in the last 7 days\"\n    )\n    parser.add_argument(\n        \"-v\", \"--verbose\",\n        action=\"store_true\",\n        help=\"Print detailed progress information to stderr\"\n    )\n    \n    args = parser.parse_args()\n    \n    try:\n        repo_path = Path(args.path).resolve()\n        if not repo_path.exists():\n            print(f\"Error: Path {repo_path} does not exist\", file=sys.stderr)\n            sys.exit(1)\n            \n        # Get repository information\n        log_verbose(f\"Analyzing repository: {repo_path}\", args.verbose)\n        repo_info = get_git_info(repo_path)\n        \n        # Discover files\n        log_verbose(f\"Discovering files in: {repo_path}\", args.verbose)\n        discovered_files = discover_files([repo_path], repo_path, [], [])\n        log_verbose(f\"Found {len(discovered_files)} files\", args.verbose)\n        \n        # will check the file in last 7 days\n        recent_files_info = {}\n        if args.recent:\n            seven_days_ago = datetime.now() - timedelta(days=7)\n            recent_files = []\n            for f in discovered_files:\n                try:\n                    mtime = datetime.fromtimestamp(f.stat().st_mtime)\n                    if mtime >= seven_days_ago:\n                        recent_files.append(f)\n                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)     \n                except Exception:\n                    continue\n            discovered_files = recent_files\n        \n        # Read file contents\n        files_data = {}\n        file_sizes = {}\n        for file_path in discovered_files:\n            try:\n                relative_path_str, content, file_size = process_file(file_path, repo_path, args.verbose)\n                files_data[relative_path_str] = content\n                file_sizes[relative_path_str] = file_size\n            except Exception:\n                continue\n        \n        # Create tree view\n        log_verbose(\"Generating directory tree\", args.verbose)\n        tree_text = create_tree_view(repo_path, files_data)\n        \n        # Count totals\n        total_files = len(files_data)\n        total_lines = sum(len(content.splitlines()) for _, content in files_data.items())\n        \n        # Render based on format\n        log_verbose(f\"Rendering output in {args.format} format\", args.verbose)\n        content = get_rendered_content(\n            args.format, str(repo_path), repo_info, tree_text,\n            files_data, total_files, total_lines,\n            recent_files_info if args.recent else {},\n            file_sizes\n        )\n        \n        handle_output(content, args.output)\n        \n    except Exception as e:\n        print(f\"Error: {e}\", file=sys.stderr)\n        sys.exit(1)\n\n# this will convert age and give us the difference\ndef human_readable_age(mtime: datetime) -> str:\n    delta = datetime.now() - mtime\n    days = delta.days\n    seconds = delta.seconds\n    if days > 0:\n        return f\"{days} day{'s' if days != 1 else ''} ago\"\n    elif seconds >= 3600:\n        hours = seconds // 3600\n        return f\"{hours} hour{'s' if hours != 1 else ''} ago\"\n    elif seconds >= 60:\n        minutes = seconds // 60\n        return f\"{minutes} minute{'s' if minutes != 1 else ''} ago\"\n    else:\n        return \"just now\"\n\nif __name__ == \"__main__\":\n    main()\n",
    "src/rcpack/config_loader.py": "# src/rcpack/config_loader.py\n\"\"\"\nTOML config loader for Repo-Contextor.\n\nRules:\n- Look for .repo-contextor.toml in the CURRENT directory\n- If missing: ignore\n- If present but invalid: print a clear error and exit(1)\n- Only recognized keys are applied; unknown keys ignored\n- Precedence: CLI > TOML > DEFAULTS\n\"\"\"\nfrom __future__ import annotations\nimport os, sys\nfrom typing import Dict, Iterable, Any\n\ntry:\n    import tomllib\n    _loads = tomllib.loads\nexcept ModuleNotFoundError:\n    try:\n        import tomli\n        _loads = tomli.loads\n    except ModuleNotFoundError:\n        _loads = None\n\ndef _need_toml():\n    if _loads is None:\n        print(\"Error: TOML parser not available. Use Python 3.11+ or `pip install tomli`.\", file=sys.stderr)\n        sys.exit(1)\n\ndef _load_toml(dotfile: str) -> Dict[str, Any]:\n    _need_toml()\n    if not os.path.exists(dotfile):\n        return {}\n    try:\n        with open(dotfile, \"rb\") as f:\n            raw = f.read().decode(\"utf-8\", errors=\"strict\")\n        data = _loads(raw)\n        return data if isinstance(data, dict) else {}\n    except Exception as e:\n        print(f\"Error: failed to parse {dotfile} as TOML.\\n{e}\", file=sys.stderr)\n        sys.exit(1)\n\ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\n    ks = set(known)\n    return {k: v for k, v in d.items() if k in ks}\n\ndef _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\n    ks = set(known)\n    out: Dict[str, Any] = {k: defaults.get(k) for k in ks}\n    for src in (filecfg, clicfg):\n        for k, v in src.items():\n            if k in ks and v is not None:\n                out[k] = v\n    return out\n\ndef load_config(*, dotfile: str = \".repo-contextor.toml\", defaults: Dict[str, Any] | None = None, cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ()) -> Dict[str, Any]:\n    defaults = defaults or {}\n    cli_cfg = cli_cfg or {}\n    known = tuple(known_keys)\n    filecfg = _filter_known(_load_toml(dotfile), known)\n    return _merge(defaults, filecfg, cli_cfg, known)\n",
    "src/rcpack/discover.py": "\"\"\"File discovery module for repository analysis.\"\"\"\n\nfrom pathlib import Path\nfrom typing import List\nimport fnmatch\nfrom .utils import DEFAULT_INCLUDE_EXTENSIONS, ALWAYS_INCLUDE_FILE_NAMES, SKIP_DIRECTORY_NAMES\n\n\ndef discover_files(\n    inputs: List[Path],\n    root: Path,\n    include_patterns: List[str],\n    exclude_patterns: List[str],\n) -> List[Path]:\n    \"\"\"Discover relevant files.\n\n    - inputs: list of files/dirs to scan\n    - root: common project root; patterns are matched against POSIX paths relative to root\n    - include_patterns: glob patterns to include (if empty, use sensible defaults)\n    - exclude_patterns: glob patterns to exclude\n    Returns a list of absolute Paths to files.\n    \"\"\"\n\n    def matches_any(patterns: List[str], rel_posix: str) -> bool:\n        return any(fnmatch.fnmatch(rel_posix, pat) for pat in patterns)\n\n    def should_take(file_path: Path) -> bool:\n        rel_posix = file_path.relative_to(root).as_posix()\n        if exclude_patterns and matches_any(exclude_patterns, rel_posix):\n            return False\n        if include_patterns:\n            return matches_any(include_patterns, rel_posix)\n        # default include logic\n        return file_path.name in ALWAYS_INCLUDE_FILE_NAMES or file_path.suffix.lower() in DEFAULT_INCLUDE_EXTENSIONS\n\n    discovered: list[Path] = []\n    seen = set()\n\n    for item in inputs:\n        p = item.resolve()\n        if p.is_file():\n            # Skip if excluded or in skipped directory\n            if any(part in SKIP_DIRECTORY_NAMES for part in p.parts):\n                continue\n            if should_take(p):\n                key = p.as_posix()\n                if key not in seen:\n                    seen.add(key)\n                    discovered.append(p)\n        elif p.is_dir():\n            for child in p.rglob('*'):\n                if not child.is_file():\n                    continue\n                if any(part in SKIP_DIRECTORY_NAMES for part in child.parts):\n                    continue\n                if should_take(child):\n                    key = child.resolve().as_posix()\n                    if key not in seen:\n                        seen.add(key)\n                        discovered.append(child.resolve())\n\n    return sorted(discovered)",
    "src/rcpack/gitinfo.py": "from __future__ import annotations\n\nimport subprocess\nfrom pathlib import Path\nfrom typing import Dict, Any\n\n\ndef _git(cmd: list[str], cwd: Path) -> str:\n    # Validate git commands to prevent injection\n    allowed_commands = {\n        \"rev-parse\", \"show\", \"log\", \"status\", \"branch\", \"config\"\n    }\n    if not cmd or cmd[0] not in allowed_commands:\n        raise ValueError(f\"Git command not allowed: {cmd[0] if cmd else 'empty'}\")\n    \n    out = subprocess.check_output([\"git\", *cmd], cwd=str(cwd), timeout=30)\n    return out.decode(\"utf-8\", errors=\"replace\").strip()\n\n\ndef is_git_repo(path: Path) -> bool:\n    try:\n        flag = _git([\"rev-parse\", \"--is-inside-work-tree\"], cwd=path)\n        return flag == \"true\"\n    except Exception:\n        return False\n\n\ndef get_git_info(path: Path) -> Dict[str, Any]:\n    \"\"\"\n    Return info for the current HEAD of a repo rooted at `path`.\n    \"\"\"\n    try:\n        commit = _git([\"rev-parse\", \"HEAD\"], cwd=path)\n        branch = _git([\"rev-parse\", \"--abbrev-ref\", \"HEAD\"], cwd=path)\n        author = _git([\"show\", \"-s\", \"--format=%an <%ae>\"], cwd=path)\n        date = _git([\"show\", \"-s\", \"--date=local\", \"--format=%ad\"], cwd=path)\n        return {\n            \"is_repo\": True,\n            \"commit\": commit,\n            \"branch\": branch,\n            \"author\": author,\n            \"date\": date,\n            \"note\": None,\n        }\n    except Exception:\n        # treat as not a repo if anything fails\n        return {\n            \"is_repo\": False,\n            \"commit\": None,\n            \"branch\": None,\n            \"author\": None,\n            \"date\": None,\n            \"note\": \"Not a git repository\",\n        }\n",
    "src/rcpack/io_utils.py": "\"\"\"I/O utilities for file operations.\"\"\"\n\nfrom pathlib import Path\nfrom typing import Tuple\n\n\ndef write_output(output_path: str, content: str) -> None:\n    \"\"\"Write content to output file.\"\"\"\n    output_file = Path(output_path)\n    \n    # Create parent directories if they don't exist\n    output_file.parent.mkdir(parents=True, exist_ok=True)\n    \n    # Write content\n    with open(output_file, 'w', encoding='utf-8') as f:\n        f.write(content)\n\n\ndef is_binary_file(path: Path, sniff_bytes: int = 2048) -> bool:\n    \"\"\"Heuristically determine if a file is binary by scanning for NUL bytes.\"\"\"\n    try:\n        with open(path, 'rb') as fb:\n            chunk = fb.read(sniff_bytes)\n        if b\"\\x00\" in chunk:\n            return True\n        # If the chunk has a lot of non-text bytes, consider it binary\n        text_byte_count = sum(32 <= b <= 126 or b in (9, 10, 13) for b in chunk)\n        return (len(chunk) - text_byte_count) > max(1, len(chunk) // 3)\n    except Exception:\n        # If we cannot read, treat as binary to avoid further processing\n        return True\n\n\ndef read_text_safely(path: Path, max_bytes: int = 16_384) -> Tuple[str, str, bool]:\n    \"\"\"Read a text file safely with size limit and encoding fallbacks.\n\n    Returns (content, encoding_used, truncated).\n    \"\"\"\n    truncated = False\n    raw: bytes\n    with open(path, 'rb') as fb:\n        raw = fb.read(max_bytes + 1)\n    if len(raw) > max_bytes:\n        truncated = True\n        raw = raw[:max_bytes]\n\n    for enc in (\"utf-8\", \"utf-16\", \"utf-16-le\", \"utf-16-be\", \"latin-1\"):\n        try:\n            text = raw.decode(enc)\n            return text, enc, truncated\n        except Exception:\n            continue\n    # Fallback: replace errors with utf-8\n    text = raw.decode(\"utf-8\", errors=\"replace\")\n    return text, \"utf-8\", truncated",
    "src/rcpack/packager.py": "from __future__ import annotations\n\nimport sys\nfrom pathlib import Path\nfrom typing import Iterable, Tuple\n\nfrom rcpack.discover import discover_files\nfrom rcpack.gitinfo import get_git_info, is_git_repo\nfrom rcpack.io_utils import read_text_safely, is_binary_file\nfrom rcpack.renderer import markdown as md_renderer\nfrom rcpack.renderer.jsonyaml import render_json, render_yaml\nfrom rcpack.treeview import render_tree\nfrom rcpack.utils import get_language_from_extension\n\n\ndef _find_root(inputs: list[str]) -> Path:\n    paths = [Path(p) for p in inputs]\n    if len(paths) == 1 and Path(paths[0]).is_dir():\n        return paths[0].resolve()\n    parents = [p if p.is_dir() else p.parent for p in paths]\n    root = Path(*Path.commonpath([str(p.resolve()) for p in parents]).split(\"/\"))\n    return root.resolve()\n\n\ndef build_package(\n    inputs: list[str],\n    include_patterns: list[str] | None,\n    exclude_patterns: list[str] | None,\n    max_file_bytes: int,\n    fmt: str = \"markdown\",\n) -> Tuple[str, dict]:\n    root = _find_root(inputs)\n    root_abs = root.resolve()\n\n    repo_info = (\n        get_git_info(root_abs) if is_git_repo(root_abs) else {\n            \"is_repo\": False,\n            \"commit\": None,\n            \"branch\": None,\n            \"author\": None,\n            \"date\": None,\n            \"note\": \"Not a git repository\",\n        }\n    )\n\n    files = discover_files(\n        inputs=[Path(p) for p in inputs],\n        root=root_abs,\n        include_patterns=include_patterns or [],\n        exclude_patterns=exclude_patterns or [],\n    )\n    rel_files = [f.relative_to(root_abs) for f in files]\n\n    project_tree = render_tree([p.as_posix() for p in rel_files])\n\n    file_sections: list[dict] = []\n    total_lines = 0\n    total_chars = 0\n\n    for f in files:\n        rel = f.relative_to(root_abs).as_posix()\n        try:\n            if is_binary_file(f):\n                content = f\"[binary file skipped: {f.name}, {f.stat().st_size} bytes]\"\n                file_sections.append({\n                    \"path\": rel,\n                    \"language\": get_language_from_extension(f.suffix),\n                    \"content\": content,\n                    \"is_truncated\": False,\n                })\n                total_chars += len(content)\n                continue\n\n            content, used_encoding, truncated = read_text_safely(f, max_bytes=max_file_bytes)\n            total_lines += content.count(\"\\n\") + (1 if content and not content.endswith(\"\\n\") else 0)\n            total_chars += len(content)\n\n            if truncated:\n                note = f\"\\n\\n[... TRUNCATED to first {max_file_bytes} bytes ...]\"\n                content = content + note\n                total_chars += len(note)\n\n            file_sections.append({\n                \"path\": rel,\n                \"language\": get_language_from_extension(f.suffix),\n                \"content\": content,\n                \"is_truncated\": truncated,\n            })\n        except Exception as exc:\n            print(f\"[rcpack] error reading {rel}: {exc}\", file=sys.stderr)\n            continue\n\n    # render in chosen format\n    if fmt == \"markdown\":\n        out_text = md_renderer.render_markdown(\n            root=str(root_abs),\n            repo_info=repo_info,\n            tree_text=project_tree,\n            files=file_sections,\n            total_files=len(file_sections),\n            total_lines=total_lines,\n        )\n    elif fmt == \"json\":\n        out_text = render_json(\n            root=str(root_abs),\n            repo_info=repo_info,\n            tree_text=project_tree,\n            files=file_sections,\n            total_files=len(file_sections),\n            total_lines=total_lines,\n        )\n    elif fmt == \"yaml\":\n        out_text = render_yaml(\n            root=str(root_abs),\n            repo_info=repo_info,\n            tree_text=project_tree,\n            files=file_sections,\n            total_files=len(file_sections),\n            total_lines=total_lines,\n        )\n    else:\n        raise ValueError(f\"Unsupported format: {fmt}\")\n\n    stats = {\"files\": len(file_sections), \"lines\": total_lines, \"chars\": total_chars}\n    return out_text, stats\n",
    "src/rcpack/renderer/jsonyaml.py": "from __future__ import annotations\nimport json\nfrom ..utils import build_repository_data\n\ntry:\n    import yaml\nexcept ImportError:\n    yaml = None\n\n\ndef render_json(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\n    data = build_repository_data(\n        root=root,\n        repo_info=repo_info,\n        tree_text=tree_text,\n        files=files,\n        total_files=total_files,\n        total_lines=total_lines,\n        recent_files=recent_files,\n        file_sizes=file_sizes\n    )\n    return json.dumps(data, indent=2, ensure_ascii=False)\n\n\ndef render_yaml(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\n    if yaml is None:\n        raise RuntimeError(\"PyYAML not installed; run `pip install pyyaml`\")\n    data = build_repository_data(\n        root=root,\n        repo_info=repo_info,\n        tree_text=tree_text,\n        files=files,\n        total_files=total_files,\n        total_lines=total_lines,\n        recent_files=recent_files,\n        file_sizes=file_sizes\n    )\n    return yaml.safe_dump(data, sort_keys=False, allow_unicode=True)\n",
    "src/rcpack/renderer/markdown.py": "\"\"\"Markdown renderer for repository context.\"\"\"\n\nfrom typing import Dict, Any\nfrom ..utils import get_language_from_extension\n\n\ndef render_markdown(root: str, repo_info: Dict[str, Any], tree_text: str, \n                   files: Dict[str, str], total_files: int, total_lines: int, recent_files=None, file_sizes=None) -> str:\n    \"\"\"Render repository context as markdown.\"\"\"\n    \n    lines = []\n    \n    # Header\n    lines.append(f\"# Repository Context: {root}\")\n    lines.append(\"\")\n    \n    # Repository info\n    if repo_info.get(\"is_repo\"):\n        lines.append(\"## Git Repository Information\")\n        lines.append(f\"- **Branch**: {repo_info.get('branch', 'N/A')}\")\n        lines.append(f\"- **Commit**: {repo_info.get('commit', 'N/A')}\")\n        lines.append(f\"- **Author**: {repo_info.get('author', 'N/A')}\")\n        lines.append(f\"- **Date**: {repo_info.get('date', 'N/A')}\")\n    else:\n        lines.append(\"## Repository Information\")\n        lines.append(f\"- **Note**: {repo_info.get('note', 'Not a git repository')}\")\n    lines.append(\"\")\n    \n    # Summary\n    lines.append(\"## Summary\")\n    lines.append(f\"- **Total Files**: {total_files}\")\n    lines.append(f\"- **Total Lines**: {total_lines}\")\n    lines.append(\"\")\n    \n    # Directory structure\n    lines.append(\"## Directory Structure\")\n    lines.append(\"```\")\n    lines.append(tree_text)\n    lines.append(\"```\")\n    lines.append(\"\")\n\n    # will produce recent files \n    # Recent files (fixed)\n    if recent_files:\n        lines.append(\"## Recent Changes\")\n        for file, age in recent_files.items():\n            lines.append(f\"- {file} (modified {age})\")\n        lines.append(\"\")\n    \n    # File contents\n    lines.append(\"## File Contents\")\n    lines.append(\"\")\n    \n    for file_path, content in sorted(files.items()):\n        if file_sizes and file_path in file_sizes:\n            size_bytes = file_sizes[file_path]\n            lines.append(f\"### {file_path} ({size_bytes} bytes)\")\n        else:\n            lines.append(f\"### {file_path}\")\n        lines.append(\"\")\n        \n        # Detect language for syntax highlighting\n        language = get_language_from_extension(file_path)\n        \n        lines.append(f\"```{language}\")\n        lines.append(content)\n        lines.append(\"```\")\n        lines.append(\"\")\n    \n    return \"\\n\".join(lines)\n",
    "src/rcpack/treeview.py": "\"\"\"Tree view generation for repository structure.\"\"\"\n\nfrom pathlib import Path\nfrom typing import Dict, List\n\n\ndef create_tree_view(repo_path: Path, files_data: Dict[str, str]) -> str:\n    \"\"\"Create a tree view of the repository structure.\"\"\"\n    paths = list(files_data.keys())\n    return render_tree(paths)\n\n\ndef render_tree(paths: List[str]) -> str:\n    \"\"\"Render a tree view from a list of relative POSIX paths.\"\"\"\n    tree_structure: dict = {}\n\n    for p in paths:\n        parts = Path(p).parts\n        current = tree_structure\n        for part in parts[:-1]:\n            if part not in current:\n                current[part] = {}\n            current = current[part]\n        if parts:\n            current[parts[-1]] = None\n\n    def _render(structure: dict, prefix: str = \"\") -> str:\n        lines = []\n        items = sorted(structure.items(), key=lambda x: (x[1] is None, x[0]))\n        for i, (name, subtree) in enumerate(items):\n            is_last = i == len(items) - 1\n            lines.append(f\"{prefix}{'└── ' if is_last else '├── '}{name}\")\n            if subtree is not None:\n                extension = (\"    \" if is_last else \"│   \")\n                lines.append(_render(subtree, prefix + extension))\n        return \"\\n\".join(filter(None, lines))\n\n    if not tree_structure:\n        return \"No files found\"\n    return _render(tree_structure)",
    "src/rcpack/utils.py": "\"\"\"Utility functions shared across the rcpack package.\"\"\"\n\nfrom typing import Dict, Any, Optional, Set\n\n\n# Shared constants for file discovery and processing\nDEFAULT_INCLUDE_EXTENSIONS = {\n    '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\n    '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\n    '.html', '.css', '.scss', '.sass', '.less', '.vue', '.svelte',\n    '.md', '.txt', '.rst', '.yaml', '.yml', '.json', '.toml', '.ini',\n    '.cfg', '.conf', '.xml', '.sql', '.sh', '.bash', '.zsh', '.fish',\n}\n\nALWAYS_INCLUDE_FILE_NAMES = {\n    'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING', 'Makefile',\n    'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\n    'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\n}\n\nSKIP_DIRECTORY_NAMES = {\n    '.git', '.svn', '.hg', '__pycache__', '.pytest_cache',\n    'node_modules', '.venv', 'venv', 'env', '.env',\n    'build', 'dist', 'target', 'out', '.next', '.nuxt',\n    '.idea', '.vscode', '.vs', 'coverage', '.coverage'\n}\n\n\ndef get_language_from_extension(file_path_or_ext: str) -> str:\n    \"\"\"Get the language identifier for syntax highlighting from a file path or extension.\n    \n    Args:\n        file_path_or_ext: Either a file path (e.g., 'src/main.py') or extension (e.g., '.py' or 'py')\n    \n    Returns:\n        Language identifier for syntax highlighting (e.g., 'python', 'javascript')\n    \"\"\"\n    # Extract extension from file path if needed\n    if '.' in file_path_or_ext and not file_path_or_ext.startswith('.'):\n        # It's a file path, extract the extension\n        ext = file_path_or_ext.split('.')[-1].lower()\n    else:\n        # It's already an extension, clean it up\n        ext = file_path_or_ext.lower().lstrip(\".\")\n    \n    # Comprehensive language mapping combining both existing mappings\n    language_map = {\n        'py': 'python', 'js': 'javascript', 'ts': 'typescript',\n        'jsx': 'javascript', 'tsx': 'typescript',\n        'java': 'java', 'cpp': 'cpp', 'c': 'c', 'h': 'c',\n        'cs': 'csharp', 'php': 'php', 'rb': 'ruby',\n        'go': 'go', 'rs': 'rust', 'swift': 'swift', 'kt': 'kotlin',\n        'html': 'html', 'css': 'css', 'scss': 'scss', 'sass': 'sass',\n        'json': 'json', 'yaml': 'yaml', 'yml': 'yaml',\n        'toml': 'toml', 'xml': 'xml', 'sql': 'sql', 'sh': 'bash',\n        'bash': 'bash', 'zsh': 'bash', 'fish': 'fish',\n        'md': 'markdown', 'txt': 'text',\n        'dockerfile': 'dockerfile', 'makefile': 'makefile'\n    }\n    \n    return language_map.get(ext, '')\n\n\ndef build_repository_data(\n    root: str,\n    repo_info: Dict[str, Any],\n    tree_text: str,\n    files: Dict[str, str],\n    total_files: int,\n    total_lines: int,\n    recent_files: Optional[Dict[str, str]] = None,\n    file_sizes: Optional[Dict[str, str]] = None\n) -> Dict[str, Any]:\n    \"\"\"Build the standard repository data structure used by all renderers.\n    \n    Args:\n        root: Repository root path\n        repo_info: Git repository information\n        tree_text: Directory tree text representation\n        files: Dictionary of file paths to content\n        total_files: Total number of files\n        total_lines: Total number of lines\n        recent_files: Optional dict of recently modified files\n        file_sizes: Optional dict of file sizes\n        \n    Returns:\n        Standardized data dictionary for rendering\n    \"\"\"\n    return {\n        \"root\": root,\n        \"repo_info\": repo_info,\n        \"structure\": tree_text,\n        \"recent_changes\": recent_files or {},\n        \"files\": files,\n        \"file_sizes\": file_sizes or {},\n        \"summary\": {\"total_files\": total_files, \"total_lines\": total_lines},\n    }\n\n\ndef calculate_total_lines(content_dict: Dict[str, str]) -> int:\n    \"\"\"Calculate the total number of lines from a dictionary of file contents.\n    \n    Args:\n        content_dict: Dictionary mapping file paths to their content\n        \n    Returns:\n        Total number of lines across all files\n    \"\"\"\n    return sum(len(content.splitlines()) for content in content_dict.values())\n\n\ndef calculate_total_characters(content_dict: Dict[str, str]) -> int:\n    \"\"\"Calculate the total number of characters from a dictionary of file contents.\n    \n    Args:\n        content_dict: Dictionary mapping file paths to their content\n        \n    Returns:\n        Total number of characters across all files\n    \"\"\"\n    return sum(len(content) for content in content_dict.values())",
    "test-iteration2.json": "{\n  \"root\": \"/Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\",\n  \"repo_info\": {\n    \"is_repo\": true,\n    \"commit\": \"57f0f88ec3d11a89d5ca08ee4fb5b9b561c1b8aa\",\n    \"branch\": \"refactoring\",\n    \"author\": \"Abhinav <abhinavbhardwaj2002@gmail.com>\",\n    \"date\": \"Fri Oct 10 19:19:52 2025\",\n    \"note\": null\n  },\n  \"structure\": \"├── src\\n│   └── rcpack\\n│       ├── renderer\\n│       │   ├── jsonyaml.py\\n│       │   └── markdown.py\\n│       ├── __init__.py\\n│       ├── __main__.py\\n│       ├── cli.py\\n│       ├── config_loader.py\\n│       ├── discover.py\\n│       ├── gitinfo.py\\n│       ├── io_utils.py\\n│       ├── packager.py\\n│       ├── treeview.py\\n│       └── utils.py\\n├── LICENSE\\n├── README.md\\n├── pyproject.toml\\n├── test-output.json\\n└── test-yaml.yaml\",\n  \"recent_changes\": {},\n  \"files\": {\n    \"LICENSE\": \"MIT License\\n\\nCopyright (c) 2025 Abhinav\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \\\"Software\\\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \\\"AS IS\\\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n\",\n    \"README.md\": \"# Repo-Contextor\\n\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\n\\nA powerful Repository Context Packager CLI tool that analyzes local git repositories and creates comprehensive text files containing repository content optimized for sharing with Large Language Models (LLMs).\\n\\n## Overview\\n\\nWhen developers want to get help from ChatGPT, Claude, or other LLMs about their code, they often struggle with how to share their codebase effectively. Common problems include:\\n\\n- **Lost Context**: Copy-pasting individual files loses important project structure and relationships\\n- **Missing Dependencies**: LLMs can't see how files connect or what libraries are used\\n- **Incomplete Picture**: Hard to convey the overall architecture and organization\\n- **Manual Work**: Time-consuming to gather and format relevant code\\n\\n**Repo-Contextor** solves this by automatically collecting and formatting repository content into a single, well-structured text file that provides rich context to LLMs, enabling them to give much better assistance with your code.\\n\\n## Features\\n\\n- **Git Integration**: Extracts commit SHA, branch, author, and date information\\n- **Project Structure**: Generates a clear directory tree visualization\\n- **File Content Packaging**: Includes file contents with syntax highlighting\\n- **Smart File Discovery**: Recursively scans directories with intelligent filtering\\n- **Binary File Detection**: Automatically skips binary files\\n- **Error Handling**: Gracefully handles permission errors and provides helpful messages\\n- **Multiple Output Formats**: Supports Markdown, JSON, and YAML formats\\n- **Flexible Output**: Write to stdout or save to a file\\n- **Recent Changes Filter**: Give the files which are updated in last 7days with the time when it was recently modified.\\n\\n## Installation\\n\\n### Prerequisites\\n\\n- Python 3.9 or higher\\n- Git (for git repository analysis)\\n\\n### For End Users\\n\\n```bash\\n# Clone and install\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\ncd Repo-Contextor\\npip install -e .\\n```\\n\\n### For Contributors & Local Development\\n\\n```bash\\n# Clone the repository\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\ncd Repo-Contextor\\n\\n# Create virtual environment\\npython -m venv .venv\\nsource .venv/bin/activate  # On Windows: .venv\\\\Scripts\\\\activate\\n\\n# Install in development mode\\npip install -e .\\n```\\n\\n## Usage\\n\\n### Basic Examples\\n\\n```bash\\n# Package current directory to terminal\\nrepo-contextor .\\n\\n# Package a specific directory\\nrepo-contextor /path/to/your/project\\n\\n# Save output to a file\\nrepo-contextor . -o my-project-context.md\\n\\n# Generate JSON format\\nrepo-contextor . -f json -o context.json\\n\\n# Generate YAML format\\nrepo-contextor . -f yaml -o context.yaml\\n\\n# Include only files modified in the last 7 days\\nrepo-contextor . --recent\\n\\n# Combine with output file\\nrepo-contextor . --recent -o recent-changes.md\\n```\\n\\n### Command Line Options\\n\\n| Option | Short | Description | Example |\\n|--------|-------|-------------|---------|\\n| `path` | - | Repository path to analyze (default: current directory) | `repo-contextor /path/to/project` |\\n| `--output` | `-o` | Output file path (default: stdout) | `-o context.md` |\\n| `--format` | `-f` | Output format: text, json, yaml (default: text) | `-f json` |\\n| `--help` | `-h` | Show help message | `-h` |\\n| `--recent`  | `-r`  | Include only files modified in the last 7 days    | `repo-contextor . -r -o recent.md` |\\n\\n### Advanced Examples\\n\\n```bash\\n# Analyze different repository\\nrepo-contextor /path/to/other/project -o other-project.md\\n\\n# Generate JSON for API consumption\\nrepo-contextor . -f json -o api-context.json\\n\\n# Create YAML configuration\\nrepo-contextor . -f yaml -o project-config.yaml\\n\\n# Generate files which are changed recently in 7 days\\nrepo-contextor . -r --output recent-changes.txt\\n\\n```\\n## Configuration via TOML\\n\\nRepo-Contextor supports configuration through a `.repo-contextor.toml` file in the current working directory.  \\nThis file allows you to avoid typing the same CLI arguments every time.\\n\\nExample `.repo-contextor.toml`:\\n\\n```toml\\n# Output file to write results\\noutput = \\\"context.yaml\\\"\\n\\n# Output format: text, json, or yaml\\nformat = \\\"yaml\\\"\\n\\n# Limit to files modified in the last 7 days\\nrecent = true\\n\\n# Repository path to analyze (default = current directory)\\npath = \\\".\\\"\\n```\\n### Rules\\n- If the `.repo-contextor.toml` file is **missing**, the tool falls back to defaults.  \\n- If the file is **present but invalid TOML**, the tool prints a clear error message and exits with status code 1.  \\n- **Unknown keys** in the TOML file are ignored (safe for future extensions).  \\n- **Precedence** of settings is:\\n  1. Command-line arguments (highest priority)  \\n  2. Values from `.repo-contextor.toml`  \\n  3. Built-in defaults (lowest priority)\\n     \\n## Output Format\\n\\nThe tool generates a structured text file with the following sections:\\n\\n### 1. Repository Context Header\\nProject path and identification\\n\\n### 2. Git Repository Information\\n- Current branch\\n- Latest commit SHA\\n- Last commit author\\n- Last commit date\\n\\n### 3. Summary Statistics\\n- Total number of files processed\\n- Total lines of code\\n\\n### 4. Directory Structure\\nClean tree visualization showing project organization\\n\\n### 5. Recent Changes (if `--recent` is used)\\n\\n- Lists files modified in the last 7 days.\\n- Shows relative file paths along with how long ago each file was modified\\n- Helps focus on recently updated parts of the project.\\n- Can be combined with `--output` or `--format` to save or change the output type.\\n\\n\\n### 5. File Contents\\nEach file's content with:\\n- Clear file path headers\\n- Appropriate syntax highlighting language tags\\n- Complete file contents\\n\\n## Example Output\\n\\nWhen you run `repo-contextor .`, the output looks like this:\\n\\n````markdown\\n# Repository Context: /path/to/your/project\\n\\n## Git Repository Information\\n- **Branch**: main\\n- **Commit**: a1b2c3d4e5f6789...\\n- **Author**: John Doe <john@example.com>\\n- **Date**: Fri Sep 12 14:30:15 2025\\n\\n## Summary\\n- **Total Files**: 15\\n- **Total Lines**: 1,247\\n\\n## Directory Structure\\n```\\n├── src/\\n│   ├── main.py\\n│   └── utils.py\\n├── tests/\\n│   └── test_main.py\\n├── README.md\\n└── requirements.txt\\n```\\n## Recent Changes\\n- src/main.py (modified 2 days ago)\\n- src/utils/helpers.py (modified 5 days ago)\\n\\n## File Contents\\n\\n### src/main.py\\n\\n```python\\ndef main():\\n    print(\\\"Hello, World!\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n```\\n\\n### README.md\\n\\n```markdown\\n# My Project\\nThis is a sample project.\\n```\\n\\n## Summary\\n- Total files: 15\\n- Total lines: 1,247\\n````\\n\\n## What Files Are Included\\n\\nThe tool includes most text files but automatically excludes:\\n\\n### Excluded Directories\\n- `.git`, `.svn`, `.hg` (version control)\\n- `__pycache__`, `.pytest_cache` (Python cache)\\n- `node_modules`, `.venv`, `venv` (dependencies/environments)\\n- `.vscode`, `.idea` (IDE directories)\\n- `build`, `dist`, `target` (build directories)\\n\\n### File Handling Rules\\n- **Text files**: All readable text files with common extensions\\n- **Binary files**: Automatically detected and skipped\\n- **Permission errors**: Skipped with graceful handling\\n- **Configuration files**: Includes pyproject.toml, package.json, etc.\\n\\n### Included File Types\\n- Source code: `.py`, `.js`, `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\n- Web files: `.html`, `.css`, `.scss`, `.vue`, `.jsx`, etc.\\n- Documentation: `.md`, `.txt`, `.rst`\\n- Configuration: `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\n- Scripts: `.sh`, `.bash`, `.zsh`\\n\\n## Error Handling\\n\\nThe tool handles errors gracefully:\\n\\n| Error Type | Behavior |\\n|------------|----------|\\n| **Permission errors** | Skipped with warning |\\n| **Binary files** | Automatically detected and skipped |\\n| **Invalid paths** | Clear error messages |\\n| **Non-git repositories** | Works fine, shows \\\"Not a git repository\\\" |\\n| **Unreadable files** | Marked as \\\"[Binary or unreadable file]\\\" |\\n\\n## Development\\n\\n### Project Structure\\n\\n```text\\nRepo-Contextor/\\n├── src/rcpack/              # Main package\\n│   ├── __init__.py         # Package initialization\\n│   ├── cli.py              # Command-line interface\\n│   ├── discover.py         # File discovery logic\\n│   ├── gitinfo.py          # Git repository analysis\\n│   ├── treeview.py         # Directory tree generation\\n│   ├── packager.py         # Main orchestration\\n│   ├── io_utils.py         # File I/O utilities\\n│   └── renderer/           # Output formatters\\n│       ├── markdown.py     # Markdown renderer\\n│       └── jsonyaml.py     # JSON/YAML renderers\\n├── pyproject.toml          # Project configuration\\n├── LICENSE                 # MIT License\\n└── README.md              # This documentation\\n```\\n\\n### Running Tests\\n\\n```bash\\n# Test on current repository\\nrepo-contextor . -o test-output.md\\n\\n# Test different formats\\nrepo-contextor . -f json | head -20\\nrepo-contextor . -f yaml | head -20\\n\\n# Test specific directory\\nrepo-contextor src/ -o src-only.md\\n```\\n\\n### Contributing\\n\\n1. **Fork the repository**\\n2. **Clone your fork:**\\n   ```bash\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\n   cd Repo-Contextor\\n   ```\\n3. **Install for development:**\\n   ```bash\\n   python -m venv .venv\\n   source .venv/bin/activate\\n   pip install -e .\\n   ```\\n4. **Make your changes and test:**\\n   ```bash\\n   repo-contextor . -o test.md\\n   ```\\n5. **Submit a pull request**\\n\\n### Development Workflow\\n\\n```bash\\n# 1. Setup development environment\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\ncd Repo-Contextor\\npython -m venv .venv\\nsource .venv/bin/activate\\npip install -e .\\n\\n# 2. Make changes to the code\\n# Edit files in src/rcpack/\\n\\n# 3. Test your changes\\nrepo-contextor . -o test-output.md\\n\\n# 4. Test different formats\\nrepo-contextor . -f json -o test.json\\nrepo-contextor . -f yaml -o test.yaml\\n\\n# 5. Commit and push changes\\ngit add .\\ngit commit -m \\\"Add new feature\\\"\\ngit push origin feature-branch\\n```\\n\\n## License\\n\\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\\n\\n## Why Repo-Contextor?\\n\\nThe name \\\"Repo-Contextor\\\" combines \\\"Repository\\\" + \\\"Context\\\" + \\\"or\\\", representing the tool's purpose of providing rich context about code repositories in a format that's perfect for LLM interactions.\\n\\n### Use Cases\\n\\n- **AI Assistance**: Get better help from ChatGPT, Claude, or GitHub Copilot\\n- **Code Reviews**: Share complete project context with team members\\n- **Documentation**: Create comprehensive project snapshots\\n- **Onboarding**: Help new team members understand project structure\\n- **Project Analysis**: Understand repository structure and dependencies\\n\\n### Perfect for LLMs\\n\\nThe output format is specifically designed to work well with Large Language Models:\\n- Clear section headers for easy parsing\\n- Syntax highlighting markers for code blocks\\n- Structured metadata (git info, file locations)\\n- Complete project context in a single file\\n- Multiple output formats (Markdown, JSON, YAML)\\n- Optimized for token efficiency\\n\",\n    \"pyproject.toml\": \"[build-system]\\nrequires = [\\\"setuptools>=68\\\", \\\"wheel\\\"]\\nbuild-backend = \\\"setuptools.build_meta\\\"\\n\\n[project]\\nname = \\\"rcpack\\\"\\nversion = \\\"0.1.0\\\"\\ndescription = \\\"Repository Context Packager CLI for LLMs\\\"\\nreadme = \\\"README.md\\\"\\nrequires-python = \\\">=3.9\\\"\\nlicense = { text = \\\"MIT\\\" }\\ndependencies = [\\n    \\\"PyYAML>=6.0\\\"\\n]\\n\\n[project.scripts]\\nrepo-contextor = \\\"rcpack.cli:main\\\"\\n\",\n    \"src/rcpack/__init__.py\": \"\\\"\\\"\\\"Repository Context Packager - CLI tool for creating LLM-optimized repository context.\\\"\\\"\\\"\\n\\n__version__ = \\\"0.1.0\\\"\\n__author__ = \\\"Abhinav\\\"\\n__description__ = \\\"Repository Context Packager CLI for LLMs\\\"\",\n    \"src/rcpack/__main__.py\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"Module entry point to enable `python -m rcpack`.\\n\\nThis simply delegates to the CLI's main() function.\\n\\\"\\\"\\\"\\n\\nfrom .cli import main\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\\n\\n\",\n    \"src/rcpack/cli.py\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"CLI for Repository Context Packager.\\\"\\\"\\\"\\n\\nfrom .config_loader import load_config\\n\\nimport argparse\\nimport sys\\nfrom pathlib import Path\\nfrom .gitinfo import get_git_info\\nfrom .discover import discover_files\\nfrom .treeview import create_tree_view\\nfrom .renderer.markdown import render_markdown\\nfrom .renderer.jsonyaml import render_json, render_yaml\\nfrom .io_utils import write_output\\nfrom datetime import datetime, timedelta\\n\\n\\ndef log_verbose(message: str, verbose: bool) -> None:\\n    \\\"\\\"\\\"Log a message to stderr if verbose mode is enabled.\\\"\\\"\\\"\\n    if verbose:\\n        print(message, file=sys.stderr)\\n\\n\\ndef get_rendered_content(format_type: str, repo_path: str, repo_info: dict, tree_text: str, \\n                        files_data: dict, total_files: int, total_lines: int, \\n                        recent_files_info: dict, file_sizes: dict) -> str:\\n    \\\"\\\"\\\"Get rendered content based on the specified format.\\\"\\\"\\\"\\n    if format_type == \\\"json\\\":\\n        return render_json(\\n            repo_path, repo_info, tree_text, \\n            files_data, total_files, total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n        )\\n    elif format_type == \\\"yaml\\\":\\n        return render_yaml(\\n            repo_path, repo_info, tree_text, \\n            files_data, total_files, total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n        )\\n    else:  # text/markdown\\n        return render_markdown(\\n            repo_path, repo_info, tree_text, \\n            files_data, total_files, total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n        )\\n\\n\\ndef process_file(file_path: Path, repo_path: Path, verbose: bool) -> tuple[str, str, str]:\\n    \\\"\\\"\\\"Process a single file and return its data.\\n    \\n    Returns:\\n        tuple: (relative_path_str, content, file_size)\\n    \\\"\\\"\\\"\\n    relative_path = file_path.relative_to(repo_path)\\n    relative_path_str = str(relative_path)\\n    \\n    log_verbose(f\\\"Reading file: {relative_path}\\\", verbose)\\n    file_size = file_path.stat().st_size\\n    \\n    try:\\n        with open(file_path, 'r', encoding='utf-8') as f:\\n            content = f.read()\\n        return relative_path_str, content, str(file_size)\\n    except (UnicodeDecodeError, PermissionError):\\n        log_verbose(f\\\"Skipping binary/unreadable file: {relative_path}\\\", verbose)\\n        file_size = file_path.stat().st_size if file_path.exists() else 0\\n        content = f\\\"[Binary or unreadable file: {file_path.name}]\\\"\\n        return relative_path_str, content, str(file_size)\\n    except Exception:\\n        log_verbose(f\\\"Error reading file: {relative_path}\\\", verbose)\\n        raise  # Re-raise to handle in calling code\\n\\n\\ndef handle_output(content: str, output_path: str = None) -> None:\\n    \\\"\\\"\\\"Handle output to either file or stdout.\\\"\\\"\\\"\\n    if output_path:\\n        # Write to file\\n        write_output(output_path, content)\\n        print(f\\\"Context package created: {output_path}\\\")\\n    else:\\n        # Output to stdout\\n        print(content)\\n\\n\\ndef main():\\n    parser = argparse.ArgumentParser(\\n        description=\\\"Package repository content for LLM context\\\"\\n    )\\n    parser.add_argument(\\n        \\\"path\\\", \\n        nargs=\\\"?\\\", \\n        default=\\\".\\\", \\n        help=\\\"Repository path (default: current directory)\\\"\\n    )\\n    parser.add_argument(\\n        \\\"-o\\\", \\\"--output\\\", \\n        help=\\\"Output file path (default: stdout)\\\"\\n    )\\n    parser.add_argument(\\n        \\\"-f\\\", \\\"--format\\\", \\n        choices=[\\\"text\\\", \\\"json\\\", \\\"yaml\\\"], \\n        default=\\\"text\\\",\\n        help=\\\"Output format (default: text)\\\"\\n    )\\n\\n    \\\"\\\"\\\" This will read -r from the console and able to search it with this\\\"\\\"\\\"\\n    parser.add_argument(\\n    \\\"-r\\\", \\\"--recent\\\",\\n    action=\\\"store_true\\\",\\n    help=\\\"Include only files modified in the last 7 days\\\"\\n    )\\n    parser.add_argument(\\n        \\\"-v\\\", \\\"--verbose\\\",\\n        action=\\\"store_true\\\",\\n        help=\\\"Print detailed progress information to stderr\\\"\\n    )\\n    \\n    args = parser.parse_args()\\n    \\n    try:\\n        repo_path = Path(args.path).resolve()\\n        if not repo_path.exists():\\n            print(f\\\"Error: Path {repo_path} does not exist\\\", file=sys.stderr)\\n            sys.exit(1)\\n            \\n        # Get repository information\\n        log_verbose(f\\\"Analyzing repository: {repo_path}\\\", args.verbose)\\n        repo_info = get_git_info(repo_path)\\n        \\n        # Discover files\\n        log_verbose(f\\\"Discovering files in: {repo_path}\\\", args.verbose)\\n        discovered_files = discover_files([repo_path], repo_path, [], [])\\n        log_verbose(f\\\"Found {len(discovered_files)} files\\\", args.verbose)\\n        \\n        # will check the file in last 7 days\\n        recent_files_info = {}\\n        if args.recent:\\n            seven_days_ago = datetime.now() - timedelta(days=7)\\n            recent_files = []\\n            for f in discovered_files:\\n                try:\\n                    mtime = datetime.fromtimestamp(f.stat().st_mtime)\\n                    if mtime >= seven_days_ago:\\n                        recent_files.append(f)\\n                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)     \\n                except Exception:\\n                    continue\\n            discovered_files = recent_files\\n        \\n        # Read file contents\\n        files_data = {}\\n        file_sizes = {}\\n        for file_path in discovered_files:\\n            try:\\n                relative_path_str, content, file_size = process_file(file_path, repo_path, args.verbose)\\n                files_data[relative_path_str] = content\\n                file_sizes[relative_path_str] = file_size\\n            except Exception:\\n                continue\\n        \\n        # Create tree view\\n        log_verbose(\\\"Generating directory tree\\\", args.verbose)\\n        tree_text = create_tree_view(repo_path, files_data)\\n        \\n        # Count totals\\n        total_files = len(files_data)\\n        total_lines = sum(len(content.splitlines()) for _, content in files_data.items())\\n        \\n        # Render based on format\\n        log_verbose(f\\\"Rendering output in {args.format} format\\\", args.verbose)\\n        content = get_rendered_content(\\n            args.format, str(repo_path), repo_info, tree_text,\\n            files_data, total_files, total_lines,\\n            recent_files_info if args.recent else {},\\n            file_sizes\\n        )\\n        \\n        handle_output(content, args.output)\\n        \\n    except Exception as e:\\n        print(f\\\"Error: {e}\\\", file=sys.stderr)\\n        sys.exit(1)\\n\\n# this will convert age and give us the difference\\ndef human_readable_age(mtime: datetime) -> str:\\n    delta = datetime.now() - mtime\\n    days = delta.days\\n    seconds = delta.seconds\\n    if days > 0:\\n        return f\\\"{days} day{'s' if days != 1 else ''} ago\\\"\\n    elif seconds >= 3600:\\n        hours = seconds // 3600\\n        return f\\\"{hours} hour{'s' if hours != 1 else ''} ago\\\"\\n    elif seconds >= 60:\\n        minutes = seconds // 60\\n        return f\\\"{minutes} minute{'s' if minutes != 1 else ''} ago\\\"\\n    else:\\n        return \\\"just now\\\"\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\",\n    \"src/rcpack/config_loader.py\": \"# src/rcpack/config_loader.py\\n\\\"\\\"\\\"\\nTOML config loader for Repo-Contextor.\\n\\nRules:\\n- Look for .repo-contextor.toml in the CURRENT directory\\n- If missing: ignore\\n- If present but invalid: print a clear error and exit(1)\\n- Only recognized keys are applied; unknown keys ignored\\n- Precedence: CLI > TOML > DEFAULTS\\n\\\"\\\"\\\"\\nfrom __future__ import annotations\\nimport os, sys\\nfrom typing import Dict, Iterable, Any\\n\\ntry:\\n    import tomllib\\n    _loads = tomllib.loads\\nexcept ModuleNotFoundError:\\n    try:\\n        import tomli\\n        _loads = tomli.loads\\n    except ModuleNotFoundError:\\n        _loads = None\\n\\ndef _need_toml():\\n    if _loads is None:\\n        print(\\\"Error: TOML parser not available. Use Python 3.11+ or `pip install tomli`.\\\", file=sys.stderr)\\n        sys.exit(1)\\n\\ndef _load_toml(dotfile: str) -> Dict[str, Any]:\\n    _need_toml()\\n    if not os.path.exists(dotfile):\\n        return {}\\n    try:\\n        with open(dotfile, \\\"rb\\\") as f:\\n            raw = f.read().decode(\\\"utf-8\\\", errors=\\\"strict\\\")\\n        data = _loads(raw)\\n        return data if isinstance(data, dict) else {}\\n    except Exception as e:\\n        print(f\\\"Error: failed to parse {dotfile} as TOML.\\\\n{e}\\\", file=sys.stderr)\\n        sys.exit(1)\\n\\ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\n    ks = set(known)\\n    return {k: v for k, v in d.items() if k in ks}\\n\\ndef _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\n    ks = set(known)\\n    out: Dict[str, Any] = {k: defaults.get(k) for k in ks}\\n    for src in (filecfg, clicfg):\\n        for k, v in src.items():\\n            if k in ks and v is not None:\\n                out[k] = v\\n    return out\\n\\ndef load_config(*, dotfile: str = \\\".repo-contextor.toml\\\", defaults: Dict[str, Any] | None = None, cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ()) -> Dict[str, Any]:\\n    defaults = defaults or {}\\n    cli_cfg = cli_cfg or {}\\n    known = tuple(known_keys)\\n    filecfg = _filter_known(_load_toml(dotfile), known)\\n    return _merge(defaults, filecfg, cli_cfg, known)\\n\",\n    \"src/rcpack/discover.py\": \"\\\"\\\"\\\"File discovery module for repository analysis.\\\"\\\"\\\"\\n\\nfrom pathlib import Path\\nfrom typing import List\\nimport fnmatch\\n\\n\\ndef discover_files(\\n    inputs: List[Path],\\n    root: Path,\\n    include_patterns: List[str],\\n    exclude_patterns: List[str],\\n) -> List[Path]:\\n    \\\"\\\"\\\"Discover relevant files.\\n\\n    - inputs: list of files/dirs to scan\\n    - root: common project root; patterns are matched against POSIX paths relative to root\\n    - include_patterns: glob patterns to include (if empty, use sensible defaults)\\n    - exclude_patterns: glob patterns to exclude\\n    Returns a list of absolute Paths to files.\\n    \\\"\\\"\\\"\\n\\n    default_include_exts = {\\n        '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\\n        '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\n        '.html', '.css', '.scss', '.sass', '.less', '.vue', '.svelte',\\n        '.md', '.txt', '.rst', '.yaml', '.yml', '.json', '.toml', '.ini',\\n        '.cfg', '.conf', '.xml', '.sql', '.sh', '.bash', '.zsh', '.fish',\\n    }\\n\\n    always_include_names = {\\n        'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING', 'Makefile',\\n        'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\\n        'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\n    }\\n\\n    skip_dir_names = {\\n        '.git', '.svn', '.hg', '__pycache__', '.pytest_cache',\\n        'node_modules', '.venv', 'venv', 'env', '.env',\\n        'build', 'dist', 'target', 'out', '.next', '.nuxt',\\n        '.idea', '.vscode', '.vs', 'coverage', '.coverage'\\n    }\\n\\n    def matches_any(patterns: List[str], rel_posix: str) -> bool:\\n        return any(fnmatch.fnmatch(rel_posix, pat) for pat in patterns)\\n\\n    def should_take(file_path: Path) -> bool:\\n        rel_posix = file_path.relative_to(root).as_posix()\\n        if exclude_patterns and matches_any(exclude_patterns, rel_posix):\\n            return False\\n        if include_patterns:\\n            return matches_any(include_patterns, rel_posix)\\n        # default include logic\\n        return file_path.name in always_include_names or file_path.suffix.lower() in default_include_exts\\n\\n    discovered: list[Path] = []\\n    seen = set()\\n\\n    for item in inputs:\\n        p = item.resolve()\\n        if p.is_file():\\n            # Skip if excluded or in skipped directory\\n            if any(part in skip_dir_names for part in p.parts):\\n                continue\\n            if should_take(p):\\n                key = p.as_posix()\\n                if key not in seen:\\n                    seen.add(key)\\n                    discovered.append(p)\\n        elif p.is_dir():\\n            for child in p.rglob('*'):\\n                if not child.is_file():\\n                    continue\\n                if any(part in skip_dir_names for part in child.parts):\\n                    continue\\n                if should_take(child):\\n                    key = child.resolve().as_posix()\\n                    if key not in seen:\\n                        seen.add(key)\\n                        discovered.append(child.resolve())\\n\\n    return sorted(discovered)\",\n    \"src/rcpack/gitinfo.py\": \"from __future__ import annotations\\n\\nimport subprocess\\nfrom pathlib import Path\\nfrom typing import Dict, Any\\n\\n\\ndef _git(cmd: list[str], cwd: Path) -> str:\\n    # Validate git commands to prevent injection\\n    allowed_commands = {\\n        \\\"rev-parse\\\", \\\"show\\\", \\\"log\\\", \\\"status\\\", \\\"branch\\\", \\\"config\\\"\\n    }\\n    if not cmd or cmd[0] not in allowed_commands:\\n        raise ValueError(f\\\"Git command not allowed: {cmd[0] if cmd else 'empty'}\\\")\\n    \\n    out = subprocess.check_output([\\\"git\\\", *cmd], cwd=str(cwd), timeout=30)\\n    return out.decode(\\\"utf-8\\\", errors=\\\"replace\\\").strip()\\n\\n\\ndef is_git_repo(path: Path) -> bool:\\n    try:\\n        flag = _git([\\\"rev-parse\\\", \\\"--is-inside-work-tree\\\"], cwd=path)\\n        return flag == \\\"true\\\"\\n    except Exception:\\n        return False\\n\\n\\ndef get_git_info(path: Path) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Return info for the current HEAD of a repo rooted at `path`.\\n    \\\"\\\"\\\"\\n    try:\\n        commit = _git([\\\"rev-parse\\\", \\\"HEAD\\\"], cwd=path)\\n        branch = _git([\\\"rev-parse\\\", \\\"--abbrev-ref\\\", \\\"HEAD\\\"], cwd=path)\\n        author = _git([\\\"show\\\", \\\"-s\\\", \\\"--format=%an <%ae>\\\"], cwd=path)\\n        date = _git([\\\"show\\\", \\\"-s\\\", \\\"--date=local\\\", \\\"--format=%ad\\\"], cwd=path)\\n        return {\\n            \\\"is_repo\\\": True,\\n            \\\"commit\\\": commit,\\n            \\\"branch\\\": branch,\\n            \\\"author\\\": author,\\n            \\\"date\\\": date,\\n            \\\"note\\\": None,\\n        }\\n    except Exception:\\n        # treat as not a repo if anything fails\\n        return {\\n            \\\"is_repo\\\": False,\\n            \\\"commit\\\": None,\\n            \\\"branch\\\": None,\\n            \\\"author\\\": None,\\n            \\\"date\\\": None,\\n            \\\"note\\\": \\\"Not a git repository\\\",\\n        }\\n\",\n    \"src/rcpack/io_utils.py\": \"\\\"\\\"\\\"I/O utilities for file operations.\\\"\\\"\\\"\\n\\nfrom pathlib import Path\\nfrom typing import Tuple\\n\\n\\ndef write_output(output_path: str, content: str) -> None:\\n    \\\"\\\"\\\"Write content to output file.\\\"\\\"\\\"\\n    output_file = Path(output_path)\\n    \\n    # Create parent directories if they don't exist\\n    output_file.parent.mkdir(parents=True, exist_ok=True)\\n    \\n    # Write content\\n    with open(output_file, 'w', encoding='utf-8') as f:\\n        f.write(content)\\n\\n\\ndef is_binary_file(path: Path, sniff_bytes: int = 2048) -> bool:\\n    \\\"\\\"\\\"Heuristically determine if a file is binary by scanning for NUL bytes.\\\"\\\"\\\"\\n    try:\\n        with open(path, 'rb') as fb:\\n            chunk = fb.read(sniff_bytes)\\n        if b\\\"\\\\x00\\\" in chunk:\\n            return True\\n        # If the chunk has a lot of non-text bytes, consider it binary\\n        text_byte_count = sum(32 <= b <= 126 or b in (9, 10, 13) for b in chunk)\\n        return (len(chunk) - text_byte_count) > max(1, len(chunk) // 3)\\n    except Exception:\\n        # If we cannot read, treat as binary to avoid further processing\\n        return True\\n\\n\\ndef read_text_safely(path: Path, max_bytes: int = 16_384) -> Tuple[str, str, bool]:\\n    \\\"\\\"\\\"Read a text file safely with size limit and encoding fallbacks.\\n\\n    Returns (content, encoding_used, truncated).\\n    \\\"\\\"\\\"\\n    truncated = False\\n    raw: bytes\\n    with open(path, 'rb') as fb:\\n        raw = fb.read(max_bytes + 1)\\n    if len(raw) > max_bytes:\\n        truncated = True\\n        raw = raw[:max_bytes]\\n\\n    for enc in (\\\"utf-8\\\", \\\"utf-16\\\", \\\"utf-16-le\\\", \\\"utf-16-be\\\", \\\"latin-1\\\"):\\n        try:\\n            text = raw.decode(enc)\\n            return text, enc, truncated\\n        except Exception:\\n            continue\\n    # Fallback: replace errors with utf-8\\n    text = raw.decode(\\\"utf-8\\\", errors=\\\"replace\\\")\\n    return text, \\\"utf-8\\\", truncated\",\n    \"src/rcpack/packager.py\": \"from __future__ import annotations\\n\\nimport sys\\nfrom pathlib import Path\\nfrom typing import Iterable, Tuple\\n\\nfrom rcpack.discover import discover_files\\nfrom rcpack.gitinfo import get_git_info, is_git_repo\\nfrom rcpack.io_utils import read_text_safely, is_binary_file\\nfrom rcpack.renderer import markdown as md_renderer\\nfrom rcpack.renderer.jsonyaml import render_json, render_yaml\\nfrom rcpack.treeview import render_tree\\nfrom rcpack.utils import get_language_from_extension\\n\\n\\ndef _find_root(inputs: list[str]) -> Path:\\n    paths = [Path(p) for p in inputs]\\n    if len(paths) == 1 and Path(paths[0]).is_dir():\\n        return paths[0].resolve()\\n    parents = [p if p.is_dir() else p.parent for p in paths]\\n    root = Path(*Path.commonpath([str(p.resolve()) for p in parents]).split(\\\"/\\\"))\\n    return root.resolve()\\n\\n\\ndef build_package(\\n    inputs: list[str],\\n    include_patterns: list[str] | None,\\n    exclude_patterns: list[str] | None,\\n    max_file_bytes: int,\\n    fmt: str = \\\"markdown\\\",\\n) -> Tuple[str, dict]:\\n    root = _find_root(inputs)\\n    root_abs = root.resolve()\\n\\n    repo_info = (\\n        get_git_info(root_abs) if is_git_repo(root_abs) else {\\n            \\\"is_repo\\\": False,\\n            \\\"commit\\\": None,\\n            \\\"branch\\\": None,\\n            \\\"author\\\": None,\\n            \\\"date\\\": None,\\n            \\\"note\\\": \\\"Not a git repository\\\",\\n        }\\n    )\\n\\n    files = discover_files(\\n        inputs=[Path(p) for p in inputs],\\n        root=root_abs,\\n        include_patterns=include_patterns or [],\\n        exclude_patterns=exclude_patterns or [],\\n    )\\n    rel_files = [f.relative_to(root_abs) for f in files]\\n\\n    project_tree = render_tree([p.as_posix() for p in rel_files])\\n\\n    file_sections: list[dict] = []\\n    total_lines = 0\\n    total_chars = 0\\n\\n    for f in files:\\n        rel = f.relative_to(root_abs).as_posix()\\n        try:\\n            if is_binary_file(f):\\n                content = f\\\"[binary file skipped: {f.name}, {f.stat().st_size} bytes]\\\"\\n                file_sections.append({\\n                    \\\"path\\\": rel,\\n                    \\\"language\\\": get_language_from_extension(f.suffix),\\n                    \\\"content\\\": content,\\n                    \\\"is_truncated\\\": False,\\n                })\\n                total_chars += len(content)\\n                continue\\n\\n            content, used_encoding, truncated = read_text_safely(f, max_bytes=max_file_bytes)\\n            total_lines += content.count(\\\"\\\\n\\\") + (1 if content and not content.endswith(\\\"\\\\n\\\") else 0)\\n            total_chars += len(content)\\n\\n            if truncated:\\n                note = f\\\"\\\\n\\\\n[... TRUNCATED to first {max_file_bytes} bytes ...]\\\"\\n                content = content + note\\n                total_chars += len(note)\\n\\n            file_sections.append({\\n                \\\"path\\\": rel,\\n                \\\"language\\\": get_language_from_extension(f.suffix),\\n                \\\"content\\\": content,\\n                \\\"is_truncated\\\": truncated,\\n            })\\n        except Exception as exc:\\n            print(f\\\"[rcpack] error reading {rel}: {exc}\\\", file=sys.stderr)\\n            continue\\n\\n    # render in chosen format\\n    if fmt == \\\"markdown\\\":\\n        out_text = md_renderer.render_markdown(\\n            root=str(root_abs),\\n            repo_info=repo_info,\\n            tree_text=project_tree,\\n            files=file_sections,\\n            total_files=len(file_sections),\\n            total_lines=total_lines,\\n        )\\n    elif fmt == \\\"json\\\":\\n        out_text = render_json(\\n            root=str(root_abs),\\n            repo_info=repo_info,\\n            tree_text=project_tree,\\n            files=file_sections,\\n            total_files=len(file_sections),\\n            total_lines=total_lines,\\n        )\\n    elif fmt == \\\"yaml\\\":\\n        out_text = render_yaml(\\n            root=str(root_abs),\\n            repo_info=repo_info,\\n            tree_text=project_tree,\\n            files=file_sections,\\n            total_files=len(file_sections),\\n            total_lines=total_lines,\\n        )\\n    else:\\n        raise ValueError(f\\\"Unsupported format: {fmt}\\\")\\n\\n    stats = {\\\"files\\\": len(file_sections), \\\"lines\\\": total_lines, \\\"chars\\\": total_chars}\\n    return out_text, stats\\n\",\n    \"src/rcpack/renderer/jsonyaml.py\": \"from __future__ import annotations\\nimport json\\nfrom ..utils import build_repository_data\\n\\ntry:\\n    import yaml\\nexcept ImportError:\\n    yaml = None\\n\\n\\ndef render_json(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\\n    data = build_repository_data(\\n        root=root,\\n        repo_info=repo_info,\\n        tree_text=tree_text,\\n        files=files,\\n        total_files=total_files,\\n        total_lines=total_lines,\\n        recent_files=recent_files,\\n        file_sizes=file_sizes\\n    )\\n    return json.dumps(data, indent=2, ensure_ascii=False)\\n\\n\\ndef render_yaml(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\\n    if yaml is None:\\n        raise RuntimeError(\\\"PyYAML not installed; run `pip install pyyaml`\\\")\\n    data = build_repository_data(\\n        root=root,\\n        repo_info=repo_info,\\n        tree_text=tree_text,\\n        files=files,\\n        total_files=total_files,\\n        total_lines=total_lines,\\n        recent_files=recent_files,\\n        file_sizes=file_sizes\\n    )\\n    return yaml.safe_dump(data, sort_keys=False, allow_unicode=True)\\n\",\n    \"src/rcpack/renderer/markdown.py\": \"\\\"\\\"\\\"Markdown renderer for repository context.\\\"\\\"\\\"\\n\\nfrom typing import Dict, Any\\nfrom ..utils import get_language_from_extension\\n\\n\\ndef render_markdown(root: str, repo_info: Dict[str, Any], tree_text: str, \\n                   files: Dict[str, str], total_files: int, total_lines: int, recent_files=None, file_sizes=None) -> str:\\n    \\\"\\\"\\\"Render repository context as markdown.\\\"\\\"\\\"\\n    \\n    lines = []\\n    \\n    # Header\\n    lines.append(f\\\"# Repository Context: {root}\\\")\\n    lines.append(\\\"\\\")\\n    \\n    # Repository info\\n    if repo_info.get(\\\"is_repo\\\"):\\n        lines.append(\\\"## Git Repository Information\\\")\\n        lines.append(f\\\"- **Branch**: {repo_info.get('branch', 'N/A')}\\\")\\n        lines.append(f\\\"- **Commit**: {repo_info.get('commit', 'N/A')}\\\")\\n        lines.append(f\\\"- **Author**: {repo_info.get('author', 'N/A')}\\\")\\n        lines.append(f\\\"- **Date**: {repo_info.get('date', 'N/A')}\\\")\\n    else:\\n        lines.append(\\\"## Repository Information\\\")\\n        lines.append(f\\\"- **Note**: {repo_info.get('note', 'Not a git repository')}\\\")\\n    lines.append(\\\"\\\")\\n    \\n    # Summary\\n    lines.append(\\\"## Summary\\\")\\n    lines.append(f\\\"- **Total Files**: {total_files}\\\")\\n    lines.append(f\\\"- **Total Lines**: {total_lines}\\\")\\n    lines.append(\\\"\\\")\\n    \\n    # Directory structure\\n    lines.append(\\\"## Directory Structure\\\")\\n    lines.append(\\\"```\\\")\\n    lines.append(tree_text)\\n    lines.append(\\\"```\\\")\\n    lines.append(\\\"\\\")\\n\\n    # will produce recent files \\n    # Recent files (fixed)\\n    if recent_files:\\n        lines.append(\\\"## Recent Changes\\\")\\n        for file, age in recent_files.items():\\n            lines.append(f\\\"- {file} (modified {age})\\\")\\n        lines.append(\\\"\\\")\\n    \\n    # File contents\\n    lines.append(\\\"## File Contents\\\")\\n    lines.append(\\\"\\\")\\n    \\n    for file_path, content in sorted(files.items()):\\n        if file_sizes and file_path in file_sizes:\\n            size_bytes = file_sizes[file_path]\\n            lines.append(f\\\"### {file_path} ({size_bytes} bytes)\\\")\\n        else:\\n            lines.append(f\\\"### {file_path}\\\")\\n        lines.append(\\\"\\\")\\n        \\n        # Detect language for syntax highlighting\\n        language = get_language_from_extension(file_path)\\n        \\n        lines.append(f\\\"```{language}\\\")\\n        lines.append(content)\\n        lines.append(\\\"```\\\")\\n        lines.append(\\\"\\\")\\n    \\n    return \\\"\\\\n\\\".join(lines)\\n\",\n    \"src/rcpack/treeview.py\": \"\\\"\\\"\\\"Tree view generation for repository structure.\\\"\\\"\\\"\\n\\nfrom pathlib import Path\\nfrom typing import Dict, List\\n\\n\\ndef create_tree_view(repo_path: Path, files_data: Dict[str, str]) -> str:\\n    \\\"\\\"\\\"Create a tree view of the repository structure.\\\"\\\"\\\"\\n    paths = list(files_data.keys())\\n    return render_tree(paths)\\n\\n\\ndef render_tree(paths: List[str]) -> str:\\n    \\\"\\\"\\\"Render a tree view from a list of relative POSIX paths.\\\"\\\"\\\"\\n    tree_structure: dict = {}\\n\\n    for p in paths:\\n        parts = Path(p).parts\\n        current = tree_structure\\n        for part in parts[:-1]:\\n            if part not in current:\\n                current[part] = {}\\n            current = current[part]\\n        if parts:\\n            current[parts[-1]] = None\\n\\n    def _render(structure: dict, prefix: str = \\\"\\\") -> str:\\n        lines = []\\n        items = sorted(structure.items(), key=lambda x: (x[1] is None, x[0]))\\n        for i, (name, subtree) in enumerate(items):\\n            is_last = i == len(items) - 1\\n            lines.append(f\\\"{prefix}{'└── ' if is_last else '├── '}{name}\\\")\\n            if subtree is not None:\\n                extension = (\\\"    \\\" if is_last else \\\"│   \\\")\\n                lines.append(_render(subtree, prefix + extension))\\n        return \\\"\\\\n\\\".join(filter(None, lines))\\n\\n    if not tree_structure:\\n        return \\\"No files found\\\"\\n    return _render(tree_structure)\",\n    \"src/rcpack/utils.py\": \"\\\"\\\"\\\"Utility functions shared across the rcpack package.\\\"\\\"\\\"\\n\\nfrom typing import Dict, Any, Optional\\n\\n\\ndef get_language_from_extension(file_path_or_ext: str) -> str:\\n    \\\"\\\"\\\"Get the language identifier for syntax highlighting from a file path or extension.\\n    \\n    Args:\\n        file_path_or_ext: Either a file path (e.g., 'src/main.py') or extension (e.g., '.py' or 'py')\\n    \\n    Returns:\\n        Language identifier for syntax highlighting (e.g., 'python', 'javascript')\\n    \\\"\\\"\\\"\\n    # Extract extension from file path if needed\\n    if '.' in file_path_or_ext and not file_path_or_ext.startswith('.'):\\n        # It's a file path, extract the extension\\n        ext = file_path_or_ext.split('.')[-1].lower()\\n    else:\\n        # It's already an extension, clean it up\\n        ext = file_path_or_ext.lower().lstrip(\\\".\\\")\\n    \\n    # Comprehensive language mapping combining both existing mappings\\n    language_map = {\\n        'py': 'python', 'js': 'javascript', 'ts': 'typescript',\\n        'jsx': 'javascript', 'tsx': 'typescript',\\n        'java': 'java', 'cpp': 'cpp', 'c': 'c', 'h': 'c',\\n        'cs': 'csharp', 'php': 'php', 'rb': 'ruby',\\n        'go': 'go', 'rs': 'rust', 'swift': 'swift', 'kt': 'kotlin',\\n        'html': 'html', 'css': 'css', 'scss': 'scss', 'sass': 'sass',\\n        'json': 'json', 'yaml': 'yaml', 'yml': 'yaml',\\n        'toml': 'toml', 'xml': 'xml', 'sql': 'sql', 'sh': 'bash',\\n        'bash': 'bash', 'zsh': 'bash', 'fish': 'fish',\\n        'md': 'markdown', 'txt': 'text',\\n        'dockerfile': 'dockerfile', 'makefile': 'makefile'\\n    }\\n    \\n    return language_map.get(ext, '')\\n\\n\\ndef build_repository_data(\\n    root: str,\\n    repo_info: Dict[str, Any],\\n    tree_text: str,\\n    files: Dict[str, str],\\n    total_files: int,\\n    total_lines: int,\\n    recent_files: Optional[Dict[str, str]] = None,\\n    file_sizes: Optional[Dict[str, str]] = None\\n) -> Dict[str, Any]:\\n    \\\"\\\"\\\"Build the standard repository data structure used by all renderers.\\n    \\n    Args:\\n        root: Repository root path\\n        repo_info: Git repository information\\n        tree_text: Directory tree text representation\\n        files: Dictionary of file paths to content\\n        total_files: Total number of files\\n        total_lines: Total number of lines\\n        recent_files: Optional dict of recently modified files\\n        file_sizes: Optional dict of file sizes\\n        \\n    Returns:\\n        Standardized data dictionary for rendering\\n    \\\"\\\"\\\"\\n    return {\\n        \\\"root\\\": root,\\n        \\\"repo_info\\\": repo_info,\\n        \\\"structure\\\": tree_text,\\n        \\\"recent_changes\\\": recent_files or {},\\n        \\\"files\\\": files,\\n        \\\"file_sizes\\\": file_sizes or {},\\n        \\\"summary\\\": {\\\"total_files\\\": total_files, \\\"total_lines\\\": total_lines},\\n    }\\n\\n\\ndef calculate_total_lines(content_dict: Dict[str, str]) -> int:\\n    \\\"\\\"\\\"Calculate the total number of lines from a dictionary of file contents.\\n    \\n    Args:\\n        content_dict: Dictionary mapping file paths to their content\\n        \\n    Returns:\\n        Total number of lines across all files\\n    \\\"\\\"\\\"\\n    return sum(len(content.splitlines()) for content in content_dict.values())\\n\\n\\ndef calculate_total_characters(content_dict: Dict[str, str]) -> int:\\n    \\\"\\\"\\\"Calculate the total number of characters from a dictionary of file contents.\\n    \\n    Args:\\n        content_dict: Dictionary mapping file paths to their content\\n        \\n    Returns:\\n        Total number of characters across all files\\n    \\\"\\\"\\\"\\n    return sum(len(content) for content in content_dict.values())\",\n    \"test-output.json\": \"{\\n  \\\"root\\\": \\\"/Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\\\",\\n  \\\"repo_info\\\": {\\n    \\\"is_repo\\\": true,\\n    \\\"commit\\\": \\\"682153b169db66d3a72e9cabdd1f3448a3b2986d\\\",\\n    \\\"branch\\\": \\\"refactoring\\\",\\n    \\\"author\\\": \\\"Abhinav <abhinavbhardwaj2002@gmail.com>\\\",\\n    \\\"date\\\": \\\"Fri Oct 3 18:45:48 2025\\\",\\n    \\\"note\\\": null\\n  },\\n  \\\"structure\\\": \\\"├── src\\\\n│   └── rcpack\\\\n│       ├── renderer\\\\n│       │   ├── jsonyaml.py\\\\n│       │   └── markdown.py\\\\n│       ├── __init__.py\\\\n│       ├── __main__.py\\\\n│       ├── cli.py\\\\n│       ├── config_loader.py\\\\n│       ├── discover.py\\\\n│       ├── gitinfo.py\\\\n│       ├── io_utils.py\\\\n│       ├── packager.py\\\\n│       └── treeview.py\\\\n├── LICENSE\\\\n├── README.md\\\\n└── pyproject.toml\\\",\\n  \\\"recent_changes\\\": [],\\n  \\\"files\\\": {\\n    \\\"LICENSE\\\": \\\"MIT License\\\\n\\\\nCopyright (c) 2025 Abhinav\\\\n\\\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\\\nof this software and associated documentation files (the \\\\\\\"Software\\\\\\\"), to deal\\\\nin the Software without restriction, including without limitation the rights\\\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\ncopies of the Software, and to permit persons to whom the Software is\\\\nfurnished to do so, subject to the following conditions:\\\\n\\\\nThe above copyright notice and this permission notice shall be included in all\\\\ncopies or substantial portions of the Software.\\\\n\\\\nTHE SOFTWARE IS PROVIDED \\\\\\\"AS IS\\\\\\\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\nSOFTWARE.\\\\n\\\",\\n    \\\"README.md\\\": \\\"# Repo-Contextor\\\\n\\\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\\\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\\\n\\\\nA powerful Repository Context Packager CLI tool that analyzes local git repositories and creates comprehensive text files containing repository content optimized for sharing with Large Language Models (LLMs).\\\\n\\\\n## Overview\\\\n\\\\nWhen developers want to get help from ChatGPT, Claude, or other LLMs about their code, they often struggle with how to share their codebase effectively. Common problems include:\\\\n\\\\n- **Lost Context**: Copy-pasting individual files loses important project structure and relationships\\\\n- **Missing Dependencies**: LLMs can't see how files connect or what libraries are used\\\\n- **Incomplete Picture**: Hard to convey the overall architecture and organization\\\\n- **Manual Work**: Time-consuming to gather and format relevant code\\\\n\\\\n**Repo-Contextor** solves this by automatically collecting and formatting repository content into a single, well-structured text file that provides rich context to LLMs, enabling them to give much better assistance with your code.\\\\n\\\\n## Features\\\\n\\\\n- **Git Integration**: Extracts commit SHA, branch, author, and date information\\\\n- **Project Structure**: Generates a clear directory tree visualization\\\\n- **File Content Packaging**: Includes file contents with syntax highlighting\\\\n- **Smart File Discovery**: Recursively scans directories with intelligent filtering\\\\n- **Binary File Detection**: Automatically skips binary files\\\\n- **Error Handling**: Gracefully handles permission errors and provides helpful messages\\\\n- **Multiple Output Formats**: Supports Markdown, JSON, and YAML formats\\\\n- **Flexible Output**: Write to stdout or save to a file\\\\n- **Recent Changes Filter**: Give the files which are updated in last 7days with the time when it was recently modified.\\\\n\\\\n## Installation\\\\n\\\\n### Prerequisites\\\\n\\\\n- Python 3.9 or higher\\\\n- Git (for git repository analysis)\\\\n\\\\n### For End Users\\\\n\\\\n```bash\\\\n# Clone and install\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\ncd Repo-Contextor\\\\npip install -e .\\\\n```\\\\n\\\\n### For Contributors & Local Development\\\\n\\\\n```bash\\\\n# Clone the repository\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\ncd Repo-Contextor\\\\n\\\\n# Create virtual environment\\\\npython -m venv .venv\\\\nsource .venv/bin/activate  # On Windows: .venv\\\\\\\\Scripts\\\\\\\\activate\\\\n\\\\n# Install in development mode\\\\npip install -e .\\\\n```\\\\n\\\\n## Usage\\\\n\\\\n### Basic Examples\\\\n\\\\n```bash\\\\n# Package current directory to terminal\\\\nrepo-contextor .\\\\n\\\\n# Package a specific directory\\\\nrepo-contextor /path/to/your/project\\\\n\\\\n# Save output to a file\\\\nrepo-contextor . -o my-project-context.md\\\\n\\\\n# Generate JSON format\\\\nrepo-contextor . -f json -o context.json\\\\n\\\\n# Generate YAML format\\\\nrepo-contextor . -f yaml -o context.yaml\\\\n\\\\n# Include only files modified in the last 7 days\\\\nrepo-contextor . --recent\\\\n\\\\n# Combine with output file\\\\nrepo-contextor . --recent -o recent-changes.md\\\\n```\\\\n\\\\n### Command Line Options\\\\n\\\\n| Option | Short | Description | Example |\\\\n|--------|-------|-------------|---------|\\\\n| `path` | - | Repository path to analyze (default: current directory) | `repo-contextor /path/to/project` |\\\\n| `--output` | `-o` | Output file path (default: stdout) | `-o context.md` |\\\\n| `--format` | `-f` | Output format: text, json, yaml (default: text) | `-f json` |\\\\n| `--help` | `-h` | Show help message | `-h` |\\\\n| `--recent`  | `-r`  | Include only files modified in the last 7 days    | `repo-contextor . -r -o recent.md` |\\\\n\\\\n### Advanced Examples\\\\n\\\\n```bash\\\\n# Analyze different repository\\\\nrepo-contextor /path/to/other/project -o other-project.md\\\\n\\\\n# Generate JSON for API consumption\\\\nrepo-contextor . -f json -o api-context.json\\\\n\\\\n# Create YAML configuration\\\\nrepo-contextor . -f yaml -o project-config.yaml\\\\n\\\\n# Generate files which are changed recently in 7 days\\\\nrepo-contextor . -r --output recent-changes.txt\\\\n\\\\n```\\\\n## Configuration via TOML\\\\n\\\\nRepo-Contextor supports configuration through a `.repo-contextor.toml` file in the current working directory.  \\\\nThis file allows you to avoid typing the same CLI arguments every time.\\\\n\\\\nExample `.repo-contextor.toml`:\\\\n\\\\n```toml\\\\n# Output file to write results\\\\noutput = \\\\\\\"context.yaml\\\\\\\"\\\\n\\\\n# Output format: text, json, or yaml\\\\nformat = \\\\\\\"yaml\\\\\\\"\\\\n\\\\n# Limit to files modified in the last 7 days\\\\nrecent = true\\\\n\\\\n# Repository path to analyze (default = current directory)\\\\npath = \\\\\\\".\\\\\\\"\\\\n```\\\\n### Rules\\\\n- If the `.repo-contextor.toml` file is **missing**, the tool falls back to defaults.  \\\\n- If the file is **present but invalid TOML**, the tool prints a clear error message and exits with status code 1.  \\\\n- **Unknown keys** in the TOML file are ignored (safe for future extensions).  \\\\n- **Precedence** of settings is:\\\\n  1. Command-line arguments (highest priority)  \\\\n  2. Values from `.repo-contextor.toml`  \\\\n  3. Built-in defaults (lowest priority)\\\\n     \\\\n## Output Format\\\\n\\\\nThe tool generates a structured text file with the following sections:\\\\n\\\\n### 1. Repository Context Header\\\\nProject path and identification\\\\n\\\\n### 2. Git Repository Information\\\\n- Current branch\\\\n- Latest commit SHA\\\\n- Last commit author\\\\n- Last commit date\\\\n\\\\n### 3. Summary Statistics\\\\n- Total number of files processed\\\\n- Total lines of code\\\\n\\\\n### 4. Directory Structure\\\\nClean tree visualization showing project organization\\\\n\\\\n### 5. Recent Changes (if `--recent` is used)\\\\n\\\\n- Lists files modified in the last 7 days.\\\\n- Shows relative file paths along with how long ago each file was modified\\\\n- Helps focus on recently updated parts of the project.\\\\n- Can be combined with `--output` or `--format` to save or change the output type.\\\\n\\\\n\\\\n### 5. File Contents\\\\nEach file's content with:\\\\n- Clear file path headers\\\\n- Appropriate syntax highlighting language tags\\\\n- Complete file contents\\\\n\\\\n## Example Output\\\\n\\\\nWhen you run `repo-contextor .`, the output looks like this:\\\\n\\\\n````markdown\\\\n# Repository Context: /path/to/your/project\\\\n\\\\n## Git Repository Information\\\\n- **Branch**: main\\\\n- **Commit**: a1b2c3d4e5f6789...\\\\n- **Author**: John Doe <john@example.com>\\\\n- **Date**: Fri Sep 12 14:30:15 2025\\\\n\\\\n## Summary\\\\n- **Total Files**: 15\\\\n- **Total Lines**: 1,247\\\\n\\\\n## Directory Structure\\\\n```\\\\n├── src/\\\\n│   ├── main.py\\\\n│   └── utils.py\\\\n├── tests/\\\\n│   └── test_main.py\\\\n├── README.md\\\\n└── requirements.txt\\\\n```\\\\n## Recent Changes\\\\n- src/main.py (modified 2 days ago)\\\\n- src/utils/helpers.py (modified 5 days ago)\\\\n\\\\n## File Contents\\\\n\\\\n### src/main.py\\\\n\\\\n```python\\\\ndef main():\\\\n    print(\\\\\\\"Hello, World!\\\\\\\")\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\\n```\\\\n\\\\n### README.md\\\\n\\\\n```markdown\\\\n# My Project\\\\nThis is a sample project.\\\\n```\\\\n\\\\n## Summary\\\\n- Total files: 15\\\\n- Total lines: 1,247\\\\n````\\\\n\\\\n## What Files Are Included\\\\n\\\\nThe tool includes most text files but automatically excludes:\\\\n\\\\n### Excluded Directories\\\\n- `.git`, `.svn`, `.hg` (version control)\\\\n- `__pycache__`, `.pytest_cache` (Python cache)\\\\n- `node_modules`, `.venv`, `venv` (dependencies/environments)\\\\n- `.vscode`, `.idea` (IDE directories)\\\\n- `build`, `dist`, `target` (build directories)\\\\n\\\\n### File Handling Rules\\\\n- **Text files**: All readable text files with common extensions\\\\n- **Binary files**: Automatically detected and skipped\\\\n- **Permission errors**: Skipped with graceful handling\\\\n- **Configuration files**: Includes pyproject.toml, package.json, etc.\\\\n\\\\n### Included File Types\\\\n- Source code: `.py`, `.js`, `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\\\n- Web files: `.html`, `.css`, `.scss`, `.vue`, `.jsx`, etc.\\\\n- Documentation: `.md`, `.txt`, `.rst`\\\\n- Configuration: `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\\\n- Scripts: `.sh`, `.bash`, `.zsh`\\\\n\\\\n## Error Handling\\\\n\\\\nThe tool handles errors gracefully:\\\\n\\\\n| Error Type | Behavior |\\\\n|------------|----------|\\\\n| **Permission errors** | Skipped with warning |\\\\n| **Binary files** | Automatically detected and skipped |\\\\n| **Invalid paths** | Clear error messages |\\\\n| **Non-git repositories** | Works fine, shows \\\\\\\"Not a git repository\\\\\\\" |\\\\n| **Unreadable files** | Marked as \\\\\\\"[Binary or unreadable file]\\\\\\\" |\\\\n\\\\n## Development\\\\n\\\\n### Project Structure\\\\n\\\\n```text\\\\nRepo-Contextor/\\\\n├── src/rcpack/              # Main package\\\\n│   ├── __init__.py         # Package initialization\\\\n│   ├── cli.py              # Command-line interface\\\\n│   ├── discover.py         # File discovery logic\\\\n│   ├── gitinfo.py          # Git repository analysis\\\\n│   ├── treeview.py         # Directory tree generation\\\\n│   ├── packager.py         # Main orchestration\\\\n│   ├── io_utils.py         # File I/O utilities\\\\n│   └── renderer/           # Output formatters\\\\n│       ├── markdown.py     # Markdown renderer\\\\n│       └── jsonyaml.py     # JSON/YAML renderers\\\\n├── pyproject.toml          # Project configuration\\\\n├── LICENSE                 # MIT License\\\\n└── README.md              # This documentation\\\\n```\\\\n\\\\n### Running Tests\\\\n\\\\n```bash\\\\n# Test on current repository\\\\nrepo-contextor . -o test-output.md\\\\n\\\\n# Test different formats\\\\nrepo-contextor . -f json | head -20\\\\nrepo-contextor . -f yaml | head -20\\\\n\\\\n# Test specific directory\\\\nrepo-contextor src/ -o src-only.md\\\\n```\\\\n\\\\n### Contributing\\\\n\\\\n1. **Fork the repository**\\\\n2. **Clone your fork:**\\\\n   ```bash\\\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\\\n   cd Repo-Contextor\\\\n   ```\\\\n3. **Install for development:**\\\\n   ```bash\\\\n   python -m venv .venv\\\\n   source .venv/bin/activate\\\\n   pip install -e .\\\\n   ```\\\\n4. **Make your changes and test:**\\\\n   ```bash\\\\n   repo-contextor . -o test.md\\\\n   ```\\\\n5. **Submit a pull request**\\\\n\\\\n### Development Workflow\\\\n\\\\n```bash\\\\n# 1. Setup development environment\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\ncd Repo-Contextor\\\\npython -m venv .venv\\\\nsource .venv/bin/activate\\\\npip install -e .\\\\n\\\\n# 2. Make changes to the code\\\\n# Edit files in src/rcpack/\\\\n\\\\n# 3. Test your changes\\\\nrepo-contextor . -o test-output.md\\\\n\\\\n# 4. Test different formats\\\\nrepo-contextor . -f json -o test.json\\\\nrepo-contextor . -f yaml -o test.yaml\\\\n\\\\n# 5. Commit and push changes\\\\ngit add .\\\\ngit commit -m \\\\\\\"Add new feature\\\\\\\"\\\\ngit push origin feature-branch\\\\n```\\\\n\\\\n## License\\\\n\\\\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\\\\n\\\\n## Why Repo-Contextor?\\\\n\\\\nThe name \\\\\\\"Repo-Contextor\\\\\\\" combines \\\\\\\"Repository\\\\\\\" + \\\\\\\"Context\\\\\\\" + \\\\\\\"or\\\\\\\", representing the tool's purpose of providing rich context about code repositories in a format that's perfect for LLM interactions.\\\\n\\\\n### Use Cases\\\\n\\\\n- **AI Assistance**: Get better help from ChatGPT, Claude, or GitHub Copilot\\\\n- **Code Reviews**: Share complete project context with team members\\\\n- **Documentation**: Create comprehensive project snapshots\\\\n- **Onboarding**: Help new team members understand project structure\\\\n- **Project Analysis**: Understand repository structure and dependencies\\\\n\\\\n### Perfect for LLMs\\\\n\\\\nThe output format is specifically designed to work well with Large Language Models:\\\\n- Clear section headers for easy parsing\\\\n- Syntax highlighting markers for code blocks\\\\n- Structured metadata (git info, file locations)\\\\n- Complete project context in a single file\\\\n- Multiple output formats (Markdown, JSON, YAML)\\\\n- Optimized for token efficiency\\\\n\\\",\\n    \\\"pyproject.toml\\\": \\\"[build-system]\\\\nrequires = [\\\\\\\"setuptools>=68\\\\\\\", \\\\\\\"wheel\\\\\\\"]\\\\nbuild-backend = \\\\\\\"setuptools.build_meta\\\\\\\"\\\\n\\\\n[project]\\\\nname = \\\\\\\"rcpack\\\\\\\"\\\\nversion = \\\\\\\"0.1.0\\\\\\\"\\\\ndescription = \\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\"\\\\nreadme = \\\\\\\"README.md\\\\\\\"\\\\nrequires-python = \\\\\\\">=3.9\\\\\\\"\\\\nlicense = { text = \\\\\\\"MIT\\\\\\\" }\\\\ndependencies = [\\\\n    \\\\\\\"PyYAML>=6.0\\\\\\\"\\\\n]\\\\n\\\\n[project.scripts]\\\\nrepo-contextor = \\\\\\\"rcpack.cli:main\\\\\\\"\\\\n\\\",\\n    \\\"src/rcpack/__init__.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Repository Context Packager - CLI tool for creating LLM-optimized repository context.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n__version__ = \\\\\\\"0.1.0\\\\\\\"\\\\n__author__ = \\\\\\\"Abhinav\\\\\\\"\\\\n__description__ = \\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\"\\\",\\n    \\\"src/rcpack/__main__.py\\\": \\\"#!/usr/bin/env python3\\\\n\\\\\\\"\\\\\\\"\\\\\\\"Module entry point to enable `python -m rcpack`.\\\\n\\\\nThis simply delegates to the CLI's main() function.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom .cli import main\\\\n\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\\n\\\\n\\\\n\\\",\\n    \\\"src/rcpack/cli.py\\\": \\\"#!/usr/bin/env python3\\\\n\\\\\\\"\\\\\\\"\\\\\\\"CLI for Repository Context Packager.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom .config_loader import load_config\\\\n\\\\nimport argparse\\\\nimport sys\\\\nfrom pathlib import Path\\\\nfrom .gitinfo import get_git_info\\\\nfrom .discover import discover_files\\\\nfrom .treeview import create_tree_view\\\\nfrom .renderer.markdown import render_markdown\\\\nfrom .renderer.jsonyaml import render_json, render_yaml\\\\nfrom .io_utils import write_output\\\\nfrom datetime import datetime, timedelta\\\\n\\\\n\\\\ndef log_verbose(message: str, verbose: bool) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Log a message to stderr if verbose mode is enabled.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if verbose:\\\\n        print(message, file=sys.stderr)\\\\n\\\\n\\\\ndef get_rendered_content(format_type: str, repo_path: str, repo_info: dict, tree_text: str, \\\\n                        files_data: dict, total_files: int, total_lines: int, \\\\n                        recent_files_info: dict, file_sizes: dict) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Get rendered content based on the specified format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if format_type == \\\\\\\"json\\\\\\\":\\\\n        return render_json(\\\\n            repo_path, repo_info, tree_text, \\\\n            files_data, total_files, total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\n        )\\\\n    elif format_type == \\\\\\\"yaml\\\\\\\":\\\\n        return render_yaml(\\\\n            repo_path, repo_info, tree_text, \\\\n            files_data, total_files, total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\n        )\\\\n    else:  # text/markdown\\\\n        return render_markdown(\\\\n            repo_path, repo_info, tree_text, \\\\n            files_data, total_files, total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\n        )\\\\n\\\\n\\\\ndef process_file(file_path: Path, repo_path: Path, verbose: bool) -> tuple[str, str, str]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Process a single file and return its data.\\\\n    \\\\n    Returns:\\\\n        tuple: (relative_path_str, content, file_size)\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    relative_path = file_path.relative_to(repo_path)\\\\n    relative_path_str = str(relative_path)\\\\n    \\\\n    log_verbose(f\\\\\\\"Reading file: {relative_path}\\\\\\\", verbose)\\\\n    file_size = file_path.stat().st_size\\\\n    \\\\n    try:\\\\n        with open(file_path, 'r', encoding='utf-8') as f:\\\\n            content = f.read()\\\\n        return relative_path_str, content, str(file_size)\\\\n    except (UnicodeDecodeError, PermissionError):\\\\n        log_verbose(f\\\\\\\"Skipping binary/unreadable file: {relative_path}\\\\\\\", verbose)\\\\n        file_size = file_path.stat().st_size if file_path.exists() else 0\\\\n        content = f\\\\\\\"[Binary or unreadable file: {file_path.name}]\\\\\\\"\\\\n        return relative_path_str, content, str(file_size)\\\\n    except Exception:\\\\n        log_verbose(f\\\\\\\"Error reading file: {relative_path}\\\\\\\", verbose)\\\\n        raise  # Re-raise to handle in calling code\\\\n\\\\n\\\\ndef handle_output(content: str, output_path: str = None) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Handle output to either file or stdout.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if output_path:\\\\n        # Write to file\\\\n        write_output(output_path, content)\\\\n        print(f\\\\\\\"Context package created: {output_path}\\\\\\\")\\\\n    else:\\\\n        # Output to stdout\\\\n        print(content)\\\\n\\\\n\\\\ndef main():\\\\n    parser = argparse.ArgumentParser(\\\\n        description=\\\\\\\"Package repository content for LLM context\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"path\\\\\\\", \\\\n        nargs=\\\\\\\"?\\\\\\\", \\\\n        default=\\\\\\\".\\\\\\\", \\\\n        help=\\\\\\\"Repository path (default: current directory)\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"-o\\\\\\\", \\\\\\\"--output\\\\\\\", \\\\n        help=\\\\\\\"Output file path (default: stdout)\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"-f\\\\\\\", \\\\\\\"--format\\\\\\\", \\\\n        choices=[\\\\\\\"text\\\\\\\", \\\\\\\"json\\\\\\\", \\\\\\\"yaml\\\\\\\"], \\\\n        default=\\\\\\\"text\\\\\\\",\\\\n        help=\\\\\\\"Output format (default: text)\\\\\\\"\\\\n    )\\\\n\\\\n    \\\\\\\"\\\\\\\"\\\\\\\" This will read -r from the console and able to search it with this\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    parser.add_argument(\\\\n    \\\\\\\"-r\\\\\\\", \\\\\\\"--recent\\\\\\\",\\\\n    action=\\\\\\\"store_true\\\\\\\",\\\\n    help=\\\\\\\"Include only files modified in the last 7 days\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"-v\\\\\\\", \\\\\\\"--verbose\\\\\\\",\\\\n        action=\\\\\\\"store_true\\\\\\\",\\\\n        help=\\\\\\\"Print detailed progress information to stderr\\\\\\\"\\\\n    )\\\\n    \\\\n    args = parser.parse_args()\\\\n    \\\\n    try:\\\\n        repo_path = Path(args.path).resolve()\\\\n        if not repo_path.exists():\\\\n            print(f\\\\\\\"Error: Path {repo_path} does not exist\\\\\\\", file=sys.stderr)\\\\n            sys.exit(1)\\\\n            \\\\n        # Get repository information\\\\n        log_verbose(f\\\\\\\"Analyzing repository: {repo_path}\\\\\\\", args.verbose)\\\\n        repo_info = get_git_info(repo_path)\\\\n        \\\\n        # Discover files\\\\n        log_verbose(f\\\\\\\"Discovering files in: {repo_path}\\\\\\\", args.verbose)\\\\n        discovered_files = discover_files([repo_path], repo_path, [], [])\\\\n        log_verbose(f\\\\\\\"Found {len(discovered_files)} files\\\\\\\", args.verbose)\\\\n        \\\\n        # will check the file in last 7 days\\\\n        recent_files_info = {}\\\\n        if args.recent:\\\\n            seven_days_ago = datetime.now() - timedelta(days=7)\\\\n            recent_files = []\\\\n            for f in discovered_files:\\\\n                try:\\\\n                    mtime = datetime.fromtimestamp(f.stat().st_mtime)\\\\n                    if mtime >= seven_days_ago:\\\\n                        recent_files.append(f)\\\\n                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)     \\\\n                except Exception:\\\\n                    continue\\\\n            discovered_files = recent_files\\\\n        \\\\n        # Read file contents\\\\n        files_data = {}\\\\n        file_sizes = {}\\\\n        for file_path in discovered_files:\\\\n            try:\\\\n                relative_path_str, content, file_size = process_file(file_path, repo_path, args.verbose)\\\\n                files_data[relative_path_str] = content\\\\n                file_sizes[relative_path_str] = file_size\\\\n            except Exception:\\\\n                continue\\\\n        \\\\n        # Create tree view\\\\n        log_verbose(\\\\\\\"Generating directory tree\\\\\\\", args.verbose)\\\\n        tree_text = create_tree_view(repo_path, files_data)\\\\n        \\\\n        # Count totals\\\\n        total_files = len(files_data)\\\\n        total_lines = sum(len(content.splitlines()) for _, content in files_data.items())\\\\n        \\\\n        # Render based on format\\\\n        log_verbose(f\\\\\\\"Rendering output in {args.format} format\\\\\\\", args.verbose)\\\\n        content = get_rendered_content(\\\\n            args.format, str(repo_path), repo_info, tree_text,\\\\n            files_data, total_files, total_lines,\\\\n            recent_files_info if args.recent else {},\\\\n            file_sizes\\\\n        )\\\\n        \\\\n        handle_output(content, args.output)\\\\n        \\\\n    except Exception as e:\\\\n        print(f\\\\\\\"Error: {e}\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\n# this will convert age and give us the difference\\\\ndef human_readable_age(mtime: datetime) -> str:\\\\n    delta = datetime.now() - mtime\\\\n    days = delta.days\\\\n    seconds = delta.seconds\\\\n    if days > 0:\\\\n        return f\\\\\\\"{days} day{'s' if days != 1 else ''} ago\\\\\\\"\\\\n    elif seconds >= 3600:\\\\n        hours = seconds // 3600\\\\n        return f\\\\\\\"{hours} hour{'s' if hours != 1 else ''} ago\\\\\\\"\\\\n    elif seconds >= 60:\\\\n        minutes = seconds // 60\\\\n        return f\\\\\\\"{minutes} minute{'s' if minutes != 1 else ''} ago\\\\\\\"\\\\n    else:\\\\n        return \\\\\\\"just now\\\\\\\"\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\\n\\\",\\n    \\\"src/rcpack/config_loader.py\\\": \\\"# src/rcpack/config_loader.py\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nTOML config loader for Repo-Contextor.\\\\n\\\\nRules:\\\\n- Look for .repo-contextor.toml in the CURRENT directory\\\\n- If missing: ignore\\\\n- If present but invalid: print a clear error and exit(1)\\\\n- Only recognized keys are applied; unknown keys ignored\\\\n- Precedence: CLI > TOML > DEFAULTS\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nfrom __future__ import annotations\\\\nimport os, sys\\\\nfrom typing import Dict, Iterable, Any\\\\n\\\\ntry:\\\\n    import tomllib\\\\n    _loads = tomllib.loads\\\\nexcept ModuleNotFoundError:\\\\n    try:\\\\n        import tomli\\\\n        _loads = tomli.loads\\\\n    except ModuleNotFoundError:\\\\n        _loads = None\\\\n\\\\ndef _need_toml():\\\\n    if _loads is None:\\\\n        print(\\\\\\\"Error: TOML parser not available. Use Python 3.11+ or `pip install tomli`.\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\ndef _load_toml(dotfile: str) -> Dict[str, Any]:\\\\n    _need_toml()\\\\n    if not os.path.exists(dotfile):\\\\n        return {}\\\\n    try:\\\\n        with open(dotfile, \\\\\\\"rb\\\\\\\") as f:\\\\n            raw = f.read().decode(\\\\\\\"utf-8\\\\\\\", errors=\\\\\\\"strict\\\\\\\")\\\\n        data = _loads(raw)\\\\n        return data if isinstance(data, dict) else {}\\\\n    except Exception as e:\\\\n        print(f\\\\\\\"Error: failed to parse {dotfile} as TOML.\\\\\\\\n{e}\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\\\n    ks = set(known)\\\\n    return {k: v for k, v in d.items() if k in ks}\\\\n\\\\ndef _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\\\n    ks = set(known)\\\\n    out: Dict[str, Any] = {k: defaults.get(k) for k in ks}\\\\n    for src in (filecfg, clicfg):\\\\n        for k, v in src.items():\\\\n            if k in ks and v is not None:\\\\n                out[k] = v\\\\n    return out\\\\n\\\\ndef load_config(*, dotfile: str = \\\\\\\".repo-contextor.toml\\\\\\\", defaults: Dict[str, Any] | None = None, cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ()) -> Dict[str, Any]:\\\\n    defaults = defaults or {}\\\\n    cli_cfg = cli_cfg or {}\\\\n    known = tuple(known_keys)\\\\n    filecfg = _filter_known(_load_toml(dotfile), known)\\\\n    return _merge(defaults, filecfg, cli_cfg, known)\\\\n\\\",\\n    \\\"src/rcpack/discover.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"File discovery module for repository analysis.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom pathlib import Path\\\\nfrom typing import List\\\\nimport fnmatch\\\\n\\\\n\\\\ndef discover_files(\\\\n    inputs: List[Path],\\\\n    root: Path,\\\\n    include_patterns: List[str],\\\\n    exclude_patterns: List[str],\\\\n) -> List[Path]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Discover relevant files.\\\\n\\\\n    - inputs: list of files/dirs to scan\\\\n    - root: common project root; patterns are matched against POSIX paths relative to root\\\\n    - include_patterns: glob patterns to include (if empty, use sensible defaults)\\\\n    - exclude_patterns: glob patterns to exclude\\\\n    Returns a list of absolute Paths to files.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    default_include_exts = {\\\\n        '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\\\\n        '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\\\n        '.html', '.css', '.scss', '.sass', '.less', '.vue', '.svelte',\\\\n        '.md', '.txt', '.rst', '.yaml', '.yml', '.json', '.toml', '.ini',\\\\n        '.cfg', '.conf', '.xml', '.sql', '.sh', '.bash', '.zsh', '.fish',\\\\n    }\\\\n\\\\n    always_include_names = {\\\\n        'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING', 'Makefile',\\\\n        'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\\\\n        'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\\\n    }\\\\n\\\\n    skip_dir_names = {\\\\n        '.git', '.svn', '.hg', '__pycache__', '.pytest_cache',\\\\n        'node_modules', '.venv', 'venv', 'env', '.env',\\\\n        'build', 'dist', 'target', 'out', '.next', '.nuxt',\\\\n        '.idea', '.vscode', '.vs', 'coverage', '.coverage'\\\\n    }\\\\n\\\\n    def matches_any(patterns: List[str], rel_posix: str) -> bool:\\\\n        return any(fnmatch.fnmatch(rel_posix, pat) for pat in patterns)\\\\n\\\\n    def should_take(file_path: Path) -> bool:\\\\n        rel_posix = file_path.relative_to(root).as_posix()\\\\n        if exclude_patterns and matches_any(exclude_patterns, rel_posix):\\\\n            return False\\\\n        if include_patterns:\\\\n            return matches_any(include_patterns, rel_posix)\\\\n        # default include logic\\\\n        return file_path.name in always_include_names or file_path.suffix.lower() in default_include_exts\\\\n\\\\n    discovered: list[Path] = []\\\\n    seen = set()\\\\n\\\\n    for item in inputs:\\\\n        p = item.resolve()\\\\n        if p.is_file():\\\\n            # Skip if excluded or in skipped directory\\\\n            if any(part in skip_dir_names for part in p.parts):\\\\n                continue\\\\n            if should_take(p):\\\\n                key = p.as_posix()\\\\n                if key not in seen:\\\\n                    seen.add(key)\\\\n                    discovered.append(p)\\\\n        elif p.is_dir():\\\\n            for child in p.rglob('*'):\\\\n                if not child.is_file():\\\\n                    continue\\\\n                if any(part in skip_dir_names for part in child.parts):\\\\n                    continue\\\\n                if should_take(child):\\\\n                    key = child.resolve().as_posix()\\\\n                    if key not in seen:\\\\n                        seen.add(key)\\\\n                        discovered.append(child.resolve())\\\\n\\\\n    return sorted(discovered)\\\",\\n    \\\"src/rcpack/gitinfo.py\\\": \\\"from __future__ import annotations\\\\n\\\\nimport subprocess\\\\nfrom pathlib import Path\\\\nfrom typing import Dict, Any\\\\n\\\\n\\\\ndef _git(cmd: list[str], cwd: Path) -> str:\\\\n    # Validate git commands to prevent injection\\\\n    allowed_commands = {\\\\n        \\\\\\\"rev-parse\\\\\\\", \\\\\\\"show\\\\\\\", \\\\\\\"log\\\\\\\", \\\\\\\"status\\\\\\\", \\\\\\\"branch\\\\\\\", \\\\\\\"config\\\\\\\"\\\\n    }\\\\n    if not cmd or cmd[0] not in allowed_commands:\\\\n        raise ValueError(f\\\\\\\"Git command not allowed: {cmd[0] if cmd else 'empty'}\\\\\\\")\\\\n    \\\\n    out = subprocess.check_output([\\\\\\\"git\\\\\\\", *cmd], cwd=str(cwd), timeout=30)\\\\n    return out.decode(\\\\\\\"utf-8\\\\\\\", errors=\\\\\\\"replace\\\\\\\").strip()\\\\n\\\\n\\\\ndef is_git_repo(path: Path) -> bool:\\\\n    try:\\\\n        flag = _git([\\\\\\\"rev-parse\\\\\\\", \\\\\\\"--is-inside-work-tree\\\\\\\"], cwd=path)\\\\n        return flag == \\\\\\\"true\\\\\\\"\\\\n    except Exception:\\\\n        return False\\\\n\\\\n\\\\ndef get_git_info(path: Path) -> Dict[str, Any]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Return info for the current HEAD of a repo rooted at `path`.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        commit = _git([\\\\\\\"rev-parse\\\\\\\", \\\\\\\"HEAD\\\\\\\"], cwd=path)\\\\n        branch = _git([\\\\\\\"rev-parse\\\\\\\", \\\\\\\"--abbrev-ref\\\\\\\", \\\\\\\"HEAD\\\\\\\"], cwd=path)\\\\n        author = _git([\\\\\\\"show\\\\\\\", \\\\\\\"-s\\\\\\\", \\\\\\\"--format=%an <%ae>\\\\\\\"], cwd=path)\\\\n        date = _git([\\\\\\\"show\\\\\\\", \\\\\\\"-s\\\\\\\", \\\\\\\"--date=local\\\\\\\", \\\\\\\"--format=%ad\\\\\\\"], cwd=path)\\\\n        return {\\\\n            \\\\\\\"is_repo\\\\\\\": True,\\\\n            \\\\\\\"commit\\\\\\\": commit,\\\\n            \\\\\\\"branch\\\\\\\": branch,\\\\n            \\\\\\\"author\\\\\\\": author,\\\\n            \\\\\\\"date\\\\\\\": date,\\\\n            \\\\\\\"note\\\\\\\": None,\\\\n        }\\\\n    except Exception:\\\\n        # treat as not a repo if anything fails\\\\n        return {\\\\n            \\\\\\\"is_repo\\\\\\\": False,\\\\n            \\\\\\\"commit\\\\\\\": None,\\\\n            \\\\\\\"branch\\\\\\\": None,\\\\n            \\\\\\\"author\\\\\\\": None,\\\\n            \\\\\\\"date\\\\\\\": None,\\\\n            \\\\\\\"note\\\\\\\": \\\\\\\"Not a git repository\\\\\\\",\\\\n        }\\\\n\\\",\\n    \\\"src/rcpack/io_utils.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"I/O utilities for file operations.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom pathlib import Path\\\\nfrom typing import Tuple\\\\n\\\\n\\\\ndef write_output(output_path: str, content: str) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Write content to output file.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    output_file = Path(output_path)\\\\n    \\\\n    # Create parent directories if they don't exist\\\\n    output_file.parent.mkdir(parents=True, exist_ok=True)\\\\n    \\\\n    # Write content\\\\n    with open(output_file, 'w', encoding='utf-8') as f:\\\\n        f.write(content)\\\\n\\\\n\\\\ndef is_binary_file(path: Path, sniff_bytes: int = 2048) -> bool:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Heuristically determine if a file is binary by scanning for NUL bytes.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        with open(path, 'rb') as fb:\\\\n            chunk = fb.read(sniff_bytes)\\\\n        if b\\\\\\\"\\\\\\\\x00\\\\\\\" in chunk:\\\\n            return True\\\\n        # If the chunk has a lot of non-text bytes, consider it binary\\\\n        text_byte_count = sum(32 <= b <= 126 or b in (9, 10, 13) for b in chunk)\\\\n        return (len(chunk) - text_byte_count) > max(1, len(chunk) // 3)\\\\n    except Exception:\\\\n        # If we cannot read, treat as binary to avoid further processing\\\\n        return True\\\\n\\\\n\\\\ndef read_text_safely(path: Path, max_bytes: int = 16_384) -> Tuple[str, str, bool]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Read a text file safely with size limit and encoding fallbacks.\\\\n\\\\n    Returns (content, encoding_used, truncated).\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    truncated = False\\\\n    raw: bytes\\\\n    with open(path, 'rb') as fb:\\\\n        raw = fb.read(max_bytes + 1)\\\\n    if len(raw) > max_bytes:\\\\n        truncated = True\\\\n        raw = raw[:max_bytes]\\\\n\\\\n    for enc in (\\\\\\\"utf-8\\\\\\\", \\\\\\\"utf-16\\\\\\\", \\\\\\\"utf-16-le\\\\\\\", \\\\\\\"utf-16-be\\\\\\\", \\\\\\\"latin-1\\\\\\\"):\\\\n        try:\\\\n            text = raw.decode(enc)\\\\n            return text, enc, truncated\\\\n        except Exception:\\\\n            continue\\\\n    # Fallback: replace errors with utf-8\\\\n    text = raw.decode(\\\\\\\"utf-8\\\\\\\", errors=\\\\\\\"replace\\\\\\\")\\\\n    return text, \\\\\\\"utf-8\\\\\\\", truncated\\\",\\n    \\\"src/rcpack/packager.py\\\": \\\"from __future__ import annotations\\\\n\\\\nimport sys\\\\nfrom pathlib import Path\\\\nfrom typing import Iterable, Tuple\\\\n\\\\nfrom rcpack.discover import discover_files\\\\nfrom rcpack.gitinfo import get_git_info, is_git_repo\\\\nfrom rcpack.io_utils import read_text_safely, is_binary_file\\\\nfrom rcpack.renderer import markdown as md_renderer\\\\nfrom rcpack.renderer.jsonyaml import render_json, render_yaml\\\\nfrom rcpack.treeview import render_tree\\\\n\\\\n\\\\ndef _find_root(inputs: list[str]) -> Path:\\\\n    paths = [Path(p) for p in inputs]\\\\n    if len(paths) == 1 and Path(paths[0]).is_dir():\\\\n        return paths[0].resolve()\\\\n    parents = [p if p.is_dir() else p.parent for p in paths]\\\\n    root = Path(*Path.commonpath([str(p.resolve()) for p in parents]).split(\\\\\\\"/\\\\\\\"))\\\\n    return root.resolve()\\\\n\\\\n\\\\ndef build_package(\\\\n    inputs: list[str],\\\\n    include_patterns: list[str] | None,\\\\n    exclude_patterns: list[str] | None,\\\\n    max_file_bytes: int,\\\\n    fmt: str = \\\\\\\"markdown\\\\\\\",\\\\n) -> Tuple[str, dict]:\\\\n    root = _find_root(inputs)\\\\n    root_abs = root.resolve()\\\\n\\\\n    repo_info = (\\\\n        get_git_info(root_abs) if is_git_repo(root_abs) else {\\\\n            \\\\\\\"is_repo\\\\\\\": False,\\\\n            \\\\\\\"commit\\\\\\\": None,\\\\n            \\\\\\\"branch\\\\\\\": None,\\\\n            \\\\\\\"author\\\\\\\": None,\\\\n            \\\\\\\"date\\\\\\\": None,\\\\n            \\\\\\\"note\\\\\\\": \\\\\\\"Not a git repository\\\\\\\",\\\\n        }\\\\n    )\\\\n\\\\n    files = discover_files(\\\\n        inputs=[Path(p) for p in inputs],\\\\n        root=root_abs,\\\\n        include_patterns=include_patterns or [],\\\\n        exclude_patterns=exclude_patterns or [],\\\\n    )\\\\n    rel_files = [f.relative_to(root_abs) for f in files]\\\\n\\\\n    project_tree = render_tree([p.as_posix() for p in rel_files])\\\\n\\\\n    file_sections: list[dict] = []\\\\n    total_lines = 0\\\\n    total_chars = 0\\\\n\\\\n    for f in files:\\\\n        rel = f.relative_to(root_abs).as_posix()\\\\n        try:\\\\n            if is_binary_file(f):\\\\n                content = f\\\\\\\"[binary file skipped: {f.name}, {f.stat().st_size} bytes]\\\\\\\"\\\\n                file_sections.append({\\\\n                    \\\\\\\"path\\\\\\\": rel,\\\\n                    \\\\\\\"language\\\\\\\": _language_from_ext(f.suffix),\\\\n                    \\\\\\\"content\\\\\\\": content,\\\\n                    \\\\\\\"is_truncated\\\\\\\": False,\\\\n                })\\\\n                total_chars += len(content)\\\\n                continue\\\\n\\\\n            content, used_encoding, truncated = read_text_safely(f, max_bytes=max_file_bytes)\\\\n            total_lines += content.count(\\\\\\\"\\\\\\\\n\\\\\\\") + (1 if content and not content.endswith(\\\\\\\"\\\\\\\\n\\\\\\\") else 0)\\\\n            total_chars += len(content)\\\\n\\\\n            if truncated:\\\\n                note = f\\\\\\\"\\\\\\\\n\\\\\\\\n[... TRUNCATED to first {max_file_bytes} bytes ...]\\\\\\\"\\\\n                content = content + note\\\\n                total_chars += len(note)\\\\n\\\\n            file_sections.append({\\\\n                \\\\\\\"path\\\\\\\": rel,\\\\n                \\\\\\\"language\\\\\\\": _language_from_ext(f.suffix),\\\\n                \\\\\\\"content\\\\\\\": content,\\\\n                \\\\\\\"is_truncated\\\\\\\": truncated,\\\\n            })\\\\n        except Exception as exc:\\\\n            print(f\\\\\\\"[rcpack] error reading {rel}: {exc}\\\\\\\", file=sys.stderr)\\\\n            continue\\\\n\\\\n    # render in chosen format\\\\n    if fmt == \\\\\\\"markdown\\\\\\\":\\\\n        out_text = md_renderer.render_markdown(\\\\n            root=str(root_abs),\\\\n            repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n            files=file_sections,\\\\n            total_files=len(file_sections),\\\\n            total_lines=total_lines,\\\\n        )\\\\n    elif fmt == \\\\\\\"json\\\\\\\":\\\\n        out_text = render_json(\\\\n            root=str(root_abs),\\\\n            repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n            files=file_sections,\\\\n            total_files=len(file_sections),\\\\n            total_lines=total_lines,\\\\n        )\\\\n    elif fmt == \\\\\\\"yaml\\\\\\\":\\\\n        out_text = render_yaml(\\\\n            root=str(root_abs),\\\\n            repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n            files=file_sections,\\\\n            total_files=len(file_sections),\\\\n            total_lines=total_lines,\\\\n        )\\\\n    else:\\\\n        raise ValueError(f\\\\\\\"Unsupported format: {fmt}\\\\\\\")\\\\n\\\\n    stats = {\\\\\\\"files\\\\\\\": len(file_sections), \\\\\\\"lines\\\\\\\": total_lines, \\\\\\\"chars\\\\\\\": total_chars}\\\\n    return out_text, stats\\\\n\\\\n\\\\ndef _language_from_ext(ext: str) -> str:\\\\n    ext = ext.lower().lstrip(\\\\\\\".\\\\\\\")\\\\n    mapping = {\\\\n        \\\\\\\"py\\\\\\\": \\\\\\\"python\\\\\\\", \\\\\\\"js\\\\\\\": \\\\\\\"javascript\\\\\\\", \\\\\\\"ts\\\\\\\": \\\\\\\"typescript\\\\\\\",\\\\n        \\\\\\\"json\\\\\\\": \\\\\\\"json\\\\\\\", \\\\\\\"md\\\\\\\": \\\\\\\"markdown\\\\\\\", \\\\\\\"yml\\\\\\\": \\\\\\\"yaml\\\\\\\", \\\\\\\"yaml\\\\\\\": \\\\\\\"yaml\\\\\\\",\\\\n        \\\\\\\"toml\\\\\\\": \\\\\\\"toml\\\\\\\", \\\\\\\"sh\\\\\\\": \\\\\\\"bash\\\\\\\", \\\\\\\"c\\\\\\\": \\\\\\\"c\\\\\\\", \\\\\\\"cpp\\\\\\\": \\\\\\\"cpp\\\\\\\",\\\\n        \\\\\\\"java\\\\\\\": \\\\\\\"java\\\\\\\", \\\\\\\"go\\\\\\\": \\\\\\\"go\\\\\\\", \\\\\\\"rs\\\\\\\": \\\\\\\"rust\\\\\\\",\\\\n    }\\\\n    return mapping.get(ext, \\\\\\\"\\\\\\\")\\\\n\\\",\\n    \\\"src/rcpack/renderer/jsonyaml.py\\\": \\\"from __future__ import annotations\\\\nimport json\\\\n\\\\ntry:\\\\n    import yaml\\\\nexcept ImportError:\\\\n    yaml = None\\\\n\\\\n\\\\ndef render_json(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\\\\n    data = {\\\\n        \\\\\\\"root\\\\\\\": root,\\\\n        \\\\\\\"repo_info\\\\\\\": repo_info,\\\\n        \\\\\\\"structure\\\\\\\": tree_text,\\\\n        \\\\\\\"recent_changes\\\\\\\": recent_files or [],\\\\n        \\\\\\\"files\\\\\\\": files,\\\\n        \\\\\\\"file_sizes\\\\\\\": file_sizes or {},\\\\n        \\\\\\\"summary\\\\\\\": {\\\\\\\"total_files\\\\\\\": total_files, \\\\\\\"total_lines\\\\\\\": total_lines},\\\\n        \\\\n    }\\\\n    return json.dumps(data, indent=2, ensure_ascii=False)\\\\n\\\\n\\\\ndef render_yaml(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\\\\n    if yaml is None:\\\\n        raise RuntimeError(\\\\\\\"PyYAML not installed; run `pip install pyyaml`\\\\\\\")\\\\n    data = {\\\\n        \\\\\\\"root\\\\\\\": root,\\\\n        \\\\\\\"repo_info\\\\\\\": repo_info,\\\\n        \\\\\\\"structure\\\\\\\": tree_text,\\\\n        \\\\\\\"recent_changes\\\\\\\": recent_files or [],\\\\n        \\\\\\\"files\\\\\\\": files,\\\\n        \\\\\\\"file_sizes\\\\\\\": file_sizes or {},\\\\n        \\\\\\\"summary\\\\\\\": {\\\\\\\"total_files\\\\\\\": total_files, \\\\\\\"total_lines\\\\\\\": total_lines},\\\\n        \\\\n    }\\\\n    return yaml.safe_dump(data, sort_keys=False, allow_unicode=True)\\\\n\\\",\\n    \\\"src/rcpack/renderer/markdown.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Markdown renderer for repository context.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom typing import Dict, Any\\\\n\\\\n\\\\ndef render_markdown(root: str, repo_info: Dict[str, Any], tree_text: str, \\\\n                   files: Dict[str, str], total_files: int, total_lines: int, recent_files=None, file_sizes=None) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Render repository context as markdown.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    lines = []\\\\n    \\\\n    # Header\\\\n    lines.append(f\\\\\\\"# Repository Context: {root}\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Repository info\\\\n    if repo_info.get(\\\\\\\"is_repo\\\\\\\"):\\\\n        lines.append(\\\\\\\"## Git Repository Information\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Branch**: {repo_info.get('branch', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Commit**: {repo_info.get('commit', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Author**: {repo_info.get('author', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Date**: {repo_info.get('date', 'N/A')}\\\\\\\")\\\\n    else:\\\\n        lines.append(\\\\\\\"## Repository Information\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Note**: {repo_info.get('note', 'Not a git repository')}\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Summary\\\\n    lines.append(\\\\\\\"## Summary\\\\\\\")\\\\n    lines.append(f\\\\\\\"- **Total Files**: {total_files}\\\\\\\")\\\\n    lines.append(f\\\\\\\"- **Total Lines**: {total_lines}\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Directory structure\\\\n    lines.append(\\\\\\\"## Directory Structure\\\\\\\")\\\\n    lines.append(\\\\\\\"```\\\\\\\")\\\\n    lines.append(tree_text)\\\\n    lines.append(\\\\\\\"```\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n\\\\n    # will produce recent files \\\\n    # Recent files (fixed)\\\\n    if recent_files:\\\\n        lines.append(\\\\\\\"## Recent Changes\\\\\\\")\\\\n        for file, age in recent_files.items():\\\\n            lines.append(f\\\\\\\"- {file} (modified {age})\\\\\\\")\\\\n        lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # File contents\\\\n    lines.append(\\\\\\\"## File Contents\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    for file_path, content in sorted(files.items()):\\\\n        if file_sizes and file_path in file_sizes:\\\\n            size_bytes = file_sizes[file_path]\\\\n            lines.append(f\\\\\\\"### {file_path} ({size_bytes} bytes)\\\\\\\")\\\\n        else:\\\\n            lines.append(f\\\\\\\"### {file_path}\\\\\\\")\\\\n        lines.append(\\\\\\\"\\\\\\\")\\\\n        \\\\n        # Detect language for syntax highlighting\\\\n        ext = file_path.split('.')[-1].lower() if '.' in file_path else ''\\\\n        lang_map = {\\\\n            'py': 'python', 'js': 'javascript', 'ts': 'typescript',\\\\n            'java': 'java', 'cpp': 'cpp', 'c': 'c', 'h': 'c',\\\\n            'cs': 'csharp', 'php': 'php', 'rb': 'ruby',\\\\n            'go': 'go', 'rs': 'rust', 'swift': 'swift',\\\\n            'html': 'html', 'css': 'css', 'scss': 'scss',\\\\n            'json': 'json', 'yaml': 'yaml', 'yml': 'yaml',\\\\n            'xml': 'xml', 'sql': 'sql', 'sh': 'bash',\\\\n            'md': 'markdown', 'dockerfile': 'dockerfile'\\\\n        }\\\\n        \\\\n        language = lang_map.get(ext, '')\\\\n        lines.append(f\\\\\\\"```{language}\\\\\\\")\\\\n        lines.append(content)\\\\n        lines.append(\\\\\\\"```\\\\\\\")\\\\n        lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    return \\\\\\\"\\\\\\\\n\\\\\\\".join(lines)\\\\n\\\",\\n    \\\"src/rcpack/treeview.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Tree view generation for repository structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom pathlib import Path\\\\nfrom typing import Dict, List\\\\n\\\\n\\\\ndef create_tree_view(repo_path: Path, files_data: Dict[str, str]) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create a tree view of the repository structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    paths = list(files_data.keys())\\\\n    return render_tree(paths)\\\\n\\\\n\\\\ndef render_tree(paths: List[str]) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Render a tree view from a list of relative POSIX paths.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    tree_structure: dict = {}\\\\n\\\\n    for p in paths:\\\\n        parts = Path(p).parts\\\\n        current = tree_structure\\\\n        for part in parts[:-1]:\\\\n            if part not in current:\\\\n                current[part] = {}\\\\n            current = current[part]\\\\n        if parts:\\\\n            current[parts[-1]] = None\\\\n\\\\n    def _render(structure: dict, prefix: str = \\\\\\\"\\\\\\\") -> str:\\\\n        lines = []\\\\n        items = sorted(structure.items(), key=lambda x: (x[1] is None, x[0]))\\\\n        for i, (name, subtree) in enumerate(items):\\\\n            is_last = i == len(items) - 1\\\\n            lines.append(f\\\\\\\"{prefix}{'└── ' if is_last else '├── '}{name}\\\\\\\")\\\\n            if subtree is not None:\\\\n                extension = (\\\\\\\"    \\\\\\\" if is_last else \\\\\\\"│   \\\\\\\")\\\\n                lines.append(_render(subtree, prefix + extension))\\\\n        return \\\\\\\"\\\\\\\\n\\\\\\\".join(filter(None, lines))\\\\n\\\\n    if not tree_structure:\\\\n        return \\\\\\\"No files found\\\\\\\"\\\\n    return _render(tree_structure)\\\"\\n  },\\n  \\\"file_sizes\\\": {\\n    \\\"LICENSE\\\": \\\"1064\\\",\\n    \\\"README.md\\\": \\\"11164\\\",\\n    \\\"pyproject.toml\\\": \\\"361\\\",\\n    \\\"src/rcpack/__init__.py\\\": \\\"198\\\",\\n    \\\"src/rcpack/__main__.py\\\": \\\"197\\\",\\n    \\\"src/rcpack/cli.py\\\": \\\"7087\\\",\\n    \\\"src/rcpack/config_loader.py\\\": \\\"2099\\\",\\n    \\\"src/rcpack/discover.py\\\": \\\"3067\\\",\\n    \\\"src/rcpack/gitinfo.py\\\": \\\"1653\\\",\\n    \\\"src/rcpack/io_utils.py\\\": \\\"1817\\\",\\n    \\\"src/rcpack/packager.py\\\": \\\"4430\\\",\\n    \\\"src/rcpack/renderer/jsonyaml.py\\\": \\\"1176\\\",\\n    \\\"src/rcpack/renderer/markdown.py\\\": \\\"2829\\\",\\n    \\\"src/rcpack/treeview.py\\\": \\\"1371\\\"\\n  },\\n  \\\"summary\\\": {\\n    \\\"total_files\\\": 14,\\n    \\\"total_lines\\\": 1180\\n  }\\n}\",\n    \"test-yaml.yaml\": \"root: /Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\\nrepo_info:\\n  is_repo: true\\n  commit: 682153b169db66d3a72e9cabdd1f3448a3b2986d\\n  branch: refactoring\\n  author: Abhinav <abhinavbhardwaj2002@gmail.com>\\n  date: Fri Oct 3 18:45:48 2025\\n  note: null\\nstructure: '├── src\\n\\n  │   └── rcpack\\n\\n  │       ├── renderer\\n\\n  │       │   ├── jsonyaml.py\\n\\n  │       │   └── markdown.py\\n\\n  │       ├── __init__.py\\n\\n  │       ├── __main__.py\\n\\n  │       ├── cli.py\\n\\n  │       ├── config_loader.py\\n\\n  │       ├── discover.py\\n\\n  │       ├── gitinfo.py\\n\\n  │       ├── io_utils.py\\n\\n  │       ├── packager.py\\n\\n  │       └── treeview.py\\n\\n  ├── LICENSE\\n\\n  ├── README.md\\n\\n  ├── pyproject.toml\\n\\n  └── test-output.json'\\nrecent_changes: []\\nfiles:\\n  LICENSE: 'MIT License\\n\\n\\n    Copyright (c) 2025 Abhinav\\n\\n\\n    Permission is hereby granted, free of charge, to any person obtaining a copy\\n\\n    of this software and associated documentation files (the \\\"Software\\\"), to deal\\n\\n    in the Software without restriction, including without limitation the rights\\n\\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\n\\n    copies of the Software, and to permit persons to whom the Software is\\n\\n    furnished to do so, subject to the following conditions:\\n\\n\\n    The above copyright notice and this permission notice shall be included in all\\n\\n    copies or substantial portions of the Software.\\n\\n\\n    THE SOFTWARE IS PROVIDED \\\"AS IS\\\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\n\\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\n\\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\n\\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\n\\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\n\\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\n\\n    SOFTWARE.\\n\\n    '\\n  README.md: \\\"# Repo-Contextor\\\\n\\\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\\\n\\\\\\n    [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\\\n\\\\\\n    \\\\nA powerful Repository Context Packager CLI tool that analyzes local git repositories\\\\\\n    \\\\ and creates comprehensive text files containing repository content optimized\\\\\\n    \\\\ for sharing with Large Language Models (LLMs).\\\\n\\\\n## Overview\\\\n\\\\nWhen developers\\\\\\n    \\\\ want to get help from ChatGPT, Claude, or other LLMs about their code, they\\\\\\n    \\\\ often struggle with how to share their codebase effectively. Common problems\\\\\\n    \\\\ include:\\\\n\\\\n- **Lost Context**: Copy-pasting individual files loses important\\\\\\n    \\\\ project structure and relationships\\\\n- **Missing Dependencies**: LLMs can't\\\\\\n    \\\\ see how files connect or what libraries are used\\\\n- **Incomplete Picture**:\\\\\\n    \\\\ Hard to convey the overall architecture and organization\\\\n- **Manual Work**:\\\\\\n    \\\\ Time-consuming to gather and format relevant code\\\\n\\\\n**Repo-Contextor** solves\\\\\\n    \\\\ this by automatically collecting and formatting repository content into a single,\\\\\\n    \\\\ well-structured text file that provides rich context to LLMs, enabling them\\\\\\n    \\\\ to give much better assistance with your code.\\\\n\\\\n## Features\\\\n\\\\n- **Git Integration**:\\\\\\n    \\\\ Extracts commit SHA, branch, author, and date information\\\\n- **Project Structure**:\\\\\\n    \\\\ Generates a clear directory tree visualization\\\\n- **File Content Packaging**:\\\\\\n    \\\\ Includes file contents with syntax highlighting\\\\n- **Smart File Discovery**:\\\\\\n    \\\\ Recursively scans directories with intelligent filtering\\\\n- **Binary File Detection**:\\\\\\n    \\\\ Automatically skips binary files\\\\n- **Error Handling**: Gracefully handles permission\\\\\\n    \\\\ errors and provides helpful messages\\\\n- **Multiple Output Formats**: Supports\\\\\\n    \\\\ Markdown, JSON, and YAML formats\\\\n- **Flexible Output**: Write to stdout or\\\\\\n    \\\\ save to a file\\\\n- **Recent Changes Filter**: Give the files which are updated\\\\\\n    \\\\ in last 7days with the time when it was recently modified.\\\\n\\\\n## Installation\\\\n\\\\\\n    \\\\n### Prerequisites\\\\n\\\\n- Python 3.9 or higher\\\\n- Git (for git repository analysis)\\\\n\\\\\\n    \\\\n### For End Users\\\\n\\\\n```bash\\\\n# Clone and install\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\n\\\\\\n    cd Repo-Contextor\\\\npip install -e .\\\\n```\\\\n\\\\n### For Contributors & Local Development\\\\n\\\\\\n    \\\\n```bash\\\\n# Clone the repository\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\n\\\\\\n    cd Repo-Contextor\\\\n\\\\n# Create virtual environment\\\\npython -m venv .venv\\\\nsource\\\\\\n    \\\\ .venv/bin/activate  # On Windows: .venv\\\\\\\\Scripts\\\\\\\\activate\\\\n\\\\n# Install in development\\\\\\n    \\\\ mode\\\\npip install -e .\\\\n```\\\\n\\\\n## Usage\\\\n\\\\n### Basic Examples\\\\n\\\\n```bash\\\\n#\\\\\\n    \\\\ Package current directory to terminal\\\\nrepo-contextor .\\\\n\\\\n# Package a specific\\\\\\n    \\\\ directory\\\\nrepo-contextor /path/to/your/project\\\\n\\\\n# Save output to a file\\\\n\\\\\\n    repo-contextor . -o my-project-context.md\\\\n\\\\n# Generate JSON format\\\\nrepo-contextor\\\\\\n    \\\\ . -f json -o context.json\\\\n\\\\n# Generate YAML format\\\\nrepo-contextor . -f yaml\\\\\\n    \\\\ -o context.yaml\\\\n\\\\n# Include only files modified in the last 7 days\\\\nrepo-contextor\\\\\\n    \\\\ . --recent\\\\n\\\\n# Combine with output file\\\\nrepo-contextor . --recent -o recent-changes.md\\\\n\\\\\\n    ```\\\\n\\\\n### Command Line Options\\\\n\\\\n| Option | Short | Description | Example |\\\\n\\\\\\n    |--------|-------|-------------|---------|\\\\n| `path` | - | Repository path to\\\\\\n    \\\\ analyze (default: current directory) | `repo-contextor /path/to/project` |\\\\n\\\\\\n    | `--output` | `-o` | Output file path (default: stdout) | `-o context.md` |\\\\n\\\\\\n    | `--format` | `-f` | Output format: text, json, yaml (default: text) | `-f json`\\\\\\n    \\\\ |\\\\n| `--help` | `-h` | Show help message | `-h` |\\\\n| `--recent`  | `-r`  | Include\\\\\\n    \\\\ only files modified in the last 7 days    | `repo-contextor . -r -o recent.md`\\\\\\n    \\\\ |\\\\n\\\\n### Advanced Examples\\\\n\\\\n```bash\\\\n# Analyze different repository\\\\nrepo-contextor\\\\\\n    \\\\ /path/to/other/project -o other-project.md\\\\n\\\\n# Generate JSON for API consumption\\\\n\\\\\\n    repo-contextor . -f json -o api-context.json\\\\n\\\\n# Create YAML configuration\\\\n\\\\\\n    repo-contextor . -f yaml -o project-config.yaml\\\\n\\\\n# Generate files which are\\\\\\n    \\\\ changed recently in 7 days\\\\nrepo-contextor . -r --output recent-changes.txt\\\\n\\\\\\n    \\\\n```\\\\n## Configuration via TOML\\\\n\\\\nRepo-Contextor supports configuration through\\\\\\n    \\\\ a `.repo-contextor.toml` file in the current working directory.  \\\\nThis file\\\\\\n    \\\\ allows you to avoid typing the same CLI arguments every time.\\\\n\\\\nExample `.repo-contextor.toml`:\\\\n\\\\\\n    \\\\n```toml\\\\n# Output file to write results\\\\noutput = \\\\\\\"context.yaml\\\\\\\"\\\\n\\\\n# Output\\\\\\n    \\\\ format: text, json, or yaml\\\\nformat = \\\\\\\"yaml\\\\\\\"\\\\n\\\\n# Limit to files modified\\\\\\n    \\\\ in the last 7 days\\\\nrecent = true\\\\n\\\\n# Repository path to analyze (default =\\\\\\n    \\\\ current directory)\\\\npath = \\\\\\\".\\\\\\\"\\\\n```\\\\n### Rules\\\\n- If the `.repo-contextor.toml`\\\\\\n    \\\\ file is **missing**, the tool falls back to defaults.  \\\\n- If the file is **present\\\\\\n    \\\\ but invalid TOML**, the tool prints a clear error message and exits with status\\\\\\n    \\\\ code 1.  \\\\n- **Unknown keys** in the TOML file are ignored (safe for future\\\\\\n    \\\\ extensions).  \\\\n- **Precedence** of settings is:\\\\n  1. Command-line arguments\\\\\\n    \\\\ (highest priority)  \\\\n  2. Values from `.repo-contextor.toml`  \\\\n  3. Built-in\\\\\\n    \\\\ defaults (lowest priority)\\\\n     \\\\n## Output Format\\\\n\\\\nThe tool generates a\\\\\\n    \\\\ structured text file with the following sections:\\\\n\\\\n### 1. Repository Context\\\\\\n    \\\\ Header\\\\nProject path and identification\\\\n\\\\n### 2. Git Repository Information\\\\n\\\\\\n    - Current branch\\\\n- Latest commit SHA\\\\n- Last commit author\\\\n- Last commit date\\\\n\\\\\\n    \\\\n### 3. Summary Statistics\\\\n- Total number of files processed\\\\n- Total lines\\\\\\n    \\\\ of code\\\\n\\\\n### 4. Directory Structure\\\\nClean tree visualization showing project\\\\\\n    \\\\ organization\\\\n\\\\n### 5. Recent Changes (if `--recent` is used)\\\\n\\\\n- Lists files\\\\\\n    \\\\ modified in the last 7 days.\\\\n- Shows relative file paths along with how long\\\\\\n    \\\\ ago each file was modified\\\\n- Helps focus on recently updated parts of the project.\\\\n\\\\\\n    - Can be combined with `--output` or `--format` to save or change the output type.\\\\n\\\\\\n    \\\\n\\\\n### 5. File Contents\\\\nEach file's content with:\\\\n- Clear file path headers\\\\n\\\\\\n    - Appropriate syntax highlighting language tags\\\\n- Complete file contents\\\\n\\\\n\\\\\\n    ## Example Output\\\\n\\\\nWhen you run `repo-contextor .`, the output looks like this:\\\\n\\\\\\n    \\\\n````markdown\\\\n# Repository Context: /path/to/your/project\\\\n\\\\n## Git Repository\\\\\\n    \\\\ Information\\\\n- **Branch**: main\\\\n- **Commit**: a1b2c3d4e5f6789...\\\\n- **Author**:\\\\\\n    \\\\ John Doe <john@example.com>\\\\n- **Date**: Fri Sep 12 14:30:15 2025\\\\n\\\\n## Summary\\\\n\\\\\\n    - **Total Files**: 15\\\\n- **Total Lines**: 1,247\\\\n\\\\n## Directory Structure\\\\n```\\\\n\\\\\\n    ├── src/\\\\n│   ├── main.py\\\\n│   └── utils.py\\\\n├── tests/\\\\n│   └── test_main.py\\\\n\\\\\\n    ├── README.md\\\\n└── requirements.txt\\\\n```\\\\n## Recent Changes\\\\n- src/main.py (modified\\\\\\n    \\\\ 2 days ago)\\\\n- src/utils/helpers.py (modified 5 days ago)\\\\n\\\\n## File Contents\\\\n\\\\\\n    \\\\n### src/main.py\\\\n\\\\n```python\\\\ndef main():\\\\n    print(\\\\\\\"Hello, World!\\\\\\\")\\\\n\\\\n\\\\\\n    if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\\n```\\\\n\\\\n### README.md\\\\n\\\\n```markdown\\\\n\\\\\\n    # My Project\\\\nThis is a sample project.\\\\n```\\\\n\\\\n## Summary\\\\n- Total files: 15\\\\n\\\\\\n    - Total lines: 1,247\\\\n````\\\\n\\\\n## What Files Are Included\\\\n\\\\nThe tool includes\\\\\\n    \\\\ most text files but automatically excludes:\\\\n\\\\n### Excluded Directories\\\\n- `.git`,\\\\\\n    \\\\ `.svn`, `.hg` (version control)\\\\n- `__pycache__`, `.pytest_cache` (Python cache)\\\\n\\\\\\n    - `node_modules`, `.venv`, `venv` (dependencies/environments)\\\\n- `.vscode`, `.idea`\\\\\\n    \\\\ (IDE directories)\\\\n- `build`, `dist`, `target` (build directories)\\\\n\\\\n### File\\\\\\n    \\\\ Handling Rules\\\\n- **Text files**: All readable text files with common extensions\\\\n\\\\\\n    - **Binary files**: Automatically detected and skipped\\\\n- **Permission errors**:\\\\\\n    \\\\ Skipped with graceful handling\\\\n- **Configuration files**: Includes pyproject.toml,\\\\\\n    \\\\ package.json, etc.\\\\n\\\\n### Included File Types\\\\n- Source code: `.py`, `.js`,\\\\\\n    \\\\ `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\\\n- Web files: `.html`, `.css`,\\\\\\n    \\\\ `.scss`, `.vue`, `.jsx`, etc.\\\\n- Documentation: `.md`, `.txt`, `.rst`\\\\n- Configuration:\\\\\\n    \\\\ `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\\\n- Scripts: `.sh`, `.bash`, `.zsh`\\\\n\\\\\\n    \\\\n## Error Handling\\\\n\\\\nThe tool handles errors gracefully:\\\\n\\\\n| Error Type | Behavior\\\\\\n    \\\\ |\\\\n|------------|----------|\\\\n| **Permission errors** | Skipped with warning\\\\\\n    \\\\ |\\\\n| **Binary files** | Automatically detected and skipped |\\\\n| **Invalid paths**\\\\\\n    \\\\ | Clear error messages |\\\\n| **Non-git repositories** | Works fine, shows \\\\\\\"\\\\\\n    Not a git repository\\\\\\\" |\\\\n| **Unreadable files** | Marked as \\\\\\\"[Binary or unreadable\\\\\\n    \\\\ file]\\\\\\\" |\\\\n\\\\n## Development\\\\n\\\\n### Project Structure\\\\n\\\\n```text\\\\nRepo-Contextor/\\\\n\\\\\\n    ├── src/rcpack/              # Main package\\\\n│   ├── __init__.py         # Package\\\\\\n    \\\\ initialization\\\\n│   ├── cli.py              # Command-line interface\\\\n│   ├──\\\\\\n    \\\\ discover.py         # File discovery logic\\\\n│   ├── gitinfo.py          # Git\\\\\\n    \\\\ repository analysis\\\\n│   ├── treeview.py         # Directory tree generation\\\\n\\\\\\n    │   ├── packager.py         # Main orchestration\\\\n│   ├── io_utils.py        \\\\\\n    \\\\ # File I/O utilities\\\\n│   └── renderer/           # Output formatters\\\\n│   \\\\\\n    \\\\    ├── markdown.py     # Markdown renderer\\\\n│       └── jsonyaml.py     # JSON/YAML\\\\\\n    \\\\ renderers\\\\n├── pyproject.toml          # Project configuration\\\\n├── LICENSE\\\\\\n    \\\\                 # MIT License\\\\n└── README.md              # This documentation\\\\n\\\\\\n    ```\\\\n\\\\n### Running Tests\\\\n\\\\n```bash\\\\n# Test on current repository\\\\nrepo-contextor\\\\\\n    \\\\ . -o test-output.md\\\\n\\\\n# Test different formats\\\\nrepo-contextor . -f json |\\\\\\n    \\\\ head -20\\\\nrepo-contextor . -f yaml | head -20\\\\n\\\\n# Test specific directory\\\\n\\\\\\n    repo-contextor src/ -o src-only.md\\\\n```\\\\n\\\\n### Contributing\\\\n\\\\n1. **Fork the repository**\\\\n\\\\\\n    2. **Clone your fork:**\\\\n   ```bash\\\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\\\n\\\\\\n    \\\\   cd Repo-Contextor\\\\n   ```\\\\n3. **Install for development:**\\\\n   ```bash\\\\n \\\\\\n    \\\\  python -m venv .venv\\\\n   source .venv/bin/activate\\\\n   pip install -e .\\\\n \\\\\\n    \\\\  ```\\\\n4. **Make your changes and test:**\\\\n   ```bash\\\\n   repo-contextor . -o\\\\\\n    \\\\ test.md\\\\n   ```\\\\n5. **Submit a pull request**\\\\n\\\\n### Development Workflow\\\\n\\\\n\\\\\\n    ```bash\\\\n# 1. Setup development environment\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\n\\\\\\n    cd Repo-Contextor\\\\npython -m venv .venv\\\\nsource .venv/bin/activate\\\\npip install\\\\\\n    \\\\ -e .\\\\n\\\\n# 2. Make changes to the code\\\\n# Edit files in src/rcpack/\\\\n\\\\n# 3. Test\\\\\\n    \\\\ your changes\\\\nrepo-contextor . -o test-output.md\\\\n\\\\n# 4. Test different formats\\\\n\\\\\\n    repo-contextor . -f json -o test.json\\\\nrepo-contextor . -f yaml -o test.yaml\\\\n\\\\\\n    \\\\n# 5. Commit and push changes\\\\ngit add .\\\\ngit commit -m \\\\\\\"Add new feature\\\\\\\"\\\\n\\\\\\n    git push origin feature-branch\\\\n```\\\\n\\\\n## License\\\\n\\\\nThis project is licensed\\\\\\n    \\\\ under the MIT License. See the [LICENSE](LICENSE) file for details.\\\\n\\\\n## Why\\\\\\n    \\\\ Repo-Contextor?\\\\n\\\\nThe name \\\\\\\"Repo-Contextor\\\\\\\" combines \\\\\\\"Repository\\\\\\\" + \\\\\\\"\\\\\\n    Context\\\\\\\" + \\\\\\\"or\\\\\\\", representing the tool's purpose of providing rich context\\\\\\n    \\\\ about code repositories in a format that's perfect for LLM interactions.\\\\n\\\\n\\\\\\n    ### Use Cases\\\\n\\\\n- **AI Assistance**: Get better help from ChatGPT, Claude, or\\\\\\n    \\\\ GitHub Copilot\\\\n- **Code Reviews**: Share complete project context with team\\\\\\n    \\\\ members\\\\n- **Documentation**: Create comprehensive project snapshots\\\\n- **Onboarding**:\\\\\\n    \\\\ Help new team members understand project structure\\\\n- **Project Analysis**:\\\\\\n    \\\\ Understand repository structure and dependencies\\\\n\\\\n### Perfect for LLMs\\\\n\\\\n\\\\\\n    The output format is specifically designed to work well with Large Language Models:\\\\n\\\\\\n    - Clear section headers for easy parsing\\\\n- Syntax highlighting markers for code\\\\\\n    \\\\ blocks\\\\n- Structured metadata (git info, file locations)\\\\n- Complete project\\\\\\n    \\\\ context in a single file\\\\n- Multiple output formats (Markdown, JSON, YAML)\\\\n\\\\\\n    - Optimized for token efficiency\\\\n\\\"\\n  pyproject.toml: \\\"[build-system]\\\\nrequires = [\\\\\\\"setuptools>=68\\\\\\\", \\\\\\\"wheel\\\\\\\"]\\\\nbuild-backend\\\\\\n    \\\\ = \\\\\\\"setuptools.build_meta\\\\\\\"\\\\n\\\\n[project]\\\\nname = \\\\\\\"rcpack\\\\\\\"\\\\nversion = \\\\\\\"0.1.0\\\\\\\"\\\\\\n    \\\\ndescription = \\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\"\\\\nreadme = \\\\\\\"README.md\\\\\\\"\\\\\\n    \\\\nrequires-python = \\\\\\\">=3.9\\\\\\\"\\\\nlicense = { text = \\\\\\\"MIT\\\\\\\" }\\\\ndependencies = [\\\\n\\\\\\n    \\\\    \\\\\\\"PyYAML>=6.0\\\\\\\"\\\\n]\\\\n\\\\n[project.scripts]\\\\nrepo-contextor = \\\\\\\"rcpack.cli:main\\\\\\\"\\\\\\n    \\\\n\\\"\\n  src/rcpack/__init__.py: '\\\"\\\"\\\"Repository Context Packager - CLI tool for creating\\n    LLM-optimized repository context.\\\"\\\"\\\"\\n\\n\\n    __version__ = \\\"0.1.0\\\"\\n\\n    __author__ = \\\"Abhinav\\\"\\n\\n    __description__ = \\\"Repository Context Packager CLI for LLMs\\\"'\\n  src/rcpack/__main__.py: \\\"#!/usr/bin/env python3\\\\n\\\\\\\"\\\\\\\"\\\\\\\"Module entry point to enable\\\\\\n    \\\\ `python -m rcpack`.\\\\n\\\\nThis simply delegates to the CLI's main() function.\\\\n\\\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom .cli import main\\\\n\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\\n\\\\\\n    \\\\n\\\\n\\\"\\n  src/rcpack/cli.py: \\\"#!/usr/bin/env python3\\\\n\\\\\\\"\\\\\\\"\\\\\\\"CLI for Repository Context Packager.\\\\\\\"\\\\\\n    \\\\\\\"\\\\\\\"\\\\n\\\\nfrom .config_loader import load_config\\\\n\\\\nimport argparse\\\\nimport sys\\\\n\\\\\\n    from pathlib import Path\\\\nfrom .gitinfo import get_git_info\\\\nfrom .discover import\\\\\\n    \\\\ discover_files\\\\nfrom .treeview import create_tree_view\\\\nfrom .renderer.markdown\\\\\\n    \\\\ import render_markdown\\\\nfrom .renderer.jsonyaml import render_json, render_yaml\\\\n\\\\\\n    from .io_utils import write_output\\\\nfrom datetime import datetime, timedelta\\\\n\\\\\\n    \\\\n\\\\ndef log_verbose(message: str, verbose: bool) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Log a message\\\\\\n    \\\\ to stderr if verbose mode is enabled.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if verbose:\\\\n        print(message,\\\\\\n    \\\\ file=sys.stderr)\\\\n\\\\n\\\\ndef get_rendered_content(format_type: str, repo_path:\\\\\\n    \\\\ str, repo_info: dict, tree_text: str, \\\\n                        files_data:\\\\\\n    \\\\ dict, total_files: int, total_lines: int, \\\\n                        recent_files_info:\\\\\\n    \\\\ dict, file_sizes: dict) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Get rendered content based on the\\\\\\n    \\\\ specified format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if format_type == \\\\\\\"json\\\\\\\":\\\\n        return render_json(\\\\n\\\\\\n    \\\\            repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\\\\n    \\\\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\n\\\\\\n    \\\\        )\\\\n    elif format_type == \\\\\\\"yaml\\\\\\\":\\\\n        return render_yaml(\\\\n \\\\\\n    \\\\           repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\\\\n    \\\\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\n\\\\\\n    \\\\        )\\\\n    else:  # text/markdown\\\\n        return render_markdown(\\\\n    \\\\\\n    \\\\        repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\\\\n    \\\\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\n\\\\\\n    \\\\        )\\\\n\\\\n\\\\ndef process_file(file_path: Path, repo_path: Path, verbose: bool)\\\\\\n    \\\\ -> tuple[str, str, str]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Process a single file and return its data.\\\\n\\\\\\n    \\\\    \\\\n    Returns:\\\\n        tuple: (relative_path_str, content, file_size)\\\\n\\\\\\n    \\\\    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    relative_path = file_path.relative_to(repo_path)\\\\n    relative_path_str\\\\\\n    \\\\ = str(relative_path)\\\\n    \\\\n    log_verbose(f\\\\\\\"Reading file: {relative_path}\\\\\\\"\\\\\\n    , verbose)\\\\n    file_size = file_path.stat().st_size\\\\n    \\\\n    try:\\\\n       \\\\\\n    \\\\ with open(file_path, 'r', encoding='utf-8') as f:\\\\n            content = f.read()\\\\n\\\\\\n    \\\\        return relative_path_str, content, str(file_size)\\\\n    except (UnicodeDecodeError,\\\\\\n    \\\\ PermissionError):\\\\n        log_verbose(f\\\\\\\"Skipping binary/unreadable file: {relative_path}\\\\\\\"\\\\\\n    , verbose)\\\\n        file_size = file_path.stat().st_size if file_path.exists()\\\\\\n    \\\\ else 0\\\\n        content = f\\\\\\\"[Binary or unreadable file: {file_path.name}]\\\\\\\"\\\\\\n    \\\\n        return relative_path_str, content, str(file_size)\\\\n    except Exception:\\\\n\\\\\\n    \\\\        log_verbose(f\\\\\\\"Error reading file: {relative_path}\\\\\\\", verbose)\\\\n    \\\\\\n    \\\\    raise  # Re-raise to handle in calling code\\\\n\\\\n\\\\ndef handle_output(content:\\\\\\n    \\\\ str, output_path: str = None) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Handle output to either file\\\\\\n    \\\\ or stdout.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if output_path:\\\\n        # Write to file\\\\n        write_output(output_path,\\\\\\n    \\\\ content)\\\\n        print(f\\\\\\\"Context package created: {output_path}\\\\\\\")\\\\n    else:\\\\n\\\\\\n    \\\\        # Output to stdout\\\\n        print(content)\\\\n\\\\n\\\\ndef main():\\\\n    parser\\\\\\n    \\\\ = argparse.ArgumentParser(\\\\n        description=\\\\\\\"Package repository content\\\\\\n    \\\\ for LLM context\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"path\\\\\\\", \\\\n   \\\\\\n    \\\\     nargs=\\\\\\\"?\\\\\\\", \\\\n        default=\\\\\\\".\\\\\\\", \\\\n        help=\\\\\\\"Repository path (default:\\\\\\n    \\\\ current directory)\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"-o\\\\\\\", \\\\\\\"--output\\\\\\\"\\\\\\n    , \\\\n        help=\\\\\\\"Output file path (default: stdout)\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n\\\\\\n    \\\\        \\\\\\\"-f\\\\\\\", \\\\\\\"--format\\\\\\\", \\\\n        choices=[\\\\\\\"text\\\\\\\", \\\\\\\"json\\\\\\\", \\\\\\\"yaml\\\\\\\"\\\\\\n    ], \\\\n        default=\\\\\\\"text\\\\\\\",\\\\n        help=\\\\\\\"Output format (default: text)\\\\\\\"\\\\\\n    \\\\n    )\\\\n\\\\n    \\\\\\\"\\\\\\\"\\\\\\\" This will read -r from the console and able to search it\\\\\\n    \\\\ with this\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    parser.add_argument(\\\\n    \\\\\\\"-r\\\\\\\", \\\\\\\"--recent\\\\\\\",\\\\n    action=\\\\\\\"\\\\\\n    store_true\\\\\\\",\\\\n    help=\\\\\\\"Include only files modified in the last 7 days\\\\\\\"\\\\n \\\\\\n    \\\\   )\\\\n    parser.add_argument(\\\\n        \\\\\\\"-v\\\\\\\", \\\\\\\"--verbose\\\\\\\",\\\\n        action=\\\\\\\"\\\\\\n    store_true\\\\\\\",\\\\n        help=\\\\\\\"Print detailed progress information to stderr\\\\\\\"\\\\n\\\\\\n    \\\\    )\\\\n    \\\\n    args = parser.parse_args()\\\\n    \\\\n    try:\\\\n        repo_path\\\\\\n    \\\\ = Path(args.path).resolve()\\\\n        if not repo_path.exists():\\\\n          \\\\\\n    \\\\  print(f\\\\\\\"Error: Path {repo_path} does not exist\\\\\\\", file=sys.stderr)\\\\n     \\\\\\n    \\\\       sys.exit(1)\\\\n            \\\\n        # Get repository information\\\\n    \\\\\\n    \\\\    log_verbose(f\\\\\\\"Analyzing repository: {repo_path}\\\\\\\", args.verbose)\\\\n     \\\\\\n    \\\\   repo_info = get_git_info(repo_path)\\\\n        \\\\n        # Discover files\\\\n\\\\\\n    \\\\        log_verbose(f\\\\\\\"Discovering files in: {repo_path}\\\\\\\", args.verbose)\\\\n \\\\\\n    \\\\       discovered_files = discover_files([repo_path], repo_path, [], [])\\\\n  \\\\\\n    \\\\      log_verbose(f\\\\\\\"Found {len(discovered_files)} files\\\\\\\", args.verbose)\\\\n \\\\\\n    \\\\       \\\\n        # will check the file in last 7 days\\\\n        recent_files_info\\\\\\n    \\\\ = {}\\\\n        if args.recent:\\\\n            seven_days_ago = datetime.now() -\\\\\\n    \\\\ timedelta(days=7)\\\\n            recent_files = []\\\\n            for f in discovered_files:\\\\n\\\\\\n    \\\\                try:\\\\n                    mtime = datetime.fromtimestamp(f.stat().st_mtime)\\\\n\\\\\\n    \\\\                    if mtime >= seven_days_ago:\\\\n                        recent_files.append(f)\\\\n\\\\\\n    \\\\                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)\\\\\\n    \\\\     \\\\n                except Exception:\\\\n                    continue\\\\n    \\\\\\n    \\\\        discovered_files = recent_files\\\\n        \\\\n        # Read file contents\\\\n\\\\\\n    \\\\        files_data = {}\\\\n        file_sizes = {}\\\\n        for file_path in discovered_files:\\\\n\\\\\\n    \\\\            try:\\\\n                relative_path_str, content, file_size = process_file(file_path,\\\\\\n    \\\\ repo_path, args.verbose)\\\\n                files_data[relative_path_str] = content\\\\n\\\\\\n    \\\\                file_sizes[relative_path_str] = file_size\\\\n            except\\\\\\n    \\\\ Exception:\\\\n                continue\\\\n        \\\\n        # Create tree view\\\\n\\\\\\n    \\\\        log_verbose(\\\\\\\"Generating directory tree\\\\\\\", args.verbose)\\\\n        tree_text\\\\\\n    \\\\ = create_tree_view(repo_path, files_data)\\\\n        \\\\n        # Count totals\\\\n\\\\\\n    \\\\        total_files = len(files_data)\\\\n        total_lines = sum(len(content.splitlines())\\\\\\n    \\\\ for _, content in files_data.items())\\\\n        \\\\n        # Render based on format\\\\n\\\\\\n    \\\\        log_verbose(f\\\\\\\"Rendering output in {args.format} format\\\\\\\", args.verbose)\\\\n\\\\\\n    \\\\        content = get_rendered_content(\\\\n            args.format, str(repo_path),\\\\\\n    \\\\ repo_info, tree_text,\\\\n            files_data, total_files, total_lines,\\\\n \\\\\\n    \\\\           recent_files_info if args.recent else {},\\\\n            file_sizes\\\\n\\\\\\n    \\\\        )\\\\n        \\\\n        handle_output(content, args.output)\\\\n        \\\\n\\\\\\n    \\\\    except Exception as e:\\\\n        print(f\\\\\\\"Error: {e}\\\\\\\", file=sys.stderr)\\\\n\\\\\\n    \\\\        sys.exit(1)\\\\n\\\\n# this will convert age and give us the difference\\\\ndef\\\\\\n    \\\\ human_readable_age(mtime: datetime) -> str:\\\\n    delta = datetime.now() - mtime\\\\n\\\\\\n    \\\\    days = delta.days\\\\n    seconds = delta.seconds\\\\n    if days > 0:\\\\n      \\\\\\n    \\\\  return f\\\\\\\"{days} day{'s' if days != 1 else ''} ago\\\\\\\"\\\\n    elif seconds >= 3600:\\\\n\\\\\\n    \\\\        hours = seconds // 3600\\\\n        return f\\\\\\\"{hours} hour{'s' if hours\\\\\\n    \\\\ != 1 else ''} ago\\\\\\\"\\\\n    elif seconds >= 60:\\\\n        minutes = seconds // 60\\\\n\\\\\\n    \\\\        return f\\\\\\\"{minutes} minute{'s' if minutes != 1 else ''} ago\\\\\\\"\\\\n    else:\\\\n\\\\\\n    \\\\        return \\\\\\\"just now\\\\\\\"\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\\n\\\"\\n  src/rcpack/config_loader.py: \\\"# src/rcpack/config_loader.py\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nTOML config\\\\\\n    \\\\ loader for Repo-Contextor.\\\\n\\\\nRules:\\\\n- Look for .repo-contextor.toml in the\\\\\\n    \\\\ CURRENT directory\\\\n- If missing: ignore\\\\n- If present but invalid: print a clear\\\\\\n    \\\\ error and exit(1)\\\\n- Only recognized keys are applied; unknown keys ignored\\\\n\\\\\\n    - Precedence: CLI > TOML > DEFAULTS\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nfrom __future__ import annotations\\\\n\\\\\\n    import os, sys\\\\nfrom typing import Dict, Iterable, Any\\\\n\\\\ntry:\\\\n    import tomllib\\\\n\\\\\\n    \\\\    _loads = tomllib.loads\\\\nexcept ModuleNotFoundError:\\\\n    try:\\\\n        import\\\\\\n    \\\\ tomli\\\\n        _loads = tomli.loads\\\\n    except ModuleNotFoundError:\\\\n     \\\\\\n    \\\\   _loads = None\\\\n\\\\ndef _need_toml():\\\\n    if _loads is None:\\\\n        print(\\\\\\\"\\\\\\n    Error: TOML parser not available. Use Python 3.11+ or `pip install tomli`.\\\\\\\",\\\\\\n    \\\\ file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\ndef _load_toml(dotfile: str) -> Dict[str,\\\\\\n    \\\\ Any]:\\\\n    _need_toml()\\\\n    if not os.path.exists(dotfile):\\\\n        return\\\\\\n    \\\\ {}\\\\n    try:\\\\n        with open(dotfile, \\\\\\\"rb\\\\\\\") as f:\\\\n            raw = f.read().decode(\\\\\\\"\\\\\\n    utf-8\\\\\\\", errors=\\\\\\\"strict\\\\\\\")\\\\n        data = _loads(raw)\\\\n        return data if\\\\\\n    \\\\ isinstance(data, dict) else {}\\\\n    except Exception as e:\\\\n        print(f\\\\\\\"\\\\\\n    Error: failed to parse {dotfile} as TOML.\\\\\\\\n{e}\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\\\n    \\\\ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\\\n\\\\\\n    \\\\    ks = set(known)\\\\n    return {k: v for k, v in d.items() if k in ks}\\\\n\\\\ndef\\\\\\n    \\\\ _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str,\\\\\\n    \\\\ Any], known: Iterable[str]) -> Dict[str, Any]:\\\\n    ks = set(known)\\\\n    out:\\\\\\n    \\\\ Dict[str, Any] = {k: defaults.get(k) for k in ks}\\\\n    for src in (filecfg,\\\\\\n    \\\\ clicfg):\\\\n        for k, v in src.items():\\\\n            if k in ks and v is\\\\\\n    \\\\ not None:\\\\n                out[k] = v\\\\n    return out\\\\n\\\\ndef load_config(*,\\\\\\n    \\\\ dotfile: str = \\\\\\\".repo-contextor.toml\\\\\\\", defaults: Dict[str, Any] | None = None,\\\\\\n    \\\\ cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ()) -> Dict[str,\\\\\\n    \\\\ Any]:\\\\n    defaults = defaults or {}\\\\n    cli_cfg = cli_cfg or {}\\\\n    known\\\\\\n    \\\\ = tuple(known_keys)\\\\n    filecfg = _filter_known(_load_toml(dotfile), known)\\\\n\\\\\\n    \\\\    return _merge(defaults, filecfg, cli_cfg, known)\\\\n\\\"\\n  src/rcpack/discover.py: \\\"\\\\\\\"\\\\\\\"\\\\\\\"File discovery module for repository analysis.\\\\\\\"\\\\\\\"\\\\\\n    \\\\\\\"\\\\n\\\\nfrom pathlib import Path\\\\nfrom typing import List\\\\nimport fnmatch\\\\n\\\\n\\\\n\\\\\\n    def discover_files(\\\\n    inputs: List[Path],\\\\n    root: Path,\\\\n    include_patterns:\\\\\\n    \\\\ List[str],\\\\n    exclude_patterns: List[str],\\\\n) -> List[Path]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Discover\\\\\\n    \\\\ relevant files.\\\\n\\\\n    - inputs: list of files/dirs to scan\\\\n    - root: common\\\\\\n    \\\\ project root; patterns are matched against POSIX paths relative to root\\\\n  \\\\\\n    \\\\  - include_patterns: glob patterns to include (if empty, use sensible defaults)\\\\n\\\\\\n    \\\\    - exclude_patterns: glob patterns to exclude\\\\n    Returns a list of absolute\\\\\\n    \\\\ Paths to files.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    default_include_exts = {\\\\n        '.py',\\\\\\n    \\\\ '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\\\\n        '.cs', '.php',\\\\\\n    \\\\ '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\\\n        '.html', '.css', '.scss',\\\\\\n    \\\\ '.sass', '.less', '.vue', '.svelte',\\\\n        '.md', '.txt', '.rst', '.yaml',\\\\\\n    \\\\ '.yml', '.json', '.toml', '.ini',\\\\n        '.cfg', '.conf', '.xml', '.sql',\\\\\\n    \\\\ '.sh', '.bash', '.zsh', '.fish',\\\\n    }\\\\n\\\\n    always_include_names = {\\\\n  \\\\\\n    \\\\      'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING', 'Makefile',\\\\n       \\\\\\n    \\\\ 'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\\\\n      \\\\\\n    \\\\  'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\\\n\\\\\\n    \\\\    }\\\\n\\\\n    skip_dir_names = {\\\\n        '.git', '.svn', '.hg', '__pycache__',\\\\\\n    \\\\ '.pytest_cache',\\\\n        'node_modules', '.venv', 'venv', 'env', '.env',\\\\n\\\\\\n    \\\\        'build', 'dist', 'target', 'out', '.next', '.nuxt',\\\\n        '.idea',\\\\\\n    \\\\ '.vscode', '.vs', 'coverage', '.coverage'\\\\n    }\\\\n\\\\n    def matches_any(patterns:\\\\\\n    \\\\ List[str], rel_posix: str) -> bool:\\\\n        return any(fnmatch.fnmatch(rel_posix,\\\\\\n    \\\\ pat) for pat in patterns)\\\\n\\\\n    def should_take(file_path: Path) -> bool:\\\\n\\\\\\n    \\\\        rel_posix = file_path.relative_to(root).as_posix()\\\\n        if exclude_patterns\\\\\\n    \\\\ and matches_any(exclude_patterns, rel_posix):\\\\n            return False\\\\n  \\\\\\n    \\\\      if include_patterns:\\\\n            return matches_any(include_patterns,\\\\\\n    \\\\ rel_posix)\\\\n        # default include logic\\\\n        return file_path.name in\\\\\\n    \\\\ always_include_names or file_path.suffix.lower() in default_include_exts\\\\n\\\\n\\\\\\n    \\\\    discovered: list[Path] = []\\\\n    seen = set()\\\\n\\\\n    for item in inputs:\\\\n\\\\\\n    \\\\        p = item.resolve()\\\\n        if p.is_file():\\\\n            # Skip if excluded\\\\\\n    \\\\ or in skipped directory\\\\n            if any(part in skip_dir_names for part\\\\\\n    \\\\ in p.parts):\\\\n                continue\\\\n            if should_take(p):\\\\n   \\\\\\n    \\\\             key = p.as_posix()\\\\n                if key not in seen:\\\\n      \\\\\\n    \\\\              seen.add(key)\\\\n                    discovered.append(p)\\\\n     \\\\\\n    \\\\   elif p.is_dir():\\\\n            for child in p.rglob('*'):\\\\n               \\\\\\n    \\\\ if not child.is_file():\\\\n                    continue\\\\n                if any(part\\\\\\n    \\\\ in skip_dir_names for part in child.parts):\\\\n                    continue\\\\n\\\\\\n    \\\\                if should_take(child):\\\\n                    key = child.resolve().as_posix()\\\\n\\\\\\n    \\\\                    if key not in seen:\\\\n                        seen.add(key)\\\\n\\\\\\n    \\\\                        discovered.append(child.resolve())\\\\n\\\\n    return sorted(discovered)\\\"\\n  src/rcpack/gitinfo.py: \\\"from __future__ import annotations\\\\n\\\\nimport subprocess\\\\n\\\\\\n    from pathlib import Path\\\\nfrom typing import Dict, Any\\\\n\\\\n\\\\ndef _git(cmd: list[str],\\\\\\n    \\\\ cwd: Path) -> str:\\\\n    # Validate git commands to prevent injection\\\\n    allowed_commands\\\\\\n    \\\\ = {\\\\n        \\\\\\\"rev-parse\\\\\\\", \\\\\\\"show\\\\\\\", \\\\\\\"log\\\\\\\", \\\\\\\"status\\\\\\\", \\\\\\\"branch\\\\\\\", \\\\\\\"config\\\\\\\"\\\\\\n    \\\\n    }\\\\n    if not cmd or cmd[0] not in allowed_commands:\\\\n        raise ValueError(f\\\\\\\"\\\\\\n    Git command not allowed: {cmd[0] if cmd else 'empty'}\\\\\\\")\\\\n    \\\\n    out = subprocess.check_output([\\\\\\\"\\\\\\n    git\\\\\\\", *cmd], cwd=str(cwd), timeout=30)\\\\n    return out.decode(\\\\\\\"utf-8\\\\\\\", errors=\\\\\\\"\\\\\\n    replace\\\\\\\").strip()\\\\n\\\\n\\\\ndef is_git_repo(path: Path) -> bool:\\\\n    try:\\\\n     \\\\\\n    \\\\   flag = _git([\\\\\\\"rev-parse\\\\\\\", \\\\\\\"--is-inside-work-tree\\\\\\\"], cwd=path)\\\\n      \\\\\\n    \\\\  return flag == \\\\\\\"true\\\\\\\"\\\\n    except Exception:\\\\n        return False\\\\n\\\\n\\\\n\\\\\\n    def get_git_info(path: Path) -> Dict[str, Any]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Return info for\\\\\\n    \\\\ the current HEAD of a repo rooted at `path`.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n       \\\\\\n    \\\\ commit = _git([\\\\\\\"rev-parse\\\\\\\", \\\\\\\"HEAD\\\\\\\"], cwd=path)\\\\n        branch = _git([\\\\\\\"\\\\\\n    rev-parse\\\\\\\", \\\\\\\"--abbrev-ref\\\\\\\", \\\\\\\"HEAD\\\\\\\"], cwd=path)\\\\n        author = _git([\\\\\\\"\\\\\\n    show\\\\\\\", \\\\\\\"-s\\\\\\\", \\\\\\\"--format=%an <%ae>\\\\\\\"], cwd=path)\\\\n        date = _git([\\\\\\\"show\\\\\\\"\\\\\\n    , \\\\\\\"-s\\\\\\\", \\\\\\\"--date=local\\\\\\\", \\\\\\\"--format=%ad\\\\\\\"], cwd=path)\\\\n        return {\\\\n \\\\\\n    \\\\           \\\\\\\"is_repo\\\\\\\": True,\\\\n            \\\\\\\"commit\\\\\\\": commit,\\\\n            \\\\\\\"\\\\\\n    branch\\\\\\\": branch,\\\\n            \\\\\\\"author\\\\\\\": author,\\\\n            \\\\\\\"date\\\\\\\": date,\\\\n\\\\\\n    \\\\            \\\\\\\"note\\\\\\\": None,\\\\n        }\\\\n    except Exception:\\\\n        # treat\\\\\\n    \\\\ as not a repo if anything fails\\\\n        return {\\\\n            \\\\\\\"is_repo\\\\\\\":\\\\\\n    \\\\ False,\\\\n            \\\\\\\"commit\\\\\\\": None,\\\\n            \\\\\\\"branch\\\\\\\": None,\\\\n     \\\\\\n    \\\\       \\\\\\\"author\\\\\\\": None,\\\\n            \\\\\\\"date\\\\\\\": None,\\\\n            \\\\\\\"note\\\\\\\":\\\\\\n    \\\\ \\\\\\\"Not a git repository\\\\\\\",\\\\n        }\\\\n\\\"\\n  src/rcpack/io_utils.py: \\\"\\\\\\\"\\\\\\\"\\\\\\\"I/O utilities for file operations.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom\\\\\\n    \\\\ pathlib import Path\\\\nfrom typing import Tuple\\\\n\\\\n\\\\ndef write_output(output_path:\\\\\\n    \\\\ str, content: str) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Write content to output file.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\\\n    \\\\    output_file = Path(output_path)\\\\n    \\\\n    # Create parent directories if\\\\\\n    \\\\ they don't exist\\\\n    output_file.parent.mkdir(parents=True, exist_ok=True)\\\\n\\\\\\n    \\\\    \\\\n    # Write content\\\\n    with open(output_file, 'w', encoding='utf-8')\\\\\\n    \\\\ as f:\\\\n        f.write(content)\\\\n\\\\n\\\\ndef is_binary_file(path: Path, sniff_bytes:\\\\\\n    \\\\ int = 2048) -> bool:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Heuristically determine if a file is binary\\\\\\n    \\\\ by scanning for NUL bytes.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        with open(path, 'rb') as\\\\\\n    \\\\ fb:\\\\n            chunk = fb.read(sniff_bytes)\\\\n        if b\\\\\\\"\\\\\\\\x00\\\\\\\" in chunk:\\\\n\\\\\\n    \\\\            return True\\\\n        # If the chunk has a lot of non-text bytes,\\\\\\n    \\\\ consider it binary\\\\n        text_byte_count = sum(32 <= b <= 126 or b in (9,\\\\\\n    \\\\ 10, 13) for b in chunk)\\\\n        return (len(chunk) - text_byte_count) > max(1,\\\\\\n    \\\\ len(chunk) // 3)\\\\n    except Exception:\\\\n        # If we cannot read, treat\\\\\\n    \\\\ as binary to avoid further processing\\\\n        return True\\\\n\\\\n\\\\ndef read_text_safely(path:\\\\\\n    \\\\ Path, max_bytes: int = 16_384) -> Tuple[str, str, bool]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Read a text\\\\\\n    \\\\ file safely with size limit and encoding fallbacks.\\\\n\\\\n    Returns (content,\\\\\\n    \\\\ encoding_used, truncated).\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    truncated = False\\\\n    raw: bytes\\\\n\\\\\\n    \\\\    with open(path, 'rb') as fb:\\\\n        raw = fb.read(max_bytes + 1)\\\\n    if\\\\\\n    \\\\ len(raw) > max_bytes:\\\\n        truncated = True\\\\n        raw = raw[:max_bytes]\\\\n\\\\\\n    \\\\n    for enc in (\\\\\\\"utf-8\\\\\\\", \\\\\\\"utf-16\\\\\\\", \\\\\\\"utf-16-le\\\\\\\", \\\\\\\"utf-16-be\\\\\\\", \\\\\\\"latin-1\\\\\\\"\\\\\\n    ):\\\\n        try:\\\\n            text = raw.decode(enc)\\\\n            return text,\\\\\\n    \\\\ enc, truncated\\\\n        except Exception:\\\\n            continue\\\\n    # Fallback:\\\\\\n    \\\\ replace errors with utf-8\\\\n    text = raw.decode(\\\\\\\"utf-8\\\\\\\", errors=\\\\\\\"replace\\\\\\\"\\\\\\n    )\\\\n    return text, \\\\\\\"utf-8\\\\\\\", truncated\\\"\\n  src/rcpack/packager.py: \\\"from __future__ import annotations\\\\n\\\\nimport sys\\\\nfrom\\\\\\n    \\\\ pathlib import Path\\\\nfrom typing import Iterable, Tuple\\\\n\\\\nfrom rcpack.discover\\\\\\n    \\\\ import discover_files\\\\nfrom rcpack.gitinfo import get_git_info, is_git_repo\\\\n\\\\\\n    from rcpack.io_utils import read_text_safely, is_binary_file\\\\nfrom rcpack.renderer\\\\\\n    \\\\ import markdown as md_renderer\\\\nfrom rcpack.renderer.jsonyaml import render_json,\\\\\\n    \\\\ render_yaml\\\\nfrom rcpack.treeview import render_tree\\\\n\\\\n\\\\ndef _find_root(inputs:\\\\\\n    \\\\ list[str]) -> Path:\\\\n    paths = [Path(p) for p in inputs]\\\\n    if len(paths)\\\\\\n    \\\\ == 1 and Path(paths[0]).is_dir():\\\\n        return paths[0].resolve()\\\\n    parents\\\\\\n    \\\\ = [p if p.is_dir() else p.parent for p in paths]\\\\n    root = Path(*Path.commonpath([str(p.resolve())\\\\\\n    \\\\ for p in parents]).split(\\\\\\\"/\\\\\\\"))\\\\n    return root.resolve()\\\\n\\\\n\\\\ndef build_package(\\\\n\\\\\\n    \\\\    inputs: list[str],\\\\n    include_patterns: list[str] | None,\\\\n    exclude_patterns:\\\\\\n    \\\\ list[str] | None,\\\\n    max_file_bytes: int,\\\\n    fmt: str = \\\\\\\"markdown\\\\\\\",\\\\n\\\\\\n    ) -> Tuple[str, dict]:\\\\n    root = _find_root(inputs)\\\\n    root_abs = root.resolve()\\\\n\\\\\\n    \\\\n    repo_info = (\\\\n        get_git_info(root_abs) if is_git_repo(root_abs) else\\\\\\n    \\\\ {\\\\n            \\\\\\\"is_repo\\\\\\\": False,\\\\n            \\\\\\\"commit\\\\\\\": None,\\\\n        \\\\\\n    \\\\    \\\\\\\"branch\\\\\\\": None,\\\\n            \\\\\\\"author\\\\\\\": None,\\\\n            \\\\\\\"date\\\\\\\": None,\\\\n\\\\\\n    \\\\            \\\\\\\"note\\\\\\\": \\\\\\\"Not a git repository\\\\\\\",\\\\n        }\\\\n    )\\\\n\\\\n    files\\\\\\n    \\\\ = discover_files(\\\\n        inputs=[Path(p) for p in inputs],\\\\n        root=root_abs,\\\\n\\\\\\n    \\\\        include_patterns=include_patterns or [],\\\\n        exclude_patterns=exclude_patterns\\\\\\n    \\\\ or [],\\\\n    )\\\\n    rel_files = [f.relative_to(root_abs) for f in files]\\\\n\\\\n\\\\\\n    \\\\    project_tree = render_tree([p.as_posix() for p in rel_files])\\\\n\\\\n    file_sections:\\\\\\n    \\\\ list[dict] = []\\\\n    total_lines = 0\\\\n    total_chars = 0\\\\n\\\\n    for f in files:\\\\n\\\\\\n    \\\\        rel = f.relative_to(root_abs).as_posix()\\\\n        try:\\\\n            if\\\\\\n    \\\\ is_binary_file(f):\\\\n                content = f\\\\\\\"[binary file skipped: {f.name},\\\\\\n    \\\\ {f.stat().st_size} bytes]\\\\\\\"\\\\n                file_sections.append({\\\\n      \\\\\\n    \\\\              \\\\\\\"path\\\\\\\": rel,\\\\n                    \\\\\\\"language\\\\\\\": _language_from_ext(f.suffix),\\\\n\\\\\\n    \\\\                    \\\\\\\"content\\\\\\\": content,\\\\n                    \\\\\\\"is_truncated\\\\\\\"\\\\\\n    : False,\\\\n                })\\\\n                total_chars += len(content)\\\\n  \\\\\\n    \\\\              continue\\\\n\\\\n            content, used_encoding, truncated = read_text_safely(f,\\\\\\n    \\\\ max_bytes=max_file_bytes)\\\\n            total_lines += content.count(\\\\\\\"\\\\\\\\n\\\\\\\"\\\\\\n    ) + (1 if content and not content.endswith(\\\\\\\"\\\\\\\\n\\\\\\\") else 0)\\\\n            total_chars\\\\\\n    \\\\ += len(content)\\\\n\\\\n            if truncated:\\\\n                note = f\\\\\\\"\\\\\\\\n\\\\\\\\\\\\\\n    n[... TRUNCATED to first {max_file_bytes} bytes ...]\\\\\\\"\\\\n                content\\\\\\n    \\\\ = content + note\\\\n                total_chars += len(note)\\\\n\\\\n            file_sections.append({\\\\n\\\\\\n    \\\\                \\\\\\\"path\\\\\\\": rel,\\\\n                \\\\\\\"language\\\\\\\": _language_from_ext(f.suffix),\\\\n\\\\\\n    \\\\                \\\\\\\"content\\\\\\\": content,\\\\n                \\\\\\\"is_truncated\\\\\\\": truncated,\\\\n\\\\\\n    \\\\            })\\\\n        except Exception as exc:\\\\n            print(f\\\\\\\"[rcpack]\\\\\\n    \\\\ error reading {rel}: {exc}\\\\\\\", file=sys.stderr)\\\\n            continue\\\\n\\\\n   \\\\\\n    \\\\ # render in chosen format\\\\n    if fmt == \\\\\\\"markdown\\\\\\\":\\\\n        out_text = md_renderer.render_markdown(\\\\n\\\\\\n    \\\\            root=str(root_abs),\\\\n            repo_info=repo_info,\\\\n         \\\\\\n    \\\\   tree_text=project_tree,\\\\n            files=file_sections,\\\\n            total_files=len(file_sections),\\\\n\\\\\\n    \\\\            total_lines=total_lines,\\\\n        )\\\\n    elif fmt == \\\\\\\"json\\\\\\\":\\\\n\\\\\\n    \\\\        out_text = render_json(\\\\n            root=str(root_abs),\\\\n          \\\\\\n    \\\\  repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n            files=file_sections,\\\\n\\\\\\n    \\\\            total_files=len(file_sections),\\\\n            total_lines=total_lines,\\\\n\\\\\\n    \\\\        )\\\\n    elif fmt == \\\\\\\"yaml\\\\\\\":\\\\n        out_text = render_yaml(\\\\n     \\\\\\n    \\\\       root=str(root_abs),\\\\n            repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n\\\\\\n    \\\\            files=file_sections,\\\\n            total_files=len(file_sections),\\\\n\\\\\\n    \\\\            total_lines=total_lines,\\\\n        )\\\\n    else:\\\\n        raise ValueError(f\\\\\\\"\\\\\\n    Unsupported format: {fmt}\\\\\\\")\\\\n\\\\n    stats = {\\\\\\\"files\\\\\\\": len(file_sections), \\\\\\\"\\\\\\n    lines\\\\\\\": total_lines, \\\\\\\"chars\\\\\\\": total_chars}\\\\n    return out_text, stats\\\\n\\\\n\\\\n\\\\\\n    def _language_from_ext(ext: str) -> str:\\\\n    ext = ext.lower().lstrip(\\\\\\\".\\\\\\\")\\\\n\\\\\\n    \\\\    mapping = {\\\\n        \\\\\\\"py\\\\\\\": \\\\\\\"python\\\\\\\", \\\\\\\"js\\\\\\\": \\\\\\\"javascript\\\\\\\", \\\\\\\"ts\\\\\\\":\\\\\\n    \\\\ \\\\\\\"typescript\\\\\\\",\\\\n        \\\\\\\"json\\\\\\\": \\\\\\\"json\\\\\\\", \\\\\\\"md\\\\\\\": \\\\\\\"markdown\\\\\\\", \\\\\\\"yml\\\\\\\":\\\\\\n    \\\\ \\\\\\\"yaml\\\\\\\", \\\\\\\"yaml\\\\\\\": \\\\\\\"yaml\\\\\\\",\\\\n        \\\\\\\"toml\\\\\\\": \\\\\\\"toml\\\\\\\", \\\\\\\"sh\\\\\\\": \\\\\\\"bash\\\\\\\"\\\\\\n    , \\\\\\\"c\\\\\\\": \\\\\\\"c\\\\\\\", \\\\\\\"cpp\\\\\\\": \\\\\\\"cpp\\\\\\\",\\\\n        \\\\\\\"java\\\\\\\": \\\\\\\"java\\\\\\\", \\\\\\\"go\\\\\\\": \\\\\\\"go\\\\\\\"\\\\\\n    , \\\\\\\"rs\\\\\\\": \\\\\\\"rust\\\\\\\",\\\\n    }\\\\n    return mapping.get(ext, \\\\\\\"\\\\\\\")\\\\n\\\"\\n  src/rcpack/renderer/jsonyaml.py: \\\"from __future__ import annotations\\\\nimport json\\\\n\\\\\\n    \\\\ntry:\\\\n    import yaml\\\\nexcept ImportError:\\\\n    yaml = None\\\\n\\\\n\\\\ndef render_json(root,\\\\\\n    \\\\ repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None)\\\\\\n    \\\\ -> str:\\\\n    data = {\\\\n        \\\\\\\"root\\\\\\\": root,\\\\n        \\\\\\\"repo_info\\\\\\\": repo_info,\\\\n\\\\\\n    \\\\        \\\\\\\"structure\\\\\\\": tree_text,\\\\n        \\\\\\\"recent_changes\\\\\\\": recent_files or\\\\\\n    \\\\ [],\\\\n        \\\\\\\"files\\\\\\\": files,\\\\n        \\\\\\\"file_sizes\\\\\\\": file_sizes or {},\\\\n\\\\\\n    \\\\        \\\\\\\"summary\\\\\\\": {\\\\\\\"total_files\\\\\\\": total_files, \\\\\\\"total_lines\\\\\\\": total_lines},\\\\n\\\\\\n    \\\\        \\\\n    }\\\\n    return json.dumps(data, indent=2, ensure_ascii=False)\\\\n\\\\n\\\\\\n    \\\\ndef render_yaml(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None,\\\\\\n    \\\\ file_sizes=None) -> str:\\\\n    if yaml is None:\\\\n        raise RuntimeError(\\\\\\\"\\\\\\n    PyYAML not installed; run `pip install pyyaml`\\\\\\\")\\\\n    data = {\\\\n        \\\\\\\"root\\\\\\\"\\\\\\n    : root,\\\\n        \\\\\\\"repo_info\\\\\\\": repo_info,\\\\n        \\\\\\\"structure\\\\\\\": tree_text,\\\\n\\\\\\n    \\\\        \\\\\\\"recent_changes\\\\\\\": recent_files or [],\\\\n        \\\\\\\"files\\\\\\\": files,\\\\n\\\\\\n    \\\\        \\\\\\\"file_sizes\\\\\\\": file_sizes or {},\\\\n        \\\\\\\"summary\\\\\\\": {\\\\\\\"total_files\\\\\\\"\\\\\\n    : total_files, \\\\\\\"total_lines\\\\\\\": total_lines},\\\\n        \\\\n    }\\\\n    return yaml.safe_dump(data,\\\\\\n    \\\\ sort_keys=False, allow_unicode=True)\\\\n\\\"\\n  src/rcpack/renderer/markdown.py: \\\"\\\\\\\"\\\\\\\"\\\\\\\"Markdown renderer for repository context.\\\\\\\"\\\\\\n    \\\\\\\"\\\\\\\"\\\\n\\\\nfrom typing import Dict, Any\\\\n\\\\n\\\\ndef render_markdown(root: str, repo_info:\\\\\\n    \\\\ Dict[str, Any], tree_text: str, \\\\n                   files: Dict[str, str],\\\\\\n    \\\\ total_files: int, total_lines: int, recent_files=None, file_sizes=None) -> str:\\\\n\\\\\\n    \\\\    \\\\\\\"\\\\\\\"\\\\\\\"Render repository context as markdown.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    lines = []\\\\n\\\\\\n    \\\\    \\\\n    # Header\\\\n    lines.append(f\\\\\\\"# Repository Context: {root}\\\\\\\")\\\\n   \\\\\\n    \\\\ lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Repository info\\\\n    if repo_info.get(\\\\\\\"is_repo\\\\\\\"\\\\\\n    ):\\\\n        lines.append(\\\\\\\"## Git Repository Information\\\\\\\")\\\\n        lines.append(f\\\\\\\"\\\\\\n    - **Branch**: {repo_info.get('branch', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Commit**:\\\\\\n    \\\\ {repo_info.get('commit', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Author**: {repo_info.get('author',\\\\\\n    \\\\ 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Date**: {repo_info.get('date', 'N/A')}\\\\\\\"\\\\\\n    )\\\\n    else:\\\\n        lines.append(\\\\\\\"## Repository Information\\\\\\\")\\\\n        lines.append(f\\\\\\\"\\\\\\n    - **Note**: {repo_info.get('note', 'Not a git repository')}\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\n    \\\\\\\")\\\\n    \\\\n    # Summary\\\\n    lines.append(\\\\\\\"## Summary\\\\\\\")\\\\n    lines.append(f\\\\\\\"\\\\\\n    - **Total Files**: {total_files}\\\\\\\")\\\\n    lines.append(f\\\\\\\"- **Total Lines**: {total_lines}\\\\\\\"\\\\\\n    )\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Directory structure\\\\n    lines.append(\\\\\\\"\\\\\\n    ## Directory Structure\\\\\\\")\\\\n    lines.append(\\\\\\\"```\\\\\\\")\\\\n    lines.append(tree_text)\\\\n\\\\\\n    \\\\    lines.append(\\\\\\\"```\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n\\\\n    # will produce recent\\\\\\n    \\\\ files \\\\n    # Recent files (fixed)\\\\n    if recent_files:\\\\n        lines.append(\\\\\\\"\\\\\\n    ## Recent Changes\\\\\\\")\\\\n        for file, age in recent_files.items():\\\\n       \\\\\\n    \\\\     lines.append(f\\\\\\\"- {file} (modified {age})\\\\\\\")\\\\n        lines.append(\\\\\\\"\\\\\\\"\\\\\\n    )\\\\n    \\\\n    # File contents\\\\n    lines.append(\\\\\\\"## File Contents\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\n    \\\\\\\")\\\\n    \\\\n    for file_path, content in sorted(files.items()):\\\\n        if file_sizes\\\\\\n    \\\\ and file_path in file_sizes:\\\\n            size_bytes = file_sizes[file_path]\\\\n\\\\\\n    \\\\            lines.append(f\\\\\\\"### {file_path} ({size_bytes} bytes)\\\\\\\")\\\\n       \\\\\\n    \\\\ else:\\\\n            lines.append(f\\\\\\\"### {file_path}\\\\\\\")\\\\n        lines.append(\\\\\\\"\\\\\\n    \\\\\\\")\\\\n        \\\\n        # Detect language for syntax highlighting\\\\n        ext\\\\\\n    \\\\ = file_path.split('.')[-1].lower() if '.' in file_path else ''\\\\n        lang_map\\\\\\n    \\\\ = {\\\\n            'py': 'python', 'js': 'javascript', 'ts': 'typescript',\\\\n \\\\\\n    \\\\           'java': 'java', 'cpp': 'cpp', 'c': 'c', 'h': 'c',\\\\n            'cs':\\\\\\n    \\\\ 'csharp', 'php': 'php', 'rb': 'ruby',\\\\n            'go': 'go', 'rs': 'rust',\\\\\\n    \\\\ 'swift': 'swift',\\\\n            'html': 'html', 'css': 'css', 'scss': 'scss',\\\\n\\\\\\n    \\\\            'json': 'json', 'yaml': 'yaml', 'yml': 'yaml',\\\\n            'xml':\\\\\\n    \\\\ 'xml', 'sql': 'sql', 'sh': 'bash',\\\\n            'md': 'markdown', 'dockerfile':\\\\\\n    \\\\ 'dockerfile'\\\\n        }\\\\n        \\\\n        language = lang_map.get(ext, '')\\\\n\\\\\\n    \\\\        lines.append(f\\\\\\\"```{language}\\\\\\\")\\\\n        lines.append(content)\\\\n   \\\\\\n    \\\\     lines.append(\\\\\\\"```\\\\\\\")\\\\n        lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    return \\\\\\\"\\\\\\\\\\\\\\n    n\\\\\\\".join(lines)\\\\n\\\"\\n  src/rcpack/treeview.py: \\\"\\\\\\\"\\\\\\\"\\\\\\\"Tree view generation for repository structure.\\\\\\\"\\\\\\\"\\\\\\n    \\\\\\\"\\\\n\\\\nfrom pathlib import Path\\\\nfrom typing import Dict, List\\\\n\\\\n\\\\ndef create_tree_view(repo_path:\\\\\\n    \\\\ Path, files_data: Dict[str, str]) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create a tree view of the\\\\\\n    \\\\ repository structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    paths = list(files_data.keys())\\\\n    return\\\\\\n    \\\\ render_tree(paths)\\\\n\\\\n\\\\ndef render_tree(paths: List[str]) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\\\n    Render a tree view from a list of relative POSIX paths.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    tree_structure:\\\\\\n    \\\\ dict = {}\\\\n\\\\n    for p in paths:\\\\n        parts = Path(p).parts\\\\n        current\\\\\\n    \\\\ = tree_structure\\\\n        for part in parts[:-1]:\\\\n            if part not in\\\\\\n    \\\\ current:\\\\n                current[part] = {}\\\\n            current = current[part]\\\\n\\\\\\n    \\\\        if parts:\\\\n            current[parts[-1]] = None\\\\n\\\\n    def _render(structure:\\\\\\n    \\\\ dict, prefix: str = \\\\\\\"\\\\\\\") -> str:\\\\n        lines = []\\\\n        items = sorted(structure.items(),\\\\\\n    \\\\ key=lambda x: (x[1] is None, x[0]))\\\\n        for i, (name, subtree) in enumerate(items):\\\\n\\\\\\n    \\\\            is_last = i == len(items) - 1\\\\n            lines.append(f\\\\\\\"{prefix}{'└──\\\\\\n    \\\\ ' if is_last else '├── '}{name}\\\\\\\")\\\\n            if subtree is not None:\\\\n  \\\\\\n    \\\\              extension = (\\\\\\\"    \\\\\\\" if is_last else \\\\\\\"│   \\\\\\\")\\\\n             \\\\\\n    \\\\   lines.append(_render(subtree, prefix + extension))\\\\n        return \\\\\\\"\\\\\\\\n\\\\\\\"\\\\\\n    .join(filter(None, lines))\\\\n\\\\n    if not tree_structure:\\\\n        return \\\\\\\"No\\\\\\n    \\\\ files found\\\\\\\"\\\\n    return _render(tree_structure)\\\"\\n  test-output.json: \\\"{\\\\n  \\\\\\\"root\\\\\\\": \\\\\\\"/Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\\\\\\\"\\\\\\n    ,\\\\n  \\\\\\\"repo_info\\\\\\\": {\\\\n    \\\\\\\"is_repo\\\\\\\": true,\\\\n    \\\\\\\"commit\\\\\\\": \\\\\\\"682153b169db66d3a72e9cabdd1f3448a3b2986d\\\\\\\"\\\\\\n    ,\\\\n    \\\\\\\"branch\\\\\\\": \\\\\\\"refactoring\\\\\\\",\\\\n    \\\\\\\"author\\\\\\\": \\\\\\\"Abhinav <abhinavbhardwaj2002@gmail.com>\\\\\\\"\\\\\\n    ,\\\\n    \\\\\\\"date\\\\\\\": \\\\\\\"Fri Oct 3 18:45:48 2025\\\\\\\",\\\\n    \\\\\\\"note\\\\\\\": null\\\\n  },\\\\n  \\\\\\\"\\\\\\n    structure\\\\\\\": \\\\\\\"├── src\\\\\\\\n│   └── rcpack\\\\\\\\n│       ├── renderer\\\\\\\\n│       │   ├──\\\\\\n    \\\\ jsonyaml.py\\\\\\\\n│       │   └── markdown.py\\\\\\\\n│       ├── __init__.py\\\\\\\\n│    \\\\\\n    \\\\   ├── __main__.py\\\\\\\\n│       ├── cli.py\\\\\\\\n│       ├── config_loader.py\\\\\\\\n│  \\\\\\n    \\\\     ├── discover.py\\\\\\\\n│       ├── gitinfo.py\\\\\\\\n│       ├── io_utils.py\\\\\\\\n│ \\\\\\n    \\\\      ├── packager.py\\\\\\\\n│       └── treeview.py\\\\\\\\n├── LICENSE\\\\\\\\n├── README.md\\\\\\\\\\\\\\n    n└── pyproject.toml\\\\\\\",\\\\n  \\\\\\\"recent_changes\\\\\\\": [],\\\\n  \\\\\\\"files\\\\\\\": {\\\\n    \\\\\\\"LICENSE\\\\\\\"\\\\\\n    : \\\\\\\"MIT License\\\\\\\\n\\\\\\\\nCopyright (c) 2025 Abhinav\\\\\\\\n\\\\\\\\nPermission is hereby granted,\\\\\\n    \\\\ free of charge, to any person obtaining a copy\\\\\\\\nof this software and associated\\\\\\n    \\\\ documentation files (the \\\\\\\\\\\\\\\"Software\\\\\\\\\\\\\\\"), to deal\\\\\\\\nin the Software without\\\\\\n    \\\\ restriction, including without limitation the rights\\\\\\\\nto use, copy, modify,\\\\\\n    \\\\ merge, publish, distribute, sublicense, and/or sell\\\\\\\\ncopies of the Software,\\\\\\n    \\\\ and to permit persons to whom the Software is\\\\\\\\nfurnished to do so, subject\\\\\\n    \\\\ to the following conditions:\\\\\\\\n\\\\\\\\nThe above copyright notice and this permission\\\\\\n    \\\\ notice shall be included in all\\\\\\\\ncopies or substantial portions of the Software.\\\\\\\\\\\\\\n    n\\\\\\\\nTHE SOFTWARE IS PROVIDED \\\\\\\\\\\\\\\"AS IS\\\\\\\\\\\\\\\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\\\\\\n    \\\\ OR\\\\\\\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\\\\\\\\\\\n    nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\\\\\\\\\\\n    nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\\\\\nLIABILITY,\\\\\\n    \\\\ WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\\\\\nOUT OF\\\\\\n    \\\\ OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\\\\\nSOFTWARE.\\\\\\\\\\\\\\n    n\\\\\\\",\\\\n    \\\\\\\"README.md\\\\\\\": \\\\\\\"# Repo-Contextor\\\\\\\\n\\\\\\\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\\\\\\\\\\\\\n    n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\\\\\\\\\\\\\n    n\\\\\\\\nA powerful Repository Context Packager CLI tool that analyzes local git repositories\\\\\\n    \\\\ and creates comprehensive text files containing repository content optimized\\\\\\n    \\\\ for sharing with Large Language Models (LLMs).\\\\\\\\n\\\\\\\\n## Overview\\\\\\\\n\\\\\\\\nWhen developers\\\\\\n    \\\\ want to get help from ChatGPT, Claude, or other LLMs about their code, they\\\\\\n    \\\\ often struggle with how to share their codebase effectively. Common problems\\\\\\n    \\\\ include:\\\\\\\\n\\\\\\\\n- **Lost Context**: Copy-pasting individual files loses important\\\\\\n    \\\\ project structure and relationships\\\\\\\\n- **Missing Dependencies**: LLMs can't\\\\\\n    \\\\ see how files connect or what libraries are used\\\\\\\\n- **Incomplete Picture**:\\\\\\n    \\\\ Hard to convey the overall architecture and organization\\\\\\\\n- **Manual Work**:\\\\\\n    \\\\ Time-consuming to gather and format relevant code\\\\\\\\n\\\\\\\\n**Repo-Contextor** solves\\\\\\n    \\\\ this by automatically collecting and formatting repository content into a single,\\\\\\n    \\\\ well-structured text file that provides rich context to LLMs, enabling them\\\\\\n    \\\\ to give much better assistance with your code.\\\\\\\\n\\\\\\\\n## Features\\\\\\\\n\\\\\\\\n- **Git\\\\\\n    \\\\ Integration**: Extracts commit SHA, branch, author, and date information\\\\\\\\n-\\\\\\n    \\\\ **Project Structure**: Generates a clear directory tree visualization\\\\\\\\n- **File\\\\\\n    \\\\ Content Packaging**: Includes file contents with syntax highlighting\\\\\\\\n- **Smart\\\\\\n    \\\\ File Discovery**: Recursively scans directories with intelligent filtering\\\\\\\\\\\\\\n    n- **Binary File Detection**: Automatically skips binary files\\\\\\\\n- **Error Handling**:\\\\\\n    \\\\ Gracefully handles permission errors and provides helpful messages\\\\\\\\n- **Multiple\\\\\\n    \\\\ Output Formats**: Supports Markdown, JSON, and YAML formats\\\\\\\\n- **Flexible Output**:\\\\\\n    \\\\ Write to stdout or save to a file\\\\\\\\n- **Recent Changes Filter**: Give the files\\\\\\n    \\\\ which are updated in last 7days with the time when it was recently modified.\\\\\\\\\\\\\\n    n\\\\\\\\n## Installation\\\\\\\\n\\\\\\\\n### Prerequisites\\\\\\\\n\\\\\\\\n- Python 3.9 or higher\\\\\\\\n- Git\\\\\\n    \\\\ (for git repository analysis)\\\\\\\\n\\\\\\\\n### For End Users\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Clone\\\\\\n    \\\\ and install\\\\\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\\\\\\\\n    ncd Repo-Contextor\\\\\\\\npip install -e .\\\\\\\\n```\\\\\\\\n\\\\\\\\n### For Contributors & Local\\\\\\n    \\\\ Development\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Clone the repository\\\\\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\\\\\\\\n    ncd Repo-Contextor\\\\\\\\n\\\\\\\\n# Create virtual environment\\\\\\\\npython -m venv .venv\\\\\\\\\\\\\\n    nsource .venv/bin/activate  # On Windows: .venv\\\\\\\\\\\\\\\\Scripts\\\\\\\\\\\\\\\\activate\\\\\\\\n\\\\\\\\n#\\\\\\n    \\\\ Install in development mode\\\\\\\\npip install -e .\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Usage\\\\\\\\n\\\\\\\\n###\\\\\\n    \\\\ Basic Examples\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Package current directory to terminal\\\\\\\\nrepo-contextor\\\\\\n    \\\\ .\\\\\\\\n\\\\\\\\n# Package a specific directory\\\\\\\\nrepo-contextor /path/to/your/project\\\\\\\\\\\\\\n    n\\\\\\\\n# Save output to a file\\\\\\\\nrepo-contextor . -o my-project-context.md\\\\\\\\n\\\\\\\\n#\\\\\\n    \\\\ Generate JSON format\\\\\\\\nrepo-contextor . -f json -o context.json\\\\\\\\n\\\\\\\\n# Generate\\\\\\n    \\\\ YAML format\\\\\\\\nrepo-contextor . -f yaml -o context.yaml\\\\\\\\n\\\\\\\\n# Include only files\\\\\\n    \\\\ modified in the last 7 days\\\\\\\\nrepo-contextor . --recent\\\\\\\\n\\\\\\\\n# Combine with\\\\\\n    \\\\ output file\\\\\\\\nrepo-contextor . --recent -o recent-changes.md\\\\\\\\n```\\\\\\\\n\\\\\\\\n###\\\\\\n    \\\\ Command Line Options\\\\\\\\n\\\\\\\\n| Option | Short | Description | Example |\\\\\\\\n|--------|-------|-------------|---------|\\\\\\\\\\\\\\n    n| `path` | - | Repository path to analyze (default: current directory) | `repo-contextor\\\\\\n    \\\\ /path/to/project` |\\\\\\\\n| `--output` | `-o` | Output file path (default: stdout)\\\\\\n    \\\\ | `-o context.md` |\\\\\\\\n| `--format` | `-f` | Output format: text, json, yaml\\\\\\n    \\\\ (default: text) | `-f json` |\\\\\\\\n| `--help` | `-h` | Show help message | `-h`\\\\\\n    \\\\ |\\\\\\\\n| `--recent`  | `-r`  | Include only files modified in the last 7 days \\\\\\n    \\\\   | `repo-contextor . -r -o recent.md` |\\\\\\\\n\\\\\\\\n### Advanced Examples\\\\\\\\n\\\\\\\\n```bash\\\\\\\\\\\\\\n    n# Analyze different repository\\\\\\\\nrepo-contextor /path/to/other/project -o other-project.md\\\\\\\\\\\\\\n    n\\\\\\\\n# Generate JSON for API consumption\\\\\\\\nrepo-contextor . -f json -o api-context.json\\\\\\\\\\\\\\n    n\\\\\\\\n# Create YAML configuration\\\\\\\\nrepo-contextor . -f yaml -o project-config.yaml\\\\\\\\\\\\\\n    n\\\\\\\\n# Generate files which are changed recently in 7 days\\\\\\\\nrepo-contextor . -r\\\\\\n    \\\\ --output recent-changes.txt\\\\\\\\n\\\\\\\\n```\\\\\\\\n## Configuration via TOML\\\\\\\\n\\\\\\\\nRepo-Contextor\\\\\\n    \\\\ supports configuration through a `.repo-contextor.toml` file in the current\\\\\\n    \\\\ working directory.  \\\\\\\\nThis file allows you to avoid typing the same CLI arguments\\\\\\n    \\\\ every time.\\\\\\\\n\\\\\\\\nExample `.repo-contextor.toml`:\\\\\\\\n\\\\\\\\n```toml\\\\\\\\n# Output file\\\\\\n    \\\\ to write results\\\\\\\\noutput = \\\\\\\\\\\\\\\"context.yaml\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Output format: text,\\\\\\n    \\\\ json, or yaml\\\\\\\\nformat = \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Limit to files modified in the\\\\\\n    \\\\ last 7 days\\\\\\\\nrecent = true\\\\\\\\n\\\\\\\\n# Repository path to analyze (default = current\\\\\\n    \\\\ directory)\\\\\\\\npath = \\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n### Rules\\\\\\\\n- If the `.repo-contextor.toml`\\\\\\n    \\\\ file is **missing**, the tool falls back to defaults.  \\\\\\\\n- If the file is **present\\\\\\n    \\\\ but invalid TOML**, the tool prints a clear error message and exits with status\\\\\\n    \\\\ code 1.  \\\\\\\\n- **Unknown keys** in the TOML file are ignored (safe for future\\\\\\n    \\\\ extensions).  \\\\\\\\n- **Precedence** of settings is:\\\\\\\\n  1. Command-line arguments\\\\\\n    \\\\ (highest priority)  \\\\\\\\n  2. Values from `.repo-contextor.toml`  \\\\\\\\n  3. Built-in\\\\\\n    \\\\ defaults (lowest priority)\\\\\\\\n     \\\\\\\\n## Output Format\\\\\\\\n\\\\\\\\nThe tool generates\\\\\\n    \\\\ a structured text file with the following sections:\\\\\\\\n\\\\\\\\n### 1. Repository Context\\\\\\n    \\\\ Header\\\\\\\\nProject path and identification\\\\\\\\n\\\\\\\\n### 2. Git Repository Information\\\\\\\\\\\\\\n    n- Current branch\\\\\\\\n- Latest commit SHA\\\\\\\\n- Last commit author\\\\\\\\n- Last commit\\\\\\n    \\\\ date\\\\\\\\n\\\\\\\\n### 3. Summary Statistics\\\\\\\\n- Total number of files processed\\\\\\\\n-\\\\\\n    \\\\ Total lines of code\\\\\\\\n\\\\\\\\n### 4. Directory Structure\\\\\\\\nClean tree visualization\\\\\\n    \\\\ showing project organization\\\\\\\\n\\\\\\\\n### 5. Recent Changes (if `--recent` is used)\\\\\\\\\\\\\\n    n\\\\\\\\n- Lists files modified in the last 7 days.\\\\\\\\n- Shows relative file paths along\\\\\\n    \\\\ with how long ago each file was modified\\\\\\\\n- Helps focus on recently updated\\\\\\n    \\\\ parts of the project.\\\\\\\\n- Can be combined with `--output` or `--format` to save\\\\\\n    \\\\ or change the output type.\\\\\\\\n\\\\\\\\n\\\\\\\\n### 5. File Contents\\\\\\\\nEach file's content\\\\\\n    \\\\ with:\\\\\\\\n- Clear file path headers\\\\\\\\n- Appropriate syntax highlighting language\\\\\\n    \\\\ tags\\\\\\\\n- Complete file contents\\\\\\\\n\\\\\\\\n## Example Output\\\\\\\\n\\\\\\\\nWhen you run `repo-contextor\\\\\\n    \\\\ .`, the output looks like this:\\\\\\\\n\\\\\\\\n````markdown\\\\\\\\n# Repository Context: /path/to/your/project\\\\\\\\\\\\\\n    n\\\\\\\\n## Git Repository Information\\\\\\\\n- **Branch**: main\\\\\\\\n- **Commit**: a1b2c3d4e5f6789...\\\\\\\\\\\\\\n    n- **Author**: John Doe <john@example.com>\\\\\\\\n- **Date**: Fri Sep 12 14:30:15 2025\\\\\\\\\\\\\\n    n\\\\\\\\n## Summary\\\\\\\\n- **Total Files**: 15\\\\\\\\n- **Total Lines**: 1,247\\\\\\\\n\\\\\\\\n## Directory\\\\\\n    \\\\ Structure\\\\\\\\n```\\\\\\\\n├── src/\\\\\\\\n│   ├── main.py\\\\\\\\n│   └── utils.py\\\\\\\\n├── tests/\\\\\\\\\\\\\\n    n│   └── test_main.py\\\\\\\\n├── README.md\\\\\\\\n└── requirements.txt\\\\\\\\n```\\\\\\\\n## Recent\\\\\\n    \\\\ Changes\\\\\\\\n- src/main.py (modified 2 days ago)\\\\\\\\n- src/utils/helpers.py (modified\\\\\\n    \\\\ 5 days ago)\\\\\\\\n\\\\\\\\n## File Contents\\\\\\\\n\\\\\\\\n### src/main.py\\\\\\\\n\\\\\\\\n```python\\\\\\\\ndef\\\\\\n    \\\\ main():\\\\\\\\n    print(\\\\\\\\\\\\\\\"Hello, World!\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\n    \\\\\\\":\\\\\\\\n    main()\\\\\\\\n```\\\\\\\\n\\\\\\\\n### README.md\\\\\\\\n\\\\\\\\n```markdown\\\\\\\\n# My Project\\\\\\\\nThis\\\\\\n    \\\\ is a sample project.\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Summary\\\\\\\\n- Total files: 15\\\\\\\\n- Total lines:\\\\\\n    \\\\ 1,247\\\\\\\\n````\\\\\\\\n\\\\\\\\n## What Files Are Included\\\\\\\\n\\\\\\\\nThe tool includes most text\\\\\\n    \\\\ files but automatically excludes:\\\\\\\\n\\\\\\\\n### Excluded Directories\\\\\\\\n- `.git`,\\\\\\n    \\\\ `.svn`, `.hg` (version control)\\\\\\\\n- `__pycache__`, `.pytest_cache` (Python cache)\\\\\\\\\\\\\\n    n- `node_modules`, `.venv`, `venv` (dependencies/environments)\\\\\\\\n- `.vscode`,\\\\\\n    \\\\ `.idea` (IDE directories)\\\\\\\\n- `build`, `dist`, `target` (build directories)\\\\\\\\\\\\\\n    n\\\\\\\\n### File Handling Rules\\\\\\\\n- **Text files**: All readable text files with common\\\\\\n    \\\\ extensions\\\\\\\\n- **Binary files**: Automatically detected and skipped\\\\\\\\n- **Permission\\\\\\n    \\\\ errors**: Skipped with graceful handling\\\\\\\\n- **Configuration files**: Includes\\\\\\n    \\\\ pyproject.toml, package.json, etc.\\\\\\\\n\\\\\\\\n### Included File Types\\\\\\\\n- Source code:\\\\\\n    \\\\ `.py`, `.js`, `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\\\\\\\n- Web files:\\\\\\n    \\\\ `.html`, `.css`, `.scss`, `.vue`, `.jsx`, etc.\\\\\\\\n- Documentation: `.md`, `.txt`,\\\\\\n    \\\\ `.rst`\\\\\\\\n- Configuration: `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\\\\\\\n- Scripts:\\\\\\n    \\\\ `.sh`, `.bash`, `.zsh`\\\\\\\\n\\\\\\\\n## Error Handling\\\\\\\\n\\\\\\\\nThe tool handles errors gracefully:\\\\\\\\\\\\\\n    n\\\\\\\\n| Error Type | Behavior |\\\\\\\\n|------------|----------|\\\\\\\\n| **Permission errors**\\\\\\n    \\\\ | Skipped with warning |\\\\\\\\n| **Binary files** | Automatically detected and skipped\\\\\\n    \\\\ |\\\\\\\\n| **Invalid paths** | Clear error messages |\\\\\\\\n| **Non-git repositories**\\\\\\n    \\\\ | Works fine, shows \\\\\\\\\\\\\\\"Not a git repository\\\\\\\\\\\\\\\" |\\\\\\\\n| **Unreadable files**\\\\\\n    \\\\ | Marked as \\\\\\\\\\\\\\\"[Binary or unreadable file]\\\\\\\\\\\\\\\" |\\\\\\\\n\\\\\\\\n## Development\\\\\\\\n\\\\\\\\n###\\\\\\n    \\\\ Project Structure\\\\\\\\n\\\\\\\\n```text\\\\\\\\nRepo-Contextor/\\\\\\\\n├── src/rcpack/         \\\\\\n    \\\\     # Main package\\\\\\\\n│   ├── __init__.py         # Package initialization\\\\\\\\\\\\\\n    n│   ├── cli.py              # Command-line interface\\\\\\\\n│   ├── discover.py  \\\\\\n    \\\\       # File discovery logic\\\\\\\\n│   ├── gitinfo.py          # Git repository\\\\\\n    \\\\ analysis\\\\\\\\n│   ├── treeview.py         # Directory tree generation\\\\\\\\n│   ├──\\\\\\n    \\\\ packager.py         # Main orchestration\\\\\\\\n│   ├── io_utils.py         # File\\\\\\n    \\\\ I/O utilities\\\\\\\\n│   └── renderer/           # Output formatters\\\\\\\\n│       ├──\\\\\\n    \\\\ markdown.py     # Markdown renderer\\\\\\\\n│       └── jsonyaml.py     # JSON/YAML\\\\\\n    \\\\ renderers\\\\\\\\n├── pyproject.toml          # Project configuration\\\\\\\\n├── LICENSE\\\\\\n    \\\\                 # MIT License\\\\\\\\n└── README.md              # This documentation\\\\\\\\\\\\\\n    n```\\\\\\\\n\\\\\\\\n### Running Tests\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Test on current repository\\\\\\\\nrepo-contextor\\\\\\n    \\\\ . -o test-output.md\\\\\\\\n\\\\\\\\n# Test different formats\\\\\\\\nrepo-contextor . -f json\\\\\\n    \\\\ | head -20\\\\\\\\nrepo-contextor . -f yaml | head -20\\\\\\\\n\\\\\\\\n# Test specific directory\\\\\\\\\\\\\\n    nrepo-contextor src/ -o src-only.md\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Contributing\\\\\\\\n\\\\\\\\n1. **Fork\\\\\\n    \\\\ the repository**\\\\\\\\n2. **Clone your fork:**\\\\\\\\n   ```bash\\\\\\\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\\\\\\\\n    n   cd Repo-Contextor\\\\\\\\n   ```\\\\\\\\n3. **Install for development:**\\\\\\\\n   ```bash\\\\\\\\\\\\\\n    n   python -m venv .venv\\\\\\\\n   source .venv/bin/activate\\\\\\\\n   pip install -e .\\\\\\\\\\\\\\n    n   ```\\\\\\\\n4. **Make your changes and test:**\\\\\\\\n   ```bash\\\\\\\\n   repo-contextor\\\\\\n    \\\\ . -o test.md\\\\\\\\n   ```\\\\\\\\n5. **Submit a pull request**\\\\\\\\n\\\\\\\\n### Development Workflow\\\\\\\\\\\\\\n    n\\\\\\\\n```bash\\\\\\\\n# 1. Setup development environment\\\\\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\\\\\\\\n    ncd Repo-Contextor\\\\\\\\npython -m venv .venv\\\\\\\\nsource .venv/bin/activate\\\\\\\\npip install\\\\\\n    \\\\ -e .\\\\\\\\n\\\\\\\\n# 2. Make changes to the code\\\\\\\\n# Edit files in src/rcpack/\\\\\\\\n\\\\\\\\n#\\\\\\n    \\\\ 3. Test your changes\\\\\\\\nrepo-contextor . -o test-output.md\\\\\\\\n\\\\\\\\n# 4. Test different\\\\\\n    \\\\ formats\\\\\\\\nrepo-contextor . -f json -o test.json\\\\\\\\nrepo-contextor . -f yaml -o\\\\\\n    \\\\ test.yaml\\\\\\\\n\\\\\\\\n# 5. Commit and push changes\\\\\\\\ngit add .\\\\\\\\ngit commit -m \\\\\\\\\\\\\\\"\\\\\\n    Add new feature\\\\\\\\\\\\\\\"\\\\\\\\ngit push origin feature-branch\\\\\\\\n```\\\\\\\\n\\\\\\\\n## License\\\\\\\\n\\\\\\\\\\\\\\n    nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file\\\\\\n    \\\\ for details.\\\\\\\\n\\\\\\\\n## Why Repo-Contextor?\\\\\\\\n\\\\\\\\nThe name \\\\\\\\\\\\\\\"Repo-Contextor\\\\\\\\\\\\\\\"\\\\\\n    \\\\ combines \\\\\\\\\\\\\\\"Repository\\\\\\\\\\\\\\\" + \\\\\\\\\\\\\\\"Context\\\\\\\\\\\\\\\" + \\\\\\\\\\\\\\\"or\\\\\\\\\\\\\\\", representing the\\\\\\n    \\\\ tool's purpose of providing rich context about code repositories in a format\\\\\\n    \\\\ that's perfect for LLM interactions.\\\\\\\\n\\\\\\\\n### Use Cases\\\\\\\\n\\\\\\\\n- **AI Assistance**:\\\\\\n    \\\\ Get better help from ChatGPT, Claude, or GitHub Copilot\\\\\\\\n- **Code Reviews**:\\\\\\n    \\\\ Share complete project context with team members\\\\\\\\n- **Documentation**: Create\\\\\\n    \\\\ comprehensive project snapshots\\\\\\\\n- **Onboarding**: Help new team members understand\\\\\\n    \\\\ project structure\\\\\\\\n- **Project Analysis**: Understand repository structure\\\\\\n    \\\\ and dependencies\\\\\\\\n\\\\\\\\n### Perfect for LLMs\\\\\\\\n\\\\\\\\nThe output format is specifically\\\\\\n    \\\\ designed to work well with Large Language Models:\\\\\\\\n- Clear section headers\\\\\\n    \\\\ for easy parsing\\\\\\\\n- Syntax highlighting markers for code blocks\\\\\\\\n- Structured\\\\\\n    \\\\ metadata (git info, file locations)\\\\\\\\n- Complete project context in a single\\\\\\n    \\\\ file\\\\\\\\n- Multiple output formats (Markdown, JSON, YAML)\\\\\\\\n- Optimized for token\\\\\\n    \\\\ efficiency\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"pyproject.toml\\\\\\\": \\\\\\\"[build-system]\\\\\\\\nrequires = [\\\\\\\\\\\\\\\"\\\\\\n    setuptools>=68\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"wheel\\\\\\\\\\\\\\\"]\\\\\\\\nbuild-backend = \\\\\\\\\\\\\\\"setuptools.build_meta\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\n\\\\\\\\n[project]\\\\\\\\nname = \\\\\\\\\\\\\\\"rcpack\\\\\\\\\\\\\\\"\\\\\\\\nversion = \\\\\\\\\\\\\\\"0.1.0\\\\\\\\\\\\\\\"\\\\\\\\ndescription\\\\\\n    \\\\ = \\\\\\\\\\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\\\\\\\\\"\\\\\\\\nreadme = \\\\\\\\\\\\\\\"README.md\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\nrequires-python = \\\\\\\\\\\\\\\">=3.9\\\\\\\\\\\\\\\"\\\\\\\\nlicense = { text = \\\\\\\\\\\\\\\"MIT\\\\\\\\\\\\\\\" }\\\\\\\\ndependencies\\\\\\n    \\\\ = [\\\\\\\\n    \\\\\\\\\\\\\\\"PyYAML>=6.0\\\\\\\\\\\\\\\"\\\\\\\\n]\\\\\\\\n\\\\\\\\n[project.scripts]\\\\\\\\nrepo-contextor =\\\\\\n    \\\\ \\\\\\\\\\\\\\\"rcpack.cli:main\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/__init__.py\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\n    Repository Context Packager - CLI tool for creating LLM-optimized repository context.\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n__version__ = \\\\\\\\\\\\\\\"0.1.0\\\\\\\\\\\\\\\"\\\\\\\\n__author__ = \\\\\\\\\\\\\\\"Abhinav\\\\\\\\\\\\\\\"\\\\\\\\n__description__\\\\\\n    \\\\ = \\\\\\\\\\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\\\\\\\\\"\\\\\\\",\\\\n    \\\\\\\"src/rcpack/__main__.py\\\\\\\"\\\\\\n    : \\\\\\\"#!/usr/bin/env python3\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Module entry point to enable `python\\\\\\n    \\\\ -m rcpack`.\\\\\\\\n\\\\\\\\nThis simply delegates to the CLI's main() function.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom .cli import main\\\\\\\\n\\\\\\\\n\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\":\\\\\\\\n\\\\\\n    \\\\    main()\\\\\\\\n\\\\\\\\n\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/cli.py\\\\\\\": \\\\\\\"#!/usr/bin/env python3\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"CLI for Repository Context Packager.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom .config_loader\\\\\\n    \\\\ import load_config\\\\\\\\n\\\\\\\\nimport argparse\\\\\\\\nimport sys\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\n    nfrom .gitinfo import get_git_info\\\\\\\\nfrom .discover import discover_files\\\\\\\\nfrom\\\\\\n    \\\\ .treeview import create_tree_view\\\\\\\\nfrom .renderer.markdown import render_markdown\\\\\\\\\\\\\\n    nfrom .renderer.jsonyaml import render_json, render_yaml\\\\\\\\nfrom .io_utils import\\\\\\n    \\\\ write_output\\\\\\\\nfrom datetime import datetime, timedelta\\\\\\\\n\\\\\\\\n\\\\\\\\ndef log_verbose(message:\\\\\\n    \\\\ str, verbose: bool) -> None:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Log a message to stderr if verbose\\\\\\n    \\\\ mode is enabled.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if verbose:\\\\\\\\n        print(message, file=sys.stderr)\\\\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\\ndef get_rendered_content(format_type: str, repo_path: str, repo_info: dict,\\\\\\n    \\\\ tree_text: str, \\\\\\\\n                        files_data: dict, total_files: int,\\\\\\n    \\\\ total_lines: int, \\\\\\\\n                        recent_files_info: dict, file_sizes:\\\\\\n    \\\\ dict) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get rendered content based on the specified\\\\\\n    \\\\ format.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if format_type == \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\":\\\\\\\\n        return render_json(\\\\\\\\\\\\\\n    n            repo_path, repo_info, tree_text, \\\\\\\\n            files_data, total_files,\\\\\\n    \\\\ total_lines,\\\\\\\\n            recent_files=recent_files_info,\\\\\\\\n            file_sizes=file_sizes\\\\\\\\\\\\\\n    n        )\\\\\\\\n    elif format_type == \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\":\\\\\\\\n        return render_yaml(\\\\\\\\\\\\\\n    n            repo_path, repo_info, tree_text, \\\\\\\\n            files_data, total_files,\\\\\\n    \\\\ total_lines,\\\\\\\\n            recent_files=recent_files_info,\\\\\\\\n            file_sizes=file_sizes\\\\\\\\\\\\\\n    n        )\\\\\\\\n    else:  # text/markdown\\\\\\\\n        return render_markdown(\\\\\\\\n \\\\\\n    \\\\           repo_path, repo_info, tree_text, \\\\\\\\n            files_data, total_files,\\\\\\n    \\\\ total_lines,\\\\\\\\n            recent_files=recent_files_info,\\\\\\\\n            file_sizes=file_sizes\\\\\\\\\\\\\\n    n        )\\\\\\\\n\\\\\\\\n\\\\\\\\ndef process_file(file_path: Path, repo_path: Path, verbose:\\\\\\n    \\\\ bool) -> tuple[str, str, str]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Process a single file and return\\\\\\n    \\\\ its data.\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        tuple: (relative_path_str, content,\\\\\\n    \\\\ file_size)\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    relative_path = file_path.relative_to(repo_path)\\\\\\\\\\\\\\n    n    relative_path_str = str(relative_path)\\\\\\\\n    \\\\\\\\n    log_verbose(f\\\\\\\\\\\\\\\"Reading\\\\\\n    \\\\ file: {relative_path}\\\\\\\\\\\\\\\", verbose)\\\\\\\\n    file_size = file_path.stat().st_size\\\\\\\\\\\\\\n    n    \\\\\\\\n    try:\\\\\\\\n        with open(file_path, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\n    n            content = f.read()\\\\\\\\n        return relative_path_str, content, str(file_size)\\\\\\\\\\\\\\n    n    except (UnicodeDecodeError, PermissionError):\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\"\\\\\\n    Skipping binary/unreadable file: {relative_path}\\\\\\\\\\\\\\\", verbose)\\\\\\\\n        file_size\\\\\\n    \\\\ = file_path.stat().st_size if file_path.exists() else 0\\\\\\\\n        content =\\\\\\n    \\\\ f\\\\\\\\\\\\\\\"[Binary or unreadable file: {file_path.name}]\\\\\\\\\\\\\\\"\\\\\\\\n        return relative_path_str,\\\\\\n    \\\\ content, str(file_size)\\\\\\\\n    except Exception:\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\"\\\\\\n    Error reading file: {relative_path}\\\\\\\\\\\\\\\", verbose)\\\\\\\\n        raise  # Re-raise\\\\\\n    \\\\ to handle in calling code\\\\\\\\n\\\\\\\\n\\\\\\\\ndef handle_output(content: str, output_path:\\\\\\n    \\\\ str = None) -> None:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Handle output to either file or stdout.\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if output_path:\\\\\\\\n        # Write to file\\\\\\\\n        write_output(output_path,\\\\\\n    \\\\ content)\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Context package created: {output_path}\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\n    n    else:\\\\\\\\n        # Output to stdout\\\\\\\\n        print(content)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef main():\\\\\\\\\\\\\\n    n    parser = argparse.ArgumentParser(\\\\\\\\n        description=\\\\\\\\\\\\\\\"Package repository\\\\\\n    \\\\ content for LLM context\\\\\\\\\\\\\\\"\\\\\\\\n    )\\\\\\\\n    parser.add_argument(\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\n    path\\\\\\\\\\\\\\\", \\\\\\\\n        nargs=\\\\\\\\\\\\\\\"?\\\\\\\\\\\\\\\", \\\\\\\\n        default=\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\", \\\\\\\\n      \\\\\\n    \\\\  help=\\\\\\\\\\\\\\\"Repository path (default: current directory)\\\\\\\\\\\\\\\"\\\\\\\\n    )\\\\\\\\n    parser.add_argument(\\\\\\\\\\\\\\n    n        \\\\\\\\\\\\\\\"-o\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--output\\\\\\\\\\\\\\\", \\\\\\\\n        help=\\\\\\\\\\\\\\\"Output file path (default:\\\\\\n    \\\\ stdout)\\\\\\\\\\\\\\\"\\\\\\\\n    )\\\\\\\\n    parser.add_argument(\\\\\\\\n        \\\\\\\\\\\\\\\"-f\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--format\\\\\\\\\\\\\\n    \\\\\\\", \\\\\\\\n        choices=[\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\"], \\\\\\\\n       \\\\\\n    \\\\ default=\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\",\\\\\\\\n        help=\\\\\\\\\\\\\\\"Output format (default: text)\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\n    n    )\\\\\\\\n\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" This will read -r from the console and able to search\\\\\\n    \\\\ it with this\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    parser.add_argument(\\\\\\\\n    \\\\\\\\\\\\\\\"-r\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--recent\\\\\\\\\\\\\\n    \\\\\\\",\\\\\\\\n    action=\\\\\\\\\\\\\\\"store_true\\\\\\\\\\\\\\\",\\\\\\\\n    help=\\\\\\\\\\\\\\\"Include only files modified\\\\\\n    \\\\ in the last 7 days\\\\\\\\\\\\\\\"\\\\\\\\n    )\\\\\\\\n    parser.add_argument(\\\\\\\\n        \\\\\\\\\\\\\\\"-v\\\\\\\\\\\\\\n    \\\\\\\", \\\\\\\\\\\\\\\"--verbose\\\\\\\\\\\\\\\",\\\\\\\\n        action=\\\\\\\\\\\\\\\"store_true\\\\\\\\\\\\\\\",\\\\\\\\n        help=\\\\\\\\\\\\\\\"\\\\\\n    Print detailed progress information to stderr\\\\\\\\\\\\\\\"\\\\\\\\n    )\\\\\\\\n    \\\\\\\\n    args =\\\\\\n    \\\\ parser.parse_args()\\\\\\\\n    \\\\\\\\n    try:\\\\\\\\n        repo_path = Path(args.path).resolve()\\\\\\\\\\\\\\n    n        if not repo_path.exists():\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error: Path {repo_path}\\\\\\n    \\\\ does not exist\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\n            sys.exit(1)\\\\\\\\n          \\\\\\n    \\\\  \\\\\\\\n        # Get repository information\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\"Analyzing\\\\\\n    \\\\ repository: {repo_path}\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n        repo_info = get_git_info(repo_path)\\\\\\\\\\\\\\n    n        \\\\\\\\n        # Discover files\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\"Discovering files\\\\\\n    \\\\ in: {repo_path}\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n        discovered_files = discover_files([repo_path],\\\\\\n    \\\\ repo_path, [], [])\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\"Found {len(discovered_files)}\\\\\\n    \\\\ files\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n        \\\\\\\\n        # will check the file in last\\\\\\n    \\\\ 7 days\\\\\\\\n        recent_files_info = {}\\\\\\\\n        if args.recent:\\\\\\\\n       \\\\\\n    \\\\     seven_days_ago = datetime.now() - timedelta(days=7)\\\\\\\\n            recent_files\\\\\\n    \\\\ = []\\\\\\\\n            for f in discovered_files:\\\\\\\\n                try:\\\\\\\\n    \\\\\\n    \\\\                mtime = datetime.fromtimestamp(f.stat().st_mtime)\\\\\\\\n        \\\\\\n    \\\\            if mtime >= seven_days_ago:\\\\\\\\n                        recent_files.append(f)\\\\\\\\\\\\\\n    n                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)\\\\\\n    \\\\     \\\\\\\\n                except Exception:\\\\\\\\n                    continue\\\\\\\\n \\\\\\n    \\\\           discovered_files = recent_files\\\\\\\\n        \\\\\\\\n        # Read file contents\\\\\\\\\\\\\\n    n        files_data = {}\\\\\\\\n        file_sizes = {}\\\\\\\\n        for file_path in\\\\\\n    \\\\ discovered_files:\\\\\\\\n            try:\\\\\\\\n                relative_path_str, content,\\\\\\n    \\\\ file_size = process_file(file_path, repo_path, args.verbose)\\\\\\\\n            \\\\\\n    \\\\    files_data[relative_path_str] = content\\\\\\\\n                file_sizes[relative_path_str]\\\\\\n    \\\\ = file_size\\\\\\\\n            except Exception:\\\\\\\\n                continue\\\\\\\\n  \\\\\\n    \\\\      \\\\\\\\n        # Create tree view\\\\\\\\n        log_verbose(\\\\\\\\\\\\\\\"Generating directory\\\\\\n    \\\\ tree\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n        tree_text = create_tree_view(repo_path, files_data)\\\\\\\\\\\\\\n    n        \\\\\\\\n        # Count totals\\\\\\\\n        total_files = len(files_data)\\\\\\\\n\\\\\\n    \\\\        total_lines = sum(len(content.splitlines()) for _, content in files_data.items())\\\\\\\\\\\\\\n    n        \\\\\\\\n        # Render based on format\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\"Rendering\\\\\\n    \\\\ output in {args.format} format\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n        content = get_rendered_content(\\\\\\\\\\\\\\n    n            args.format, str(repo_path), repo_info, tree_text,\\\\\\\\n           \\\\\\n    \\\\ files_data, total_files, total_lines,\\\\\\\\n            recent_files_info if args.recent\\\\\\n    \\\\ else {},\\\\\\\\n            file_sizes\\\\\\\\n        )\\\\\\\\n        \\\\\\\\n        handle_output(content,\\\\\\n    \\\\ args.output)\\\\\\\\n        \\\\\\\\n    except Exception as e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Error:\\\\\\n    \\\\ {e}\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\n        sys.exit(1)\\\\\\\\n\\\\\\\\n# this will convert age\\\\\\n    \\\\ and give us the difference\\\\\\\\ndef human_readable_age(mtime: datetime) -> str:\\\\\\\\\\\\\\n    n    delta = datetime.now() - mtime\\\\\\\\n    days = delta.days\\\\\\\\n    seconds = delta.seconds\\\\\\\\\\\\\\n    n    if days > 0:\\\\\\\\n        return f\\\\\\\\\\\\\\\"{days} day{'s' if days != 1 else ''} ago\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\n    elif seconds >= 3600:\\\\\\\\n        hours = seconds // 3600\\\\\\\\n        return\\\\\\n    \\\\ f\\\\\\\\\\\\\\\"{hours} hour{'s' if hours != 1 else ''} ago\\\\\\\\\\\\\\\"\\\\\\\\n    elif seconds >= 60:\\\\\\\\\\\\\\n    n        minutes = seconds // 60\\\\\\\\n        return f\\\\\\\\\\\\\\\"{minutes} minute{'s' if\\\\\\n    \\\\ minutes != 1 else ''} ago\\\\\\\\\\\\\\\"\\\\\\\\n    else:\\\\\\\\n        return \\\\\\\\\\\\\\\"just now\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\n    n\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\":\\\\\\\\n    main()\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/config_loader.py\\\\\\\"\\\\\\n    : \\\\\\\"# src/rcpack/config_loader.py\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nTOML config loader for Repo-Contextor.\\\\\\\\\\\\\\n    n\\\\\\\\nRules:\\\\\\\\n- Look for .repo-contextor.toml in the CURRENT directory\\\\\\\\n- If missing:\\\\\\n    \\\\ ignore\\\\\\\\n- If present but invalid: print a clear error and exit(1)\\\\\\\\n- Only\\\\\\n    \\\\ recognized keys are applied; unknown keys ignored\\\\\\\\n- Precedence: CLI > TOML\\\\\\n    \\\\ > DEFAULTS\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nfrom __future__ import annotations\\\\\\\\nimport os,\\\\\\n    \\\\ sys\\\\\\\\nfrom typing import Dict, Iterable, Any\\\\\\\\n\\\\\\\\ntry:\\\\\\\\n    import tomllib\\\\\\\\\\\\\\n    n    _loads = tomllib.loads\\\\\\\\nexcept ModuleNotFoundError:\\\\\\\\n    try:\\\\\\\\n      \\\\\\n    \\\\  import tomli\\\\\\\\n        _loads = tomli.loads\\\\\\\\n    except ModuleNotFoundError:\\\\\\\\\\\\\\n    n        _loads = None\\\\\\\\n\\\\\\\\ndef _need_toml():\\\\\\\\n    if _loads is None:\\\\\\\\n    \\\\\\n    \\\\    print(\\\\\\\\\\\\\\\"Error: TOML parser not available. Use Python 3.11+ or `pip install\\\\\\n    \\\\ tomli`.\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\n        sys.exit(1)\\\\\\\\n\\\\\\\\ndef _load_toml(dotfile:\\\\\\n    \\\\ str) -> Dict[str, Any]:\\\\\\\\n    _need_toml()\\\\\\\\n    if not os.path.exists(dotfile):\\\\\\\\\\\\\\n    n        return {}\\\\\\\\n    try:\\\\\\\\n        with open(dotfile, \\\\\\\\\\\\\\\"rb\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\n    n            raw = f.read().decode(\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", errors=\\\\\\\\\\\\\\\"strict\\\\\\\\\\\\\\\")\\\\\\\\n  \\\\\\n    \\\\      data = _loads(raw)\\\\\\\\n        return data if isinstance(data, dict) else\\\\\\n    \\\\ {}\\\\\\\\n    except Exception as e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Error: failed to parse\\\\\\n    \\\\ {dotfile} as TOML.\\\\\\\\\\\\\\\\n{e}\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\n        sys.exit(1)\\\\\\\\n\\\\\\\\\\\\\\n    ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\\\\\\\\\\\\\n    n    ks = set(known)\\\\\\\\n    return {k: v for k, v in d.items() if k in ks}\\\\\\\\n\\\\\\\\\\\\\\n    ndef _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str,\\\\\\n    \\\\ Any], known: Iterable[str]) -> Dict[str, Any]:\\\\\\\\n    ks = set(known)\\\\\\\\n    out:\\\\\\n    \\\\ Dict[str, Any] = {k: defaults.get(k) for k in ks}\\\\\\\\n    for src in (filecfg,\\\\\\n    \\\\ clicfg):\\\\\\\\n        for k, v in src.items():\\\\\\\\n            if k in ks and v is\\\\\\n    \\\\ not None:\\\\\\\\n                out[k] = v\\\\\\\\n    return out\\\\\\\\n\\\\\\\\ndef load_config(*,\\\\\\n    \\\\ dotfile: str = \\\\\\\\\\\\\\\".repo-contextor.toml\\\\\\\\\\\\\\\", defaults: Dict[str, Any] | None\\\\\\n    \\\\ = None, cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ())\\\\\\n    \\\\ -> Dict[str, Any]:\\\\\\\\n    defaults = defaults or {}\\\\\\\\n    cli_cfg = cli_cfg or\\\\\\n    \\\\ {}\\\\\\\\n    known = tuple(known_keys)\\\\\\\\n    filecfg = _filter_known(_load_toml(dotfile),\\\\\\n    \\\\ known)\\\\\\\\n    return _merge(defaults, filecfg, cli_cfg, known)\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"\\\\\\n    src/rcpack/discover.py\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"File discovery module for repository analysis.\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import List\\\\\\\\nimport fnmatch\\\\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\\ndef discover_files(\\\\\\\\n    inputs: List[Path],\\\\\\\\n    root: Path,\\\\\\\\n    include_patterns:\\\\\\n    \\\\ List[str],\\\\\\\\n    exclude_patterns: List[str],\\\\\\\\n) -> List[Path]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"Discover relevant files.\\\\\\\\n\\\\\\\\n    - inputs: list of files/dirs to scan\\\\\\\\\\\\\\n    n    - root: common project root; patterns are matched against POSIX paths relative\\\\\\n    \\\\ to root\\\\\\\\n    - include_patterns: glob patterns to include (if empty, use sensible\\\\\\n    \\\\ defaults)\\\\\\\\n    - exclude_patterns: glob patterns to exclude\\\\\\\\n    Returns a\\\\\\n    \\\\ list of absolute Paths to files.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    default_include_exts\\\\\\n    \\\\ = {\\\\\\\\n        '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\\\\\\\\\\\\\\n    n        '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\\\\\\\n   \\\\\\n    \\\\     '.html', '.css', '.scss', '.sass', '.less', '.vue', '.svelte',\\\\\\\\n      \\\\\\n    \\\\  '.md', '.txt', '.rst', '.yaml', '.yml', '.json', '.toml', '.ini',\\\\\\\\n      \\\\\\n    \\\\  '.cfg', '.conf', '.xml', '.sql', '.sh', '.bash', '.zsh', '.fish',\\\\\\\\n    }\\\\\\\\\\\\\\n    n\\\\\\\\n    always_include_names = {\\\\\\\\n        'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING',\\\\\\n    \\\\ 'Makefile',\\\\\\\\n        'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\\\\\\\\\\\\\\n    n        'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\\\\\\\\\\\\\n    n    }\\\\\\\\n\\\\\\\\n    skip_dir_names = {\\\\\\\\n        '.git', '.svn', '.hg', '__pycache__',\\\\\\n    \\\\ '.pytest_cache',\\\\\\\\n        'node_modules', '.venv', 'venv', 'env', '.env',\\\\\\\\\\\\\\n    n        'build', 'dist', 'target', 'out', '.next', '.nuxt',\\\\\\\\n        '.idea',\\\\\\n    \\\\ '.vscode', '.vs', 'coverage', '.coverage'\\\\\\\\n    }\\\\\\\\n\\\\\\\\n    def matches_any(patterns:\\\\\\n    \\\\ List[str], rel_posix: str) -> bool:\\\\\\\\n        return any(fnmatch.fnmatch(rel_posix,\\\\\\n    \\\\ pat) for pat in patterns)\\\\\\\\n\\\\\\\\n    def should_take(file_path: Path) -> bool:\\\\\\\\\\\\\\n    n        rel_posix = file_path.relative_to(root).as_posix()\\\\\\\\n        if exclude_patterns\\\\\\n    \\\\ and matches_any(exclude_patterns, rel_posix):\\\\\\\\n            return False\\\\\\\\n\\\\\\n    \\\\        if include_patterns:\\\\\\\\n            return matches_any(include_patterns,\\\\\\n    \\\\ rel_posix)\\\\\\\\n        # default include logic\\\\\\\\n        return file_path.name\\\\\\n    \\\\ in always_include_names or file_path.suffix.lower() in default_include_exts\\\\\\\\\\\\\\n    n\\\\\\\\n    discovered: list[Path] = []\\\\\\\\n    seen = set()\\\\\\\\n\\\\\\\\n    for item in inputs:\\\\\\\\\\\\\\n    n        p = item.resolve()\\\\\\\\n        if p.is_file():\\\\\\\\n            # Skip if\\\\\\n    \\\\ excluded or in skipped directory\\\\\\\\n            if any(part in skip_dir_names\\\\\\n    \\\\ for part in p.parts):\\\\\\\\n                continue\\\\\\\\n            if should_take(p):\\\\\\\\\\\\\\n    n                key = p.as_posix()\\\\\\\\n                if key not in seen:\\\\\\\\n \\\\\\n    \\\\                   seen.add(key)\\\\\\\\n                    discovered.append(p)\\\\\\\\\\\\\\n    n        elif p.is_dir():\\\\\\\\n            for child in p.rglob('*'):\\\\\\\\n        \\\\\\n    \\\\        if not child.is_file():\\\\\\\\n                    continue\\\\\\\\n           \\\\\\n    \\\\     if any(part in skip_dir_names for part in child.parts):\\\\\\\\n             \\\\\\n    \\\\       continue\\\\\\\\n                if should_take(child):\\\\\\\\n                 \\\\\\n    \\\\   key = child.resolve().as_posix()\\\\\\\\n                    if key not in seen:\\\\\\\\\\\\\\n    n                        seen.add(key)\\\\\\\\n                        discovered.append(child.resolve())\\\\\\\\\\\\\\n    n\\\\\\\\n    return sorted(discovered)\\\\\\\",\\\\n    \\\\\\\"src/rcpack/gitinfo.py\\\\\\\": \\\\\\\"from __future__\\\\\\n    \\\\ import annotations\\\\\\\\n\\\\\\\\nimport subprocess\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom\\\\\\n    \\\\ typing import Dict, Any\\\\\\\\n\\\\\\\\n\\\\\\\\ndef _git(cmd: list[str], cwd: Path) -> str:\\\\\\\\\\\\\\n    n    # Validate git commands to prevent injection\\\\\\\\n    allowed_commands = {\\\\\\\\\\\\\\n    n        \\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"show\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"log\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\n    \\\\\\\", \\\\\\\\\\\\\\\"config\\\\\\\\\\\\\\\"\\\\\\\\n    }\\\\\\\\n    if not cmd or cmd[0] not in allowed_commands:\\\\\\\\\\\\\\n    n        raise ValueError(f\\\\\\\\\\\\\\\"Git command not allowed: {cmd[0] if cmd else 'empty'}\\\\\\\\\\\\\\n    \\\\\\\")\\\\\\\\n    \\\\\\\\n    out = subprocess.check_output([\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\", *cmd], cwd=str(cwd),\\\\\\n    \\\\ timeout=30)\\\\\\\\n    return out.decode(\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", errors=\\\\\\\\\\\\\\\"replace\\\\\\\\\\\\\\\").strip()\\\\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\\ndef is_git_repo(path: Path) -> bool:\\\\\\\\n    try:\\\\\\\\n        flag = _git([\\\\\\\\\\\\\\n    \\\\\\\"rev-parse\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--is-inside-work-tree\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\\n        return flag\\\\\\n    \\\\ == \\\\\\\\\\\\\\\"true\\\\\\\\\\\\\\\"\\\\\\\\n    except Exception:\\\\\\\\n        return False\\\\\\\\n\\\\\\\\n\\\\\\\\ndef get_git_info(path:\\\\\\n    \\\\ Path) -> Dict[str, Any]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Return info for the current\\\\\\n    \\\\ HEAD of a repo rooted at `path`.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        commit\\\\\\n    \\\\ = _git([\\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"HEAD\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\\n        branch = _git([\\\\\\\\\\\\\\n    \\\\\\\"rev-parse\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--abbrev-ref\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"HEAD\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\\n        author\\\\\\n    \\\\ = _git([\\\\\\\\\\\\\\\"show\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"-s\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--format=%an <%ae>\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\\n\\\\\\n    \\\\        date = _git([\\\\\\\\\\\\\\\"show\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"-s\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--date=local\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--format=%ad\\\\\\\\\\\\\\n    \\\\\\\"], cwd=path)\\\\\\\\n        return {\\\\\\\\n            \\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\": True,\\\\\\\\n    \\\\\\n    \\\\        \\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\": commit,\\\\\\\\n            \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\": branch,\\\\\\\\n    \\\\\\n    \\\\        \\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\": author,\\\\\\\\n            \\\\\\\\\\\\\\\"date\\\\\\\\\\\\\\\": date,\\\\\\\\n        \\\\\\n    \\\\    \\\\\\\\\\\\\\\"note\\\\\\\\\\\\\\\": None,\\\\\\\\n        }\\\\\\\\n    except Exception:\\\\\\\\n        # treat\\\\\\n    \\\\ as not a repo if anything fails\\\\\\\\n        return {\\\\\\\\n            \\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\n    \\\\\\\": False,\\\\\\\\n            \\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\": None,\\\\\\\\\\\\\\n    n            \\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"date\\\\\\\\\\\\\\\": None,\\\\\\\\n      \\\\\\n    \\\\      \\\\\\\\\\\\\\\"note\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Not a git repository\\\\\\\\\\\\\\\",\\\\\\\\n        }\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/io_utils.py\\\\\\\"\\\\\\n    : \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"I/O utilities for file operations.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom pathlib\\\\\\n    \\\\ import Path\\\\\\\\nfrom typing import Tuple\\\\\\\\n\\\\\\\\n\\\\\\\\ndef write_output(output_path:\\\\\\n    \\\\ str, content: str) -> None:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Write content to output file.\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    output_file = Path(output_path)\\\\\\\\n    \\\\\\\\n    # Create parent\\\\\\n    \\\\ directories if they don't exist\\\\\\\\n    output_file.parent.mkdir(parents=True,\\\\\\n    \\\\ exist_ok=True)\\\\\\\\n    \\\\\\\\n    # Write content\\\\\\\\n    with open(output_file, 'w',\\\\\\n    \\\\ encoding='utf-8') as f:\\\\\\\\n        f.write(content)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef is_binary_file(path:\\\\\\n    \\\\ Path, sniff_bytes: int = 2048) -> bool:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Heuristically determine\\\\\\n    \\\\ if a file is binary by scanning for NUL bytes.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n   \\\\\\n    \\\\     with open(path, 'rb') as fb:\\\\\\\\n            chunk = fb.read(sniff_bytes)\\\\\\\\\\\\\\n    n        if b\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\x00\\\\\\\\\\\\\\\" in chunk:\\\\\\\\n            return True\\\\\\\\n        # If\\\\\\n    \\\\ the chunk has a lot of non-text bytes, consider it binary\\\\\\\\n        text_byte_count\\\\\\n    \\\\ = sum(32 <= b <= 126 or b in (9, 10, 13) for b in chunk)\\\\\\\\n        return (len(chunk)\\\\\\n    \\\\ - text_byte_count) > max(1, len(chunk) // 3)\\\\\\\\n    except Exception:\\\\\\\\n    \\\\\\n    \\\\    # If we cannot read, treat as binary to avoid further processing\\\\\\\\n     \\\\\\n    \\\\   return True\\\\\\\\n\\\\\\\\n\\\\\\\\ndef read_text_safely(path: Path, max_bytes: int = 16_384)\\\\\\n    \\\\ -> Tuple[str, str, bool]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Read a text file safely with size\\\\\\n    \\\\ limit and encoding fallbacks.\\\\\\\\n\\\\\\\\n    Returns (content, encoding_used, truncated).\\\\\\\\\\\\\\n    n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    truncated = False\\\\\\\\n    raw: bytes\\\\\\\\n    with open(path,\\\\\\n    \\\\ 'rb') as fb:\\\\\\\\n        raw = fb.read(max_bytes + 1)\\\\\\\\n    if len(raw) > max_bytes:\\\\\\\\\\\\\\n    n        truncated = True\\\\\\\\n        raw = raw[:max_bytes]\\\\\\\\n\\\\\\\\n    for enc in\\\\\\n    \\\\ (\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"utf-16\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"utf-16-le\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"utf-16-be\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"latin-1\\\\\\\\\\\\\\n    \\\\\\\"):\\\\\\\\n        try:\\\\\\\\n            text = raw.decode(enc)\\\\\\\\n            return\\\\\\n    \\\\ text, enc, truncated\\\\\\\\n        except Exception:\\\\\\\\n            continue\\\\\\\\n \\\\\\n    \\\\   # Fallback: replace errors with utf-8\\\\\\\\n    text = raw.decode(\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\"\\\\\\n    , errors=\\\\\\\\\\\\\\\"replace\\\\\\\\\\\\\\\")\\\\\\\\n    return text, \\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", truncated\\\\\\\",\\\\n   \\\\\\n    \\\\ \\\\\\\"src/rcpack/packager.py\\\\\\\": \\\\\\\"from __future__ import annotations\\\\\\\\n\\\\\\\\nimport\\\\\\n    \\\\ sys\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import Iterable, Tuple\\\\\\\\n\\\\\\\\nfrom\\\\\\n    \\\\ rcpack.discover import discover_files\\\\\\\\nfrom rcpack.gitinfo import get_git_info,\\\\\\n    \\\\ is_git_repo\\\\\\\\nfrom rcpack.io_utils import read_text_safely, is_binary_file\\\\\\\\\\\\\\n    nfrom rcpack.renderer import markdown as md_renderer\\\\\\\\nfrom rcpack.renderer.jsonyaml\\\\\\n    \\\\ import render_json, render_yaml\\\\\\\\nfrom rcpack.treeview import render_tree\\\\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\\ndef _find_root(inputs: list[str]) -> Path:\\\\\\\\n    paths = [Path(p) for p\\\\\\n    \\\\ in inputs]\\\\\\\\n    if len(paths) == 1 and Path(paths[0]).is_dir():\\\\\\\\n        return\\\\\\n    \\\\ paths[0].resolve()\\\\\\\\n    parents = [p if p.is_dir() else p.parent for p in paths]\\\\\\\\\\\\\\n    n    root = Path(*Path.commonpath([str(p.resolve()) for p in parents]).split(\\\\\\\\\\\\\\n    \\\\\\\"/\\\\\\\\\\\\\\\"))\\\\\\\\n    return root.resolve()\\\\\\\\n\\\\\\\\n\\\\\\\\ndef build_package(\\\\\\\\n    inputs:\\\\\\n    \\\\ list[str],\\\\\\\\n    include_patterns: list[str] | None,\\\\\\\\n    exclude_patterns:\\\\\\n    \\\\ list[str] | None,\\\\\\\\n    max_file_bytes: int,\\\\\\\\n    fmt: str = \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\n    \\\\\\\",\\\\\\\\n) -> Tuple[str, dict]:\\\\\\\\n    root = _find_root(inputs)\\\\\\\\n    root_abs =\\\\\\n    \\\\ root.resolve()\\\\\\\\n\\\\\\\\n    repo_info = (\\\\\\\\n        get_git_info(root_abs) if is_git_repo(root_abs)\\\\\\n    \\\\ else {\\\\\\\\n            \\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\": False,\\\\\\\\n            \\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\": None,\\\\\\\\\\\\\\n    n            \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\": None,\\\\\\\\n    \\\\\\n    \\\\        \\\\\\\\\\\\\\\"date\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"note\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Not a git repository\\\\\\\\\\\\\\n    \\\\\\\",\\\\\\\\n        }\\\\\\\\n    )\\\\\\\\n\\\\\\\\n    files = discover_files(\\\\\\\\n        inputs=[Path(p)\\\\\\n    \\\\ for p in inputs],\\\\\\\\n        root=root_abs,\\\\\\\\n        include_patterns=include_patterns\\\\\\n    \\\\ or [],\\\\\\\\n        exclude_patterns=exclude_patterns or [],\\\\\\\\n    )\\\\\\\\n    rel_files\\\\\\n    \\\\ = [f.relative_to(root_abs) for f in files]\\\\\\\\n\\\\\\\\n    project_tree = render_tree([p.as_posix()\\\\\\n    \\\\ for p in rel_files])\\\\\\\\n\\\\\\\\n    file_sections: list[dict] = []\\\\\\\\n    total_lines\\\\\\n    \\\\ = 0\\\\\\\\n    total_chars = 0\\\\\\\\n\\\\\\\\n    for f in files:\\\\\\\\n        rel = f.relative_to(root_abs).as_posix()\\\\\\\\\\\\\\n    n        try:\\\\\\\\n            if is_binary_file(f):\\\\\\\\n                content =\\\\\\n    \\\\ f\\\\\\\\\\\\\\\"[binary file skipped: {f.name}, {f.stat().st_size} bytes]\\\\\\\\\\\\\\\"\\\\\\\\n      \\\\\\n    \\\\          file_sections.append({\\\\\\\\n                    \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": rel,\\\\\\\\n\\\\\\n    \\\\                    \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": _language_from_ext(f.suffix),\\\\\\\\n      \\\\\\n    \\\\              \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": content,\\\\\\\\n                    \\\\\\\\\\\\\\\"is_truncated\\\\\\\\\\\\\\n    \\\\\\\": False,\\\\\\\\n                })\\\\\\\\n                total_chars += len(content)\\\\\\\\\\\\\\n    n                continue\\\\\\\\n\\\\\\\\n            content, used_encoding, truncated =\\\\\\n    \\\\ read_text_safely(f, max_bytes=max_file_bytes)\\\\\\\\n            total_lines += content.count(\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\") + (1 if content and not content.endswith(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\") else 0)\\\\\\\\\\\\\\n    n            total_chars += len(content)\\\\\\\\n\\\\\\\\n            if truncated:\\\\\\\\n   \\\\\\n    \\\\             note = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n[... TRUNCATED to first {max_file_bytes} bytes\\\\\\n    \\\\ ...]\\\\\\\\\\\\\\\"\\\\\\\\n                content = content + note\\\\\\\\n                total_chars\\\\\\n    \\\\ += len(note)\\\\\\\\n\\\\\\\\n            file_sections.append({\\\\\\\\n                \\\\\\\\\\\\\\\"\\\\\\n    path\\\\\\\\\\\\\\\": rel,\\\\\\\\n                \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": _language_from_ext(f.suffix),\\\\\\\\\\\\\\n    n                \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": content,\\\\\\\\n                \\\\\\\\\\\\\\\"is_truncated\\\\\\\\\\\\\\n    \\\\\\\": truncated,\\\\\\\\n            })\\\\\\\\n        except Exception as exc:\\\\\\\\n        \\\\\\n    \\\\    print(f\\\\\\\\\\\\\\\"[rcpack] error reading {rel}: {exc}\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\n \\\\\\n    \\\\           continue\\\\\\\\n\\\\\\\\n    # render in chosen format\\\\\\\\n    if fmt == \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\n    \\\\\\\":\\\\\\\\n        out_text = md_renderer.render_markdown(\\\\\\\\n            root=str(root_abs),\\\\\\\\\\\\\\n    n            repo_info=repo_info,\\\\\\\\n            tree_text=project_tree,\\\\\\\\n   \\\\\\n    \\\\         files=file_sections,\\\\\\\\n            total_files=len(file_sections),\\\\\\\\\\\\\\n    n            total_lines=total_lines,\\\\\\\\n        )\\\\\\\\n    elif fmt == \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\n    \\\\\\\":\\\\\\\\n        out_text = render_json(\\\\\\\\n            root=str(root_abs),\\\\\\\\n   \\\\\\n    \\\\         repo_info=repo_info,\\\\\\\\n            tree_text=project_tree,\\\\\\\\n      \\\\\\n    \\\\      files=file_sections,\\\\\\\\n            total_files=len(file_sections),\\\\\\\\n \\\\\\n    \\\\           total_lines=total_lines,\\\\\\\\n        )\\\\\\\\n    elif fmt == \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\"\\\\\\n    :\\\\\\\\n        out_text = render_yaml(\\\\\\\\n            root=str(root_abs),\\\\\\\\n     \\\\\\n    \\\\       repo_info=repo_info,\\\\\\\\n            tree_text=project_tree,\\\\\\\\n        \\\\\\n    \\\\    files=file_sections,\\\\\\\\n            total_files=len(file_sections),\\\\\\\\n   \\\\\\n    \\\\         total_lines=total_lines,\\\\\\\\n        )\\\\\\\\n    else:\\\\\\\\n        raise ValueError(f\\\\\\\\\\\\\\n    \\\\\\\"Unsupported format: {fmt}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    stats = {\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\": len(file_sections),\\\\\\n    \\\\ \\\\\\\\\\\\\\\"lines\\\\\\\\\\\\\\\": total_lines, \\\\\\\\\\\\\\\"chars\\\\\\\\\\\\\\\": total_chars}\\\\\\\\n    return out_text,\\\\\\n    \\\\ stats\\\\\\\\n\\\\\\\\n\\\\\\\\ndef _language_from_ext(ext: str) -> str:\\\\\\\\n    ext = ext.lower().lstrip(\\\\\\\\\\\\\\n    \\\\\\\".\\\\\\\\\\\\\\\")\\\\\\\\n    mapping = {\\\\\\\\n        \\\\\\\\\\\\\\\"py\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"js\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\n    \\\\\\\"javascript\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"ts\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"typescript\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\n    json\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"md\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"yml\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\"\\\\\\n    : \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"toml\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"toml\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"sh\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"bash\\\\\\\\\\\\\\\"\\\\\\n    , \\\\\\\\\\\\\\\"c\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"c\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"cpp\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"cpp\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"java\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\n    java\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"go\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"go\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"rs\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"rust\\\\\\\\\\\\\\\",\\\\\\\\n    }\\\\\\\\n    return\\\\\\n    \\\\ mapping.get(ext, \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/renderer/jsonyaml.py\\\\\\\": \\\\\\\"\\\\\\n    from __future__ import annotations\\\\\\\\nimport json\\\\\\\\n\\\\\\\\ntry:\\\\\\\\n    import yaml\\\\\\\\\\\\\\n    nexcept ImportError:\\\\\\\\n    yaml = None\\\\\\\\n\\\\\\\\n\\\\\\\\ndef render_json(root, repo_info,\\\\\\n    \\\\ tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None)\\\\\\n    \\\\ -> str:\\\\\\\\n    data = {\\\\\\\\n        \\\\\\\\\\\\\\\"root\\\\\\\\\\\\\\\": root,\\\\\\\\n        \\\\\\\\\\\\\\\"repo_info\\\\\\\\\\\\\\n    \\\\\\\": repo_info,\\\\\\\\n        \\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\": tree_text,\\\\\\\\n        \\\\\\\\\\\\\\\"recent_changes\\\\\\\\\\\\\\n    \\\\\\\": recent_files or [],\\\\\\\\n        \\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\": files,\\\\\\\\n        \\\\\\\\\\\\\\\"file_sizes\\\\\\\\\\\\\\n    \\\\\\\": file_sizes or {},\\\\\\\\n        \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\": total_files,\\\\\\n    \\\\ \\\\\\\\\\\\\\\"total_lines\\\\\\\\\\\\\\\": total_lines},\\\\\\\\n        \\\\\\\\n    }\\\\\\\\n    return json.dumps(data,\\\\\\n    \\\\ indent=2, ensure_ascii=False)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef render_yaml(root, repo_info, tree_text,\\\\\\n    \\\\ files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\\\\\\\\\\\\\\n    n    if yaml is None:\\\\\\\\n        raise RuntimeError(\\\\\\\\\\\\\\\"PyYAML not installed; run\\\\\\n    \\\\ `pip install pyyaml`\\\\\\\\\\\\\\\")\\\\\\\\n    data = {\\\\\\\\n        \\\\\\\\\\\\\\\"root\\\\\\\\\\\\\\\": root,\\\\\\\\n  \\\\\\n    \\\\      \\\\\\\\\\\\\\\"repo_info\\\\\\\\\\\\\\\": repo_info,\\\\\\\\n        \\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\": tree_text,\\\\\\\\\\\\\\n    n        \\\\\\\\\\\\\\\"recent_changes\\\\\\\\\\\\\\\": recent_files or [],\\\\\\\\n        \\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\":\\\\\\n    \\\\ files,\\\\\\\\n        \\\\\\\\\\\\\\\"file_sizes\\\\\\\\\\\\\\\": file_sizes or {},\\\\\\\\n        \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\n    \\\\\\\": {\\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\": total_files, \\\\\\\\\\\\\\\"total_lines\\\\\\\\\\\\\\\": total_lines},\\\\\\\\n \\\\\\n    \\\\       \\\\\\\\n    }\\\\\\\\n    return yaml.safe_dump(data, sort_keys=False, allow_unicode=True)\\\\\\\\\\\\\\n    n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/renderer/markdown.py\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Markdown renderer\\\\\\n    \\\\ for repository context.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom typing import Dict, Any\\\\\\\\n\\\\\\\\n\\\\\\\\\\\\\\n    ndef render_markdown(root: str, repo_info: Dict[str, Any], tree_text: str, \\\\\\\\\\\\\\n    n                   files: Dict[str, str], total_files: int, total_lines: int,\\\\\\n    \\\\ recent_files=None, file_sizes=None) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Render repository\\\\\\n    \\\\ context as markdown.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    lines = []\\\\\\\\n    \\\\\\\\n    # Header\\\\\\\\\\\\\\n    n    lines.append(f\\\\\\\\\\\\\\\"# Repository Context: {root}\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # Repository info\\\\\\\\n    if repo_info.get(\\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\"\\\\\\n    ):\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\"## Git Repository Information\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\n    \\\\\\\"- **Branch**: {repo_info.get('branch', 'N/A')}\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\n    \\\\\\\"- **Commit**: {repo_info.get('commit', 'N/A')}\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\n    \\\\\\\"- **Author**: {repo_info.get('author', 'N/A')}\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\n    \\\\\\\"- **Date**: {repo_info.get('date', 'N/A')}\\\\\\\\\\\\\\\")\\\\\\\\n    else:\\\\\\\\n        lines.append(\\\\\\\\\\\\\\n    \\\\\\\"## Repository Information\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\"- **Note**: {repo_info.get('note',\\\\\\n    \\\\ 'Not a git repository')}\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # Summary\\\\\\\\\\\\\\n    n    lines.append(\\\\\\\\\\\\\\\"## Summary\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(f\\\\\\\\\\\\\\\"- **Total Files**:\\\\\\n    \\\\ {total_files}\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(f\\\\\\\\\\\\\\\"- **Total Lines**: {total_lines}\\\\\\\\\\\\\\n    \\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # Directory structure\\\\\\\\n    lines.append(\\\\\\\\\\\\\\n    \\\\\\\"## Directory Structure\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"```\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(tree_text)\\\\\\\\\\\\\\n    n    lines.append(\\\\\\\\\\\\\\\"```\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # will produce\\\\\\n    \\\\ recent files \\\\\\\\n    # Recent files (fixed)\\\\\\\\n    if recent_files:\\\\\\\\n       \\\\\\n    \\\\ lines.append(\\\\\\\\\\\\\\\"## Recent Changes\\\\\\\\\\\\\\\")\\\\\\\\n        for file, age in recent_files.items():\\\\\\\\\\\\\\n    n            lines.append(f\\\\\\\\\\\\\\\"- {file} (modified {age})\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # File contents\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"## File Contents\\\\\\\\\\\\\\n    \\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    for file_path, content in sorted(files.items()):\\\\\\\\\\\\\\n    n        if file_sizes and file_path in file_sizes:\\\\\\\\n            size_bytes =\\\\\\n    \\\\ file_sizes[file_path]\\\\\\\\n            lines.append(f\\\\\\\\\\\\\\\"### {file_path} ({size_bytes}\\\\\\n    \\\\ bytes)\\\\\\\\\\\\\\\")\\\\\\\\n        else:\\\\\\\\n            lines.append(f\\\\\\\\\\\\\\\"### {file_path}\\\\\\\\\\\\\\n    \\\\\\\")\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Detect language for\\\\\\n    \\\\ syntax highlighting\\\\\\\\n        ext = file_path.split('.')[-1].lower() if '.'\\\\\\n    \\\\ in file_path else ''\\\\\\\\n        lang_map = {\\\\\\\\n            'py': 'python', 'js':\\\\\\n    \\\\ 'javascript', 'ts': 'typescript',\\\\\\\\n            'java': 'java', 'cpp': 'cpp',\\\\\\n    \\\\ 'c': 'c', 'h': 'c',\\\\\\\\n            'cs': 'csharp', 'php': 'php', 'rb': 'ruby',\\\\\\\\\\\\\\n    n            'go': 'go', 'rs': 'rust', 'swift': 'swift',\\\\\\\\n            'html':\\\\\\n    \\\\ 'html', 'css': 'css', 'scss': 'scss',\\\\\\\\n            'json': 'json', 'yaml':\\\\\\n    \\\\ 'yaml', 'yml': 'yaml',\\\\\\\\n            'xml': 'xml', 'sql': 'sql', 'sh': 'bash',\\\\\\\\\\\\\\n    n            'md': 'markdown', 'dockerfile': 'dockerfile'\\\\\\\\n        }\\\\\\\\n     \\\\\\n    \\\\   \\\\\\\\n        language = lang_map.get(ext, '')\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\"```{language}\\\\\\\\\\\\\\n    \\\\\\\")\\\\\\\\n        lines.append(content)\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\"```\\\\\\\\\\\\\\\")\\\\\\\\n   \\\\\\n    \\\\     lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\".join(lines)\\\\\\\\n\\\\\\\"\\\\\\n    ,\\\\n    \\\\\\\"src/rcpack/treeview.py\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Tree view generation for repository\\\\\\n    \\\\ structure.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import Dict,\\\\\\n    \\\\ List\\\\\\\\n\\\\\\\\n\\\\\\\\ndef create_tree_view(repo_path: Path, files_data: Dict[str, str])\\\\\\n    \\\\ -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create a tree view of the repository structure.\\\\\\\\\\\\\\\"\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    paths = list(files_data.keys())\\\\\\\\n    return render_tree(paths)\\\\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\\ndef render_tree(paths: List[str]) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Render a tree\\\\\\n    \\\\ view from a list of relative POSIX paths.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    tree_structure:\\\\\\n    \\\\ dict = {}\\\\\\\\n\\\\\\\\n    for p in paths:\\\\\\\\n        parts = Path(p).parts\\\\\\\\n      \\\\\\n    \\\\  current = tree_structure\\\\\\\\n        for part in parts[:-1]:\\\\\\\\n            if\\\\\\n    \\\\ part not in current:\\\\\\\\n                current[part] = {}\\\\\\\\n            current\\\\\\n    \\\\ = current[part]\\\\\\\\n        if parts:\\\\\\\\n            current[parts[-1]] = None\\\\\\\\\\\\\\n    n\\\\\\\\n    def _render(structure: dict, prefix: str = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\") -> str:\\\\\\\\n      \\\\\\n    \\\\  lines = []\\\\\\\\n        items = sorted(structure.items(), key=lambda x: (x[1]\\\\\\n    \\\\ is None, x[0]))\\\\\\\\n        for i, (name, subtree) in enumerate(items):\\\\\\\\n   \\\\\\n    \\\\         is_last = i == len(items) - 1\\\\\\\\n            lines.append(f\\\\\\\\\\\\\\\"{prefix}{'└──\\\\\\n    \\\\ ' if is_last else '├── '}{name}\\\\\\\\\\\\\\\")\\\\\\\\n            if subtree is not None:\\\\\\\\\\\\\\n    n                extension = (\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\" if is_last else \\\\\\\\\\\\\\\"│   \\\\\\\\\\\\\\\")\\\\\\\\n  \\\\\\n    \\\\              lines.append(_render(subtree, prefix + extension))\\\\\\\\n        return\\\\\\n    \\\\ \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\".join(filter(None, lines))\\\\\\\\n\\\\\\\\n    if not tree_structure:\\\\\\\\n \\\\\\n    \\\\       return \\\\\\\\\\\\\\\"No files found\\\\\\\\\\\\\\\"\\\\\\\\n    return _render(tree_structure)\\\\\\\"\\\\n\\\\\\n    \\\\  },\\\\n  \\\\\\\"file_sizes\\\\\\\": {\\\\n    \\\\\\\"LICENSE\\\\\\\": \\\\\\\"1064\\\\\\\",\\\\n    \\\\\\\"README.md\\\\\\\": \\\\\\\"\\\\\\n    11164\\\\\\\",\\\\n    \\\\\\\"pyproject.toml\\\\\\\": \\\\\\\"361\\\\\\\",\\\\n    \\\\\\\"src/rcpack/__init__.py\\\\\\\": \\\\\\\"\\\\\\n    198\\\\\\\",\\\\n    \\\\\\\"src/rcpack/__main__.py\\\\\\\": \\\\\\\"197\\\\\\\",\\\\n    \\\\\\\"src/rcpack/cli.py\\\\\\\": \\\\\\\"\\\\\\n    7087\\\\\\\",\\\\n    \\\\\\\"src/rcpack/config_loader.py\\\\\\\": \\\\\\\"2099\\\\\\\",\\\\n    \\\\\\\"src/rcpack/discover.py\\\\\\\"\\\\\\n    : \\\\\\\"3067\\\\\\\",\\\\n    \\\\\\\"src/rcpack/gitinfo.py\\\\\\\": \\\\\\\"1653\\\\\\\",\\\\n    \\\\\\\"src/rcpack/io_utils.py\\\\\\\"\\\\\\n    : \\\\\\\"1817\\\\\\\",\\\\n    \\\\\\\"src/rcpack/packager.py\\\\\\\": \\\\\\\"4430\\\\\\\",\\\\n    \\\\\\\"src/rcpack/renderer/jsonyaml.py\\\\\\\"\\\\\\n    : \\\\\\\"1176\\\\\\\",\\\\n    \\\\\\\"src/rcpack/renderer/markdown.py\\\\\\\": \\\\\\\"2829\\\\\\\",\\\\n    \\\\\\\"src/rcpack/treeview.py\\\\\\\"\\\\\\n    : \\\\\\\"1371\\\\\\\"\\\\n  },\\\\n  \\\\\\\"summary\\\\\\\": {\\\\n    \\\\\\\"total_files\\\\\\\": 14,\\\\n    \\\\\\\"total_lines\\\\\\\"\\\\\\n    : 1180\\\\n  }\\\\n}\\\"\\nfile_sizes:\\n  LICENSE: '1064'\\n  README.md: '11164'\\n  pyproject.toml: '361'\\n  src/rcpack/__init__.py: '198'\\n  src/rcpack/__main__.py: '197'\\n  src/rcpack/cli.py: '7087'\\n  src/rcpack/config_loader.py: '2099'\\n  src/rcpack/discover.py: '3067'\\n  src/rcpack/gitinfo.py: '1653'\\n  src/rcpack/io_utils.py: '1817'\\n  src/rcpack/packager.py: '4430'\\n  src/rcpack/renderer/jsonyaml.py: '1176'\\n  src/rcpack/renderer/markdown.py: '2829'\\n  src/rcpack/treeview.py: '1371'\\n  test-output.json: '42249'\\nsummary:\\n  total_files: 15\\n  total_lines: 1229\\n\"\n  },\n  \"file_sizes\": {\n    \"LICENSE\": \"1064\",\n    \"README.md\": \"11164\",\n    \"pyproject.toml\": \"361\",\n    \"src/rcpack/__init__.py\": \"198\",\n    \"src/rcpack/__main__.py\": \"197\",\n    \"src/rcpack/cli.py\": \"7087\",\n    \"src/rcpack/config_loader.py\": \"2099\",\n    \"src/rcpack/discover.py\": \"3067\",\n    \"src/rcpack/gitinfo.py\": \"1653\",\n    \"src/rcpack/io_utils.py\": \"1817\",\n    \"src/rcpack/packager.py\": \"4121\",\n    \"src/rcpack/renderer/jsonyaml.py\": \"1154\",\n    \"src/rcpack/renderer/markdown.py\": \"2318\",\n    \"src/rcpack/treeview.py\": \"1371\",\n    \"src/rcpack/utils.py\": \"3500\",\n    \"test-output.json\": \"42249\",\n    \"test-yaml.yaml\": \"93888\"\n  },\n  \"summary\": {\n    \"total_files\": 17,\n    \"total_lines\": 2456\n  }\n}",
    "test-iteration2.yaml": "root: /Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\nrepo_info:\n  is_repo: true\n  commit: 57f0f88ec3d11a89d5ca08ee4fb5b9b561c1b8aa\n  branch: refactoring\n  author: Abhinav <abhinavbhardwaj2002@gmail.com>\n  date: Fri Oct 10 19:19:52 2025\n  note: null\nstructure: '├── src\n\n  │   └── rcpack\n\n  │       ├── renderer\n\n  │       │   ├── jsonyaml.py\n\n  │       │   └── markdown.py\n\n  │       ├── __init__.py\n\n  │       ├── __main__.py\n\n  │       ├── cli.py\n\n  │       ├── config_loader.py\n\n  │       ├── discover.py\n\n  │       ├── gitinfo.py\n\n  │       ├── io_utils.py\n\n  │       ├── packager.py\n\n  │       ├── treeview.py\n\n  │       └── utils.py\n\n  ├── LICENSE\n\n  ├── README.md\n\n  ├── pyproject.toml\n\n  ├── test-iteration2.json\n\n  ├── test-output.json\n\n  └── test-yaml.yaml'\nrecent_changes: {}\nfiles:\n  LICENSE: 'MIT License\n\n\n    Copyright (c) 2025 Abhinav\n\n\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n\n    of this software and associated documentation files (the \"Software\"), to deal\n\n    in the Software without restriction, including without limitation the rights\n\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n\n    copies of the Software, and to permit persons to whom the Software is\n\n    furnished to do so, subject to the following conditions:\n\n\n    The above copyright notice and this permission notice shall be included in all\n\n    copies or substantial portions of the Software.\n\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n\n    SOFTWARE.\n\n    '\n  README.md: \"# Repo-Contextor\\n\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\n\\\n    [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\n\\\n    \\nA powerful Repository Context Packager CLI tool that analyzes local git repositories\\\n    \\ and creates comprehensive text files containing repository content optimized\\\n    \\ for sharing with Large Language Models (LLMs).\\n\\n## Overview\\n\\nWhen developers\\\n    \\ want to get help from ChatGPT, Claude, or other LLMs about their code, they\\\n    \\ often struggle with how to share their codebase effectively. Common problems\\\n    \\ include:\\n\\n- **Lost Context**: Copy-pasting individual files loses important\\\n    \\ project structure and relationships\\n- **Missing Dependencies**: LLMs can't\\\n    \\ see how files connect or what libraries are used\\n- **Incomplete Picture**:\\\n    \\ Hard to convey the overall architecture and organization\\n- **Manual Work**:\\\n    \\ Time-consuming to gather and format relevant code\\n\\n**Repo-Contextor** solves\\\n    \\ this by automatically collecting and formatting repository content into a single,\\\n    \\ well-structured text file that provides rich context to LLMs, enabling them\\\n    \\ to give much better assistance with your code.\\n\\n## Features\\n\\n- **Git Integration**:\\\n    \\ Extracts commit SHA, branch, author, and date information\\n- **Project Structure**:\\\n    \\ Generates a clear directory tree visualization\\n- **File Content Packaging**:\\\n    \\ Includes file contents with syntax highlighting\\n- **Smart File Discovery**:\\\n    \\ Recursively scans directories with intelligent filtering\\n- **Binary File Detection**:\\\n    \\ Automatically skips binary files\\n- **Error Handling**: Gracefully handles permission\\\n    \\ errors and provides helpful messages\\n- **Multiple Output Formats**: Supports\\\n    \\ Markdown, JSON, and YAML formats\\n- **Flexible Output**: Write to stdout or\\\n    \\ save to a file\\n- **Recent Changes Filter**: Give the files which are updated\\\n    \\ in last 7days with the time when it was recently modified.\\n\\n## Installation\\n\\\n    \\n### Prerequisites\\n\\n- Python 3.9 or higher\\n- Git (for git repository analysis)\\n\\\n    \\n### For End Users\\n\\n```bash\\n# Clone and install\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\n\\\n    cd Repo-Contextor\\npip install -e .\\n```\\n\\n### For Contributors & Local Development\\n\\\n    \\n```bash\\n# Clone the repository\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\n\\\n    cd Repo-Contextor\\n\\n# Create virtual environment\\npython -m venv .venv\\nsource\\\n    \\ .venv/bin/activate  # On Windows: .venv\\\\Scripts\\\\activate\\n\\n# Install in development\\\n    \\ mode\\npip install -e .\\n```\\n\\n## Usage\\n\\n### Basic Examples\\n\\n```bash\\n#\\\n    \\ Package current directory to terminal\\nrepo-contextor .\\n\\n# Package a specific\\\n    \\ directory\\nrepo-contextor /path/to/your/project\\n\\n# Save output to a file\\n\\\n    repo-contextor . -o my-project-context.md\\n\\n# Generate JSON format\\nrepo-contextor\\\n    \\ . -f json -o context.json\\n\\n# Generate YAML format\\nrepo-contextor . -f yaml\\\n    \\ -o context.yaml\\n\\n# Include only files modified in the last 7 days\\nrepo-contextor\\\n    \\ . --recent\\n\\n# Combine with output file\\nrepo-contextor . --recent -o recent-changes.md\\n\\\n    ```\\n\\n### Command Line Options\\n\\n| Option | Short | Description | Example |\\n\\\n    |--------|-------|-------------|---------|\\n| `path` | - | Repository path to\\\n    \\ analyze (default: current directory) | `repo-contextor /path/to/project` |\\n\\\n    | `--output` | `-o` | Output file path (default: stdout) | `-o context.md` |\\n\\\n    | `--format` | `-f` | Output format: text, json, yaml (default: text) | `-f json`\\\n    \\ |\\n| `--help` | `-h` | Show help message | `-h` |\\n| `--recent`  | `-r`  | Include\\\n    \\ only files modified in the last 7 days    | `repo-contextor . -r -o recent.md`\\\n    \\ |\\n\\n### Advanced Examples\\n\\n```bash\\n# Analyze different repository\\nrepo-contextor\\\n    \\ /path/to/other/project -o other-project.md\\n\\n# Generate JSON for API consumption\\n\\\n    repo-contextor . -f json -o api-context.json\\n\\n# Create YAML configuration\\n\\\n    repo-contextor . -f yaml -o project-config.yaml\\n\\n# Generate files which are\\\n    \\ changed recently in 7 days\\nrepo-contextor . -r --output recent-changes.txt\\n\\\n    \\n```\\n## Configuration via TOML\\n\\nRepo-Contextor supports configuration through\\\n    \\ a `.repo-contextor.toml` file in the current working directory.  \\nThis file\\\n    \\ allows you to avoid typing the same CLI arguments every time.\\n\\nExample `.repo-contextor.toml`:\\n\\\n    \\n```toml\\n# Output file to write results\\noutput = \\\"context.yaml\\\"\\n\\n# Output\\\n    \\ format: text, json, or yaml\\nformat = \\\"yaml\\\"\\n\\n# Limit to files modified\\\n    \\ in the last 7 days\\nrecent = true\\n\\n# Repository path to analyze (default =\\\n    \\ current directory)\\npath = \\\".\\\"\\n```\\n### Rules\\n- If the `.repo-contextor.toml`\\\n    \\ file is **missing**, the tool falls back to defaults.  \\n- If the file is **present\\\n    \\ but invalid TOML**, the tool prints a clear error message and exits with status\\\n    \\ code 1.  \\n- **Unknown keys** in the TOML file are ignored (safe for future\\\n    \\ extensions).  \\n- **Precedence** of settings is:\\n  1. Command-line arguments\\\n    \\ (highest priority)  \\n  2. Values from `.repo-contextor.toml`  \\n  3. Built-in\\\n    \\ defaults (lowest priority)\\n     \\n## Output Format\\n\\nThe tool generates a\\\n    \\ structured text file with the following sections:\\n\\n### 1. Repository Context\\\n    \\ Header\\nProject path and identification\\n\\n### 2. Git Repository Information\\n\\\n    - Current branch\\n- Latest commit SHA\\n- Last commit author\\n- Last commit date\\n\\\n    \\n### 3. Summary Statistics\\n- Total number of files processed\\n- Total lines\\\n    \\ of code\\n\\n### 4. Directory Structure\\nClean tree visualization showing project\\\n    \\ organization\\n\\n### 5. Recent Changes (if `--recent` is used)\\n\\n- Lists files\\\n    \\ modified in the last 7 days.\\n- Shows relative file paths along with how long\\\n    \\ ago each file was modified\\n- Helps focus on recently updated parts of the project.\\n\\\n    - Can be combined with `--output` or `--format` to save or change the output type.\\n\\\n    \\n\\n### 5. File Contents\\nEach file's content with:\\n- Clear file path headers\\n\\\n    - Appropriate syntax highlighting language tags\\n- Complete file contents\\n\\n\\\n    ## Example Output\\n\\nWhen you run `repo-contextor .`, the output looks like this:\\n\\\n    \\n````markdown\\n# Repository Context: /path/to/your/project\\n\\n## Git Repository\\\n    \\ Information\\n- **Branch**: main\\n- **Commit**: a1b2c3d4e5f6789...\\n- **Author**:\\\n    \\ John Doe <john@example.com>\\n- **Date**: Fri Sep 12 14:30:15 2025\\n\\n## Summary\\n\\\n    - **Total Files**: 15\\n- **Total Lines**: 1,247\\n\\n## Directory Structure\\n```\\n\\\n    ├── src/\\n│   ├── main.py\\n│   └── utils.py\\n├── tests/\\n│   └── test_main.py\\n\\\n    ├── README.md\\n└── requirements.txt\\n```\\n## Recent Changes\\n- src/main.py (modified\\\n    \\ 2 days ago)\\n- src/utils/helpers.py (modified 5 days ago)\\n\\n## File Contents\\n\\\n    \\n### src/main.py\\n\\n```python\\ndef main():\\n    print(\\\"Hello, World!\\\")\\n\\n\\\n    if __name__ == \\\"__main__\\\":\\n    main()\\n```\\n\\n### README.md\\n\\n```markdown\\n\\\n    # My Project\\nThis is a sample project.\\n```\\n\\n## Summary\\n- Total files: 15\\n\\\n    - Total lines: 1,247\\n````\\n\\n## What Files Are Included\\n\\nThe tool includes\\\n    \\ most text files but automatically excludes:\\n\\n### Excluded Directories\\n- `.git`,\\\n    \\ `.svn`, `.hg` (version control)\\n- `__pycache__`, `.pytest_cache` (Python cache)\\n\\\n    - `node_modules`, `.venv`, `venv` (dependencies/environments)\\n- `.vscode`, `.idea`\\\n    \\ (IDE directories)\\n- `build`, `dist`, `target` (build directories)\\n\\n### File\\\n    \\ Handling Rules\\n- **Text files**: All readable text files with common extensions\\n\\\n    - **Binary files**: Automatically detected and skipped\\n- **Permission errors**:\\\n    \\ Skipped with graceful handling\\n- **Configuration files**: Includes pyproject.toml,\\\n    \\ package.json, etc.\\n\\n### Included File Types\\n- Source code: `.py`, `.js`,\\\n    \\ `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\n- Web files: `.html`, `.css`,\\\n    \\ `.scss`, `.vue`, `.jsx`, etc.\\n- Documentation: `.md`, `.txt`, `.rst`\\n- Configuration:\\\n    \\ `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\n- Scripts: `.sh`, `.bash`, `.zsh`\\n\\\n    \\n## Error Handling\\n\\nThe tool handles errors gracefully:\\n\\n| Error Type | Behavior\\\n    \\ |\\n|------------|----------|\\n| **Permission errors** | Skipped with warning\\\n    \\ |\\n| **Binary files** | Automatically detected and skipped |\\n| **Invalid paths**\\\n    \\ | Clear error messages |\\n| **Non-git repositories** | Works fine, shows \\\"\\\n    Not a git repository\\\" |\\n| **Unreadable files** | Marked as \\\"[Binary or unreadable\\\n    \\ file]\\\" |\\n\\n## Development\\n\\n### Project Structure\\n\\n```text\\nRepo-Contextor/\\n\\\n    ├── src/rcpack/              # Main package\\n│   ├── __init__.py         # Package\\\n    \\ initialization\\n│   ├── cli.py              # Command-line interface\\n│   ├──\\\n    \\ discover.py         # File discovery logic\\n│   ├── gitinfo.py          # Git\\\n    \\ repository analysis\\n│   ├── treeview.py         # Directory tree generation\\n\\\n    │   ├── packager.py         # Main orchestration\\n│   ├── io_utils.py        \\\n    \\ # File I/O utilities\\n│   └── renderer/           # Output formatters\\n│   \\\n    \\    ├── markdown.py     # Markdown renderer\\n│       └── jsonyaml.py     # JSON/YAML\\\n    \\ renderers\\n├── pyproject.toml          # Project configuration\\n├── LICENSE\\\n    \\                 # MIT License\\n└── README.md              # This documentation\\n\\\n    ```\\n\\n### Running Tests\\n\\n```bash\\n# Test on current repository\\nrepo-contextor\\\n    \\ . -o test-output.md\\n\\n# Test different formats\\nrepo-contextor . -f json |\\\n    \\ head -20\\nrepo-contextor . -f yaml | head -20\\n\\n# Test specific directory\\n\\\n    repo-contextor src/ -o src-only.md\\n```\\n\\n### Contributing\\n\\n1. **Fork the repository**\\n\\\n    2. **Clone your fork:**\\n   ```bash\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\n\\\n    \\   cd Repo-Contextor\\n   ```\\n3. **Install for development:**\\n   ```bash\\n \\\n    \\  python -m venv .venv\\n   source .venv/bin/activate\\n   pip install -e .\\n \\\n    \\  ```\\n4. **Make your changes and test:**\\n   ```bash\\n   repo-contextor . -o\\\n    \\ test.md\\n   ```\\n5. **Submit a pull request**\\n\\n### Development Workflow\\n\\n\\\n    ```bash\\n# 1. Setup development environment\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\n\\\n    cd Repo-Contextor\\npython -m venv .venv\\nsource .venv/bin/activate\\npip install\\\n    \\ -e .\\n\\n# 2. Make changes to the code\\n# Edit files in src/rcpack/\\n\\n# 3. Test\\\n    \\ your changes\\nrepo-contextor . -o test-output.md\\n\\n# 4. Test different formats\\n\\\n    repo-contextor . -f json -o test.json\\nrepo-contextor . -f yaml -o test.yaml\\n\\\n    \\n# 5. Commit and push changes\\ngit add .\\ngit commit -m \\\"Add new feature\\\"\\n\\\n    git push origin feature-branch\\n```\\n\\n## License\\n\\nThis project is licensed\\\n    \\ under the MIT License. See the [LICENSE](LICENSE) file for details.\\n\\n## Why\\\n    \\ Repo-Contextor?\\n\\nThe name \\\"Repo-Contextor\\\" combines \\\"Repository\\\" + \\\"\\\n    Context\\\" + \\\"or\\\", representing the tool's purpose of providing rich context\\\n    \\ about code repositories in a format that's perfect for LLM interactions.\\n\\n\\\n    ### Use Cases\\n\\n- **AI Assistance**: Get better help from ChatGPT, Claude, or\\\n    \\ GitHub Copilot\\n- **Code Reviews**: Share complete project context with team\\\n    \\ members\\n- **Documentation**: Create comprehensive project snapshots\\n- **Onboarding**:\\\n    \\ Help new team members understand project structure\\n- **Project Analysis**:\\\n    \\ Understand repository structure and dependencies\\n\\n### Perfect for LLMs\\n\\n\\\n    The output format is specifically designed to work well with Large Language Models:\\n\\\n    - Clear section headers for easy parsing\\n- Syntax highlighting markers for code\\\n    \\ blocks\\n- Structured metadata (git info, file locations)\\n- Complete project\\\n    \\ context in a single file\\n- Multiple output formats (Markdown, JSON, YAML)\\n\\\n    - Optimized for token efficiency\\n\"\n  pyproject.toml: \"[build-system]\\nrequires = [\\\"setuptools>=68\\\", \\\"wheel\\\"]\\nbuild-backend\\\n    \\ = \\\"setuptools.build_meta\\\"\\n\\n[project]\\nname = \\\"rcpack\\\"\\nversion = \\\"0.1.0\\\"\\\n    \\ndescription = \\\"Repository Context Packager CLI for LLMs\\\"\\nreadme = \\\"README.md\\\"\\\n    \\nrequires-python = \\\">=3.9\\\"\\nlicense = { text = \\\"MIT\\\" }\\ndependencies = [\\n\\\n    \\    \\\"PyYAML>=6.0\\\"\\n]\\n\\n[project.scripts]\\nrepo-contextor = \\\"rcpack.cli:main\\\"\\\n    \\n\"\n  src/rcpack/__init__.py: '\"\"\"Repository Context Packager - CLI tool for creating\n    LLM-optimized repository context.\"\"\"\n\n\n    __version__ = \"0.1.0\"\n\n    __author__ = \"Abhinav\"\n\n    __description__ = \"Repository Context Packager CLI for LLMs\"'\n  src/rcpack/__main__.py: \"#!/usr/bin/env python3\\n\\\"\\\"\\\"Module entry point to enable\\\n    \\ `python -m rcpack`.\\n\\nThis simply delegates to the CLI's main() function.\\n\\\n    \\\"\\\"\\\"\\n\\nfrom .cli import main\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\\\n    \\n\\n\"\n  src/rcpack/cli.py: \"#!/usr/bin/env python3\\n\\\"\\\"\\\"CLI for Repository Context Packager.\\\"\\\n    \\\"\\\"\\n\\nfrom .config_loader import load_config\\n\\nimport argparse\\nimport sys\\n\\\n    from pathlib import Path\\nfrom .gitinfo import get_git_info\\nfrom .discover import\\\n    \\ discover_files\\nfrom .treeview import create_tree_view\\nfrom .renderer.markdown\\\n    \\ import render_markdown\\nfrom .renderer.jsonyaml import render_json, render_yaml\\n\\\n    from .io_utils import write_output\\nfrom datetime import datetime, timedelta\\n\\\n    \\n\\ndef log_verbose(message: str, verbose: bool) -> None:\\n    \\\"\\\"\\\"Log a message\\\n    \\ to stderr if verbose mode is enabled.\\\"\\\"\\\"\\n    if verbose:\\n        print(message,\\\n    \\ file=sys.stderr)\\n\\n\\ndef get_rendered_content(format_type: str, repo_path:\\\n    \\ str, repo_info: dict, tree_text: str, \\n                        files_data:\\\n    \\ dict, total_files: int, total_lines: int, \\n                        recent_files_info:\\\n    \\ dict, file_sizes: dict) -> str:\\n    \\\"\\\"\\\"Get rendered content based on the\\\n    \\ specified format.\\\"\\\"\\\"\\n    if format_type == \\\"json\\\":\\n        return render_json(\\n\\\n    \\            repo_path, repo_info, tree_text, \\n            files_data, total_files,\\\n    \\ total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n\\\n    \\        )\\n    elif format_type == \\\"yaml\\\":\\n        return render_yaml(\\n \\\n    \\           repo_path, repo_info, tree_text, \\n            files_data, total_files,\\\n    \\ total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n\\\n    \\        )\\n    else:  # text/markdown\\n        return render_markdown(\\n    \\\n    \\        repo_path, repo_info, tree_text, \\n            files_data, total_files,\\\n    \\ total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n\\\n    \\        )\\n\\n\\ndef process_file(file_path: Path, repo_path: Path, verbose: bool)\\\n    \\ -> tuple[str, str, str]:\\n    \\\"\\\"\\\"Process a single file and return its data.\\n\\\n    \\    \\n    Returns:\\n        tuple: (relative_path_str, content, file_size)\\n\\\n    \\    \\\"\\\"\\\"\\n    relative_path = file_path.relative_to(repo_path)\\n    relative_path_str\\\n    \\ = str(relative_path)\\n    \\n    log_verbose(f\\\"Reading file: {relative_path}\\\"\\\n    , verbose)\\n    file_size = file_path.stat().st_size\\n    \\n    try:\\n       \\\n    \\ with open(file_path, 'r', encoding='utf-8') as f:\\n            content = f.read()\\n\\\n    \\        return relative_path_str, content, str(file_size)\\n    except (UnicodeDecodeError,\\\n    \\ PermissionError):\\n        log_verbose(f\\\"Skipping binary/unreadable file: {relative_path}\\\"\\\n    , verbose)\\n        file_size = file_path.stat().st_size if file_path.exists()\\\n    \\ else 0\\n        content = f\\\"[Binary or unreadable file: {file_path.name}]\\\"\\\n    \\n        return relative_path_str, content, str(file_size)\\n    except Exception:\\n\\\n    \\        log_verbose(f\\\"Error reading file: {relative_path}\\\", verbose)\\n    \\\n    \\    raise  # Re-raise to handle in calling code\\n\\n\\ndef handle_output(content:\\\n    \\ str, output_path: str = None) -> None:\\n    \\\"\\\"\\\"Handle output to either file\\\n    \\ or stdout.\\\"\\\"\\\"\\n    if output_path:\\n        # Write to file\\n        write_output(output_path,\\\n    \\ content)\\n        print(f\\\"Context package created: {output_path}\\\")\\n    else:\\n\\\n    \\        # Output to stdout\\n        print(content)\\n\\n\\ndef main():\\n    parser\\\n    \\ = argparse.ArgumentParser(\\n        description=\\\"Package repository content\\\n    \\ for LLM context\\\"\\n    )\\n    parser.add_argument(\\n        \\\"path\\\", \\n   \\\n    \\     nargs=\\\"?\\\", \\n        default=\\\".\\\", \\n        help=\\\"Repository path (default:\\\n    \\ current directory)\\\"\\n    )\\n    parser.add_argument(\\n        \\\"-o\\\", \\\"--output\\\"\\\n    , \\n        help=\\\"Output file path (default: stdout)\\\"\\n    )\\n    parser.add_argument(\\n\\\n    \\        \\\"-f\\\", \\\"--format\\\", \\n        choices=[\\\"text\\\", \\\"json\\\", \\\"yaml\\\"\\\n    ], \\n        default=\\\"text\\\",\\n        help=\\\"Output format (default: text)\\\"\\\n    \\n    )\\n\\n    \\\"\\\"\\\" This will read -r from the console and able to search it\\\n    \\ with this\\\"\\\"\\\"\\n    parser.add_argument(\\n    \\\"-r\\\", \\\"--recent\\\",\\n    action=\\\"\\\n    store_true\\\",\\n    help=\\\"Include only files modified in the last 7 days\\\"\\n \\\n    \\   )\\n    parser.add_argument(\\n        \\\"-v\\\", \\\"--verbose\\\",\\n        action=\\\"\\\n    store_true\\\",\\n        help=\\\"Print detailed progress information to stderr\\\"\\n\\\n    \\    )\\n    \\n    args = parser.parse_args()\\n    \\n    try:\\n        repo_path\\\n    \\ = Path(args.path).resolve()\\n        if not repo_path.exists():\\n          \\\n    \\  print(f\\\"Error: Path {repo_path} does not exist\\\", file=sys.stderr)\\n     \\\n    \\       sys.exit(1)\\n            \\n        # Get repository information\\n    \\\n    \\    log_verbose(f\\\"Analyzing repository: {repo_path}\\\", args.verbose)\\n     \\\n    \\   repo_info = get_git_info(repo_path)\\n        \\n        # Discover files\\n\\\n    \\        log_verbose(f\\\"Discovering files in: {repo_path}\\\", args.verbose)\\n \\\n    \\       discovered_files = discover_files([repo_path], repo_path, [], [])\\n  \\\n    \\      log_verbose(f\\\"Found {len(discovered_files)} files\\\", args.verbose)\\n \\\n    \\       \\n        # will check the file in last 7 days\\n        recent_files_info\\\n    \\ = {}\\n        if args.recent:\\n            seven_days_ago = datetime.now() -\\\n    \\ timedelta(days=7)\\n            recent_files = []\\n            for f in discovered_files:\\n\\\n    \\                try:\\n                    mtime = datetime.fromtimestamp(f.stat().st_mtime)\\n\\\n    \\                    if mtime >= seven_days_ago:\\n                        recent_files.append(f)\\n\\\n    \\                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)\\\n    \\     \\n                except Exception:\\n                    continue\\n    \\\n    \\        discovered_files = recent_files\\n        \\n        # Read file contents\\n\\\n    \\        files_data = {}\\n        file_sizes = {}\\n        for file_path in discovered_files:\\n\\\n    \\            try:\\n                relative_path_str, content, file_size = process_file(file_path,\\\n    \\ repo_path, args.verbose)\\n                files_data[relative_path_str] = content\\n\\\n    \\                file_sizes[relative_path_str] = file_size\\n            except\\\n    \\ Exception:\\n                continue\\n        \\n        # Create tree view\\n\\\n    \\        log_verbose(\\\"Generating directory tree\\\", args.verbose)\\n        tree_text\\\n    \\ = create_tree_view(repo_path, files_data)\\n        \\n        # Count totals\\n\\\n    \\        total_files = len(files_data)\\n        total_lines = sum(len(content.splitlines())\\\n    \\ for _, content in files_data.items())\\n        \\n        # Render based on format\\n\\\n    \\        log_verbose(f\\\"Rendering output in {args.format} format\\\", args.verbose)\\n\\\n    \\        content = get_rendered_content(\\n            args.format, str(repo_path),\\\n    \\ repo_info, tree_text,\\n            files_data, total_files, total_lines,\\n \\\n    \\           recent_files_info if args.recent else {},\\n            file_sizes\\n\\\n    \\        )\\n        \\n        handle_output(content, args.output)\\n        \\n\\\n    \\    except Exception as e:\\n        print(f\\\"Error: {e}\\\", file=sys.stderr)\\n\\\n    \\        sys.exit(1)\\n\\n# this will convert age and give us the difference\\ndef\\\n    \\ human_readable_age(mtime: datetime) -> str:\\n    delta = datetime.now() - mtime\\n\\\n    \\    days = delta.days\\n    seconds = delta.seconds\\n    if days > 0:\\n      \\\n    \\  return f\\\"{days} day{'s' if days != 1 else ''} ago\\\"\\n    elif seconds >= 3600:\\n\\\n    \\        hours = seconds // 3600\\n        return f\\\"{hours} hour{'s' if hours\\\n    \\ != 1 else ''} ago\\\"\\n    elif seconds >= 60:\\n        minutes = seconds // 60\\n\\\n    \\        return f\\\"{minutes} minute{'s' if minutes != 1 else ''} ago\\\"\\n    else:\\n\\\n    \\        return \\\"just now\\\"\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\"\n  src/rcpack/config_loader.py: \"# src/rcpack/config_loader.py\\n\\\"\\\"\\\"\\nTOML config\\\n    \\ loader for Repo-Contextor.\\n\\nRules:\\n- Look for .repo-contextor.toml in the\\\n    \\ CURRENT directory\\n- If missing: ignore\\n- If present but invalid: print a clear\\\n    \\ error and exit(1)\\n- Only recognized keys are applied; unknown keys ignored\\n\\\n    - Precedence: CLI > TOML > DEFAULTS\\n\\\"\\\"\\\"\\nfrom __future__ import annotations\\n\\\n    import os, sys\\nfrom typing import Dict, Iterable, Any\\n\\ntry:\\n    import tomllib\\n\\\n    \\    _loads = tomllib.loads\\nexcept ModuleNotFoundError:\\n    try:\\n        import\\\n    \\ tomli\\n        _loads = tomli.loads\\n    except ModuleNotFoundError:\\n     \\\n    \\   _loads = None\\n\\ndef _need_toml():\\n    if _loads is None:\\n        print(\\\"\\\n    Error: TOML parser not available. Use Python 3.11+ or `pip install tomli`.\\\",\\\n    \\ file=sys.stderr)\\n        sys.exit(1)\\n\\ndef _load_toml(dotfile: str) -> Dict[str,\\\n    \\ Any]:\\n    _need_toml()\\n    if not os.path.exists(dotfile):\\n        return\\\n    \\ {}\\n    try:\\n        with open(dotfile, \\\"rb\\\") as f:\\n            raw = f.read().decode(\\\"\\\n    utf-8\\\", errors=\\\"strict\\\")\\n        data = _loads(raw)\\n        return data if\\\n    \\ isinstance(data, dict) else {}\\n    except Exception as e:\\n        print(f\\\"\\\n    Error: failed to parse {dotfile} as TOML.\\\\n{e}\\\", file=sys.stderr)\\n        sys.exit(1)\\n\\\n    \\ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\n\\\n    \\    ks = set(known)\\n    return {k: v for k, v in d.items() if k in ks}\\n\\ndef\\\n    \\ _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str,\\\n    \\ Any], known: Iterable[str]) -> Dict[str, Any]:\\n    ks = set(known)\\n    out:\\\n    \\ Dict[str, Any] = {k: defaults.get(k) for k in ks}\\n    for src in (filecfg,\\\n    \\ clicfg):\\n        for k, v in src.items():\\n            if k in ks and v is\\\n    \\ not None:\\n                out[k] = v\\n    return out\\n\\ndef load_config(*,\\\n    \\ dotfile: str = \\\".repo-contextor.toml\\\", defaults: Dict[str, Any] | None = None,\\\n    \\ cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ()) -> Dict[str,\\\n    \\ Any]:\\n    defaults = defaults or {}\\n    cli_cfg = cli_cfg or {}\\n    known\\\n    \\ = tuple(known_keys)\\n    filecfg = _filter_known(_load_toml(dotfile), known)\\n\\\n    \\    return _merge(defaults, filecfg, cli_cfg, known)\\n\"\n  src/rcpack/discover.py: \"\\\"\\\"\\\"File discovery module for repository analysis.\\\"\\\"\\\n    \\\"\\n\\nfrom pathlib import Path\\nfrom typing import List\\nimport fnmatch\\n\\n\\n\\\n    def discover_files(\\n    inputs: List[Path],\\n    root: Path,\\n    include_patterns:\\\n    \\ List[str],\\n    exclude_patterns: List[str],\\n) -> List[Path]:\\n    \\\"\\\"\\\"Discover\\\n    \\ relevant files.\\n\\n    - inputs: list of files/dirs to scan\\n    - root: common\\\n    \\ project root; patterns are matched against POSIX paths relative to root\\n  \\\n    \\  - include_patterns: glob patterns to include (if empty, use sensible defaults)\\n\\\n    \\    - exclude_patterns: glob patterns to exclude\\n    Returns a list of absolute\\\n    \\ Paths to files.\\n    \\\"\\\"\\\"\\n\\n    default_include_exts = {\\n        '.py',\\\n    \\ '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\\n        '.cs', '.php',\\\n    \\ '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\n        '.html', '.css', '.scss',\\\n    \\ '.sass', '.less', '.vue', '.svelte',\\n        '.md', '.txt', '.rst', '.yaml',\\\n    \\ '.yml', '.json', '.toml', '.ini',\\n        '.cfg', '.conf', '.xml', '.sql',\\\n    \\ '.sh', '.bash', '.zsh', '.fish',\\n    }\\n\\n    always_include_names = {\\n  \\\n    \\      'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING', 'Makefile',\\n       \\\n    \\ 'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\\n      \\\n    \\  'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\n\\\n    \\    }\\n\\n    skip_dir_names = {\\n        '.git', '.svn', '.hg', '__pycache__',\\\n    \\ '.pytest_cache',\\n        'node_modules', '.venv', 'venv', 'env', '.env',\\n\\\n    \\        'build', 'dist', 'target', 'out', '.next', '.nuxt',\\n        '.idea',\\\n    \\ '.vscode', '.vs', 'coverage', '.coverage'\\n    }\\n\\n    def matches_any(patterns:\\\n    \\ List[str], rel_posix: str) -> bool:\\n        return any(fnmatch.fnmatch(rel_posix,\\\n    \\ pat) for pat in patterns)\\n\\n    def should_take(file_path: Path) -> bool:\\n\\\n    \\        rel_posix = file_path.relative_to(root).as_posix()\\n        if exclude_patterns\\\n    \\ and matches_any(exclude_patterns, rel_posix):\\n            return False\\n  \\\n    \\      if include_patterns:\\n            return matches_any(include_patterns,\\\n    \\ rel_posix)\\n        # default include logic\\n        return file_path.name in\\\n    \\ always_include_names or file_path.suffix.lower() in default_include_exts\\n\\n\\\n    \\    discovered: list[Path] = []\\n    seen = set()\\n\\n    for item in inputs:\\n\\\n    \\        p = item.resolve()\\n        if p.is_file():\\n            # Skip if excluded\\\n    \\ or in skipped directory\\n            if any(part in skip_dir_names for part\\\n    \\ in p.parts):\\n                continue\\n            if should_take(p):\\n   \\\n    \\             key = p.as_posix()\\n                if key not in seen:\\n      \\\n    \\              seen.add(key)\\n                    discovered.append(p)\\n     \\\n    \\   elif p.is_dir():\\n            for child in p.rglob('*'):\\n               \\\n    \\ if not child.is_file():\\n                    continue\\n                if any(part\\\n    \\ in skip_dir_names for part in child.parts):\\n                    continue\\n\\\n    \\                if should_take(child):\\n                    key = child.resolve().as_posix()\\n\\\n    \\                    if key not in seen:\\n                        seen.add(key)\\n\\\n    \\                        discovered.append(child.resolve())\\n\\n    return sorted(discovered)\"\n  src/rcpack/gitinfo.py: \"from __future__ import annotations\\n\\nimport subprocess\\n\\\n    from pathlib import Path\\nfrom typing import Dict, Any\\n\\n\\ndef _git(cmd: list[str],\\\n    \\ cwd: Path) -> str:\\n    # Validate git commands to prevent injection\\n    allowed_commands\\\n    \\ = {\\n        \\\"rev-parse\\\", \\\"show\\\", \\\"log\\\", \\\"status\\\", \\\"branch\\\", \\\"config\\\"\\\n    \\n    }\\n    if not cmd or cmd[0] not in allowed_commands:\\n        raise ValueError(f\\\"\\\n    Git command not allowed: {cmd[0] if cmd else 'empty'}\\\")\\n    \\n    out = subprocess.check_output([\\\"\\\n    git\\\", *cmd], cwd=str(cwd), timeout=30)\\n    return out.decode(\\\"utf-8\\\", errors=\\\"\\\n    replace\\\").strip()\\n\\n\\ndef is_git_repo(path: Path) -> bool:\\n    try:\\n     \\\n    \\   flag = _git([\\\"rev-parse\\\", \\\"--is-inside-work-tree\\\"], cwd=path)\\n      \\\n    \\  return flag == \\\"true\\\"\\n    except Exception:\\n        return False\\n\\n\\n\\\n    def get_git_info(path: Path) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Return info for\\\n    \\ the current HEAD of a repo rooted at `path`.\\n    \\\"\\\"\\\"\\n    try:\\n       \\\n    \\ commit = _git([\\\"rev-parse\\\", \\\"HEAD\\\"], cwd=path)\\n        branch = _git([\\\"\\\n    rev-parse\\\", \\\"--abbrev-ref\\\", \\\"HEAD\\\"], cwd=path)\\n        author = _git([\\\"\\\n    show\\\", \\\"-s\\\", \\\"--format=%an <%ae>\\\"], cwd=path)\\n        date = _git([\\\"show\\\"\\\n    , \\\"-s\\\", \\\"--date=local\\\", \\\"--format=%ad\\\"], cwd=path)\\n        return {\\n \\\n    \\           \\\"is_repo\\\": True,\\n            \\\"commit\\\": commit,\\n            \\\"\\\n    branch\\\": branch,\\n            \\\"author\\\": author,\\n            \\\"date\\\": date,\\n\\\n    \\            \\\"note\\\": None,\\n        }\\n    except Exception:\\n        # treat\\\n    \\ as not a repo if anything fails\\n        return {\\n            \\\"is_repo\\\":\\\n    \\ False,\\n            \\\"commit\\\": None,\\n            \\\"branch\\\": None,\\n     \\\n    \\       \\\"author\\\": None,\\n            \\\"date\\\": None,\\n            \\\"note\\\":\\\n    \\ \\\"Not a git repository\\\",\\n        }\\n\"\n  src/rcpack/io_utils.py: \"\\\"\\\"\\\"I/O utilities for file operations.\\\"\\\"\\\"\\n\\nfrom\\\n    \\ pathlib import Path\\nfrom typing import Tuple\\n\\n\\ndef write_output(output_path:\\\n    \\ str, content: str) -> None:\\n    \\\"\\\"\\\"Write content to output file.\\\"\\\"\\\"\\n\\\n    \\    output_file = Path(output_path)\\n    \\n    # Create parent directories if\\\n    \\ they don't exist\\n    output_file.parent.mkdir(parents=True, exist_ok=True)\\n\\\n    \\    \\n    # Write content\\n    with open(output_file, 'w', encoding='utf-8')\\\n    \\ as f:\\n        f.write(content)\\n\\n\\ndef is_binary_file(path: Path, sniff_bytes:\\\n    \\ int = 2048) -> bool:\\n    \\\"\\\"\\\"Heuristically determine if a file is binary\\\n    \\ by scanning for NUL bytes.\\\"\\\"\\\"\\n    try:\\n        with open(path, 'rb') as\\\n    \\ fb:\\n            chunk = fb.read(sniff_bytes)\\n        if b\\\"\\\\x00\\\" in chunk:\\n\\\n    \\            return True\\n        # If the chunk has a lot of non-text bytes,\\\n    \\ consider it binary\\n        text_byte_count = sum(32 <= b <= 126 or b in (9,\\\n    \\ 10, 13) for b in chunk)\\n        return (len(chunk) - text_byte_count) > max(1,\\\n    \\ len(chunk) // 3)\\n    except Exception:\\n        # If we cannot read, treat\\\n    \\ as binary to avoid further processing\\n        return True\\n\\n\\ndef read_text_safely(path:\\\n    \\ Path, max_bytes: int = 16_384) -> Tuple[str, str, bool]:\\n    \\\"\\\"\\\"Read a text\\\n    \\ file safely with size limit and encoding fallbacks.\\n\\n    Returns (content,\\\n    \\ encoding_used, truncated).\\n    \\\"\\\"\\\"\\n    truncated = False\\n    raw: bytes\\n\\\n    \\    with open(path, 'rb') as fb:\\n        raw = fb.read(max_bytes + 1)\\n    if\\\n    \\ len(raw) > max_bytes:\\n        truncated = True\\n        raw = raw[:max_bytes]\\n\\\n    \\n    for enc in (\\\"utf-8\\\", \\\"utf-16\\\", \\\"utf-16-le\\\", \\\"utf-16-be\\\", \\\"latin-1\\\"\\\n    ):\\n        try:\\n            text = raw.decode(enc)\\n            return text,\\\n    \\ enc, truncated\\n        except Exception:\\n            continue\\n    # Fallback:\\\n    \\ replace errors with utf-8\\n    text = raw.decode(\\\"utf-8\\\", errors=\\\"replace\\\"\\\n    )\\n    return text, \\\"utf-8\\\", truncated\"\n  src/rcpack/packager.py: \"from __future__ import annotations\\n\\nimport sys\\nfrom\\\n    \\ pathlib import Path\\nfrom typing import Iterable, Tuple\\n\\nfrom rcpack.discover\\\n    \\ import discover_files\\nfrom rcpack.gitinfo import get_git_info, is_git_repo\\n\\\n    from rcpack.io_utils import read_text_safely, is_binary_file\\nfrom rcpack.renderer\\\n    \\ import markdown as md_renderer\\nfrom rcpack.renderer.jsonyaml import render_json,\\\n    \\ render_yaml\\nfrom rcpack.treeview import render_tree\\nfrom rcpack.utils import\\\n    \\ get_language_from_extension\\n\\n\\ndef _find_root(inputs: list[str]) -> Path:\\n\\\n    \\    paths = [Path(p) for p in inputs]\\n    if len(paths) == 1 and Path(paths[0]).is_dir():\\n\\\n    \\        return paths[0].resolve()\\n    parents = [p if p.is_dir() else p.parent\\\n    \\ for p in paths]\\n    root = Path(*Path.commonpath([str(p.resolve()) for p in\\\n    \\ parents]).split(\\\"/\\\"))\\n    return root.resolve()\\n\\n\\ndef build_package(\\n\\\n    \\    inputs: list[str],\\n    include_patterns: list[str] | None,\\n    exclude_patterns:\\\n    \\ list[str] | None,\\n    max_file_bytes: int,\\n    fmt: str = \\\"markdown\\\",\\n\\\n    ) -> Tuple[str, dict]:\\n    root = _find_root(inputs)\\n    root_abs = root.resolve()\\n\\\n    \\n    repo_info = (\\n        get_git_info(root_abs) if is_git_repo(root_abs) else\\\n    \\ {\\n            \\\"is_repo\\\": False,\\n            \\\"commit\\\": None,\\n        \\\n    \\    \\\"branch\\\": None,\\n            \\\"author\\\": None,\\n            \\\"date\\\": None,\\n\\\n    \\            \\\"note\\\": \\\"Not a git repository\\\",\\n        }\\n    )\\n\\n    files\\\n    \\ = discover_files(\\n        inputs=[Path(p) for p in inputs],\\n        root=root_abs,\\n\\\n    \\        include_patterns=include_patterns or [],\\n        exclude_patterns=exclude_patterns\\\n    \\ or [],\\n    )\\n    rel_files = [f.relative_to(root_abs) for f in files]\\n\\n\\\n    \\    project_tree = render_tree([p.as_posix() for p in rel_files])\\n\\n    file_sections:\\\n    \\ list[dict] = []\\n    total_lines = 0\\n    total_chars = 0\\n\\n    for f in files:\\n\\\n    \\        rel = f.relative_to(root_abs).as_posix()\\n        try:\\n            if\\\n    \\ is_binary_file(f):\\n                content = f\\\"[binary file skipped: {f.name},\\\n    \\ {f.stat().st_size} bytes]\\\"\\n                file_sections.append({\\n      \\\n    \\              \\\"path\\\": rel,\\n                    \\\"language\\\": get_language_from_extension(f.suffix),\\n\\\n    \\                    \\\"content\\\": content,\\n                    \\\"is_truncated\\\"\\\n    : False,\\n                })\\n                total_chars += len(content)\\n  \\\n    \\              continue\\n\\n            content, used_encoding, truncated = read_text_safely(f,\\\n    \\ max_bytes=max_file_bytes)\\n            total_lines += content.count(\\\"\\\\n\\\"\\\n    ) + (1 if content and not content.endswith(\\\"\\\\n\\\") else 0)\\n            total_chars\\\n    \\ += len(content)\\n\\n            if truncated:\\n                note = f\\\"\\\\n\\\\\\\n    n[... TRUNCATED to first {max_file_bytes} bytes ...]\\\"\\n                content\\\n    \\ = content + note\\n                total_chars += len(note)\\n\\n            file_sections.append({\\n\\\n    \\                \\\"path\\\": rel,\\n                \\\"language\\\": get_language_from_extension(f.suffix),\\n\\\n    \\                \\\"content\\\": content,\\n                \\\"is_truncated\\\": truncated,\\n\\\n    \\            })\\n        except Exception as exc:\\n            print(f\\\"[rcpack]\\\n    \\ error reading {rel}: {exc}\\\", file=sys.stderr)\\n            continue\\n\\n   \\\n    \\ # render in chosen format\\n    if fmt == \\\"markdown\\\":\\n        out_text = md_renderer.render_markdown(\\n\\\n    \\            root=str(root_abs),\\n            repo_info=repo_info,\\n         \\\n    \\   tree_text=project_tree,\\n            files=file_sections,\\n            total_files=len(file_sections),\\n\\\n    \\            total_lines=total_lines,\\n        )\\n    elif fmt == \\\"json\\\":\\n\\\n    \\        out_text = render_json(\\n            root=str(root_abs),\\n          \\\n    \\  repo_info=repo_info,\\n            tree_text=project_tree,\\n            files=file_sections,\\n\\\n    \\            total_files=len(file_sections),\\n            total_lines=total_lines,\\n\\\n    \\        )\\n    elif fmt == \\\"yaml\\\":\\n        out_text = render_yaml(\\n     \\\n    \\       root=str(root_abs),\\n            repo_info=repo_info,\\n            tree_text=project_tree,\\n\\\n    \\            files=file_sections,\\n            total_files=len(file_sections),\\n\\\n    \\            total_lines=total_lines,\\n        )\\n    else:\\n        raise ValueError(f\\\"\\\n    Unsupported format: {fmt}\\\")\\n\\n    stats = {\\\"files\\\": len(file_sections), \\\"\\\n    lines\\\": total_lines, \\\"chars\\\": total_chars}\\n    return out_text, stats\\n\"\n  src/rcpack/renderer/jsonyaml.py: \"from __future__ import annotations\\nimport json\\n\\\n    from ..utils import build_repository_data\\n\\ntry:\\n    import yaml\\nexcept ImportError:\\n\\\n    \\    yaml = None\\n\\n\\ndef render_json(root, repo_info, tree_text, files, total_files,\\\n    \\ total_lines,recent_files=None, file_sizes=None) -> str:\\n    data = build_repository_data(\\n\\\n    \\        root=root,\\n        repo_info=repo_info,\\n        tree_text=tree_text,\\n\\\n    \\        files=files,\\n        total_files=total_files,\\n        total_lines=total_lines,\\n\\\n    \\        recent_files=recent_files,\\n        file_sizes=file_sizes\\n    )\\n  \\\n    \\  return json.dumps(data, indent=2, ensure_ascii=False)\\n\\n\\ndef render_yaml(root,\\\n    \\ repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None)\\\n    \\ -> str:\\n    if yaml is None:\\n        raise RuntimeError(\\\"PyYAML not installed;\\\n    \\ run `pip install pyyaml`\\\")\\n    data = build_repository_data(\\n        root=root,\\n\\\n    \\        repo_info=repo_info,\\n        tree_text=tree_text,\\n        files=files,\\n\\\n    \\        total_files=total_files,\\n        total_lines=total_lines,\\n        recent_files=recent_files,\\n\\\n    \\        file_sizes=file_sizes\\n    )\\n    return yaml.safe_dump(data, sort_keys=False,\\\n    \\ allow_unicode=True)\\n\"\n  src/rcpack/renderer/markdown.py: \"\\\"\\\"\\\"Markdown renderer for repository context.\\\"\\\n    \\\"\\\"\\n\\nfrom typing import Dict, Any\\nfrom ..utils import get_language_from_extension\\n\\\n    \\n\\ndef render_markdown(root: str, repo_info: Dict[str, Any], tree_text: str,\\\n    \\ \\n                   files: Dict[str, str], total_files: int, total_lines: int,\\\n    \\ recent_files=None, file_sizes=None) -> str:\\n    \\\"\\\"\\\"Render repository context\\\n    \\ as markdown.\\\"\\\"\\\"\\n    \\n    lines = []\\n    \\n    # Header\\n    lines.append(f\\\"\\\n    # Repository Context: {root}\\\")\\n    lines.append(\\\"\\\")\\n    \\n    # Repository\\\n    \\ info\\n    if repo_info.get(\\\"is_repo\\\"):\\n        lines.append(\\\"## Git Repository\\\n    \\ Information\\\")\\n        lines.append(f\\\"- **Branch**: {repo_info.get('branch',\\\n    \\ 'N/A')}\\\")\\n        lines.append(f\\\"- **Commit**: {repo_info.get('commit', 'N/A')}\\\"\\\n    )\\n        lines.append(f\\\"- **Author**: {repo_info.get('author', 'N/A')}\\\")\\n\\\n    \\        lines.append(f\\\"- **Date**: {repo_info.get('date', 'N/A')}\\\")\\n    else:\\n\\\n    \\        lines.append(\\\"## Repository Information\\\")\\n        lines.append(f\\\"\\\n    - **Note**: {repo_info.get('note', 'Not a git repository')}\\\")\\n    lines.append(\\\"\\\n    \\\")\\n    \\n    # Summary\\n    lines.append(\\\"## Summary\\\")\\n    lines.append(f\\\"\\\n    - **Total Files**: {total_files}\\\")\\n    lines.append(f\\\"- **Total Lines**: {total_lines}\\\"\\\n    )\\n    lines.append(\\\"\\\")\\n    \\n    # Directory structure\\n    lines.append(\\\"\\\n    ## Directory Structure\\\")\\n    lines.append(\\\"```\\\")\\n    lines.append(tree_text)\\n\\\n    \\    lines.append(\\\"```\\\")\\n    lines.append(\\\"\\\")\\n\\n    # will produce recent\\\n    \\ files \\n    # Recent files (fixed)\\n    if recent_files:\\n        lines.append(\\\"\\\n    ## Recent Changes\\\")\\n        for file, age in recent_files.items():\\n       \\\n    \\     lines.append(f\\\"- {file} (modified {age})\\\")\\n        lines.append(\\\"\\\"\\\n    )\\n    \\n    # File contents\\n    lines.append(\\\"## File Contents\\\")\\n    lines.append(\\\"\\\n    \\\")\\n    \\n    for file_path, content in sorted(files.items()):\\n        if file_sizes\\\n    \\ and file_path in file_sizes:\\n            size_bytes = file_sizes[file_path]\\n\\\n    \\            lines.append(f\\\"### {file_path} ({size_bytes} bytes)\\\")\\n       \\\n    \\ else:\\n            lines.append(f\\\"### {file_path}\\\")\\n        lines.append(\\\"\\\n    \\\")\\n        \\n        # Detect language for syntax highlighting\\n        language\\\n    \\ = get_language_from_extension(file_path)\\n        \\n        lines.append(f\\\"\\\n    ```{language}\\\")\\n        lines.append(content)\\n        lines.append(\\\"```\\\"\\\n    )\\n        lines.append(\\\"\\\")\\n    \\n    return \\\"\\\\n\\\".join(lines)\\n\"\n  src/rcpack/treeview.py: \"\\\"\\\"\\\"Tree view generation for repository structure.\\\"\\\"\\\n    \\\"\\n\\nfrom pathlib import Path\\nfrom typing import Dict, List\\n\\n\\ndef create_tree_view(repo_path:\\\n    \\ Path, files_data: Dict[str, str]) -> str:\\n    \\\"\\\"\\\"Create a tree view of the\\\n    \\ repository structure.\\\"\\\"\\\"\\n    paths = list(files_data.keys())\\n    return\\\n    \\ render_tree(paths)\\n\\n\\ndef render_tree(paths: List[str]) -> str:\\n    \\\"\\\"\\\"\\\n    Render a tree view from a list of relative POSIX paths.\\\"\\\"\\\"\\n    tree_structure:\\\n    \\ dict = {}\\n\\n    for p in paths:\\n        parts = Path(p).parts\\n        current\\\n    \\ = tree_structure\\n        for part in parts[:-1]:\\n            if part not in\\\n    \\ current:\\n                current[part] = {}\\n            current = current[part]\\n\\\n    \\        if parts:\\n            current[parts[-1]] = None\\n\\n    def _render(structure:\\\n    \\ dict, prefix: str = \\\"\\\") -> str:\\n        lines = []\\n        items = sorted(structure.items(),\\\n    \\ key=lambda x: (x[1] is None, x[0]))\\n        for i, (name, subtree) in enumerate(items):\\n\\\n    \\            is_last = i == len(items) - 1\\n            lines.append(f\\\"{prefix}{'└──\\\n    \\ ' if is_last else '├── '}{name}\\\")\\n            if subtree is not None:\\n  \\\n    \\              extension = (\\\"    \\\" if is_last else \\\"│   \\\")\\n             \\\n    \\   lines.append(_render(subtree, prefix + extension))\\n        return \\\"\\\\n\\\"\\\n    .join(filter(None, lines))\\n\\n    if not tree_structure:\\n        return \\\"No\\\n    \\ files found\\\"\\n    return _render(tree_structure)\"\n  src/rcpack/utils.py: \"\\\"\\\"\\\"Utility functions shared across the rcpack package.\\\"\\\n    \\\"\\\"\\n\\nfrom typing import Dict, Any, Optional\\n\\n\\ndef get_language_from_extension(file_path_or_ext:\\\n    \\ str) -> str:\\n    \\\"\\\"\\\"Get the language identifier for syntax highlighting\\\n    \\ from a file path or extension.\\n    \\n    Args:\\n        file_path_or_ext: Either\\\n    \\ a file path (e.g., 'src/main.py') or extension (e.g., '.py' or 'py')\\n    \\n\\\n    \\    Returns:\\n        Language identifier for syntax highlighting (e.g., 'python',\\\n    \\ 'javascript')\\n    \\\"\\\"\\\"\\n    # Extract extension from file path if needed\\n\\\n    \\    if '.' in file_path_or_ext and not file_path_or_ext.startswith('.'):\\n  \\\n    \\      # It's a file path, extract the extension\\n        ext = file_path_or_ext.split('.')[-1].lower()\\n\\\n    \\    else:\\n        # It's already an extension, clean it up\\n        ext = file_path_or_ext.lower().lstrip(\\\"\\\n    .\\\")\\n    \\n    # Comprehensive language mapping combining both existing mappings\\n\\\n    \\    language_map = {\\n        'py': 'python', 'js': 'javascript', 'ts': 'typescript',\\n\\\n    \\        'jsx': 'javascript', 'tsx': 'typescript',\\n        'java': 'java', 'cpp':\\\n    \\ 'cpp', 'c': 'c', 'h': 'c',\\n        'cs': 'csharp', 'php': 'php', 'rb': 'ruby',\\n\\\n    \\        'go': 'go', 'rs': 'rust', 'swift': 'swift', 'kt': 'kotlin',\\n       \\\n    \\ 'html': 'html', 'css': 'css', 'scss': 'scss', 'sass': 'sass',\\n        'json':\\\n    \\ 'json', 'yaml': 'yaml', 'yml': 'yaml',\\n        'toml': 'toml', 'xml': 'xml',\\\n    \\ 'sql': 'sql', 'sh': 'bash',\\n        'bash': 'bash', 'zsh': 'bash', 'fish':\\\n    \\ 'fish',\\n        'md': 'markdown', 'txt': 'text',\\n        'dockerfile': 'dockerfile',\\\n    \\ 'makefile': 'makefile'\\n    }\\n    \\n    return language_map.get(ext, '')\\n\\n\\\n    \\ndef build_repository_data(\\n    root: str,\\n    repo_info: Dict[str, Any],\\n\\\n    \\    tree_text: str,\\n    files: Dict[str, str],\\n    total_files: int,\\n    total_lines:\\\n    \\ int,\\n    recent_files: Optional[Dict[str, str]] = None,\\n    file_sizes: Optional[Dict[str,\\\n    \\ str]] = None\\n) -> Dict[str, Any]:\\n    \\\"\\\"\\\"Build the standard repository\\\n    \\ data structure used by all renderers.\\n    \\n    Args:\\n        root: Repository\\\n    \\ root path\\n        repo_info: Git repository information\\n        tree_text:\\\n    \\ Directory tree text representation\\n        files: Dictionary of file paths\\\n    \\ to content\\n        total_files: Total number of files\\n        total_lines:\\\n    \\ Total number of lines\\n        recent_files: Optional dict of recently modified\\\n    \\ files\\n        file_sizes: Optional dict of file sizes\\n        \\n    Returns:\\n\\\n    \\        Standardized data dictionary for rendering\\n    \\\"\\\"\\\"\\n    return {\\n\\\n    \\        \\\"root\\\": root,\\n        \\\"repo_info\\\": repo_info,\\n        \\\"structure\\\"\\\n    : tree_text,\\n        \\\"recent_changes\\\": recent_files or {},\\n        \\\"files\\\"\\\n    : files,\\n        \\\"file_sizes\\\": file_sizes or {},\\n        \\\"summary\\\": {\\\"\\\n    total_files\\\": total_files, \\\"total_lines\\\": total_lines},\\n    }\\n\\n\\ndef calculate_total_lines(content_dict:\\\n    \\ Dict[str, str]) -> int:\\n    \\\"\\\"\\\"Calculate the total number of lines from\\\n    \\ a dictionary of file contents.\\n    \\n    Args:\\n        content_dict: Dictionary\\\n    \\ mapping file paths to their content\\n        \\n    Returns:\\n        Total number\\\n    \\ of lines across all files\\n    \\\"\\\"\\\"\\n    return sum(len(content.splitlines())\\\n    \\ for content in content_dict.values())\\n\\n\\ndef calculate_total_characters(content_dict:\\\n    \\ Dict[str, str]) -> int:\\n    \\\"\\\"\\\"Calculate the total number of characters\\\n    \\ from a dictionary of file contents.\\n    \\n    Args:\\n        content_dict:\\\n    \\ Dictionary mapping file paths to their content\\n        \\n    Returns:\\n   \\\n    \\     Total number of characters across all files\\n    \\\"\\\"\\\"\\n    return sum(len(content)\\\n    \\ for content in content_dict.values())\"\n  test-iteration2.json: \"{\\n  \\\"root\\\": \\\"/Users/abhinavbhardwaj/Desktop/Semester\\\n    \\ 5/OSD600/Repo-Contextor\\\",\\n  \\\"repo_info\\\": {\\n    \\\"is_repo\\\": true,\\n   \\\n    \\ \\\"commit\\\": \\\"57f0f88ec3d11a89d5ca08ee4fb5b9b561c1b8aa\\\",\\n    \\\"branch\\\": \\\"\\\n    refactoring\\\",\\n    \\\"author\\\": \\\"Abhinav <abhinavbhardwaj2002@gmail.com>\\\",\\n\\\n    \\    \\\"date\\\": \\\"Fri Oct 10 19:19:52 2025\\\",\\n    \\\"note\\\": null\\n  },\\n  \\\"structure\\\"\\\n    : \\\"├── src\\\\n│   └── rcpack\\\\n│       ├── renderer\\\\n│       │   ├── jsonyaml.py\\\\\\\n    n│       │   └── markdown.py\\\\n│       ├── __init__.py\\\\n│       ├── __main__.py\\\\\\\n    n│       ├── cli.py\\\\n│       ├── config_loader.py\\\\n│       ├── discover.py\\\\\\\n    n│       ├── gitinfo.py\\\\n│       ├── io_utils.py\\\\n│       ├── packager.py\\\\\\\n    n│       ├── treeview.py\\\\n│       └── utils.py\\\\n├── LICENSE\\\\n├── README.md\\\\\\\n    n├── pyproject.toml\\\\n├── test-output.json\\\\n└── test-yaml.yaml\\\",\\n  \\\"recent_changes\\\"\\\n    : {},\\n  \\\"files\\\": {\\n    \\\"LICENSE\\\": \\\"MIT License\\\\n\\\\nCopyright (c) 2025\\\n    \\ Abhinav\\\\n\\\\nPermission is hereby granted, free of charge, to any person obtaining\\\n    \\ a copy\\\\nof this software and associated documentation files (the \\\\\\\"Software\\\\\\\n    \\\"), to deal\\\\nin the Software without restriction, including without limitation\\\n    \\ the rights\\\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or\\\n    \\ sell\\\\ncopies of the Software, and to permit persons to whom the Software is\\\\\\\n    nfurnished to do so, subject to the following conditions:\\\\n\\\\nThe above copyright\\\n    \\ notice and this permission notice shall be included in all\\\\ncopies or substantial\\\n    \\ portions of the Software.\\\\n\\\\nTHE SOFTWARE IS PROVIDED \\\\\\\"AS IS\\\\\\\", WITHOUT\\\n    \\ WARRANTY OF ANY KIND, EXPRESS OR\\\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE\\\n    \\ WARRANTIES OF MERCHANTABILITY,\\\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\\\n    \\ IN NO EVENT SHALL THE\\\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\\\n    \\ DAMAGES OR OTHER\\\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\\\n    \\ ARISING FROM,\\\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\\\n    \\ DEALINGS IN THE\\\\nSOFTWARE.\\\\n\\\",\\n    \\\"README.md\\\": \\\"# Repo-Contextor\\\\n\\\\\\\n    n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\\\\\\n    n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\\\\\\n    n\\\\nA powerful Repository Context Packager CLI tool that analyzes local git repositories\\\n    \\ and creates comprehensive text files containing repository content optimized\\\n    \\ for sharing with Large Language Models (LLMs).\\\\n\\\\n## Overview\\\\n\\\\nWhen developers\\\n    \\ want to get help from ChatGPT, Claude, or other LLMs about their code, they\\\n    \\ often struggle with how to share their codebase effectively. Common problems\\\n    \\ include:\\\\n\\\\n- **Lost Context**: Copy-pasting individual files loses important\\\n    \\ project structure and relationships\\\\n- **Missing Dependencies**: LLMs can't\\\n    \\ see how files connect or what libraries are used\\\\n- **Incomplete Picture**:\\\n    \\ Hard to convey the overall architecture and organization\\\\n- **Manual Work**:\\\n    \\ Time-consuming to gather and format relevant code\\\\n\\\\n**Repo-Contextor** solves\\\n    \\ this by automatically collecting and formatting repository content into a single,\\\n    \\ well-structured text file that provides rich context to LLMs, enabling them\\\n    \\ to give much better assistance with your code.\\\\n\\\\n## Features\\\\n\\\\n- **Git\\\n    \\ Integration**: Extracts commit SHA, branch, author, and date information\\\\n-\\\n    \\ **Project Structure**: Generates a clear directory tree visualization\\\\n- **File\\\n    \\ Content Packaging**: Includes file contents with syntax highlighting\\\\n- **Smart\\\n    \\ File Discovery**: Recursively scans directories with intelligent filtering\\\\\\\n    n- **Binary File Detection**: Automatically skips binary files\\\\n- **Error Handling**:\\\n    \\ Gracefully handles permission errors and provides helpful messages\\\\n- **Multiple\\\n    \\ Output Formats**: Supports Markdown, JSON, and YAML formats\\\\n- **Flexible Output**:\\\n    \\ Write to stdout or save to a file\\\\n- **Recent Changes Filter**: Give the files\\\n    \\ which are updated in last 7days with the time when it was recently modified.\\\\\\\n    n\\\\n## Installation\\\\n\\\\n### Prerequisites\\\\n\\\\n- Python 3.9 or higher\\\\n- Git\\\n    \\ (for git repository analysis)\\\\n\\\\n### For End Users\\\\n\\\\n```bash\\\\n# Clone\\\n    \\ and install\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    ncd Repo-Contextor\\\\npip install -e .\\\\n```\\\\n\\\\n### For Contributors & Local\\\n    \\ Development\\\\n\\\\n```bash\\\\n# Clone the repository\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    ncd Repo-Contextor\\\\n\\\\n# Create virtual environment\\\\npython -m venv .venv\\\\\\\n    nsource .venv/bin/activate  # On Windows: .venv\\\\\\\\Scripts\\\\\\\\activate\\\\n\\\\n#\\\n    \\ Install in development mode\\\\npip install -e .\\\\n```\\\\n\\\\n## Usage\\\\n\\\\n###\\\n    \\ Basic Examples\\\\n\\\\n```bash\\\\n# Package current directory to terminal\\\\nrepo-contextor\\\n    \\ .\\\\n\\\\n# Package a specific directory\\\\nrepo-contextor /path/to/your/project\\\\\\\n    n\\\\n# Save output to a file\\\\nrepo-contextor . -o my-project-context.md\\\\n\\\\n#\\\n    \\ Generate JSON format\\\\nrepo-contextor . -f json -o context.json\\\\n\\\\n# Generate\\\n    \\ YAML format\\\\nrepo-contextor . -f yaml -o context.yaml\\\\n\\\\n# Include only files\\\n    \\ modified in the last 7 days\\\\nrepo-contextor . --recent\\\\n\\\\n# Combine with\\\n    \\ output file\\\\nrepo-contextor . --recent -o recent-changes.md\\\\n```\\\\n\\\\n###\\\n    \\ Command Line Options\\\\n\\\\n| Option | Short | Description | Example |\\\\n|--------|-------|-------------|---------|\\\\\\\n    n| `path` | - | Repository path to analyze (default: current directory) | `repo-contextor\\\n    \\ /path/to/project` |\\\\n| `--output` | `-o` | Output file path (default: stdout)\\\n    \\ | `-o context.md` |\\\\n| `--format` | `-f` | Output format: text, json, yaml\\\n    \\ (default: text) | `-f json` |\\\\n| `--help` | `-h` | Show help message | `-h`\\\n    \\ |\\\\n| `--recent`  | `-r`  | Include only files modified in the last 7 days \\\n    \\   | `repo-contextor . -r -o recent.md` |\\\\n\\\\n### Advanced Examples\\\\n\\\\n```bash\\\\\\\n    n# Analyze different repository\\\\nrepo-contextor /path/to/other/project -o other-project.md\\\\\\\n    n\\\\n# Generate JSON for API consumption\\\\nrepo-contextor . -f json -o api-context.json\\\\\\\n    n\\\\n# Create YAML configuration\\\\nrepo-contextor . -f yaml -o project-config.yaml\\\\\\\n    n\\\\n# Generate files which are changed recently in 7 days\\\\nrepo-contextor . -r\\\n    \\ --output recent-changes.txt\\\\n\\\\n```\\\\n## Configuration via TOML\\\\n\\\\nRepo-Contextor\\\n    \\ supports configuration through a `.repo-contextor.toml` file in the current\\\n    \\ working directory.  \\\\nThis file allows you to avoid typing the same CLI arguments\\\n    \\ every time.\\\\n\\\\nExample `.repo-contextor.toml`:\\\\n\\\\n```toml\\\\n# Output file\\\n    \\ to write results\\\\noutput = \\\\\\\"context.yaml\\\\\\\"\\\\n\\\\n# Output format: text,\\\n    \\ json, or yaml\\\\nformat = \\\\\\\"yaml\\\\\\\"\\\\n\\\\n# Limit to files modified in the\\\n    \\ last 7 days\\\\nrecent = true\\\\n\\\\n# Repository path to analyze (default = current\\\n    \\ directory)\\\\npath = \\\\\\\".\\\\\\\"\\\\n```\\\\n### Rules\\\\n- If the `.repo-contextor.toml`\\\n    \\ file is **missing**, the tool falls back to defaults.  \\\\n- If the file is **present\\\n    \\ but invalid TOML**, the tool prints a clear error message and exits with status\\\n    \\ code 1.  \\\\n- **Unknown keys** in the TOML file are ignored (safe for future\\\n    \\ extensions).  \\\\n- **Precedence** of settings is:\\\\n  1. Command-line arguments\\\n    \\ (highest priority)  \\\\n  2. Values from `.repo-contextor.toml`  \\\\n  3. Built-in\\\n    \\ defaults (lowest priority)\\\\n     \\\\n## Output Format\\\\n\\\\nThe tool generates\\\n    \\ a structured text file with the following sections:\\\\n\\\\n### 1. Repository Context\\\n    \\ Header\\\\nProject path and identification\\\\n\\\\n### 2. Git Repository Information\\\\\\\n    n- Current branch\\\\n- Latest commit SHA\\\\n- Last commit author\\\\n- Last commit\\\n    \\ date\\\\n\\\\n### 3. Summary Statistics\\\\n- Total number of files processed\\\\n-\\\n    \\ Total lines of code\\\\n\\\\n### 4. Directory Structure\\\\nClean tree visualization\\\n    \\ showing project organization\\\\n\\\\n### 5. Recent Changes (if `--recent` is used)\\\\\\\n    n\\\\n- Lists files modified in the last 7 days.\\\\n- Shows relative file paths along\\\n    \\ with how long ago each file was modified\\\\n- Helps focus on recently updated\\\n    \\ parts of the project.\\\\n- Can be combined with `--output` or `--format` to save\\\n    \\ or change the output type.\\\\n\\\\n\\\\n### 5. File Contents\\\\nEach file's content\\\n    \\ with:\\\\n- Clear file path headers\\\\n- Appropriate syntax highlighting language\\\n    \\ tags\\\\n- Complete file contents\\\\n\\\\n## Example Output\\\\n\\\\nWhen you run `repo-contextor\\\n    \\ .`, the output looks like this:\\\\n\\\\n````markdown\\\\n# Repository Context: /path/to/your/project\\\\\\\n    n\\\\n## Git Repository Information\\\\n- **Branch**: main\\\\n- **Commit**: a1b2c3d4e5f6789...\\\\\\\n    n- **Author**: John Doe <john@example.com>\\\\n- **Date**: Fri Sep 12 14:30:15 2025\\\\\\\n    n\\\\n## Summary\\\\n- **Total Files**: 15\\\\n- **Total Lines**: 1,247\\\\n\\\\n## Directory\\\n    \\ Structure\\\\n```\\\\n├── src/\\\\n│   ├── main.py\\\\n│   └── utils.py\\\\n├── tests/\\\\\\\n    n│   └── test_main.py\\\\n├── README.md\\\\n└── requirements.txt\\\\n```\\\\n## Recent\\\n    \\ Changes\\\\n- src/main.py (modified 2 days ago)\\\\n- src/utils/helpers.py (modified\\\n    \\ 5 days ago)\\\\n\\\\n## File Contents\\\\n\\\\n### src/main.py\\\\n\\\\n```python\\\\ndef\\\n    \\ main():\\\\n    print(\\\\\\\"Hello, World!\\\\\\\")\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\n    \\\":\\\\n    main()\\\\n```\\\\n\\\\n### README.md\\\\n\\\\n```markdown\\\\n# My Project\\\\nThis\\\n    \\ is a sample project.\\\\n```\\\\n\\\\n## Summary\\\\n- Total files: 15\\\\n- Total lines:\\\n    \\ 1,247\\\\n````\\\\n\\\\n## What Files Are Included\\\\n\\\\nThe tool includes most text\\\n    \\ files but automatically excludes:\\\\n\\\\n### Excluded Directories\\\\n- `.git`,\\\n    \\ `.svn`, `.hg` (version control)\\\\n- `__pycache__`, `.pytest_cache` (Python cache)\\\\\\\n    n- `node_modules`, `.venv`, `venv` (dependencies/environments)\\\\n- `.vscode`,\\\n    \\ `.idea` (IDE directories)\\\\n- `build`, `dist`, `target` (build directories)\\\\\\\n    n\\\\n### File Handling Rules\\\\n- **Text files**: All readable text files with common\\\n    \\ extensions\\\\n- **Binary files**: Automatically detected and skipped\\\\n- **Permission\\\n    \\ errors**: Skipped with graceful handling\\\\n- **Configuration files**: Includes\\\n    \\ pyproject.toml, package.json, etc.\\\\n\\\\n### Included File Types\\\\n- Source code:\\\n    \\ `.py`, `.js`, `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\\\n- Web files:\\\n    \\ `.html`, `.css`, `.scss`, `.vue`, `.jsx`, etc.\\\\n- Documentation: `.md`, `.txt`,\\\n    \\ `.rst`\\\\n- Configuration: `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\\\n- Scripts:\\\n    \\ `.sh`, `.bash`, `.zsh`\\\\n\\\\n## Error Handling\\\\n\\\\nThe tool handles errors gracefully:\\\\\\\n    n\\\\n| Error Type | Behavior |\\\\n|------------|----------|\\\\n| **Permission errors**\\\n    \\ | Skipped with warning |\\\\n| **Binary files** | Automatically detected and skipped\\\n    \\ |\\\\n| **Invalid paths** | Clear error messages |\\\\n| **Non-git repositories**\\\n    \\ | Works fine, shows \\\\\\\"Not a git repository\\\\\\\" |\\\\n| **Unreadable files**\\\n    \\ | Marked as \\\\\\\"[Binary or unreadable file]\\\\\\\" |\\\\n\\\\n## Development\\\\n\\\\n###\\\n    \\ Project Structure\\\\n\\\\n```text\\\\nRepo-Contextor/\\\\n├── src/rcpack/         \\\n    \\     # Main package\\\\n│   ├── __init__.py         # Package initialization\\\\\\\n    n│   ├── cli.py              # Command-line interface\\\\n│   ├── discover.py  \\\n    \\       # File discovery logic\\\\n│   ├── gitinfo.py          # Git repository\\\n    \\ analysis\\\\n│   ├── treeview.py         # Directory tree generation\\\\n│   ├──\\\n    \\ packager.py         # Main orchestration\\\\n│   ├── io_utils.py         # File\\\n    \\ I/O utilities\\\\n│   └── renderer/           # Output formatters\\\\n│       ├──\\\n    \\ markdown.py     # Markdown renderer\\\\n│       └── jsonyaml.py     # JSON/YAML\\\n    \\ renderers\\\\n├── pyproject.toml          # Project configuration\\\\n├── LICENSE\\\n    \\                 # MIT License\\\\n└── README.md              # This documentation\\\\\\\n    n```\\\\n\\\\n### Running Tests\\\\n\\\\n```bash\\\\n# Test on current repository\\\\nrepo-contextor\\\n    \\ . -o test-output.md\\\\n\\\\n# Test different formats\\\\nrepo-contextor . -f json\\\n    \\ | head -20\\\\nrepo-contextor . -f yaml | head -20\\\\n\\\\n# Test specific directory\\\\\\\n    nrepo-contextor src/ -o src-only.md\\\\n```\\\\n\\\\n### Contributing\\\\n\\\\n1. **Fork\\\n    \\ the repository**\\\\n2. **Clone your fork:**\\\\n   ```bash\\\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    n   cd Repo-Contextor\\\\n   ```\\\\n3. **Install for development:**\\\\n   ```bash\\\\\\\n    n   python -m venv .venv\\\\n   source .venv/bin/activate\\\\n   pip install -e .\\\\\\\n    n   ```\\\\n4. **Make your changes and test:**\\\\n   ```bash\\\\n   repo-contextor\\\n    \\ . -o test.md\\\\n   ```\\\\n5. **Submit a pull request**\\\\n\\\\n### Development Workflow\\\\\\\n    n\\\\n```bash\\\\n# 1. Setup development environment\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    ncd Repo-Contextor\\\\npython -m venv .venv\\\\nsource .venv/bin/activate\\\\npip install\\\n    \\ -e .\\\\n\\\\n# 2. Make changes to the code\\\\n# Edit files in src/rcpack/\\\\n\\\\n#\\\n    \\ 3. Test your changes\\\\nrepo-contextor . -o test-output.md\\\\n\\\\n# 4. Test different\\\n    \\ formats\\\\nrepo-contextor . -f json -o test.json\\\\nrepo-contextor . -f yaml -o\\\n    \\ test.yaml\\\\n\\\\n# 5. Commit and push changes\\\\ngit add .\\\\ngit commit -m \\\\\\\"\\\n    Add new feature\\\\\\\"\\\\ngit push origin feature-branch\\\\n```\\\\n\\\\n## License\\\\n\\\\\\\n    nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file\\\n    \\ for details.\\\\n\\\\n## Why Repo-Contextor?\\\\n\\\\nThe name \\\\\\\"Repo-Contextor\\\\\\\"\\\n    \\ combines \\\\\\\"Repository\\\\\\\" + \\\\\\\"Context\\\\\\\" + \\\\\\\"or\\\\\\\", representing the\\\n    \\ tool's purpose of providing rich context about code repositories in a format\\\n    \\ that's perfect for LLM interactions.\\\\n\\\\n### Use Cases\\\\n\\\\n- **AI Assistance**:\\\n    \\ Get better help from ChatGPT, Claude, or GitHub Copilot\\\\n- **Code Reviews**:\\\n    \\ Share complete project context with team members\\\\n- **Documentation**: Create\\\n    \\ comprehensive project snapshots\\\\n- **Onboarding**: Help new team members understand\\\n    \\ project structure\\\\n- **Project Analysis**: Understand repository structure\\\n    \\ and dependencies\\\\n\\\\n### Perfect for LLMs\\\\n\\\\nThe output format is specifically\\\n    \\ designed to work well with Large Language Models:\\\\n- Clear section headers\\\n    \\ for easy parsing\\\\n- Syntax highlighting markers for code blocks\\\\n- Structured\\\n    \\ metadata (git info, file locations)\\\\n- Complete project context in a single\\\n    \\ file\\\\n- Multiple output formats (Markdown, JSON, YAML)\\\\n- Optimized for token\\\n    \\ efficiency\\\\n\\\",\\n    \\\"pyproject.toml\\\": \\\"[build-system]\\\\nrequires = [\\\\\\\"\\\n    setuptools>=68\\\\\\\", \\\\\\\"wheel\\\\\\\"]\\\\nbuild-backend = \\\\\\\"setuptools.build_meta\\\\\\\n    \\\"\\\\n\\\\n[project]\\\\nname = \\\\\\\"rcpack\\\\\\\"\\\\nversion = \\\\\\\"0.1.0\\\\\\\"\\\\ndescription\\\n    \\ = \\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\"\\\\nreadme = \\\\\\\"README.md\\\\\\\n    \\\"\\\\nrequires-python = \\\\\\\">=3.9\\\\\\\"\\\\nlicense = { text = \\\\\\\"MIT\\\\\\\" }\\\\ndependencies\\\n    \\ = [\\\\n    \\\\\\\"PyYAML>=6.0\\\\\\\"\\\\n]\\\\n\\\\n[project.scripts]\\\\nrepo-contextor =\\\n    \\ \\\\\\\"rcpack.cli:main\\\\\\\"\\\\n\\\",\\n    \\\"src/rcpack/__init__.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\n    Repository Context Packager - CLI tool for creating LLM-optimized repository context.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n\\\\n__version__ = \\\\\\\"0.1.0\\\\\\\"\\\\n__author__ = \\\\\\\"Abhinav\\\\\\\"\\\\n__description__\\\n    \\ = \\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\"\\\",\\n    \\\"src/rcpack/__main__.py\\\"\\\n    : \\\"#!/usr/bin/env python3\\\\n\\\\\\\"\\\\\\\"\\\\\\\"Module entry point to enable `python\\\n    \\ -m rcpack`.\\\\n\\\\nThis simply delegates to the CLI's main() function.\\\\n\\\\\\\"\\\\\\\n    \\\"\\\\\\\"\\\\n\\\\nfrom .cli import main\\\\n\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\n    \\    main()\\\\n\\\\n\\\\n\\\",\\n    \\\"src/rcpack/cli.py\\\": \\\"#!/usr/bin/env python3\\\\\\\n    n\\\\\\\"\\\\\\\"\\\\\\\"CLI for Repository Context Packager.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom .config_loader\\\n    \\ import load_config\\\\n\\\\nimport argparse\\\\nimport sys\\\\nfrom pathlib import Path\\\\\\\n    nfrom .gitinfo import get_git_info\\\\nfrom .discover import discover_files\\\\nfrom\\\n    \\ .treeview import create_tree_view\\\\nfrom .renderer.markdown import render_markdown\\\\\\\n    nfrom .renderer.jsonyaml import render_json, render_yaml\\\\nfrom .io_utils import\\\n    \\ write_output\\\\nfrom datetime import datetime, timedelta\\\\n\\\\n\\\\ndef log_verbose(message:\\\n    \\ str, verbose: bool) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Log a message to stderr if verbose\\\n    \\ mode is enabled.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if verbose:\\\\n        print(message, file=sys.stderr)\\\\\\\n    n\\\\n\\\\ndef get_rendered_content(format_type: str, repo_path: str, repo_info: dict,\\\n    \\ tree_text: str, \\\\n                        files_data: dict, total_files: int,\\\n    \\ total_lines: int, \\\\n                        recent_files_info: dict, file_sizes:\\\n    \\ dict) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Get rendered content based on the specified\\\n    \\ format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if format_type == \\\\\\\"json\\\\\\\":\\\\n        return render_json(\\\\\\\n    n            repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\n    \\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\\\\n    n        )\\\\n    elif format_type == \\\\\\\"yaml\\\\\\\":\\\\n        return render_yaml(\\\\\\\n    n            repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\n    \\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\\\\n    n        )\\\\n    else:  # text/markdown\\\\n        return render_markdown(\\\\n \\\n    \\           repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\n    \\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\\\\n    n        )\\\\n\\\\n\\\\ndef process_file(file_path: Path, repo_path: Path, verbose:\\\n    \\ bool) -> tuple[str, str, str]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Process a single file and return\\\n    \\ its data.\\\\n    \\\\n    Returns:\\\\n        tuple: (relative_path_str, content,\\\n    \\ file_size)\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    relative_path = file_path.relative_to(repo_path)\\\\\\\n    n    relative_path_str = str(relative_path)\\\\n    \\\\n    log_verbose(f\\\\\\\"Reading\\\n    \\ file: {relative_path}\\\\\\\", verbose)\\\\n    file_size = file_path.stat().st_size\\\\\\\n    n    \\\\n    try:\\\\n        with open(file_path, 'r', encoding='utf-8') as f:\\\\\\\n    n            content = f.read()\\\\n        return relative_path_str, content, str(file_size)\\\\\\\n    n    except (UnicodeDecodeError, PermissionError):\\\\n        log_verbose(f\\\\\\\"\\\n    Skipping binary/unreadable file: {relative_path}\\\\\\\", verbose)\\\\n        file_size\\\n    \\ = file_path.stat().st_size if file_path.exists() else 0\\\\n        content =\\\n    \\ f\\\\\\\"[Binary or unreadable file: {file_path.name}]\\\\\\\"\\\\n        return relative_path_str,\\\n    \\ content, str(file_size)\\\\n    except Exception:\\\\n        log_verbose(f\\\\\\\"\\\n    Error reading file: {relative_path}\\\\\\\", verbose)\\\\n        raise  # Re-raise\\\n    \\ to handle in calling code\\\\n\\\\n\\\\ndef handle_output(content: str, output_path:\\\n    \\ str = None) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Handle output to either file or stdout.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n    if output_path:\\\\n        # Write to file\\\\n        write_output(output_path,\\\n    \\ content)\\\\n        print(f\\\\\\\"Context package created: {output_path}\\\\\\\")\\\\\\\n    n    else:\\\\n        # Output to stdout\\\\n        print(content)\\\\n\\\\n\\\\ndef main():\\\\\\\n    n    parser = argparse.ArgumentParser(\\\\n        description=\\\\\\\"Package repository\\\n    \\ content for LLM context\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"\\\n    path\\\\\\\", \\\\n        nargs=\\\\\\\"?\\\\\\\", \\\\n        default=\\\\\\\".\\\\\\\", \\\\n      \\\n    \\  help=\\\\\\\"Repository path (default: current directory)\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\\\\n    n        \\\\\\\"-o\\\\\\\", \\\\\\\"--output\\\\\\\", \\\\n        help=\\\\\\\"Output file path (default:\\\n    \\ stdout)\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"-f\\\\\\\", \\\\\\\"--format\\\\\\\n    \\\", \\\\n        choices=[\\\\\\\"text\\\\\\\", \\\\\\\"json\\\\\\\", \\\\\\\"yaml\\\\\\\"], \\\\n       \\\n    \\ default=\\\\\\\"text\\\\\\\",\\\\n        help=\\\\\\\"Output format (default: text)\\\\\\\"\\\\\\\n    n    )\\\\n\\\\n    \\\\\\\"\\\\\\\"\\\\\\\" This will read -r from the console and able to search\\\n    \\ it with this\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    parser.add_argument(\\\\n    \\\\\\\"-r\\\\\\\", \\\\\\\"--recent\\\\\\\n    \\\",\\\\n    action=\\\\\\\"store_true\\\\\\\",\\\\n    help=\\\\\\\"Include only files modified\\\n    \\ in the last 7 days\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"-v\\\\\\\n    \\\", \\\\\\\"--verbose\\\\\\\",\\\\n        action=\\\\\\\"store_true\\\\\\\",\\\\n        help=\\\\\\\"\\\n    Print detailed progress information to stderr\\\\\\\"\\\\n    )\\\\n    \\\\n    args =\\\n    \\ parser.parse_args()\\\\n    \\\\n    try:\\\\n        repo_path = Path(args.path).resolve()\\\\\\\n    n        if not repo_path.exists():\\\\n            print(f\\\\\\\"Error: Path {repo_path}\\\n    \\ does not exist\\\\\\\", file=sys.stderr)\\\\n            sys.exit(1)\\\\n          \\\n    \\  \\\\n        # Get repository information\\\\n        log_verbose(f\\\\\\\"Analyzing\\\n    \\ repository: {repo_path}\\\\\\\", args.verbose)\\\\n        repo_info = get_git_info(repo_path)\\\\\\\n    n        \\\\n        # Discover files\\\\n        log_verbose(f\\\\\\\"Discovering files\\\n    \\ in: {repo_path}\\\\\\\", args.verbose)\\\\n        discovered_files = discover_files([repo_path],\\\n    \\ repo_path, [], [])\\\\n        log_verbose(f\\\\\\\"Found {len(discovered_files)}\\\n    \\ files\\\\\\\", args.verbose)\\\\n        \\\\n        # will check the file in last\\\n    \\ 7 days\\\\n        recent_files_info = {}\\\\n        if args.recent:\\\\n       \\\n    \\     seven_days_ago = datetime.now() - timedelta(days=7)\\\\n            recent_files\\\n    \\ = []\\\\n            for f in discovered_files:\\\\n                try:\\\\n    \\\n    \\                mtime = datetime.fromtimestamp(f.stat().st_mtime)\\\\n        \\\n    \\            if mtime >= seven_days_ago:\\\\n                        recent_files.append(f)\\\\\\\n    n                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)\\\n    \\     \\\\n                except Exception:\\\\n                    continue\\\\n \\\n    \\           discovered_files = recent_files\\\\n        \\\\n        # Read file contents\\\\\\\n    n        files_data = {}\\\\n        file_sizes = {}\\\\n        for file_path in\\\n    \\ discovered_files:\\\\n            try:\\\\n                relative_path_str, content,\\\n    \\ file_size = process_file(file_path, repo_path, args.verbose)\\\\n            \\\n    \\    files_data[relative_path_str] = content\\\\n                file_sizes[relative_path_str]\\\n    \\ = file_size\\\\n            except Exception:\\\\n                continue\\\\n  \\\n    \\      \\\\n        # Create tree view\\\\n        log_verbose(\\\\\\\"Generating directory\\\n    \\ tree\\\\\\\", args.verbose)\\\\n        tree_text = create_tree_view(repo_path, files_data)\\\\\\\n    n        \\\\n        # Count totals\\\\n        total_files = len(files_data)\\\\n\\\n    \\        total_lines = sum(len(content.splitlines()) for _, content in files_data.items())\\\\\\\n    n        \\\\n        # Render based on format\\\\n        log_verbose(f\\\\\\\"Rendering\\\n    \\ output in {args.format} format\\\\\\\", args.verbose)\\\\n        content = get_rendered_content(\\\\\\\n    n            args.format, str(repo_path), repo_info, tree_text,\\\\n           \\\n    \\ files_data, total_files, total_lines,\\\\n            recent_files_info if args.recent\\\n    \\ else {},\\\\n            file_sizes\\\\n        )\\\\n        \\\\n        handle_output(content,\\\n    \\ args.output)\\\\n        \\\\n    except Exception as e:\\\\n        print(f\\\\\\\"Error:\\\n    \\ {e}\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\n# this will convert age\\\n    \\ and give us the difference\\\\ndef human_readable_age(mtime: datetime) -> str:\\\\\\\n    n    delta = datetime.now() - mtime\\\\n    days = delta.days\\\\n    seconds = delta.seconds\\\\\\\n    n    if days > 0:\\\\n        return f\\\\\\\"{days} day{'s' if days != 1 else ''} ago\\\\\\\n    \\\"\\\\n    elif seconds >= 3600:\\\\n        hours = seconds // 3600\\\\n        return\\\n    \\ f\\\\\\\"{hours} hour{'s' if hours != 1 else ''} ago\\\\\\\"\\\\n    elif seconds >= 60:\\\\\\\n    n        minutes = seconds // 60\\\\n        return f\\\\\\\"{minutes} minute{'s' if\\\n    \\ minutes != 1 else ''} ago\\\\\\\"\\\\n    else:\\\\n        return \\\\\\\"just now\\\\\\\"\\\\\\\n    n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\\n\\\",\\n    \\\"src/rcpack/config_loader.py\\\"\\\n    : \\\"# src/rcpack/config_loader.py\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nTOML config loader for Repo-Contextor.\\\\\\\n    n\\\\nRules:\\\\n- Look for .repo-contextor.toml in the CURRENT directory\\\\n- If missing:\\\n    \\ ignore\\\\n- If present but invalid: print a clear error and exit(1)\\\\n- Only\\\n    \\ recognized keys are applied; unknown keys ignored\\\\n- Precedence: CLI > TOML\\\n    \\ > DEFAULTS\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nfrom __future__ import annotations\\\\nimport os,\\\n    \\ sys\\\\nfrom typing import Dict, Iterable, Any\\\\n\\\\ntry:\\\\n    import tomllib\\\\\\\n    n    _loads = tomllib.loads\\\\nexcept ModuleNotFoundError:\\\\n    try:\\\\n      \\\n    \\  import tomli\\\\n        _loads = tomli.loads\\\\n    except ModuleNotFoundError:\\\\\\\n    n        _loads = None\\\\n\\\\ndef _need_toml():\\\\n    if _loads is None:\\\\n    \\\n    \\    print(\\\\\\\"Error: TOML parser not available. Use Python 3.11+ or `pip install\\\n    \\ tomli`.\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\ndef _load_toml(dotfile:\\\n    \\ str) -> Dict[str, Any]:\\\\n    _need_toml()\\\\n    if not os.path.exists(dotfile):\\\\\\\n    n        return {}\\\\n    try:\\\\n        with open(dotfile, \\\\\\\"rb\\\\\\\") as f:\\\\\\\n    n            raw = f.read().decode(\\\\\\\"utf-8\\\\\\\", errors=\\\\\\\"strict\\\\\\\")\\\\n  \\\n    \\      data = _loads(raw)\\\\n        return data if isinstance(data, dict) else\\\n    \\ {}\\\\n    except Exception as e:\\\\n        print(f\\\\\\\"Error: failed to parse\\\n    \\ {dotfile} as TOML.\\\\\\\\n{e}\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\\\\n    ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\\\\\\n    n    ks = set(known)\\\\n    return {k: v for k, v in d.items() if k in ks}\\\\n\\\\\\\n    ndef _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str,\\\n    \\ Any], known: Iterable[str]) -> Dict[str, Any]:\\\\n    ks = set(known)\\\\n    out:\\\n    \\ Dict[str, Any] = {k: defaults.get(k) for k in ks}\\\\n    for src in (filecfg,\\\n    \\ clicfg):\\\\n        for k, v in src.items():\\\\n            if k in ks and v is\\\n    \\ not None:\\\\n                out[k] = v\\\\n    return out\\\\n\\\\ndef load_config(*,\\\n    \\ dotfile: str = \\\\\\\".repo-contextor.toml\\\\\\\", defaults: Dict[str, Any] | None\\\n    \\ = None, cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ())\\\n    \\ -> Dict[str, Any]:\\\\n    defaults = defaults or {}\\\\n    cli_cfg = cli_cfg or\\\n    \\ {}\\\\n    known = tuple(known_keys)\\\\n    filecfg = _filter_known(_load_toml(dotfile),\\\n    \\ known)\\\\n    return _merge(defaults, filecfg, cli_cfg, known)\\\\n\\\",\\n    \\\"\\\n    src/rcpack/discover.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"File discovery module for repository analysis.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom pathlib import Path\\\\nfrom typing import List\\\\nimport fnmatch\\\\\\\n    n\\\\n\\\\ndef discover_files(\\\\n    inputs: List[Path],\\\\n    root: Path,\\\\n    include_patterns:\\\n    \\ List[str],\\\\n    exclude_patterns: List[str],\\\\n) -> List[Path]:\\\\n    \\\\\\\"\\\\\\\n    \\\"\\\\\\\"Discover relevant files.\\\\n\\\\n    - inputs: list of files/dirs to scan\\\\\\\n    n    - root: common project root; patterns are matched against POSIX paths relative\\\n    \\ to root\\\\n    - include_patterns: glob patterns to include (if empty, use sensible\\\n    \\ defaults)\\\\n    - exclude_patterns: glob patterns to exclude\\\\n    Returns a\\\n    \\ list of absolute Paths to files.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    default_include_exts\\\n    \\ = {\\\\n        '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\\\\\\\n    n        '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\\\n   \\\n    \\     '.html', '.css', '.scss', '.sass', '.less', '.vue', '.svelte',\\\\n      \\\n    \\  '.md', '.txt', '.rst', '.yaml', '.yml', '.json', '.toml', '.ini',\\\\n      \\\n    \\  '.cfg', '.conf', '.xml', '.sql', '.sh', '.bash', '.zsh', '.fish',\\\\n    }\\\\\\\n    n\\\\n    always_include_names = {\\\\n        'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING',\\\n    \\ 'Makefile',\\\\n        'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\\\\\\\n    n        'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\\\\\\n    n    }\\\\n\\\\n    skip_dir_names = {\\\\n        '.git', '.svn', '.hg', '__pycache__',\\\n    \\ '.pytest_cache',\\\\n        'node_modules', '.venv', 'venv', 'env', '.env',\\\\\\\n    n        'build', 'dist', 'target', 'out', '.next', '.nuxt',\\\\n        '.idea',\\\n    \\ '.vscode', '.vs', 'coverage', '.coverage'\\\\n    }\\\\n\\\\n    def matches_any(patterns:\\\n    \\ List[str], rel_posix: str) -> bool:\\\\n        return any(fnmatch.fnmatch(rel_posix,\\\n    \\ pat) for pat in patterns)\\\\n\\\\n    def should_take(file_path: Path) -> bool:\\\\\\\n    n        rel_posix = file_path.relative_to(root).as_posix()\\\\n        if exclude_patterns\\\n    \\ and matches_any(exclude_patterns, rel_posix):\\\\n            return False\\\\n\\\n    \\        if include_patterns:\\\\n            return matches_any(include_patterns,\\\n    \\ rel_posix)\\\\n        # default include logic\\\\n        return file_path.name\\\n    \\ in always_include_names or file_path.suffix.lower() in default_include_exts\\\\\\\n    n\\\\n    discovered: list[Path] = []\\\\n    seen = set()\\\\n\\\\n    for item in inputs:\\\\\\\n    n        p = item.resolve()\\\\n        if p.is_file():\\\\n            # Skip if\\\n    \\ excluded or in skipped directory\\\\n            if any(part in skip_dir_names\\\n    \\ for part in p.parts):\\\\n                continue\\\\n            if should_take(p):\\\\\\\n    n                key = p.as_posix()\\\\n                if key not in seen:\\\\n \\\n    \\                   seen.add(key)\\\\n                    discovered.append(p)\\\\\\\n    n        elif p.is_dir():\\\\n            for child in p.rglob('*'):\\\\n        \\\n    \\        if not child.is_file():\\\\n                    continue\\\\n           \\\n    \\     if any(part in skip_dir_names for part in child.parts):\\\\n             \\\n    \\       continue\\\\n                if should_take(child):\\\\n                 \\\n    \\   key = child.resolve().as_posix()\\\\n                    if key not in seen:\\\\\\\n    n                        seen.add(key)\\\\n                        discovered.append(child.resolve())\\\\\\\n    n\\\\n    return sorted(discovered)\\\",\\n    \\\"src/rcpack/gitinfo.py\\\": \\\"from __future__\\\n    \\ import annotations\\\\n\\\\nimport subprocess\\\\nfrom pathlib import Path\\\\nfrom\\\n    \\ typing import Dict, Any\\\\n\\\\n\\\\ndef _git(cmd: list[str], cwd: Path) -> str:\\\\\\\n    n    # Validate git commands to prevent injection\\\\n    allowed_commands = {\\\\\\\n    n        \\\\\\\"rev-parse\\\\\\\", \\\\\\\"show\\\\\\\", \\\\\\\"log\\\\\\\", \\\\\\\"status\\\\\\\", \\\\\\\"branch\\\\\\\n    \\\", \\\\\\\"config\\\\\\\"\\\\n    }\\\\n    if not cmd or cmd[0] not in allowed_commands:\\\\\\\n    n        raise ValueError(f\\\\\\\"Git command not allowed: {cmd[0] if cmd else 'empty'}\\\\\\\n    \\\")\\\\n    \\\\n    out = subprocess.check_output([\\\\\\\"git\\\\\\\", *cmd], cwd=str(cwd),\\\n    \\ timeout=30)\\\\n    return out.decode(\\\\\\\"utf-8\\\\\\\", errors=\\\\\\\"replace\\\\\\\").strip()\\\\\\\n    n\\\\n\\\\ndef is_git_repo(path: Path) -> bool:\\\\n    try:\\\\n        flag = _git([\\\\\\\n    \\\"rev-parse\\\\\\\", \\\\\\\"--is-inside-work-tree\\\\\\\"], cwd=path)\\\\n        return flag\\\n    \\ == \\\\\\\"true\\\\\\\"\\\\n    except Exception:\\\\n        return False\\\\n\\\\n\\\\ndef get_git_info(path:\\\n    \\ Path) -> Dict[str, Any]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Return info for the current\\\n    \\ HEAD of a repo rooted at `path`.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        commit\\\n    \\ = _git([\\\\\\\"rev-parse\\\\\\\", \\\\\\\"HEAD\\\\\\\"], cwd=path)\\\\n        branch = _git([\\\\\\\n    \\\"rev-parse\\\\\\\", \\\\\\\"--abbrev-ref\\\\\\\", \\\\\\\"HEAD\\\\\\\"], cwd=path)\\\\n        author\\\n    \\ = _git([\\\\\\\"show\\\\\\\", \\\\\\\"-s\\\\\\\", \\\\\\\"--format=%an <%ae>\\\\\\\"], cwd=path)\\\\n\\\n    \\        date = _git([\\\\\\\"show\\\\\\\", \\\\\\\"-s\\\\\\\", \\\\\\\"--date=local\\\\\\\", \\\\\\\"--format=%ad\\\\\\\n    \\\"], cwd=path)\\\\n        return {\\\\n            \\\\\\\"is_repo\\\\\\\": True,\\\\n    \\\n    \\        \\\\\\\"commit\\\\\\\": commit,\\\\n            \\\\\\\"branch\\\\\\\": branch,\\\\n    \\\n    \\        \\\\\\\"author\\\\\\\": author,\\\\n            \\\\\\\"date\\\\\\\": date,\\\\n        \\\n    \\    \\\\\\\"note\\\\\\\": None,\\\\n        }\\\\n    except Exception:\\\\n        # treat\\\n    \\ as not a repo if anything fails\\\\n        return {\\\\n            \\\\\\\"is_repo\\\\\\\n    \\\": False,\\\\n            \\\\\\\"commit\\\\\\\": None,\\\\n            \\\\\\\"branch\\\\\\\": None,\\\\\\\n    n            \\\\\\\"author\\\\\\\": None,\\\\n            \\\\\\\"date\\\\\\\": None,\\\\n      \\\n    \\      \\\\\\\"note\\\\\\\": \\\\\\\"Not a git repository\\\\\\\",\\\\n        }\\\\n\\\",\\n    \\\"src/rcpack/io_utils.py\\\"\\\n    : \\\"\\\\\\\"\\\\\\\"\\\\\\\"I/O utilities for file operations.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom pathlib\\\n    \\ import Path\\\\nfrom typing import Tuple\\\\n\\\\n\\\\ndef write_output(output_path:\\\n    \\ str, content: str) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Write content to output file.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n    output_file = Path(output_path)\\\\n    \\\\n    # Create parent\\\n    \\ directories if they don't exist\\\\n    output_file.parent.mkdir(parents=True,\\\n    \\ exist_ok=True)\\\\n    \\\\n    # Write content\\\\n    with open(output_file, 'w',\\\n    \\ encoding='utf-8') as f:\\\\n        f.write(content)\\\\n\\\\n\\\\ndef is_binary_file(path:\\\n    \\ Path, sniff_bytes: int = 2048) -> bool:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Heuristically determine\\\n    \\ if a file is binary by scanning for NUL bytes.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n   \\\n    \\     with open(path, 'rb') as fb:\\\\n            chunk = fb.read(sniff_bytes)\\\\\\\n    n        if b\\\\\\\"\\\\\\\\x00\\\\\\\" in chunk:\\\\n            return True\\\\n        # If\\\n    \\ the chunk has a lot of non-text bytes, consider it binary\\\\n        text_byte_count\\\n    \\ = sum(32 <= b <= 126 or b in (9, 10, 13) for b in chunk)\\\\n        return (len(chunk)\\\n    \\ - text_byte_count) > max(1, len(chunk) // 3)\\\\n    except Exception:\\\\n    \\\n    \\    # If we cannot read, treat as binary to avoid further processing\\\\n     \\\n    \\   return True\\\\n\\\\n\\\\ndef read_text_safely(path: Path, max_bytes: int = 16_384)\\\n    \\ -> Tuple[str, str, bool]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Read a text file safely with size\\\n    \\ limit and encoding fallbacks.\\\\n\\\\n    Returns (content, encoding_used, truncated).\\\\\\\n    n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    truncated = False\\\\n    raw: bytes\\\\n    with open(path,\\\n    \\ 'rb') as fb:\\\\n        raw = fb.read(max_bytes + 1)\\\\n    if len(raw) > max_bytes:\\\\\\\n    n        truncated = True\\\\n        raw = raw[:max_bytes]\\\\n\\\\n    for enc in\\\n    \\ (\\\\\\\"utf-8\\\\\\\", \\\\\\\"utf-16\\\\\\\", \\\\\\\"utf-16-le\\\\\\\", \\\\\\\"utf-16-be\\\\\\\", \\\\\\\"latin-1\\\\\\\n    \\\"):\\\\n        try:\\\\n            text = raw.decode(enc)\\\\n            return\\\n    \\ text, enc, truncated\\\\n        except Exception:\\\\n            continue\\\\n \\\n    \\   # Fallback: replace errors with utf-8\\\\n    text = raw.decode(\\\\\\\"utf-8\\\\\\\"\\\n    , errors=\\\\\\\"replace\\\\\\\")\\\\n    return text, \\\\\\\"utf-8\\\\\\\", truncated\\\",\\n   \\\n    \\ \\\"src/rcpack/packager.py\\\": \\\"from __future__ import annotations\\\\n\\\\nimport\\\n    \\ sys\\\\nfrom pathlib import Path\\\\nfrom typing import Iterable, Tuple\\\\n\\\\nfrom\\\n    \\ rcpack.discover import discover_files\\\\nfrom rcpack.gitinfo import get_git_info,\\\n    \\ is_git_repo\\\\nfrom rcpack.io_utils import read_text_safely, is_binary_file\\\\\\\n    nfrom rcpack.renderer import markdown as md_renderer\\\\nfrom rcpack.renderer.jsonyaml\\\n    \\ import render_json, render_yaml\\\\nfrom rcpack.treeview import render_tree\\\\\\\n    nfrom rcpack.utils import get_language_from_extension\\\\n\\\\n\\\\ndef _find_root(inputs:\\\n    \\ list[str]) -> Path:\\\\n    paths = [Path(p) for p in inputs]\\\\n    if len(paths)\\\n    \\ == 1 and Path(paths[0]).is_dir():\\\\n        return paths[0].resolve()\\\\n   \\\n    \\ parents = [p if p.is_dir() else p.parent for p in paths]\\\\n    root = Path(*Path.commonpath([str(p.resolve())\\\n    \\ for p in parents]).split(\\\\\\\"/\\\\\\\"))\\\\n    return root.resolve()\\\\n\\\\n\\\\ndef\\\n    \\ build_package(\\\\n    inputs: list[str],\\\\n    include_patterns: list[str] |\\\n    \\ None,\\\\n    exclude_patterns: list[str] | None,\\\\n    max_file_bytes: int,\\\\\\\n    n    fmt: str = \\\\\\\"markdown\\\\\\\",\\\\n) -> Tuple[str, dict]:\\\\n    root = _find_root(inputs)\\\\\\\n    n    root_abs = root.resolve()\\\\n\\\\n    repo_info = (\\\\n        get_git_info(root_abs)\\\n    \\ if is_git_repo(root_abs) else {\\\\n            \\\\\\\"is_repo\\\\\\\": False,\\\\n   \\\n    \\         \\\\\\\"commit\\\\\\\": None,\\\\n            \\\\\\\"branch\\\\\\\": None,\\\\n       \\\n    \\     \\\\\\\"author\\\\\\\": None,\\\\n            \\\\\\\"date\\\\\\\": None,\\\\n            \\\\\\\n    \\\"note\\\\\\\": \\\\\\\"Not a git repository\\\\\\\",\\\\n        }\\\\n    )\\\\n\\\\n    files =\\\n    \\ discover_files(\\\\n        inputs=[Path(p) for p in inputs],\\\\n        root=root_abs,\\\\\\\n    n        include_patterns=include_patterns or [],\\\\n        exclude_patterns=exclude_patterns\\\n    \\ or [],\\\\n    )\\\\n    rel_files = [f.relative_to(root_abs) for f in files]\\\\\\\n    n\\\\n    project_tree = render_tree([p.as_posix() for p in rel_files])\\\\n\\\\n  \\\n    \\  file_sections: list[dict] = []\\\\n    total_lines = 0\\\\n    total_chars = 0\\\\\\\n    n\\\\n    for f in files:\\\\n        rel = f.relative_to(root_abs).as_posix()\\\\n\\\n    \\        try:\\\\n            if is_binary_file(f):\\\\n                content =\\\n    \\ f\\\\\\\"[binary file skipped: {f.name}, {f.stat().st_size} bytes]\\\\\\\"\\\\n      \\\n    \\          file_sections.append({\\\\n                    \\\\\\\"path\\\\\\\": rel,\\\\n\\\n    \\                    \\\\\\\"language\\\\\\\": get_language_from_extension(f.suffix),\\\\\\\n    n                    \\\\\\\"content\\\\\\\": content,\\\\n                    \\\\\\\"is_truncated\\\\\\\n    \\\": False,\\\\n                })\\\\n                total_chars += len(content)\\\\\\\n    n                continue\\\\n\\\\n            content, used_encoding, truncated =\\\n    \\ read_text_safely(f, max_bytes=max_file_bytes)\\\\n            total_lines += content.count(\\\\\\\n    \\\"\\\\\\\\n\\\\\\\") + (1 if content and not content.endswith(\\\\\\\"\\\\\\\\n\\\\\\\") else 0)\\\\\\\n    n            total_chars += len(content)\\\\n\\\\n            if truncated:\\\\n   \\\n    \\             note = f\\\\\\\"\\\\\\\\n\\\\\\\\n[... TRUNCATED to first {max_file_bytes} bytes\\\n    \\ ...]\\\\\\\"\\\\n                content = content + note\\\\n                total_chars\\\n    \\ += len(note)\\\\n\\\\n            file_sections.append({\\\\n                \\\\\\\"\\\n    path\\\\\\\": rel,\\\\n                \\\\\\\"language\\\\\\\": get_language_from_extension(f.suffix),\\\\\\\n    n                \\\\\\\"content\\\\\\\": content,\\\\n                \\\\\\\"is_truncated\\\\\\\n    \\\": truncated,\\\\n            })\\\\n        except Exception as exc:\\\\n        \\\n    \\    print(f\\\\\\\"[rcpack] error reading {rel}: {exc}\\\\\\\", file=sys.stderr)\\\\n \\\n    \\           continue\\\\n\\\\n    # render in chosen format\\\\n    if fmt == \\\\\\\"markdown\\\\\\\n    \\\":\\\\n        out_text = md_renderer.render_markdown(\\\\n            root=str(root_abs),\\\\\\\n    n            repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n   \\\n    \\         files=file_sections,\\\\n            total_files=len(file_sections),\\\\\\\n    n            total_lines=total_lines,\\\\n        )\\\\n    elif fmt == \\\\\\\"json\\\\\\\n    \\\":\\\\n        out_text = render_json(\\\\n            root=str(root_abs),\\\\n   \\\n    \\         repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n      \\\n    \\      files=file_sections,\\\\n            total_files=len(file_sections),\\\\n \\\n    \\           total_lines=total_lines,\\\\n        )\\\\n    elif fmt == \\\\\\\"yaml\\\\\\\"\\\n    :\\\\n        out_text = render_yaml(\\\\n            root=str(root_abs),\\\\n     \\\n    \\       repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n        \\\n    \\    files=file_sections,\\\\n            total_files=len(file_sections),\\\\n   \\\n    \\         total_lines=total_lines,\\\\n        )\\\\n    else:\\\\n        raise ValueError(f\\\\\\\n    \\\"Unsupported format: {fmt}\\\\\\\")\\\\n\\\\n    stats = {\\\\\\\"files\\\\\\\": len(file_sections),\\\n    \\ \\\\\\\"lines\\\\\\\": total_lines, \\\\\\\"chars\\\\\\\": total_chars}\\\\n    return out_text,\\\n    \\ stats\\\\n\\\",\\n    \\\"src/rcpack/renderer/jsonyaml.py\\\": \\\"from __future__ import\\\n    \\ annotations\\\\nimport json\\\\nfrom ..utils import build_repository_data\\\\n\\\\ntry:\\\\\\\n    n    import yaml\\\\nexcept ImportError:\\\\n    yaml = None\\\\n\\\\n\\\\ndef render_json(root,\\\n    \\ repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None)\\\n    \\ -> str:\\\\n    data = build_repository_data(\\\\n        root=root,\\\\n        repo_info=repo_info,\\\\\\\n    n        tree_text=tree_text,\\\\n        files=files,\\\\n        total_files=total_files,\\\\\\\n    n        total_lines=total_lines,\\\\n        recent_files=recent_files,\\\\n    \\\n    \\    file_sizes=file_sizes\\\\n    )\\\\n    return json.dumps(data, indent=2, ensure_ascii=False)\\\\\\\n    n\\\\n\\\\ndef render_yaml(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None,\\\n    \\ file_sizes=None) -> str:\\\\n    if yaml is None:\\\\n        raise RuntimeError(\\\\\\\n    \\\"PyYAML not installed; run `pip install pyyaml`\\\\\\\")\\\\n    data = build_repository_data(\\\\\\\n    n        root=root,\\\\n        repo_info=repo_info,\\\\n        tree_text=tree_text,\\\\\\\n    n        files=files,\\\\n        total_files=total_files,\\\\n        total_lines=total_lines,\\\\\\\n    n        recent_files=recent_files,\\\\n        file_sizes=file_sizes\\\\n    )\\\\\\\n    n    return yaml.safe_dump(data, sort_keys=False, allow_unicode=True)\\\\n\\\",\\n\\\n    \\    \\\"src/rcpack/renderer/markdown.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Markdown renderer for\\\n    \\ repository context.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom typing import Dict, Any\\\\nfrom ..utils\\\n    \\ import get_language_from_extension\\\\n\\\\n\\\\ndef render_markdown(root: str, repo_info:\\\n    \\ Dict[str, Any], tree_text: str, \\\\n                   files: Dict[str, str],\\\n    \\ total_files: int, total_lines: int, recent_files=None, file_sizes=None) -> str:\\\\\\\n    n    \\\\\\\"\\\\\\\"\\\\\\\"Render repository context as markdown.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n\\\n    \\    lines = []\\\\n    \\\\n    # Header\\\\n    lines.append(f\\\\\\\"# Repository Context:\\\n    \\ {root}\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Repository info\\\\n \\\n    \\   if repo_info.get(\\\\\\\"is_repo\\\\\\\"):\\\\n        lines.append(\\\\\\\"## Git Repository\\\n    \\ Information\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Branch**: {repo_info.get('branch',\\\n    \\ 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Commit**: {repo_info.get('commit',\\\n    \\ 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Author**: {repo_info.get('author',\\\n    \\ 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Date**: {repo_info.get('date',\\\n    \\ 'N/A')}\\\\\\\")\\\\n    else:\\\\n        lines.append(\\\\\\\"## Repository Information\\\\\\\n    \\\")\\\\n        lines.append(f\\\\\\\"- **Note**: {repo_info.get('note', 'Not a git\\\n    \\ repository')}\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Summary\\\\n  \\\n    \\  lines.append(\\\\\\\"## Summary\\\\\\\")\\\\n    lines.append(f\\\\\\\"- **Total Files**:\\\n    \\ {total_files}\\\\\\\")\\\\n    lines.append(f\\\\\\\"- **Total Lines**: {total_lines}\\\\\\\n    \\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Directory structure\\\\n    lines.append(\\\\\\\n    \\\"## Directory Structure\\\\\\\")\\\\n    lines.append(\\\\\\\"```\\\\\\\")\\\\n    lines.append(tree_text)\\\\\\\n    n    lines.append(\\\\\\\"```\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n\\\\n    # will produce\\\n    \\ recent files \\\\n    # Recent files (fixed)\\\\n    if recent_files:\\\\n       \\\n    \\ lines.append(\\\\\\\"## Recent Changes\\\\\\\")\\\\n        for file, age in recent_files.items():\\\\\\\n    n            lines.append(f\\\\\\\"- {file} (modified {age})\\\\\\\")\\\\n        lines.append(\\\\\\\n    \\\"\\\\\\\")\\\\n    \\\\n    # File contents\\\\n    lines.append(\\\\\\\"## File Contents\\\\\\\n    \\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    for file_path, content in sorted(files.items()):\\\\\\\n    n        if file_sizes and file_path in file_sizes:\\\\n            size_bytes =\\\n    \\ file_sizes[file_path]\\\\n            lines.append(f\\\\\\\"### {file_path} ({size_bytes}\\\n    \\ bytes)\\\\\\\")\\\\n        else:\\\\n            lines.append(f\\\\\\\"### {file_path}\\\\\\\n    \\\")\\\\n        lines.append(\\\\\\\"\\\\\\\")\\\\n        \\\\n        # Detect language for\\\n    \\ syntax highlighting\\\\n        language = get_language_from_extension(file_path)\\\\\\\n    n        \\\\n        lines.append(f\\\\\\\"```{language}\\\\\\\")\\\\n        lines.append(content)\\\\\\\n    n        lines.append(\\\\\\\"```\\\\\\\")\\\\n        lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n\\\n    \\    return \\\\\\\"\\\\\\\\n\\\\\\\".join(lines)\\\\n\\\",\\n    \\\"src/rcpack/treeview.py\\\": \\\"\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Tree view generation for repository structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom\\\n    \\ pathlib import Path\\\\nfrom typing import Dict, List\\\\n\\\\n\\\\ndef create_tree_view(repo_path:\\\n    \\ Path, files_data: Dict[str, str]) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create a tree view\\\n    \\ of the repository structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    paths = list(files_data.keys())\\\\\\\n    n    return render_tree(paths)\\\\n\\\\n\\\\ndef render_tree(paths: List[str]) -> str:\\\\\\\n    n    \\\\\\\"\\\\\\\"\\\\\\\"Render a tree view from a list of relative POSIX paths.\\\\\\\"\\\\\\\n    \\\"\\\\\\\"\\\\n    tree_structure: dict = {}\\\\n\\\\n    for p in paths:\\\\n        parts\\\n    \\ = Path(p).parts\\\\n        current = tree_structure\\\\n        for part in parts[:-1]:\\\\\\\n    n            if part not in current:\\\\n                current[part] = {}\\\\n \\\n    \\           current = current[part]\\\\n        if parts:\\\\n            current[parts[-1]]\\\n    \\ = None\\\\n\\\\n    def _render(structure: dict, prefix: str = \\\\\\\"\\\\\\\") -> str:\\\\\\\n    n        lines = []\\\\n        items = sorted(structure.items(), key=lambda x:\\\n    \\ (x[1] is None, x[0]))\\\\n        for i, (name, subtree) in enumerate(items):\\\\\\\n    n            is_last = i == len(items) - 1\\\\n            lines.append(f\\\\\\\"{prefix}{'└──\\\n    \\ ' if is_last else '├── '}{name}\\\\\\\")\\\\n            if subtree is not None:\\\\\\\n    n                extension = (\\\\\\\"    \\\\\\\" if is_last else \\\\\\\"│   \\\\\\\")\\\\n  \\\n    \\              lines.append(_render(subtree, prefix + extension))\\\\n        return\\\n    \\ \\\\\\\"\\\\\\\\n\\\\\\\".join(filter(None, lines))\\\\n\\\\n    if not tree_structure:\\\\n \\\n    \\       return \\\\\\\"No files found\\\\\\\"\\\\n    return _render(tree_structure)\\\",\\n\\\n    \\    \\\"src/rcpack/utils.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Utility functions shared across the\\\n    \\ rcpack package.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom typing import Dict, Any, Optional\\\\n\\\\\\\n    n\\\\ndef get_language_from_extension(file_path_or_ext: str) -> str:\\\\n    \\\\\\\"\\\\\\\n    \\\"\\\\\\\"Get the language identifier for syntax highlighting from a file path or\\\n    \\ extension.\\\\n    \\\\n    Args:\\\\n        file_path_or_ext: Either a file path\\\n    \\ (e.g., 'src/main.py') or extension (e.g., '.py' or 'py')\\\\n    \\\\n    Returns:\\\\\\\n    n        Language identifier for syntax highlighting (e.g., 'python', 'javascript')\\\\\\\n    n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    # Extract extension from file path if needed\\\\n    if\\\n    \\ '.' in file_path_or_ext and not file_path_or_ext.startswith('.'):\\\\n       \\\n    \\ # It's a file path, extract the extension\\\\n        ext = file_path_or_ext.split('.')[-1].lower()\\\\\\\n    n    else:\\\\n        # It's already an extension, clean it up\\\\n        ext =\\\n    \\ file_path_or_ext.lower().lstrip(\\\\\\\".\\\\\\\")\\\\n    \\\\n    # Comprehensive language\\\n    \\ mapping combining both existing mappings\\\\n    language_map = {\\\\n        'py':\\\n    \\ 'python', 'js': 'javascript', 'ts': 'typescript',\\\\n        'jsx': 'javascript',\\\n    \\ 'tsx': 'typescript',\\\\n        'java': 'java', 'cpp': 'cpp', 'c': 'c', 'h':\\\n    \\ 'c',\\\\n        'cs': 'csharp', 'php': 'php', 'rb': 'ruby',\\\\n        'go': 'go',\\\n    \\ 'rs': 'rust', 'swift': 'swift', 'kt': 'kotlin',\\\\n        'html': 'html', 'css':\\\n    \\ 'css', 'scss': 'scss', 'sass': 'sass',\\\\n        'json': 'json', 'yaml': 'yaml',\\\n    \\ 'yml': 'yaml',\\\\n        'toml': 'toml', 'xml': 'xml', 'sql': 'sql', 'sh': 'bash',\\\\\\\n    n        'bash': 'bash', 'zsh': 'bash', 'fish': 'fish',\\\\n        'md': 'markdown',\\\n    \\ 'txt': 'text',\\\\n        'dockerfile': 'dockerfile', 'makefile': 'makefile'\\\\\\\n    n    }\\\\n    \\\\n    return language_map.get(ext, '')\\\\n\\\\n\\\\ndef build_repository_data(\\\\\\\n    n    root: str,\\\\n    repo_info: Dict[str, Any],\\\\n    tree_text: str,\\\\n    files:\\\n    \\ Dict[str, str],\\\\n    total_files: int,\\\\n    total_lines: int,\\\\n    recent_files:\\\n    \\ Optional[Dict[str, str]] = None,\\\\n    file_sizes: Optional[Dict[str, str]]\\\n    \\ = None\\\\n) -> Dict[str, Any]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Build the standard repository\\\n    \\ data structure used by all renderers.\\\\n    \\\\n    Args:\\\\n        root: Repository\\\n    \\ root path\\\\n        repo_info: Git repository information\\\\n        tree_text:\\\n    \\ Directory tree text representation\\\\n        files: Dictionary of file paths\\\n    \\ to content\\\\n        total_files: Total number of files\\\\n        total_lines:\\\n    \\ Total number of lines\\\\n        recent_files: Optional dict of recently modified\\\n    \\ files\\\\n        file_sizes: Optional dict of file sizes\\\\n        \\\\n    Returns:\\\\\\\n    n        Standardized data dictionary for rendering\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return\\\n    \\ {\\\\n        \\\\\\\"root\\\\\\\": root,\\\\n        \\\\\\\"repo_info\\\\\\\": repo_info,\\\\n \\\n    \\       \\\\\\\"structure\\\\\\\": tree_text,\\\\n        \\\\\\\"recent_changes\\\\\\\": recent_files\\\n    \\ or {},\\\\n        \\\\\\\"files\\\\\\\": files,\\\\n        \\\\\\\"file_sizes\\\\\\\": file_sizes\\\n    \\ or {},\\\\n        \\\\\\\"summary\\\\\\\": {\\\\\\\"total_files\\\\\\\": total_files, \\\\\\\"total_lines\\\\\\\n    \\\": total_lines},\\\\n    }\\\\n\\\\n\\\\ndef calculate_total_lines(content_dict: Dict[str,\\\n    \\ str]) -> int:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Calculate the total number of lines from a dictionary\\\n    \\ of file contents.\\\\n    \\\\n    Args:\\\\n        content_dict: Dictionary mapping\\\n    \\ file paths to their content\\\\n        \\\\n    Returns:\\\\n        Total number\\\n    \\ of lines across all files\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return sum(len(content.splitlines())\\\n    \\ for content in content_dict.values())\\\\n\\\\n\\\\ndef calculate_total_characters(content_dict:\\\n    \\ Dict[str, str]) -> int:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Calculate the total number of characters\\\n    \\ from a dictionary of file contents.\\\\n    \\\\n    Args:\\\\n        content_dict:\\\n    \\ Dictionary mapping file paths to their content\\\\n        \\\\n    Returns:\\\\n\\\n    \\        Total number of characters across all files\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n   \\\n    \\ return sum(len(content) for content in content_dict.values())\\\",\\n    \\\"test-output.json\\\"\\\n    : \\\"{\\\\n  \\\\\\\"root\\\\\\\": \\\\\\\"/Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\\\\\\\n    \\\",\\\\n  \\\\\\\"repo_info\\\\\\\": {\\\\n    \\\\\\\"is_repo\\\\\\\": true,\\\\n    \\\\\\\"commit\\\\\\\"\\\n    : \\\\\\\"682153b169db66d3a72e9cabdd1f3448a3b2986d\\\\\\\",\\\\n    \\\\\\\"branch\\\\\\\": \\\\\\\"\\\n    refactoring\\\\\\\",\\\\n    \\\\\\\"author\\\\\\\": \\\\\\\"Abhinav <abhinavbhardwaj2002@gmail.com>\\\\\\\n    \\\",\\\\n    \\\\\\\"date\\\\\\\": \\\\\\\"Fri Oct 3 18:45:48 2025\\\\\\\",\\\\n    \\\\\\\"note\\\\\\\": null\\\\\\\n    n  },\\\\n  \\\\\\\"structure\\\\\\\": \\\\\\\"├── src\\\\\\\\n│   └── rcpack\\\\\\\\n│       ├── renderer\\\\\\\n    \\\\n│       │   ├── jsonyaml.py\\\\\\\\n│       │   └── markdown.py\\\\\\\\n│       ├──\\\n    \\ __init__.py\\\\\\\\n│       ├── __main__.py\\\\\\\\n│       ├── cli.py\\\\\\\\n│       ├──\\\n    \\ config_loader.py\\\\\\\\n│       ├── discover.py\\\\\\\\n│       ├── gitinfo.py\\\\\\\\\\\n    n│       ├── io_utils.py\\\\\\\\n│       ├── packager.py\\\\\\\\n│       └── treeview.py\\\\\\\n    \\\\n├── LICENSE\\\\\\\\n├── README.md\\\\\\\\n└── pyproject.toml\\\\\\\",\\\\n  \\\\\\\"recent_changes\\\\\\\n    \\\": [],\\\\n  \\\\\\\"files\\\\\\\": {\\\\n    \\\\\\\"LICENSE\\\\\\\": \\\\\\\"MIT License\\\\\\\\n\\\\\\\\nCopyright\\\n    \\ (c) 2025 Abhinav\\\\\\\\n\\\\\\\\nPermission is hereby granted, free of charge, to any\\\n    \\ person obtaining a copy\\\\\\\\nof this software and associated documentation files\\\n    \\ (the \\\\\\\\\\\\\\\"Software\\\\\\\\\\\\\\\"), to deal\\\\\\\\nin the Software without restriction,\\\n    \\ including without limitation the rights\\\\\\\\nto use, copy, modify, merge, publish,\\\n    \\ distribute, sublicense, and/or sell\\\\\\\\ncopies of the Software, and to permit\\\n    \\ persons to whom the Software is\\\\\\\\nfurnished to do so, subject to the following\\\n    \\ conditions:\\\\\\\\n\\\\\\\\nThe above copyright notice and this permission notice shall\\\n    \\ be included in all\\\\\\\\ncopies or substantial portions of the Software.\\\\\\\\n\\\\\\\n    \\\\nTHE SOFTWARE IS PROVIDED \\\\\\\\\\\\\\\"AS IS\\\\\\\\\\\\\\\", WITHOUT WARRANTY OF ANY KIND,\\\n    \\ EXPRESS OR\\\\\\\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\\\\n    \\\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\\\\n    \\\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\\\\\\\\n    nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\\\\n    \\\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\\\\n    \\\\nSOFTWARE.\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"README.md\\\\\\\": \\\\\\\"# Repo-Contextor\\\\\\\\n\\\\\\\\\\\n    n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\\\\\\n    \\\\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\\\\\\n    \\\\n\\\\\\\\nA powerful Repository Context Packager CLI tool that analyzes local git\\\n    \\ repositories and creates comprehensive text files containing repository content\\\n    \\ optimized for sharing with Large Language Models (LLMs).\\\\\\\\n\\\\\\\\n## Overview\\\\\\\n    \\\\n\\\\\\\\nWhen developers want to get help from ChatGPT, Claude, or other LLMs about\\\n    \\ their code, they often struggle with how to share their codebase effectively.\\\n    \\ Common problems include:\\\\\\\\n\\\\\\\\n- **Lost Context**: Copy-pasting individual\\\n    \\ files loses important project structure and relationships\\\\\\\\n- **Missing Dependencies**:\\\n    \\ LLMs can't see how files connect or what libraries are used\\\\\\\\n- **Incomplete\\\n    \\ Picture**: Hard to convey the overall architecture and organization\\\\\\\\n- **Manual\\\n    \\ Work**: Time-consuming to gather and format relevant code\\\\\\\\n\\\\\\\\n**Repo-Contextor**\\\n    \\ solves this by automatically collecting and formatting repository content into\\\n    \\ a single, well-structured text file that provides rich context to LLMs, enabling\\\n    \\ them to give much better assistance with your code.\\\\\\\\n\\\\\\\\n## Features\\\\\\\\\\\n    n\\\\\\\\n- **Git Integration**: Extracts commit SHA, branch, author, and date information\\\\\\\n    \\\\n- **Project Structure**: Generates a clear directory tree visualization\\\\\\\\\\\n    n- **File Content Packaging**: Includes file contents with syntax highlighting\\\\\\\n    \\\\n- **Smart File Discovery**: Recursively scans directories with intelligent\\\n    \\ filtering\\\\\\\\n- **Binary File Detection**: Automatically skips binary files\\\\\\\n    \\\\n- **Error Handling**: Gracefully handles permission errors and provides helpful\\\n    \\ messages\\\\\\\\n- **Multiple Output Formats**: Supports Markdown, JSON, and YAML\\\n    \\ formats\\\\\\\\n- **Flexible Output**: Write to stdout or save to a file\\\\\\\\n- **Recent\\\n    \\ Changes Filter**: Give the files which are updated in last 7days with the time\\\n    \\ when it was recently modified.\\\\\\\\n\\\\\\\\n## Installation\\\\\\\\n\\\\\\\\n### Prerequisites\\\\\\\n    \\\\n\\\\\\\\n- Python 3.9 or higher\\\\\\\\n- Git (for git repository analysis)\\\\\\\\n\\\\\\\\\\\n    n### For End Users\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Clone and install\\\\\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    \\\\ncd Repo-Contextor\\\\\\\\npip install -e .\\\\\\\\n```\\\\\\\\n\\\\\\\\n### For Contributors\\\n    \\ & Local Development\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Clone the repository\\\\\\\\ngit clone\\\n    \\ https://github.com/yourusername/Repo-Contextor.git\\\\\\\\ncd Repo-Contextor\\\\\\\\\\\n    n\\\\\\\\n# Create virtual environment\\\\\\\\npython -m venv .venv\\\\\\\\nsource .venv/bin/activate\\\n    \\  # On Windows: .venv\\\\\\\\\\\\\\\\Scripts\\\\\\\\\\\\\\\\activate\\\\\\\\n\\\\\\\\n# Install in development\\\n    \\ mode\\\\\\\\npip install -e .\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Usage\\\\\\\\n\\\\\\\\n### Basic Examples\\\\\\\n    \\\\n\\\\\\\\n```bash\\\\\\\\n# Package current directory to terminal\\\\\\\\nrepo-contextor\\\n    \\ .\\\\\\\\n\\\\\\\\n# Package a specific directory\\\\\\\\nrepo-contextor /path/to/your/project\\\\\\\n    \\\\n\\\\\\\\n# Save output to a file\\\\\\\\nrepo-contextor . -o my-project-context.md\\\\\\\n    \\\\n\\\\\\\\n# Generate JSON format\\\\\\\\nrepo-contextor . -f json -o context.json\\\\\\\\\\\n    n\\\\\\\\n# Generate YAML format\\\\\\\\nrepo-contextor . -f yaml -o context.yaml\\\\\\\\\\\n    n\\\\\\\\n# Include only files modified in the last 7 days\\\\\\\\nrepo-contextor . --recent\\\\\\\n    \\\\n\\\\\\\\n# Combine with output file\\\\\\\\nrepo-contextor . --recent -o recent-changes.md\\\\\\\n    \\\\n```\\\\\\\\n\\\\\\\\n### Command Line Options\\\\\\\\n\\\\\\\\n| Option | Short | Description\\\n    \\ | Example |\\\\\\\\n|--------|-------|-------------|---------|\\\\\\\\n| `path` | -\\\n    \\ | Repository path to analyze (default: current directory) | `repo-contextor\\\n    \\ /path/to/project` |\\\\\\\\n| `--output` | `-o` | Output file path (default: stdout)\\\n    \\ | `-o context.md` |\\\\\\\\n| `--format` | `-f` | Output format: text, json, yaml\\\n    \\ (default: text) | `-f json` |\\\\\\\\n| `--help` | `-h` | Show help message | `-h`\\\n    \\ |\\\\\\\\n| `--recent`  | `-r`  | Include only files modified in the last 7 days\\\n    \\    | `repo-contextor . -r -o recent.md` |\\\\\\\\n\\\\\\\\n### Advanced Examples\\\\\\\\\\\n    n\\\\\\\\n```bash\\\\\\\\n# Analyze different repository\\\\\\\\nrepo-contextor /path/to/other/project\\\n    \\ -o other-project.md\\\\\\\\n\\\\\\\\n# Generate JSON for API consumption\\\\\\\\nrepo-contextor\\\n    \\ . -f json -o api-context.json\\\\\\\\n\\\\\\\\n# Create YAML configuration\\\\\\\\nrepo-contextor\\\n    \\ . -f yaml -o project-config.yaml\\\\\\\\n\\\\\\\\n# Generate files which are changed\\\n    \\ recently in 7 days\\\\\\\\nrepo-contextor . -r --output recent-changes.txt\\\\\\\\n\\\\\\\n    \\\\n```\\\\\\\\n## Configuration via TOML\\\\\\\\n\\\\\\\\nRepo-Contextor supports configuration\\\n    \\ through a `.repo-contextor.toml` file in the current working directory.  \\\\\\\\\\\n    nThis file allows you to avoid typing the same CLI arguments every time.\\\\\\\\n\\\\\\\n    \\\\nExample `.repo-contextor.toml`:\\\\\\\\n\\\\\\\\n```toml\\\\\\\\n# Output file to write\\\n    \\ results\\\\\\\\noutput = \\\\\\\\\\\\\\\"context.yaml\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Output format:\\\n    \\ text, json, or yaml\\\\\\\\nformat = \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Limit to files\\\n    \\ modified in the last 7 days\\\\\\\\nrecent = true\\\\\\\\n\\\\\\\\n# Repository path to\\\n    \\ analyze (default = current directory)\\\\\\\\npath = \\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\n    \\\\n### Rules\\\\\\\\n- If the `.repo-contextor.toml` file is **missing**, the tool\\\n    \\ falls back to defaults.  \\\\\\\\n- If the file is **present but invalid TOML**,\\\n    \\ the tool prints a clear error message and exits with status code 1.  \\\\\\\\n-\\\n    \\ **Unknown keys** in the TOML file are ignored (safe for future extensions).\\\n    \\  \\\\\\\\n- **Precedence** of settings is:\\\\\\\\n  1. Command-line arguments (highest\\\n    \\ priority)  \\\\\\\\n  2. Values from `.repo-contextor.toml`  \\\\\\\\n  3. Built-in\\\n    \\ defaults (lowest priority)\\\\\\\\n     \\\\\\\\n## Output Format\\\\\\\\n\\\\\\\\nThe tool\\\n    \\ generates a structured text file with the following sections:\\\\\\\\n\\\\\\\\n### 1.\\\n    \\ Repository Context Header\\\\\\\\nProject path and identification\\\\\\\\n\\\\\\\\n### 2.\\\n    \\ Git Repository Information\\\\\\\\n- Current branch\\\\\\\\n- Latest commit SHA\\\\\\\\\\\n    n- Last commit author\\\\\\\\n- Last commit date\\\\\\\\n\\\\\\\\n### 3. Summary Statistics\\\\\\\n    \\\\n- Total number of files processed\\\\\\\\n- Total lines of code\\\\\\\\n\\\\\\\\n### 4.\\\n    \\ Directory Structure\\\\\\\\nClean tree visualization showing project organization\\\\\\\n    \\\\n\\\\\\\\n### 5. Recent Changes (if `--recent` is used)\\\\\\\\n\\\\\\\\n- Lists files modified\\\n    \\ in the last 7 days.\\\\\\\\n- Shows relative file paths along with how long ago\\\n    \\ each file was modified\\\\\\\\n- Helps focus on recently updated parts of the project.\\\\\\\n    \\\\n- Can be combined with `--output` or `--format` to save or change the output\\\n    \\ type.\\\\\\\\n\\\\\\\\n\\\\\\\\n### 5. File Contents\\\\\\\\nEach file's content with:\\\\\\\\n-\\\n    \\ Clear file path headers\\\\\\\\n- Appropriate syntax highlighting language tags\\\\\\\n    \\\\n- Complete file contents\\\\\\\\n\\\\\\\\n## Example Output\\\\\\\\n\\\\\\\\nWhen you run `repo-contextor\\\n    \\ .`, the output looks like this:\\\\\\\\n\\\\\\\\n````markdown\\\\\\\\n# Repository Context:\\\n    \\ /path/to/your/project\\\\\\\\n\\\\\\\\n## Git Repository Information\\\\\\\\n- **Branch**:\\\n    \\ main\\\\\\\\n- **Commit**: a1b2c3d4e5f6789...\\\\\\\\n- **Author**: John Doe <john@example.com>\\\\\\\n    \\\\n- **Date**: Fri Sep 12 14:30:15 2025\\\\\\\\n\\\\\\\\n## Summary\\\\\\\\n- **Total Files**:\\\n    \\ 15\\\\\\\\n- **Total Lines**: 1,247\\\\\\\\n\\\\\\\\n## Directory Structure\\\\\\\\n```\\\\\\\\\\\n    n├── src/\\\\\\\\n│   ├── main.py\\\\\\\\n│   └── utils.py\\\\\\\\n├── tests/\\\\\\\\n│   └──\\\n    \\ test_main.py\\\\\\\\n├── README.md\\\\\\\\n└── requirements.txt\\\\\\\\n```\\\\\\\\n## Recent\\\n    \\ Changes\\\\\\\\n- src/main.py (modified 2 days ago)\\\\\\\\n- src/utils/helpers.py (modified\\\n    \\ 5 days ago)\\\\\\\\n\\\\\\\\n## File Contents\\\\\\\\n\\\\\\\\n### src/main.py\\\\\\\\n\\\\\\\\n```python\\\\\\\n    \\\\ndef main():\\\\\\\\n    print(\\\\\\\\\\\\\\\"Hello, World!\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\nif __name__\\\n    \\ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\":\\\\\\\\n    main()\\\\\\\\n```\\\\\\\\n\\\\\\\\n### README.md\\\\\\\n    \\\\n\\\\\\\\n```markdown\\\\\\\\n# My Project\\\\\\\\nThis is a sample project.\\\\\\\\n```\\\\\\\\\\\n    n\\\\\\\\n## Summary\\\\\\\\n- Total files: 15\\\\\\\\n- Total lines: 1,247\\\\\\\\n````\\\\\\\\n\\\\\\\n    \\\\n## What Files Are Included\\\\\\\\n\\\\\\\\nThe tool includes most text files but automatically\\\n    \\ excludes:\\\\\\\\n\\\\\\\\n### Excluded Directories\\\\\\\\n- `.git`, `.svn`, `.hg` (version\\\n    \\ control)\\\\\\\\n- `__pycache__`, `.pytest_cache` (Python cache)\\\\\\\\n- `node_modules`,\\\n    \\ `.venv`, `venv` (dependencies/environments)\\\\\\\\n- `.vscode`, `.idea` (IDE directories)\\\\\\\n    \\\\n- `build`, `dist`, `target` (build directories)\\\\\\\\n\\\\\\\\n### File Handling\\\n    \\ Rules\\\\\\\\n- **Text files**: All readable text files with common extensions\\\\\\\n    \\\\n- **Binary files**: Automatically detected and skipped\\\\\\\\n- **Permission errors**:\\\n    \\ Skipped with graceful handling\\\\\\\\n- **Configuration files**: Includes pyproject.toml,\\\n    \\ package.json, etc.\\\\\\\\n\\\\\\\\n### Included File Types\\\\\\\\n- Source code: `.py`,\\\n    \\ `.js`, `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\\\\\\\n- Web files: `.html`,\\\n    \\ `.css`, `.scss`, `.vue`, `.jsx`, etc.\\\\\\\\n- Documentation: `.md`, `.txt`, `.rst`\\\\\\\n    \\\\n- Configuration: `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\\\\\\\n- Scripts: `.sh`,\\\n    \\ `.bash`, `.zsh`\\\\\\\\n\\\\\\\\n## Error Handling\\\\\\\\n\\\\\\\\nThe tool handles errors\\\n    \\ gracefully:\\\\\\\\n\\\\\\\\n| Error Type | Behavior |\\\\\\\\n|------------|----------|\\\\\\\n    \\\\n| **Permission errors** | Skipped with warning |\\\\\\\\n| **Binary files** | Automatically\\\n    \\ detected and skipped |\\\\\\\\n| **Invalid paths** | Clear error messages |\\\\\\\\\\\n    n| **Non-git repositories** | Works fine, shows \\\\\\\\\\\\\\\"Not a git repository\\\\\\\n    \\\\\\\\\\\" |\\\\\\\\n| **Unreadable files** | Marked as \\\\\\\\\\\\\\\"[Binary or unreadable\\\n    \\ file]\\\\\\\\\\\\\\\" |\\\\\\\\n\\\\\\\\n## Development\\\\\\\\n\\\\\\\\n### Project Structure\\\\\\\\n\\\\\\\n    \\\\n```text\\\\\\\\nRepo-Contextor/\\\\\\\\n├── src/rcpack/              # Main package\\\\\\\n    \\\\n│   ├── __init__.py         # Package initialization\\\\\\\\n│   ├── cli.py   \\\n    \\           # Command-line interface\\\\\\\\n│   ├── discover.py         # File discovery\\\n    \\ logic\\\\\\\\n│   ├── gitinfo.py          # Git repository analysis\\\\\\\\n│   ├──\\\n    \\ treeview.py         # Directory tree generation\\\\\\\\n│   ├── packager.py    \\\n    \\     # Main orchestration\\\\\\\\n│   ├── io_utils.py         # File I/O utilities\\\\\\\n    \\\\n│   └── renderer/           # Output formatters\\\\\\\\n│       ├── markdown.py\\\n    \\     # Markdown renderer\\\\\\\\n│       └── jsonyaml.py     # JSON/YAML renderers\\\\\\\n    \\\\n├── pyproject.toml          # Project configuration\\\\\\\\n├── LICENSE       \\\n    \\          # MIT License\\\\\\\\n└── README.md              # This documentation\\\\\\\n    \\\\n```\\\\\\\\n\\\\\\\\n### Running Tests\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Test on current repository\\\\\\\n    \\\\nrepo-contextor . -o test-output.md\\\\\\\\n\\\\\\\\n# Test different formats\\\\\\\\nrepo-contextor\\\n    \\ . -f json | head -20\\\\\\\\nrepo-contextor . -f yaml | head -20\\\\\\\\n\\\\\\\\n# Test\\\n    \\ specific directory\\\\\\\\nrepo-contextor src/ -o src-only.md\\\\\\\\n```\\\\\\\\n\\\\\\\\n###\\\n    \\ Contributing\\\\\\\\n\\\\\\\\n1. **Fork the repository**\\\\\\\\n2. **Clone your fork:**\\\\\\\n    \\\\n   ```bash\\\\\\\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    \\\\n   cd Repo-Contextor\\\\\\\\n   ```\\\\\\\\n3. **Install for development:**\\\\\\\\n  \\\n    \\ ```bash\\\\\\\\n   python -m venv .venv\\\\\\\\n   source .venv/bin/activate\\\\\\\\n  \\\n    \\ pip install -e .\\\\\\\\n   ```\\\\\\\\n4. **Make your changes and test:**\\\\\\\\n   ```bash\\\\\\\n    \\\\n   repo-contextor . -o test.md\\\\\\\\n   ```\\\\\\\\n5. **Submit a pull request**\\\\\\\n    \\\\n\\\\\\\\n### Development Workflow\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# 1. Setup development environment\\\\\\\n    \\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\\ncd Repo-Contextor\\\\\\\n    \\\\npython -m venv .venv\\\\\\\\nsource .venv/bin/activate\\\\\\\\npip install -e .\\\\\\\\\\\n    n\\\\\\\\n# 2. Make changes to the code\\\\\\\\n# Edit files in src/rcpack/\\\\\\\\n\\\\\\\\n#\\\n    \\ 3. Test your changes\\\\\\\\nrepo-contextor . -o test-output.md\\\\\\\\n\\\\\\\\n# 4. Test\\\n    \\ different formats\\\\\\\\nrepo-contextor . -f json -o test.json\\\\\\\\nrepo-contextor\\\n    \\ . -f yaml -o test.yaml\\\\\\\\n\\\\\\\\n# 5. Commit and push changes\\\\\\\\ngit add .\\\\\\\n    \\\\ngit commit -m \\\\\\\\\\\\\\\"Add new feature\\\\\\\\\\\\\\\"\\\\\\\\ngit push origin feature-branch\\\\\\\n    \\\\n```\\\\\\\\n\\\\\\\\n## License\\\\\\\\n\\\\\\\\nThis project is licensed under the MIT License.\\\n    \\ See the [LICENSE](LICENSE) file for details.\\\\\\\\n\\\\\\\\n## Why Repo-Contextor?\\\\\\\n    \\\\n\\\\\\\\nThe name \\\\\\\\\\\\\\\"Repo-Contextor\\\\\\\\\\\\\\\" combines \\\\\\\\\\\\\\\"Repository\\\\\\\\\\\n    \\\\\\\" + \\\\\\\\\\\\\\\"Context\\\\\\\\\\\\\\\" + \\\\\\\\\\\\\\\"or\\\\\\\\\\\\\\\", representing the tool's purpose\\\n    \\ of providing rich context about code repositories in a format that's perfect\\\n    \\ for LLM interactions.\\\\\\\\n\\\\\\\\n### Use Cases\\\\\\\\n\\\\\\\\n- **AI Assistance**: Get\\\n    \\ better help from ChatGPT, Claude, or GitHub Copilot\\\\\\\\n- **Code Reviews**:\\\n    \\ Share complete project context with team members\\\\\\\\n- **Documentation**: Create\\\n    \\ comprehensive project snapshots\\\\\\\\n- **Onboarding**: Help new team members\\\n    \\ understand project structure\\\\\\\\n- **Project Analysis**: Understand repository\\\n    \\ structure and dependencies\\\\\\\\n\\\\\\\\n### Perfect for LLMs\\\\\\\\n\\\\\\\\nThe output\\\n    \\ format is specifically designed to work well with Large Language Models:\\\\\\\\\\\n    n- Clear section headers for easy parsing\\\\\\\\n- Syntax highlighting markers for\\\n    \\ code blocks\\\\\\\\n- Structured metadata (git info, file locations)\\\\\\\\n- Complete\\\n    \\ project context in a single file\\\\\\\\n- Multiple output formats (Markdown, JSON,\\\n    \\ YAML)\\\\\\\\n- Optimized for token efficiency\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"pyproject.toml\\\\\\\n    \\\": \\\\\\\"[build-system]\\\\\\\\nrequires = [\\\\\\\\\\\\\\\"setuptools>=68\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"\\\n    wheel\\\\\\\\\\\\\\\"]\\\\\\\\nbuild-backend = \\\\\\\\\\\\\\\"setuptools.build_meta\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\n    \\\\n[project]\\\\\\\\nname = \\\\\\\\\\\\\\\"rcpack\\\\\\\\\\\\\\\"\\\\\\\\nversion = \\\\\\\\\\\\\\\"0.1.0\\\\\\\\\\\n    \\\\\\\"\\\\\\\\ndescription = \\\\\\\\\\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\\\\\\\\\"\\\n    \\\\\\\\nreadme = \\\\\\\\\\\\\\\"README.md\\\\\\\\\\\\\\\"\\\\\\\\nrequires-python = \\\\\\\\\\\\\\\">=3.9\\\\\\\\\\\n    \\\\\\\"\\\\\\\\nlicense = { text = \\\\\\\\\\\\\\\"MIT\\\\\\\\\\\\\\\" }\\\\\\\\ndependencies = [\\\\\\\\n  \\\n    \\  \\\\\\\\\\\\\\\"PyYAML>=6.0\\\\\\\\\\\\\\\"\\\\\\\\n]\\\\\\\\n\\\\\\\\n[project.scripts]\\\\\\\\nrepo-contextor\\\n    \\ = \\\\\\\\\\\\\\\"rcpack.cli:main\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/__init__.py\\\\\\\n    \\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Repository Context Packager - CLI tool for creating\\\n    \\ LLM-optimized repository context.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n__version__\\\n    \\ = \\\\\\\\\\\\\\\"0.1.0\\\\\\\\\\\\\\\"\\\\\\\\n__author__ = \\\\\\\\\\\\\\\"Abhinav\\\\\\\\\\\\\\\"\\\\\\\\n__description__\\\n    \\ = \\\\\\\\\\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\\\\\\\\\"\\\\\\\",\\\\n    \\\\\\\"src/rcpack/__main__.py\\\\\\\n    \\\": \\\\\\\"#!/usr/bin/env python3\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Module entry point\\\n    \\ to enable `python -m rcpack`.\\\\\\\\n\\\\\\\\nThis simply delegates to the CLI's main()\\\n    \\ function.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom .cli import main\\\\\\\\n\\\\\\\n    \\\\n\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\":\\\\\\\\n    main()\\\\\\\\n\\\\\\\\n\\\\\\\\\\\n    n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/cli.py\\\\\\\": \\\\\\\"#!/usr/bin/env python3\\\\\\\\n\\\\\\\\\\\\\\\"\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"CLI for Repository Context Packager.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\n    \\\\n\\\\\\\\nfrom .config_loader import load_config\\\\\\\\n\\\\\\\\nimport argparse\\\\\\\\nimport\\\n    \\ sys\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom .gitinfo import get_git_info\\\\\\\\nfrom\\\n    \\ .discover import discover_files\\\\\\\\nfrom .treeview import create_tree_view\\\\\\\n    \\\\nfrom .renderer.markdown import render_markdown\\\\\\\\nfrom .renderer.jsonyaml\\\n    \\ import render_json, render_yaml\\\\\\\\nfrom .io_utils import write_output\\\\\\\\nfrom\\\n    \\ datetime import datetime, timedelta\\\\\\\\n\\\\\\\\n\\\\\\\\ndef log_verbose(message: str,\\\n    \\ verbose: bool) -> None:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Log a message to stderr\\\n    \\ if verbose mode is enabled.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if verbose:\\\\\\\\\\\n    n        print(message, file=sys.stderr)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef get_rendered_content(format_type:\\\n    \\ str, repo_path: str, repo_info: dict, tree_text: str, \\\\\\\\n                \\\n    \\        files_data: dict, total_files: int, total_lines: int, \\\\\\\\n         \\\n    \\               recent_files_info: dict, file_sizes: dict) -> str:\\\\\\\\n    \\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get rendered content based on the specified format.\\\\\\\\\\\\\\\"\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if format_type == \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\":\\\\\\\\n        return\\\n    \\ render_json(\\\\\\\\n            repo_path, repo_info, tree_text, \\\\\\\\n        \\\n    \\    files_data, total_files, total_lines,\\\\\\\\n            recent_files=recent_files_info,\\\\\\\n    \\\\n            file_sizes=file_sizes\\\\\\\\n        )\\\\\\\\n    elif format_type ==\\\n    \\ \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\":\\\\\\\\n        return render_yaml(\\\\\\\\n            repo_path,\\\n    \\ repo_info, tree_text, \\\\\\\\n            files_data, total_files, total_lines,\\\\\\\n    \\\\n            recent_files=recent_files_info,\\\\\\\\n            file_sizes=file_sizes\\\\\\\n    \\\\n        )\\\\\\\\n    else:  # text/markdown\\\\\\\\n        return render_markdown(\\\\\\\n    \\\\n            repo_path, repo_info, tree_text, \\\\\\\\n            files_data, total_files,\\\n    \\ total_lines,\\\\\\\\n            recent_files=recent_files_info,\\\\\\\\n          \\\n    \\  file_sizes=file_sizes\\\\\\\\n        )\\\\\\\\n\\\\\\\\n\\\\\\\\ndef process_file(file_path:\\\n    \\ Path, repo_path: Path, verbose: bool) -> tuple[str, str, str]:\\\\\\\\n    \\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Process a single file and return its data.\\\\\\\\n    \\\\\\\\n   \\\n    \\ Returns:\\\\\\\\n        tuple: (relative_path_str, content, file_size)\\\\\\\\n   \\\n    \\ \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    relative_path = file_path.relative_to(repo_path)\\\\\\\n    \\\\n    relative_path_str = str(relative_path)\\\\\\\\n    \\\\\\\\n    log_verbose(f\\\\\\\n    \\\\\\\\\\\"Reading file: {relative_path}\\\\\\\\\\\\\\\", verbose)\\\\\\\\n    file_size = file_path.stat().st_size\\\\\\\n    \\\\n    \\\\\\\\n    try:\\\\\\\\n        with open(file_path, 'r', encoding='utf-8') as\\\n    \\ f:\\\\\\\\n            content = f.read()\\\\\\\\n        return relative_path_str,\\\n    \\ content, str(file_size)\\\\\\\\n    except (UnicodeDecodeError, PermissionError):\\\\\\\n    \\\\n        log_verbose(f\\\\\\\\\\\\\\\"Skipping binary/unreadable file: {relative_path}\\\\\\\n    \\\\\\\\\\\", verbose)\\\\\\\\n        file_size = file_path.stat().st_size if file_path.exists()\\\n    \\ else 0\\\\\\\\n        content = f\\\\\\\\\\\\\\\"[Binary or unreadable file: {file_path.name}]\\\\\\\n    \\\\\\\\\\\"\\\\\\\\n        return relative_path_str, content, str(file_size)\\\\\\\\n    except\\\n    \\ Exception:\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\"Error reading file: {relative_path}\\\\\\\n    \\\\\\\\\\\", verbose)\\\\\\\\n        raise  # Re-raise to handle in calling code\\\\\\\\n\\\\\\\n    \\\\n\\\\\\\\ndef handle_output(content: str, output_path: str = None) -> None:\\\\\\\\\\\n    n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Handle output to either file or stdout.\\\\\\\\\\\\\\\"\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if output_path:\\\\\\\\n        # Write to file\\\\\\\\n      \\\n    \\  write_output(output_path, content)\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Context package\\\n    \\ created: {output_path}\\\\\\\\\\\\\\\")\\\\\\\\n    else:\\\\\\\\n        # Output to stdout\\\\\\\n    \\\\n        print(content)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef main():\\\\\\\\n    parser = argparse.ArgumentParser(\\\\\\\n    \\\\n        description=\\\\\\\\\\\\\\\"Package repository content for LLM context\\\\\\\\\\\\\\\n    \\\"\\\\\\\\n    )\\\\\\\\n    parser.add_argument(\\\\\\\\n        \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\", \\\\\\\n    \\\\n        nargs=\\\\\\\\\\\\\\\"?\\\\\\\\\\\\\\\", \\\\\\\\n        default=\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\", \\\\\\\n    \\\\n        help=\\\\\\\\\\\\\\\"Repository path (default: current directory)\\\\\\\\\\\\\\\"\\\\\\\n    \\\\n    )\\\\\\\\n    parser.add_argument(\\\\\\\\n        \\\\\\\\\\\\\\\"-o\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"\\\n    --output\\\\\\\\\\\\\\\", \\\\\\\\n        help=\\\\\\\\\\\\\\\"Output file path (default: stdout)\\\\\\\n    \\\\\\\\\\\"\\\\\\\\n    )\\\\\\\\n    parser.add_argument(\\\\\\\\n        \\\\\\\\\\\\\\\"-f\\\\\\\\\\\\\\\",\\\n    \\ \\\\\\\\\\\\\\\"--format\\\\\\\\\\\\\\\", \\\\\\\\n        choices=[\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\n    \\\"json\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\"], \\\\\\\\n        default=\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\n    \\\",\\\\\\\\n        help=\\\\\\\\\\\\\\\"Output format (default: text)\\\\\\\\\\\\\\\"\\\\\\\\n    )\\\\\\\n    \\\\n\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" This will read -r from the console and able\\\n    \\ to search it with this\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    parser.add_argument(\\\\\\\n    \\\\n    \\\\\\\\\\\\\\\"-r\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--recent\\\\\\\\\\\\\\\",\\\\\\\\n    action=\\\\\\\\\\\\\\\"store_true\\\\\\\n    \\\\\\\\\\\",\\\\\\\\n    help=\\\\\\\\\\\\\\\"Include only files modified in the last 7 days\\\\\\\\\\\n    \\\\\\\"\\\\\\\\n    )\\\\\\\\n    parser.add_argument(\\\\\\\\n        \\\\\\\\\\\\\\\"-v\\\\\\\\\\\\\\\", \\\\\\\n    \\\\\\\\\\\"--verbose\\\\\\\\\\\\\\\",\\\\\\\\n        action=\\\\\\\\\\\\\\\"store_true\\\\\\\\\\\\\\\",\\\\\\\\n \\\n    \\       help=\\\\\\\\\\\\\\\"Print detailed progress information to stderr\\\\\\\\\\\\\\\"\\\\\\\\\\\n    n    )\\\\\\\\n    \\\\\\\\n    args = parser.parse_args()\\\\\\\\n    \\\\\\\\n    try:\\\\\\\\n\\\n    \\        repo_path = Path(args.path).resolve()\\\\\\\\n        if not repo_path.exists():\\\\\\\n    \\\\n            print(f\\\\\\\\\\\\\\\"Error: Path {repo_path} does not exist\\\\\\\\\\\\\\\",\\\n    \\ file=sys.stderr)\\\\\\\\n            sys.exit(1)\\\\\\\\n            \\\\\\\\n        #\\\n    \\ Get repository information\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\"Analyzing repository:\\\n    \\ {repo_path}\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n        repo_info = get_git_info(repo_path)\\\\\\\n    \\\\n        \\\\\\\\n        # Discover files\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\"Discovering\\\n    \\ files in: {repo_path}\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n        discovered_files =\\\n    \\ discover_files([repo_path], repo_path, [], [])\\\\\\\\n        log_verbose(f\\\\\\\\\\\n    \\\\\\\"Found {len(discovered_files)} files\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n        \\\\\\\\\\\n    n        # will check the file in last 7 days\\\\\\\\n        recent_files_info =\\\n    \\ {}\\\\\\\\n        if args.recent:\\\\\\\\n            seven_days_ago = datetime.now()\\\n    \\ - timedelta(days=7)\\\\\\\\n            recent_files = []\\\\\\\\n            for f\\\n    \\ in discovered_files:\\\\\\\\n                try:\\\\\\\\n                    mtime\\\n    \\ = datetime.fromtimestamp(f.stat().st_mtime)\\\\\\\\n                    if mtime\\\n    \\ >= seven_days_ago:\\\\\\\\n                        recent_files.append(f)\\\\\\\\n \\\n    \\                       recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)\\\n    \\     \\\\\\\\n                except Exception:\\\\\\\\n                    continue\\\\\\\n    \\\\n            discovered_files = recent_files\\\\\\\\n        \\\\\\\\n        # Read\\\n    \\ file contents\\\\\\\\n        files_data = {}\\\\\\\\n        file_sizes = {}\\\\\\\\n \\\n    \\       for file_path in discovered_files:\\\\\\\\n            try:\\\\\\\\n         \\\n    \\       relative_path_str, content, file_size = process_file(file_path, repo_path,\\\n    \\ args.verbose)\\\\\\\\n                files_data[relative_path_str] = content\\\\\\\\\\\n    n                file_sizes[relative_path_str] = file_size\\\\\\\\n            except\\\n    \\ Exception:\\\\\\\\n                continue\\\\\\\\n        \\\\\\\\n        # Create tree\\\n    \\ view\\\\\\\\n        log_verbose(\\\\\\\\\\\\\\\"Generating directory tree\\\\\\\\\\\\\\\", args.verbose)\\\\\\\n    \\\\n        tree_text = create_tree_view(repo_path, files_data)\\\\\\\\n        \\\\\\\\\\\n    n        # Count totals\\\\\\\\n        total_files = len(files_data)\\\\\\\\n       \\\n    \\ total_lines = sum(len(content.splitlines()) for _, content in files_data.items())\\\\\\\n    \\\\n        \\\\\\\\n        # Render based on format\\\\\\\\n        log_verbose(f\\\\\\\\\\\n    \\\\\\\"Rendering output in {args.format} format\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n     \\\n    \\   content = get_rendered_content(\\\\\\\\n            args.format, str(repo_path),\\\n    \\ repo_info, tree_text,\\\\\\\\n            files_data, total_files, total_lines,\\\\\\\n    \\\\n            recent_files_info if args.recent else {},\\\\\\\\n            file_sizes\\\\\\\n    \\\\n        )\\\\\\\\n        \\\\\\\\n        handle_output(content, args.output)\\\\\\\\\\\n    n        \\\\\\\\n    except Exception as e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Error: {e}\\\\\\\n    \\\\\\\\\\\", file=sys.stderr)\\\\\\\\n        sys.exit(1)\\\\\\\\n\\\\\\\\n# this will convert\\\n    \\ age and give us the difference\\\\\\\\ndef human_readable_age(mtime: datetime) ->\\\n    \\ str:\\\\\\\\n    delta = datetime.now() - mtime\\\\\\\\n    days = delta.days\\\\\\\\n \\\n    \\   seconds = delta.seconds\\\\\\\\n    if days > 0:\\\\\\\\n        return f\\\\\\\\\\\\\\\"\\\n    {days} day{'s' if days != 1 else ''} ago\\\\\\\\\\\\\\\"\\\\\\\\n    elif seconds >= 3600:\\\\\\\n    \\\\n        hours = seconds // 3600\\\\\\\\n        return f\\\\\\\\\\\\\\\"{hours} hour{'s'\\\n    \\ if hours != 1 else ''} ago\\\\\\\\\\\\\\\"\\\\\\\\n    elif seconds >= 60:\\\\\\\\n        minutes\\\n    \\ = seconds // 60\\\\\\\\n        return f\\\\\\\\\\\\\\\"{minutes} minute{'s' if minutes\\\n    \\ != 1 else ''} ago\\\\\\\\\\\\\\\"\\\\\\\\n    else:\\\\\\\\n        return \\\\\\\\\\\\\\\"just now\\\\\\\n    \\\\\\\\\\\"\\\\\\\\n\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\":\\\\\\\\n    main()\\\\\\\\n\\\\\\\n    \\\",\\\\n    \\\\\\\"src/rcpack/config_loader.py\\\\\\\": \\\\\\\"# src/rcpack/config_loader.py\\\\\\\n    \\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nTOML config loader for Repo-Contextor.\\\\\\\\n\\\\\\\\\\\n    nRules:\\\\\\\\n- Look for .repo-contextor.toml in the CURRENT directory\\\\\\\\n- If\\\n    \\ missing: ignore\\\\\\\\n- If present but invalid: print a clear error and exit(1)\\\\\\\n    \\\\n- Only recognized keys are applied; unknown keys ignored\\\\\\\\n- Precedence:\\\n    \\ CLI > TOML > DEFAULTS\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nfrom __future__ import\\\n    \\ annotations\\\\\\\\nimport os, sys\\\\\\\\nfrom typing import Dict, Iterable, Any\\\\\\\\\\\n    n\\\\\\\\ntry:\\\\\\\\n    import tomllib\\\\\\\\n    _loads = tomllib.loads\\\\\\\\nexcept ModuleNotFoundError:\\\\\\\n    \\\\n    try:\\\\\\\\n        import tomli\\\\\\\\n        _loads = tomli.loads\\\\\\\\n   \\\n    \\ except ModuleNotFoundError:\\\\\\\\n        _loads = None\\\\\\\\n\\\\\\\\ndef _need_toml():\\\\\\\n    \\\\n    if _loads is None:\\\\\\\\n        print(\\\\\\\\\\\\\\\"Error: TOML parser not available.\\\n    \\ Use Python 3.11+ or `pip install tomli`.\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\n    \\\n    \\    sys.exit(1)\\\\\\\\n\\\\\\\\ndef _load_toml(dotfile: str) -> Dict[str, Any]:\\\\\\\\\\\n    n    _need_toml()\\\\\\\\n    if not os.path.exists(dotfile):\\\\\\\\n        return {}\\\\\\\n    \\\\n    try:\\\\\\\\n        with open(dotfile, \\\\\\\\\\\\\\\"rb\\\\\\\\\\\\\\\") as f:\\\\\\\\n    \\\n    \\        raw = f.read().decode(\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", errors=\\\\\\\\\\\\\\\"strict\\\\\\\\\\\n    \\\\\\\")\\\\\\\\n        data = _loads(raw)\\\\\\\\n        return data if isinstance(data,\\\n    \\ dict) else {}\\\\\\\\n    except Exception as e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Error:\\\n    \\ failed to parse {dotfile} as TOML.\\\\\\\\\\\\\\\\n{e}\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\\\\n    n        sys.exit(1)\\\\\\\\n\\\\\\\\ndef _filter_known(d: Dict[str, Any], known: Iterable[str])\\\n    \\ -> Dict[str, Any]:\\\\\\\\n    ks = set(known)\\\\\\\\n    return {k: v for k, v in\\\n    \\ d.items() if k in ks}\\\\\\\\n\\\\\\\\ndef _merge(defaults: Dict[str, Any], filecfg:\\\n    \\ Dict[str, Any], clicfg: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\\\\\\n    \\\\n    ks = set(known)\\\\\\\\n    out: Dict[str, Any] = {k: defaults.get(k) for k\\\n    \\ in ks}\\\\\\\\n    for src in (filecfg, clicfg):\\\\\\\\n        for k, v in src.items():\\\\\\\n    \\\\n            if k in ks and v is not None:\\\\\\\\n                out[k] = v\\\\\\\\\\\n    n    return out\\\\\\\\n\\\\\\\\ndef load_config(*, dotfile: str = \\\\\\\\\\\\\\\".repo-contextor.toml\\\\\\\n    \\\\\\\\\\\", defaults: Dict[str, Any] | None = None, cli_cfg: Dict[str, Any] | None\\\n    \\ = None, known_keys: Iterable[str] = ()) -> Dict[str, Any]:\\\\\\\\n    defaults\\\n    \\ = defaults or {}\\\\\\\\n    cli_cfg = cli_cfg or {}\\\\\\\\n    known = tuple(known_keys)\\\\\\\n    \\\\n    filecfg = _filter_known(_load_toml(dotfile), known)\\\\\\\\n    return _merge(defaults,\\\n    \\ filecfg, cli_cfg, known)\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/discover.py\\\\\\\": \\\\\\\"\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"File discovery module for repository analysis.\\\\\\\\\\\\\\\"\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import List\\\\\\\n    \\\\nimport fnmatch\\\\\\\\n\\\\\\\\n\\\\\\\\ndef discover_files(\\\\\\\\n    inputs: List[Path],\\\\\\\n    \\\\n    root: Path,\\\\\\\\n    include_patterns: List[str],\\\\\\\\n    exclude_patterns:\\\n    \\ List[str],\\\\\\\\n) -> List[Path]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Discover relevant\\\n    \\ files.\\\\\\\\n\\\\\\\\n    - inputs: list of files/dirs to scan\\\\\\\\n    - root: common\\\n    \\ project root; patterns are matched against POSIX paths relative to root\\\\\\\\\\\n    n    - include_patterns: glob patterns to include (if empty, use sensible defaults)\\\\\\\n    \\\\n    - exclude_patterns: glob patterns to exclude\\\\\\\\n    Returns a list of\\\n    \\ absolute Paths to files.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    default_include_exts\\\n    \\ = {\\\\\\\\n        '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c',\\\n    \\ '.h',\\\\\\\\n        '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\\\\\\n    \\\\n        '.html', '.css', '.scss', '.sass', '.less', '.vue', '.svelte',\\\\\\\\\\\n    n        '.md', '.txt', '.rst', '.yaml', '.yml', '.json', '.toml', '.ini',\\\\\\\\\\\n    n        '.cfg', '.conf', '.xml', '.sql', '.sh', '.bash', '.zsh', '.fish',\\\\\\\\\\\n    n    }\\\\\\\\n\\\\\\\\n    always_include_names = {\\\\\\\\n        'README', 'LICENSE',\\\n    \\ 'CHANGELOG', 'CONTRIBUTING', 'Makefile',\\\\\\\\n        'requirements.txt', 'package.json',\\\n    \\ 'Cargo.toml', 'pyproject.toml',\\\\\\\\n        'setup.py', 'setup.cfg', 'pom.xml',\\\n    \\ 'build.gradle', '.gitignore', '.gitattributes'\\\\\\\\n    }\\\\\\\\n\\\\\\\\n    skip_dir_names\\\n    \\ = {\\\\\\\\n        '.git', '.svn', '.hg', '__pycache__', '.pytest_cache',\\\\\\\\n\\\n    \\        'node_modules', '.venv', 'venv', 'env', '.env',\\\\\\\\n        'build',\\\n    \\ 'dist', 'target', 'out', '.next', '.nuxt',\\\\\\\\n        '.idea', '.vscode', '.vs',\\\n    \\ 'coverage', '.coverage'\\\\\\\\n    }\\\\\\\\n\\\\\\\\n    def matches_any(patterns: List[str],\\\n    \\ rel_posix: str) -> bool:\\\\\\\\n        return any(fnmatch.fnmatch(rel_posix, pat)\\\n    \\ for pat in patterns)\\\\\\\\n\\\\\\\\n    def should_take(file_path: Path) -> bool:\\\\\\\n    \\\\n        rel_posix = file_path.relative_to(root).as_posix()\\\\\\\\n        if exclude_patterns\\\n    \\ and matches_any(exclude_patterns, rel_posix):\\\\\\\\n            return False\\\\\\\n    \\\\n        if include_patterns:\\\\\\\\n            return matches_any(include_patterns,\\\n    \\ rel_posix)\\\\\\\\n        # default include logic\\\\\\\\n        return file_path.name\\\n    \\ in always_include_names or file_path.suffix.lower() in default_include_exts\\\\\\\n    \\\\n\\\\\\\\n    discovered: list[Path] = []\\\\\\\\n    seen = set()\\\\\\\\n\\\\\\\\n    for\\\n    \\ item in inputs:\\\\\\\\n        p = item.resolve()\\\\\\\\n        if p.is_file():\\\\\\\n    \\\\n            # Skip if excluded or in skipped directory\\\\\\\\n            if any(part\\\n    \\ in skip_dir_names for part in p.parts):\\\\\\\\n                continue\\\\\\\\n  \\\n    \\          if should_take(p):\\\\\\\\n                key = p.as_posix()\\\\\\\\n    \\\n    \\            if key not in seen:\\\\\\\\n                    seen.add(key)\\\\\\\\n  \\\n    \\                  discovered.append(p)\\\\\\\\n        elif p.is_dir():\\\\\\\\n    \\\n    \\        for child in p.rglob('*'):\\\\\\\\n                if not child.is_file():\\\\\\\n    \\\\n                    continue\\\\\\\\n                if any(part in skip_dir_names\\\n    \\ for part in child.parts):\\\\\\\\n                    continue\\\\\\\\n            \\\n    \\    if should_take(child):\\\\\\\\n                    key = child.resolve().as_posix()\\\\\\\n    \\\\n                    if key not in seen:\\\\\\\\n                        seen.add(key)\\\\\\\n    \\\\n                        discovered.append(child.resolve())\\\\\\\\n\\\\\\\\n    return\\\n    \\ sorted(discovered)\\\\\\\",\\\\n    \\\\\\\"src/rcpack/gitinfo.py\\\\\\\": \\\\\\\"from __future__\\\n    \\ import annotations\\\\\\\\n\\\\\\\\nimport subprocess\\\\\\\\nfrom pathlib import Path\\\\\\\n    \\\\nfrom typing import Dict, Any\\\\\\\\n\\\\\\\\n\\\\\\\\ndef _git(cmd: list[str], cwd: Path)\\\n    \\ -> str:\\\\\\\\n    # Validate git commands to prevent injection\\\\\\\\n    allowed_commands\\\n    \\ = {\\\\\\\\n        \\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"show\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"log\\\\\\\n    \\\\\\\\\\\", \\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"config\\\\\\\\\\\\\\\"\\\n    \\\\\\\\n    }\\\\\\\\n    if not cmd or cmd[0] not in allowed_commands:\\\\\\\\n        raise\\\n    \\ ValueError(f\\\\\\\\\\\\\\\"Git command not allowed: {cmd[0] if cmd else 'empty'}\\\\\\\\\\\n    \\\\\\\")\\\\\\\\n    \\\\\\\\n    out = subprocess.check_output([\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\", *cmd],\\\n    \\ cwd=str(cwd), timeout=30)\\\\\\\\n    return out.decode(\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", errors=\\\\\\\n    \\\\\\\\\\\"replace\\\\\\\\\\\\\\\").strip()\\\\\\\\n\\\\\\\\n\\\\\\\\ndef is_git_repo(path: Path) -> bool:\\\\\\\n    \\\\n    try:\\\\\\\\n        flag = _git([\\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--is-inside-work-tree\\\\\\\n    \\\\\\\\\\\"], cwd=path)\\\\\\\\n        return flag == \\\\\\\\\\\\\\\"true\\\\\\\\\\\\\\\"\\\\\\\\n    except\\\n    \\ Exception:\\\\\\\\n        return False\\\\\\\\n\\\\\\\\n\\\\\\\\ndef get_git_info(path: Path)\\\n    \\ -> Dict[str, Any]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Return info for\\\n    \\ the current HEAD of a repo rooted at `path`.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\n    \\\\\\\\n    try:\\\\\\\\n        commit = _git([\\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"HEAD\\\\\\\n    \\\\\\\\\\\"], cwd=path)\\\\\\\\n        branch = _git([\\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\n    \\\"--abbrev-ref\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"HEAD\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\\n        author =\\\n    \\ _git([\\\\\\\\\\\\\\\"show\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"-s\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--format=%an <%ae>\\\\\\\n    \\\\\\\\\\\"], cwd=path)\\\\\\\\n        date = _git([\\\\\\\\\\\\\\\"show\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"-s\\\\\\\n    \\\\\\\\\\\", \\\\\\\\\\\\\\\"--date=local\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--format=%ad\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\n    \\\\n        return {\\\\\\\\n            \\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\": True,\\\\\\\\n      \\\n    \\      \\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\": commit,\\\\\\\\n            \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\"\\\n    : branch,\\\\\\\\n            \\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\": author,\\\\\\\\n            \\\\\\\\\\\n    \\\\\\\"date\\\\\\\\\\\\\\\": date,\\\\\\\\n            \\\\\\\\\\\\\\\"note\\\\\\\\\\\\\\\": None,\\\\\\\\n     \\\n    \\   }\\\\\\\\n    except Exception:\\\\\\\\n        # treat as not a repo if anything\\\n    \\ fails\\\\\\\\n        return {\\\\\\\\n            \\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\": False,\\\\\\\n    \\\\n            \\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"branch\\\\\\\\\\\n    \\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\n    \\\\\\\"date\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"note\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Not a git\\\n    \\ repository\\\\\\\\\\\\\\\",\\\\\\\\n        }\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/io_utils.py\\\\\\\n    \\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"I/O utilities for file operations.\\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import Tuple\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\\ndef write_output(output_path: str, content: str) -> None:\\\\\\\\n    \\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Write content to output file.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\n    n    output_file = Path(output_path)\\\\\\\\n    \\\\\\\\n    # Create parent directories\\\n    \\ if they don't exist\\\\\\\\n    output_file.parent.mkdir(parents=True, exist_ok=True)\\\\\\\n    \\\\n    \\\\\\\\n    # Write content\\\\\\\\n    with open(output_file, 'w', encoding='utf-8')\\\n    \\ as f:\\\\\\\\n        f.write(content)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef is_binary_file(path: Path,\\\n    \\ sniff_bytes: int = 2048) -> bool:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Heuristically\\\n    \\ determine if a file is binary by scanning for NUL bytes.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\\\\"\\\\\\\\n    try:\\\\\\\\n        with open(path, 'rb') as fb:\\\\\\\\n            chunk\\\n    \\ = fb.read(sniff_bytes)\\\\\\\\n        if b\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\x00\\\\\\\\\\\\\\\" in chunk:\\\\\\\n    \\\\n            return True\\\\\\\\n        # If the chunk has a lot of non-text bytes,\\\n    \\ consider it binary\\\\\\\\n        text_byte_count = sum(32 <= b <= 126 or b in\\\n    \\ (9, 10, 13) for b in chunk)\\\\\\\\n        return (len(chunk) - text_byte_count)\\\n    \\ > max(1, len(chunk) // 3)\\\\\\\\n    except Exception:\\\\\\\\n        # If we cannot\\\n    \\ read, treat as binary to avoid further processing\\\\\\\\n        return True\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\\ndef read_text_safely(path: Path, max_bytes: int = 16_384) -> Tuple[str,\\\n    \\ str, bool]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Read a text file safely with size\\\n    \\ limit and encoding fallbacks.\\\\\\\\n\\\\\\\\n    Returns (content, encoding_used,\\\n    \\ truncated).\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    truncated = False\\\\\\\\n\\\n    \\    raw: bytes\\\\\\\\n    with open(path, 'rb') as fb:\\\\\\\\n        raw = fb.read(max_bytes\\\n    \\ + 1)\\\\\\\\n    if len(raw) > max_bytes:\\\\\\\\n        truncated = True\\\\\\\\n    \\\n    \\    raw = raw[:max_bytes]\\\\\\\\n\\\\\\\\n    for enc in (\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", \\\\\\\\\\\n    \\\\\\\"utf-16\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"utf-16-le\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"utf-16-be\\\\\\\\\\\\\\\", \\\\\\\\\\\n    \\\\\\\"latin-1\\\\\\\\\\\\\\\"):\\\\\\\\n        try:\\\\\\\\n            text = raw.decode(enc)\\\\\\\n    \\\\n            return text, enc, truncated\\\\\\\\n        except Exception:\\\\\\\\n\\\n    \\            continue\\\\\\\\n    # Fallback: replace errors with utf-8\\\\\\\\n    text\\\n    \\ = raw.decode(\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", errors=\\\\\\\\\\\\\\\"replace\\\\\\\\\\\\\\\")\\\\\\\\n   \\\n    \\ return text, \\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", truncated\\\\\\\",\\\\n    \\\\\\\"src/rcpack/packager.py\\\\\\\n    \\\": \\\\\\\"from __future__ import annotations\\\\\\\\n\\\\\\\\nimport sys\\\\\\\\nfrom pathlib\\\n    \\ import Path\\\\\\\\nfrom typing import Iterable, Tuple\\\\\\\\n\\\\\\\\nfrom rcpack.discover\\\n    \\ import discover_files\\\\\\\\nfrom rcpack.gitinfo import get_git_info, is_git_repo\\\\\\\n    \\\\nfrom rcpack.io_utils import read_text_safely, is_binary_file\\\\\\\\nfrom rcpack.renderer\\\n    \\ import markdown as md_renderer\\\\\\\\nfrom rcpack.renderer.jsonyaml import render_json,\\\n    \\ render_yaml\\\\\\\\nfrom rcpack.treeview import render_tree\\\\\\\\n\\\\\\\\n\\\\\\\\ndef _find_root(inputs:\\\n    \\ list[str]) -> Path:\\\\\\\\n    paths = [Path(p) for p in inputs]\\\\\\\\n    if len(paths)\\\n    \\ == 1 and Path(paths[0]).is_dir():\\\\\\\\n        return paths[0].resolve()\\\\\\\\\\\n    n    parents = [p if p.is_dir() else p.parent for p in paths]\\\\\\\\n    root = Path(*Path.commonpath([str(p.resolve())\\\n    \\ for p in parents]).split(\\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\"))\\\\\\\\n    return root.resolve()\\\\\\\n    \\\\n\\\\\\\\n\\\\\\\\ndef build_package(\\\\\\\\n    inputs: list[str],\\\\\\\\n    include_patterns:\\\n    \\ list[str] | None,\\\\\\\\n    exclude_patterns: list[str] | None,\\\\\\\\n    max_file_bytes:\\\n    \\ int,\\\\\\\\n    fmt: str = \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n) -> Tuple[str, dict]:\\\\\\\n    \\\\n    root = _find_root(inputs)\\\\\\\\n    root_abs = root.resolve()\\\\\\\\n\\\\\\\\n \\\n    \\   repo_info = (\\\\\\\\n        get_git_info(root_abs) if is_git_repo(root_abs)\\\n    \\ else {\\\\\\\\n            \\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\": False,\\\\\\\\n            \\\\\\\\\\\\\\\n    \\\"commit\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\": None,\\\\\\\\n   \\\n    \\         \\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"date\\\\\\\\\\\\\\\":\\\n    \\ None,\\\\\\\\n            \\\\\\\\\\\\\\\"note\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Not a git repository\\\\\\\\\\\n    \\\\\\\",\\\\\\\\n        }\\\\\\\\n    )\\\\\\\\n\\\\\\\\n    files = discover_files(\\\\\\\\n      \\\n    \\  inputs=[Path(p) for p in inputs],\\\\\\\\n        root=root_abs,\\\\\\\\n        include_patterns=include_patterns\\\n    \\ or [],\\\\\\\\n        exclude_patterns=exclude_patterns or [],\\\\\\\\n    )\\\\\\\\n \\\n    \\   rel_files = [f.relative_to(root_abs) for f in files]\\\\\\\\n\\\\\\\\n    project_tree\\\n    \\ = render_tree([p.as_posix() for p in rel_files])\\\\\\\\n\\\\\\\\n    file_sections:\\\n    \\ list[dict] = []\\\\\\\\n    total_lines = 0\\\\\\\\n    total_chars = 0\\\\\\\\n\\\\\\\\n  \\\n    \\  for f in files:\\\\\\\\n        rel = f.relative_to(root_abs).as_posix()\\\\\\\\n \\\n    \\       try:\\\\\\\\n            if is_binary_file(f):\\\\\\\\n                content\\\n    \\ = f\\\\\\\\\\\\\\\"[binary file skipped: {f.name}, {f.stat().st_size} bytes]\\\\\\\\\\\\\\\"\\\n    \\\\\\\\n                file_sections.append({\\\\\\\\n                    \\\\\\\\\\\\\\\"path\\\\\\\n    \\\\\\\\\\\": rel,\\\\\\\\n                    \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": _language_from_ext(f.suffix),\\\\\\\n    \\\\n                    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": content,\\\\\\\\n                \\\n    \\    \\\\\\\\\\\\\\\"is_truncated\\\\\\\\\\\\\\\": False,\\\\\\\\n                })\\\\\\\\n        \\\n    \\        total_chars += len(content)\\\\\\\\n                continue\\\\\\\\n\\\\\\\\n  \\\n    \\          content, used_encoding, truncated = read_text_safely(f, max_bytes=max_file_bytes)\\\\\\\n    \\\\n            total_lines += content.count(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\") + (1 if\\\n    \\ content and not content.endswith(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\") else 0)\\\\\\\\n   \\\n    \\         total_chars += len(content)\\\\\\\\n\\\\\\\\n            if truncated:\\\\\\\\n\\\n    \\                note = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n[... TRUNCATED to first {max_file_bytes}\\\n    \\ bytes ...]\\\\\\\\\\\\\\\"\\\\\\\\n                content = content + note\\\\\\\\n       \\\n    \\         total_chars += len(note)\\\\\\\\n\\\\\\\\n            file_sections.append({\\\\\\\n    \\\\n                \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": rel,\\\\\\\\n                \\\\\\\\\\\\\\\"language\\\\\\\n    \\\\\\\\\\\": _language_from_ext(f.suffix),\\\\\\\\n                \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\n    \\\": content,\\\\\\\\n                \\\\\\\\\\\\\\\"is_truncated\\\\\\\\\\\\\\\": truncated,\\\\\\\\\\\n    n            })\\\\\\\\n        except Exception as exc:\\\\\\\\n            print(f\\\\\\\n    \\\\\\\\\\\"[rcpack] error reading {rel}: {exc}\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\n     \\\n    \\       continue\\\\\\\\n\\\\\\\\n    # render in chosen format\\\\\\\\n    if fmt == \\\\\\\\\\\n    \\\\\\\"markdown\\\\\\\\\\\\\\\":\\\\\\\\n        out_text = md_renderer.render_markdown(\\\\\\\\\\\n    n            root=str(root_abs),\\\\\\\\n            repo_info=repo_info,\\\\\\\\n   \\\n    \\         tree_text=project_tree,\\\\\\\\n            files=file_sections,\\\\\\\\n  \\\n    \\          total_files=len(file_sections),\\\\\\\\n            total_lines=total_lines,\\\\\\\n    \\\\n        )\\\\\\\\n    elif fmt == \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\":\\\\\\\\n        out_text =\\\n    \\ render_json(\\\\\\\\n            root=str(root_abs),\\\\\\\\n            repo_info=repo_info,\\\\\\\n    \\\\n            tree_text=project_tree,\\\\\\\\n            files=file_sections,\\\\\\\\\\\n    n            total_files=len(file_sections),\\\\\\\\n            total_lines=total_lines,\\\\\\\n    \\\\n        )\\\\\\\\n    elif fmt == \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\":\\\\\\\\n        out_text =\\\n    \\ render_yaml(\\\\\\\\n            root=str(root_abs),\\\\\\\\n            repo_info=repo_info,\\\\\\\n    \\\\n            tree_text=project_tree,\\\\\\\\n            files=file_sections,\\\\\\\\\\\n    n            total_files=len(file_sections),\\\\\\\\n            total_lines=total_lines,\\\\\\\n    \\\\n        )\\\\\\\\n    else:\\\\\\\\n        raise ValueError(f\\\\\\\\\\\\\\\"Unsupported format:\\\n    \\ {fmt}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    stats = {\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\": len(file_sections),\\\n    \\ \\\\\\\\\\\\\\\"lines\\\\\\\\\\\\\\\": total_lines, \\\\\\\\\\\\\\\"chars\\\\\\\\\\\\\\\": total_chars}\\\\\\\\\\\n    n    return out_text, stats\\\\\\\\n\\\\\\\\n\\\\\\\\ndef _language_from_ext(ext: str) ->\\\n    \\ str:\\\\\\\\n    ext = ext.lower().lstrip(\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\")\\\\\\\\n    mapping = {\\\\\\\n    \\\\n        \\\\\\\\\\\\\\\"py\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"js\\\\\\\\\\\\\\\": \\\\\\\\\\\n    \\\\\\\"javascript\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"ts\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"typescript\\\\\\\\\\\\\\\",\\\\\\\\n \\\n    \\       \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"md\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\n    \\\"markdown\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"yml\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\n    \\\\\\\": \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"toml\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"toml\\\\\\\\\\\n    \\\\\\\", \\\\\\\\\\\\\\\"sh\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"bash\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"c\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"c\\\\\\\n    \\\\\\\\\\\", \\\\\\\\\\\\\\\"cpp\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"cpp\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"java\\\\\\\\\\\n    \\\\\\\": \\\\\\\\\\\\\\\"java\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"go\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"go\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"rs\\\\\\\n    \\\\\\\\\\\": \\\\\\\\\\\\\\\"rust\\\\\\\\\\\\\\\",\\\\\\\\n    }\\\\\\\\n    return mapping.get(ext, \\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/renderer/jsonyaml.py\\\\\\\": \\\\\\\"from\\\n    \\ __future__ import annotations\\\\\\\\nimport json\\\\\\\\n\\\\\\\\ntry:\\\\\\\\n    import yaml\\\\\\\n    \\\\nexcept ImportError:\\\\\\\\n    yaml = None\\\\\\\\n\\\\\\\\n\\\\\\\\ndef render_json(root,\\\n    \\ repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None)\\\n    \\ -> str:\\\\\\\\n    data = {\\\\\\\\n        \\\\\\\\\\\\\\\"root\\\\\\\\\\\\\\\": root,\\\\\\\\n      \\\n    \\  \\\\\\\\\\\\\\\"repo_info\\\\\\\\\\\\\\\": repo_info,\\\\\\\\n        \\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\"\\\n    : tree_text,\\\\\\\\n        \\\\\\\\\\\\\\\"recent_changes\\\\\\\\\\\\\\\": recent_files or [],\\\\\\\n    \\\\n        \\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\": files,\\\\\\\\n        \\\\\\\\\\\\\\\"file_sizes\\\\\\\\\\\\\\\"\\\n    : file_sizes or {},\\\\\\\\n        \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"total_files\\\\\\\n    \\\\\\\\\\\": total_files, \\\\\\\\\\\\\\\"total_lines\\\\\\\\\\\\\\\": total_lines},\\\\\\\\n        \\\\\\\n    \\\\n    }\\\\\\\\n    return json.dumps(data, indent=2, ensure_ascii=False)\\\\\\\\n\\\\\\\\\\\n    n\\\\\\\\ndef render_yaml(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None,\\\n    \\ file_sizes=None) -> str:\\\\\\\\n    if yaml is None:\\\\\\\\n        raise RuntimeError(\\\\\\\n    \\\\\\\\\\\"PyYAML not installed; run `pip install pyyaml`\\\\\\\\\\\\\\\")\\\\\\\\n    data = {\\\\\\\n    \\\\n        \\\\\\\\\\\\\\\"root\\\\\\\\\\\\\\\": root,\\\\\\\\n        \\\\\\\\\\\\\\\"repo_info\\\\\\\\\\\\\\\":\\\n    \\ repo_info,\\\\\\\\n        \\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\": tree_text,\\\\\\\\n        \\\\\\\\\\\n    \\\\\\\"recent_changes\\\\\\\\\\\\\\\": recent_files or [],\\\\\\\\n        \\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\n    \\\": files,\\\\\\\\n        \\\\\\\\\\\\\\\"file_sizes\\\\\\\\\\\\\\\": file_sizes or {},\\\\\\\\n    \\\n    \\    \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\": total_files, \\\\\\\\\\\\\\\n    \\\"total_lines\\\\\\\\\\\\\\\": total_lines},\\\\\\\\n        \\\\\\\\n    }\\\\\\\\n    return yaml.safe_dump(data,\\\n    \\ sort_keys=False, allow_unicode=True)\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/renderer/markdown.py\\\\\\\n    \\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Markdown renderer for repository context.\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom typing import Dict, Any\\\\\\\\n\\\\\\\\n\\\\\\\\ndef render_markdown(root:\\\n    \\ str, repo_info: Dict[str, Any], tree_text: str, \\\\\\\\n                   files:\\\n    \\ Dict[str, str], total_files: int, total_lines: int, recent_files=None, file_sizes=None)\\\n    \\ -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Render repository context as markdown.\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    lines = []\\\\\\\\n    \\\\\\\\n    # Header\\\\\\\n    \\\\n    lines.append(f\\\\\\\\\\\\\\\"# Repository Context: {root}\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # Repository info\\\\\\\\n    if repo_info.get(\\\\\\\n    \\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\"):\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\"## Git Repository Information\\\\\\\n    \\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\"- **Branch**: {repo_info.get('branch',\\\n    \\ 'N/A')}\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\"- **Commit**: {repo_info.get('commit',\\\n    \\ 'N/A')}\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\"- **Author**: {repo_info.get('author',\\\n    \\ 'N/A')}\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\"- **Date**: {repo_info.get('date',\\\n    \\ 'N/A')}\\\\\\\\\\\\\\\")\\\\\\\\n    else:\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\"## Repository\\\n    \\ Information\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\"- **Note**: {repo_info.get('note',\\\n    \\ 'Not a git repository')}\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\\\\n    n    \\\\\\\\n    # Summary\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"## Summary\\\\\\\\\\\\\\\")\\\\\\\\n\\\n    \\    lines.append(f\\\\\\\\\\\\\\\"- **Total Files**: {total_files}\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(f\\\\\\\n    \\\\\\\\\\\"- **Total Lines**: {total_lines}\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"\\\\\\\n    \\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # Directory structure\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"##\\\n    \\ Directory Structure\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"```\\\\\\\\\\\\\\\")\\\\\\\\n\\\n    \\    lines.append(tree_text)\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"```\\\\\\\\\\\\\\\")\\\\\\\\n  \\\n    \\  lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # will produce recent files \\\\\\\\\\\n    n    # Recent files (fixed)\\\\\\\\n    if recent_files:\\\\\\\\n        lines.append(\\\\\\\n    \\\\\\\\\\\"## Recent Changes\\\\\\\\\\\\\\\")\\\\\\\\n        for file, age in recent_files.items():\\\\\\\n    \\\\n            lines.append(f\\\\\\\\\\\\\\\"- {file} (modified {age})\\\\\\\\\\\\\\\")\\\\\\\\n \\\n    \\       lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # File contents\\\\\\\\n \\\n    \\   lines.append(\\\\\\\\\\\\\\\"## File Contents\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    for file_path, content in sorted(files.items()):\\\\\\\n    \\\\n        if file_sizes and file_path in file_sizes:\\\\\\\\n            size_bytes\\\n    \\ = file_sizes[file_path]\\\\\\\\n            lines.append(f\\\\\\\\\\\\\\\"### {file_path}\\\n    \\ ({size_bytes} bytes)\\\\\\\\\\\\\\\")\\\\\\\\n        else:\\\\\\\\n            lines.append(f\\\\\\\n    \\\\\\\\\\\"### {file_path}\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\\\\n    n        \\\\\\\\n        # Detect language for syntax highlighting\\\\\\\\n        ext\\\n    \\ = file_path.split('.')[-1].lower() if '.' in file_path else ''\\\\\\\\n        lang_map\\\n    \\ = {\\\\\\\\n            'py': 'python', 'js': 'javascript', 'ts': 'typescript',\\\\\\\n    \\\\n            'java': 'java', 'cpp': 'cpp', 'c': 'c', 'h': 'c',\\\\\\\\n        \\\n    \\    'cs': 'csharp', 'php': 'php', 'rb': 'ruby',\\\\\\\\n            'go': 'go', 'rs':\\\n    \\ 'rust', 'swift': 'swift',\\\\\\\\n            'html': 'html', 'css': 'css', 'scss':\\\n    \\ 'scss',\\\\\\\\n            'json': 'json', 'yaml': 'yaml', 'yml': 'yaml',\\\\\\\\n\\\n    \\            'xml': 'xml', 'sql': 'sql', 'sh': 'bash',\\\\\\\\n            'md': 'markdown',\\\n    \\ 'dockerfile': 'dockerfile'\\\\\\\\n        }\\\\\\\\n        \\\\\\\\n        language =\\\n    \\ lang_map.get(ext, '')\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\"```{language}\\\\\\\\\\\\\\\"\\\n    )\\\\\\\\n        lines.append(content)\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\"```\\\\\\\\\\\\\\\n    \\\")\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    return \\\\\\\\\\\\\\\"\\\n    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\".join(lines)\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/treeview.py\\\\\\\":\\\n    \\ \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Tree view generation for repository structure.\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import\\\n    \\ Dict, List\\\\\\\\n\\\\\\\\n\\\\\\\\ndef create_tree_view(repo_path: Path, files_data: Dict[str,\\\n    \\ str]) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create a tree view of the repository\\\n    \\ structure.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    paths = list(files_data.keys())\\\\\\\n    \\\\n    return render_tree(paths)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef render_tree(paths: List[str])\\\n    \\ -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Render a tree view from a list of relative\\\n    \\ POSIX paths.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    tree_structure: dict = {}\\\\\\\\n\\\\\\\n    \\\\n    for p in paths:\\\\\\\\n        parts = Path(p).parts\\\\\\\\n        current =\\\n    \\ tree_structure\\\\\\\\n        for part in parts[:-1]:\\\\\\\\n            if part not\\\n    \\ in current:\\\\\\\\n                current[part] = {}\\\\\\\\n            current =\\\n    \\ current[part]\\\\\\\\n        if parts:\\\\\\\\n            current[parts[-1]] = None\\\\\\\n    \\\\n\\\\\\\\n    def _render(structure: dict, prefix: str = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\") -> str:\\\\\\\n    \\\\n        lines = []\\\\\\\\n        items = sorted(structure.items(), key=lambda\\\n    \\ x: (x[1] is None, x[0]))\\\\\\\\n        for i, (name, subtree) in enumerate(items):\\\\\\\n    \\\\n            is_last = i == len(items) - 1\\\\\\\\n            lines.append(f\\\\\\\\\\\n    \\\\\\\"{prefix}{'└── ' if is_last else '├── '}{name}\\\\\\\\\\\\\\\")\\\\\\\\n            if\\\n    \\ subtree is not None:\\\\\\\\n                extension = (\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\" if\\\n    \\ is_last else \\\\\\\\\\\\\\\"│   \\\\\\\\\\\\\\\")\\\\\\\\n                lines.append(_render(subtree,\\\n    \\ prefix + extension))\\\\\\\\n        return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\".join(filter(None,\\\n    \\ lines))\\\\\\\\n\\\\\\\\n    if not tree_structure:\\\\\\\\n        return \\\\\\\\\\\\\\\"No files\\\n    \\ found\\\\\\\\\\\\\\\"\\\\\\\\n    return _render(tree_structure)\\\\\\\"\\\\n  },\\\\n  \\\\\\\"file_sizes\\\\\\\n    \\\": {\\\\n    \\\\\\\"LICENSE\\\\\\\": \\\\\\\"1064\\\\\\\",\\\\n    \\\\\\\"README.md\\\\\\\": \\\\\\\"11164\\\\\\\n    \\\",\\\\n    \\\\\\\"pyproject.toml\\\\\\\": \\\\\\\"361\\\\\\\",\\\\n    \\\\\\\"src/rcpack/__init__.py\\\\\\\n    \\\": \\\\\\\"198\\\\\\\",\\\\n    \\\\\\\"src/rcpack/__main__.py\\\\\\\": \\\\\\\"197\\\\\\\",\\\\n    \\\\\\\"\\\n    src/rcpack/cli.py\\\\\\\": \\\\\\\"7087\\\\\\\",\\\\n    \\\\\\\"src/rcpack/config_loader.py\\\\\\\"\\\n    : \\\\\\\"2099\\\\\\\",\\\\n    \\\\\\\"src/rcpack/discover.py\\\\\\\": \\\\\\\"3067\\\\\\\",\\\\n    \\\\\\\"\\\n    src/rcpack/gitinfo.py\\\\\\\": \\\\\\\"1653\\\\\\\",\\\\n    \\\\\\\"src/rcpack/io_utils.py\\\\\\\"\\\n    : \\\\\\\"1817\\\\\\\",\\\\n    \\\\\\\"src/rcpack/packager.py\\\\\\\": \\\\\\\"4430\\\\\\\",\\\\n    \\\\\\\"\\\n    src/rcpack/renderer/jsonyaml.py\\\\\\\": \\\\\\\"1176\\\\\\\",\\\\n    \\\\\\\"src/rcpack/renderer/markdown.py\\\\\\\n    \\\": \\\\\\\"2829\\\\\\\",\\\\n    \\\\\\\"src/rcpack/treeview.py\\\\\\\": \\\\\\\"1371\\\\\\\"\\\\n  },\\\\\\\n    n  \\\\\\\"summary\\\\\\\": {\\\\n    \\\\\\\"total_files\\\\\\\": 14,\\\\n    \\\\\\\"total_lines\\\\\\\"\\\n    : 1180\\\\n  }\\\\n}\\\",\\n    \\\"test-yaml.yaml\\\": \\\"root: /Users/abhinavbhardwaj/Desktop/Semester\\\n    \\ 5/OSD600/Repo-Contextor\\\\nrepo_info:\\\\n  is_repo: true\\\\n  commit: 682153b169db66d3a72e9cabdd1f3448a3b2986d\\\\\\\n    n  branch: refactoring\\\\n  author: Abhinav <abhinavbhardwaj2002@gmail.com>\\\\n\\\n    \\  date: Fri Oct 3 18:45:48 2025\\\\n  note: null\\\\nstructure: '├── src\\\\n\\\\n  │\\\n    \\   └── rcpack\\\\n\\\\n  │       ├── renderer\\\\n\\\\n  │       │   ├── jsonyaml.py\\\\\\\n    n\\\\n  │       │   └── markdown.py\\\\n\\\\n  │       ├── __init__.py\\\\n\\\\n  │    \\\n    \\   ├── __main__.py\\\\n\\\\n  │       ├── cli.py\\\\n\\\\n  │       ├── config_loader.py\\\\\\\n    n\\\\n  │       ├── discover.py\\\\n\\\\n  │       ├── gitinfo.py\\\\n\\\\n  │       ├──\\\n    \\ io_utils.py\\\\n\\\\n  │       ├── packager.py\\\\n\\\\n  │       └── treeview.py\\\\\\\n    n\\\\n  ├── LICENSE\\\\n\\\\n  ├── README.md\\\\n\\\\n  ├── pyproject.toml\\\\n\\\\n  └── test-output.json'\\\\\\\n    nrecent_changes: []\\\\nfiles:\\\\n  LICENSE: 'MIT License\\\\n\\\\n\\\\n    Copyright (c)\\\n    \\ 2025 Abhinav\\\\n\\\\n\\\\n    Permission is hereby granted, free of charge, to any\\\n    \\ person obtaining a copy\\\\n\\\\n    of this software and associated documentation\\\n    \\ files (the \\\\\\\"Software\\\\\\\"), to deal\\\\n\\\\n    in the Software without restriction,\\\n    \\ including without limitation the rights\\\\n\\\\n    to use, copy, modify, merge,\\\n    \\ publish, distribute, sublicense, and/or sell\\\\n\\\\n    copies of the Software,\\\n    \\ and to permit persons to whom the Software is\\\\n\\\\n    furnished to do so, subject\\\n    \\ to the following conditions:\\\\n\\\\n\\\\n    The above copyright notice and this\\\n    \\ permission notice shall be included in all\\\\n\\\\n    copies or substantial portions\\\n    \\ of the Software.\\\\n\\\\n\\\\n    THE SOFTWARE IS PROVIDED \\\\\\\"AS IS\\\\\\\", WITHOUT\\\n    \\ WARRANTY OF ANY KIND, EXPRESS OR\\\\n\\\\n    IMPLIED, INCLUDING BUT NOT LIMITED\\\n    \\ TO THE WARRANTIES OF MERCHANTABILITY,\\\\n\\\\n    FITNESS FOR A PARTICULAR PURPOSE\\\n    \\ AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n\\\\n    AUTHORS OR COPYRIGHT HOLDERS\\\n    \\ BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n\\\\n    LIABILITY, WHETHER IN AN\\\n    \\ ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n\\\\n    OUT OF OR IN CONNECTION\\\n    \\ WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n\\\\n    SOFTWARE.\\\\n\\\\\\\n    n    '\\\\n  README.md: \\\\\\\"# Repo-Contextor\\\\\\\\n\\\\\\\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\\\\\\n    \\\\n\\\\\\\\\\\\n    [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\\\\\\n    \\\\n\\\\\\\\\\\\n    \\\\\\\\nA powerful Repository Context Packager CLI tool that analyzes\\\n    \\ local git repositories\\\\\\\\\\\\n    \\\\\\\\ and creates comprehensive text files containing\\\n    \\ repository content optimized\\\\\\\\\\\\n    \\\\\\\\ for sharing with Large Language\\\n    \\ Models (LLMs).\\\\\\\\n\\\\\\\\n## Overview\\\\\\\\n\\\\\\\\nWhen developers\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ want to get help from ChatGPT, Claude, or other LLMs about their code, they\\\\\\\n    \\\\\\\\n    \\\\\\\\ often struggle with how to share their codebase effectively. Common\\\n    \\ problems\\\\\\\\\\\\n    \\\\\\\\ include:\\\\\\\\n\\\\\\\\n- **Lost Context**: Copy-pasting individual\\\n    \\ files loses important\\\\\\\\\\\\n    \\\\\\\\ project structure and relationships\\\\\\\\\\\n    n- **Missing Dependencies**: LLMs can't\\\\\\\\\\\\n    \\\\\\\\ see how files connect or\\\n    \\ what libraries are used\\\\\\\\n- **Incomplete Picture**:\\\\\\\\\\\\n    \\\\\\\\ Hard to\\\n    \\ convey the overall architecture and organization\\\\\\\\n- **Manual Work**:\\\\\\\\\\\\\\\n    n    \\\\\\\\ Time-consuming to gather and format relevant code\\\\\\\\n\\\\\\\\n**Repo-Contextor**\\\n    \\ solves\\\\\\\\\\\\n    \\\\\\\\ this by automatically collecting and formatting repository\\\n    \\ content into a single,\\\\\\\\\\\\n    \\\\\\\\ well-structured text file that provides\\\n    \\ rich context to LLMs, enabling them\\\\\\\\\\\\n    \\\\\\\\ to give much better assistance\\\n    \\ with your code.\\\\\\\\n\\\\\\\\n## Features\\\\\\\\n\\\\\\\\n- **Git Integration**:\\\\\\\\\\\\n\\\n    \\    \\\\\\\\ Extracts commit SHA, branch, author, and date information\\\\\\\\n- **Project\\\n    \\ Structure**:\\\\\\\\\\\\n    \\\\\\\\ Generates a clear directory tree visualization\\\\\\\n    \\\\n- **File Content Packaging**:\\\\\\\\\\\\n    \\\\\\\\ Includes file contents with syntax\\\n    \\ highlighting\\\\\\\\n- **Smart File Discovery**:\\\\\\\\\\\\n    \\\\\\\\ Recursively scans\\\n    \\ directories with intelligent filtering\\\\\\\\n- **Binary File Detection**:\\\\\\\\\\\\\\\n    n    \\\\\\\\ Automatically skips binary files\\\\\\\\n- **Error Handling**: Gracefully\\\n    \\ handles permission\\\\\\\\\\\\n    \\\\\\\\ errors and provides helpful messages\\\\\\\\n-\\\n    \\ **Multiple Output Formats**: Supports\\\\\\\\\\\\n    \\\\\\\\ Markdown, JSON, and YAML\\\n    \\ formats\\\\\\\\n- **Flexible Output**: Write to stdout or\\\\\\\\\\\\n    \\\\\\\\ save to\\\n    \\ a file\\\\\\\\n- **Recent Changes Filter**: Give the files which are updated\\\\\\\\\\\n    \\\\n    \\\\\\\\ in last 7days with the time when it was recently modified.\\\\\\\\n\\\\\\\\\\\n    n## Installation\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\n### Prerequisites\\\\\\\\n\\\\\\\\n- Python 3.9 or\\\n    \\ higher\\\\\\\\n- Git (for git repository analysis)\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\n### For End\\\n    \\ Users\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Clone and install\\\\\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    \\\\n\\\\\\\\\\\\n    cd Repo-Contextor\\\\\\\\npip install -e .\\\\\\\\n```\\\\\\\\n\\\\\\\\n### For\\\n    \\ Contributors & Local Development\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\n```bash\\\\\\\\n# Clone the\\\n    \\ repository\\\\\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    \\\\n\\\\\\\\\\\\n    cd Repo-Contextor\\\\\\\\n\\\\\\\\n# Create virtual environment\\\\\\\\npython\\\n    \\ -m venv .venv\\\\\\\\nsource\\\\\\\\\\\\n    \\\\\\\\ .venv/bin/activate  # On Windows: .venv\\\\\\\n    \\\\\\\\\\\\Scripts\\\\\\\\\\\\\\\\activate\\\\\\\\n\\\\\\\\n# Install in development\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ mode\\\\\\\\npip install -e .\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Usage\\\\\\\\n\\\\\\\\n### Basic Examples\\\\\\\n    \\\\n\\\\\\\\n```bash\\\\\\\\n#\\\\\\\\\\\\n    \\\\\\\\ Package current directory to terminal\\\\\\\\\\\n    nrepo-contextor .\\\\\\\\n\\\\\\\\n# Package a specific\\\\\\\\\\\\n    \\\\\\\\ directory\\\\\\\\nrepo-contextor\\\n    \\ /path/to/your/project\\\\\\\\n\\\\\\\\n# Save output to a file\\\\\\\\n\\\\\\\\\\\\n    repo-contextor\\\n    \\ . -o my-project-context.md\\\\\\\\n\\\\\\\\n# Generate JSON format\\\\\\\\nrepo-contextor\\\\\\\n    \\\\\\\\n    \\\\\\\\ . -f json -o context.json\\\\\\\\n\\\\\\\\n# Generate YAML format\\\\\\\\nrepo-contextor\\\n    \\ . -f yaml\\\\\\\\\\\\n    \\\\\\\\ -o context.yaml\\\\\\\\n\\\\\\\\n# Include only files modified\\\n    \\ in the last 7 days\\\\\\\\nrepo-contextor\\\\\\\\\\\\n    \\\\\\\\ . --recent\\\\\\\\n\\\\\\\\n# Combine\\\n    \\ with output file\\\\\\\\nrepo-contextor . --recent -o recent-changes.md\\\\\\\\n\\\\\\\\\\\n    \\\\n    ```\\\\\\\\n\\\\\\\\n### Command Line Options\\\\\\\\n\\\\\\\\n| Option | Short | Description\\\n    \\ | Example |\\\\\\\\n\\\\\\\\\\\\n    |--------|-------|-------------|---------|\\\\\\\\n|\\\n    \\ `path` | - | Repository path to\\\\\\\\\\\\n    \\\\\\\\ analyze (default: current directory)\\\n    \\ | `repo-contextor /path/to/project` |\\\\\\\\n\\\\\\\\\\\\n    | `--output` | `-o` | Output\\\n    \\ file path (default: stdout) | `-o context.md` |\\\\\\\\n\\\\\\\\\\\\n    | `--format`\\\n    \\ | `-f` | Output format: text, json, yaml (default: text) | `-f json`\\\\\\\\\\\\n\\\n    \\    \\\\\\\\ |\\\\\\\\n| `--help` | `-h` | Show help message | `-h` |\\\\\\\\n| `--recent`\\\n    \\  | `-r`  | Include\\\\\\\\\\\\n    \\\\\\\\ only files modified in the last 7 days   \\\n    \\ | `repo-contextor . -r -o recent.md`\\\\\\\\\\\\n    \\\\\\\\ |\\\\\\\\n\\\\\\\\n### Advanced\\\n    \\ Examples\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Analyze different repository\\\\\\\\nrepo-contextor\\\\\\\n    \\\\\\\\n    \\\\\\\\ /path/to/other/project -o other-project.md\\\\\\\\n\\\\\\\\n# Generate JSON\\\n    \\ for API consumption\\\\\\\\n\\\\\\\\\\\\n    repo-contextor . -f json -o api-context.json\\\\\\\n    \\\\n\\\\\\\\n# Create YAML configuration\\\\\\\\n\\\\\\\\\\\\n    repo-contextor . -f yaml -o\\\n    \\ project-config.yaml\\\\\\\\n\\\\\\\\n# Generate files which are\\\\\\\\\\\\n    \\\\\\\\ changed\\\n    \\ recently in 7 days\\\\\\\\nrepo-contextor . -r --output recent-changes.txt\\\\\\\\n\\\\\\\n    \\\\\\\\n    \\\\\\\\n```\\\\\\\\n## Configuration via TOML\\\\\\\\n\\\\\\\\nRepo-Contextor supports\\\n    \\ configuration through\\\\\\\\\\\\n    \\\\\\\\ a `.repo-contextor.toml` file in the current\\\n    \\ working directory.  \\\\\\\\nThis file\\\\\\\\\\\\n    \\\\\\\\ allows you to avoid typing\\\n    \\ the same CLI arguments every time.\\\\\\\\n\\\\\\\\nExample `.repo-contextor.toml`:\\\\\\\n    \\\\n\\\\\\\\\\\\n    \\\\\\\\n```toml\\\\\\\\n# Output file to write results\\\\\\\\noutput = \\\\\\\\\\\n    \\\\\\\"context.yaml\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Output\\\\\\\\\\\\n    \\\\\\\\ format: text, json,\\\n    \\ or yaml\\\\\\\\nformat = \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Limit to files modified\\\\\\\n    \\\\\\\\n    \\\\\\\\ in the last 7 days\\\\\\\\nrecent = true\\\\\\\\n\\\\\\\\n# Repository path\\\n    \\ to analyze (default =\\\\\\\\\\\\n    \\\\\\\\ current directory)\\\\\\\\npath = \\\\\\\\\\\\\\\"\\\n    .\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n### Rules\\\\\\\\n- If the `.repo-contextor.toml`\\\\\\\\\\\\n   \\\n    \\ \\\\\\\\ file is **missing**, the tool falls back to defaults.  \\\\\\\\n- If the file\\\n    \\ is **present\\\\\\\\\\\\n    \\\\\\\\ but invalid TOML**, the tool prints a clear error\\\n    \\ message and exits with status\\\\\\\\\\\\n    \\\\\\\\ code 1.  \\\\\\\\n- **Unknown keys**\\\n    \\ in the TOML file are ignored (safe for future\\\\\\\\\\\\n    \\\\\\\\ extensions).  \\\\\\\n    \\\\n- **Precedence** of settings is:\\\\\\\\n  1. Command-line arguments\\\\\\\\\\\\n   \\\n    \\ \\\\\\\\ (highest priority)  \\\\\\\\n  2. Values from `.repo-contextor.toml`  \\\\\\\\\\\n    n  3. Built-in\\\\\\\\\\\\n    \\\\\\\\ defaults (lowest priority)\\\\\\\\n     \\\\\\\\n## Output\\\n    \\ Format\\\\\\\\n\\\\\\\\nThe tool generates a\\\\\\\\\\\\n    \\\\\\\\ structured text file with\\\n    \\ the following sections:\\\\\\\\n\\\\\\\\n### 1. Repository Context\\\\\\\\\\\\n    \\\\\\\\ Header\\\\\\\n    \\\\nProject path and identification\\\\\\\\n\\\\\\\\n### 2. Git Repository Information\\\\\\\n    \\\\n\\\\\\\\\\\\n    - Current branch\\\\\\\\n- Latest commit SHA\\\\\\\\n- Last commit author\\\\\\\n    \\\\n- Last commit date\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\n### 3. Summary Statistics\\\\\\\\n- Total\\\n    \\ number of files processed\\\\\\\\n- Total lines\\\\\\\\\\\\n    \\\\\\\\ of code\\\\\\\\n\\\\\\\\\\\n    n### 4. Directory Structure\\\\\\\\nClean tree visualization showing project\\\\\\\\\\\\\\\n    n    \\\\\\\\ organization\\\\\\\\n\\\\\\\\n### 5. Recent Changes (if `--recent` is used)\\\\\\\n    \\\\n\\\\\\\\n- Lists files\\\\\\\\\\\\n    \\\\\\\\ modified in the last 7 days.\\\\\\\\n- Shows\\\n    \\ relative file paths along with how long\\\\\\\\\\\\n    \\\\\\\\ ago each file was modified\\\\\\\n    \\\\n- Helps focus on recently updated parts of the project.\\\\\\\\n\\\\\\\\\\\\n    - Can\\\n    \\ be combined with `--output` or `--format` to save or change the output type.\\\\\\\n    \\\\n\\\\\\\\\\\\n    \\\\\\\\n\\\\\\\\n### 5. File Contents\\\\\\\\nEach file's content with:\\\\\\\\\\\n    n- Clear file path headers\\\\\\\\n\\\\\\\\\\\\n    - Appropriate syntax highlighting language\\\n    \\ tags\\\\\\\\n- Complete file contents\\\\\\\\n\\\\\\\\n\\\\\\\\\\\\n    ## Example Output\\\\\\\\\\\n    n\\\\\\\\nWhen you run `repo-contextor .`, the output looks like this:\\\\\\\\n\\\\\\\\\\\\\\\n    n    \\\\\\\\n````markdown\\\\\\\\n# Repository Context: /path/to/your/project\\\\\\\\n\\\\\\\\\\\n    n## Git Repository\\\\\\\\\\\\n    \\\\\\\\ Information\\\\\\\\n- **Branch**: main\\\\\\\\n- **Commit**:\\\n    \\ a1b2c3d4e5f6789...\\\\\\\\n- **Author**:\\\\\\\\\\\\n    \\\\\\\\ John Doe <john@example.com>\\\\\\\n    \\\\n- **Date**: Fri Sep 12 14:30:15 2025\\\\\\\\n\\\\\\\\n## Summary\\\\\\\\n\\\\\\\\\\\\n    - **Total\\\n    \\ Files**: 15\\\\\\\\n- **Total Lines**: 1,247\\\\\\\\n\\\\\\\\n## Directory Structure\\\\\\\\\\\n    n```\\\\\\\\n\\\\\\\\\\\\n    ├── src/\\\\\\\\n│   ├── main.py\\\\\\\\n│   └── utils.py\\\\\\\\n├──\\\n    \\ tests/\\\\\\\\n│   └── test_main.py\\\\\\\\n\\\\\\\\\\\\n    ├── README.md\\\\\\\\n└── requirements.txt\\\\\\\n    \\\\n```\\\\\\\\n## Recent Changes\\\\\\\\n- src/main.py (modified\\\\\\\\\\\\n    \\\\\\\\ 2 days\\\n    \\ ago)\\\\\\\\n- src/utils/helpers.py (modified 5 days ago)\\\\\\\\n\\\\\\\\n## File Contents\\\\\\\n    \\\\n\\\\\\\\\\\\n    \\\\\\\\n### src/main.py\\\\\\\\n\\\\\\\\n```python\\\\\\\\ndef main():\\\\\\\\n   \\\n    \\ print(\\\\\\\\\\\\\\\"Hello, World!\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n\\\\\\\\\\\\n    if __name__ == \\\\\\\\\\\n    \\\\\\\"__main__\\\\\\\\\\\\\\\":\\\\\\\\n    main()\\\\\\\\n```\\\\\\\\n\\\\\\\\n### README.md\\\\\\\\n\\\\\\\\n```markdown\\\\\\\n    \\\\n\\\\\\\\\\\\n    # My Project\\\\\\\\nThis is a sample project.\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Summary\\\\\\\n    \\\\n- Total files: 15\\\\\\\\n\\\\\\\\\\\\n    - Total lines: 1,247\\\\\\\\n````\\\\\\\\n\\\\\\\\n##\\\n    \\ What Files Are Included\\\\\\\\n\\\\\\\\nThe tool includes\\\\\\\\\\\\n    \\\\\\\\ most text\\\n    \\ files but automatically excludes:\\\\\\\\n\\\\\\\\n### Excluded Directories\\\\\\\\n- `.git`,\\\\\\\n    \\\\\\\\n    \\\\\\\\ `.svn`, `.hg` (version control)\\\\\\\\n- `__pycache__`, `.pytest_cache`\\\n    \\ (Python cache)\\\\\\\\n\\\\\\\\\\\\n    - `node_modules`, `.venv`, `venv` (dependencies/environments)\\\\\\\n    \\\\n- `.vscode`, `.idea`\\\\\\\\\\\\n    \\\\\\\\ (IDE directories)\\\\\\\\n- `build`, `dist`,\\\n    \\ `target` (build directories)\\\\\\\\n\\\\\\\\n### File\\\\\\\\\\\\n    \\\\\\\\ Handling Rules\\\\\\\n    \\\\n- **Text files**: All readable text files with common extensions\\\\\\\\n\\\\\\\\\\\\\\\n    n    - **Binary files**: Automatically detected and skipped\\\\\\\\n- **Permission\\\n    \\ errors**:\\\\\\\\\\\\n    \\\\\\\\ Skipped with graceful handling\\\\\\\\n- **Configuration\\\n    \\ files**: Includes pyproject.toml,\\\\\\\\\\\\n    \\\\\\\\ package.json, etc.\\\\\\\\n\\\\\\\\\\\n    n### Included File Types\\\\\\\\n- Source code: `.py`, `.js`,\\\\\\\\\\\\n    \\\\\\\\ `.ts`,\\\n    \\ `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\\\\\\\n- Web files: `.html`, `.css`,\\\\\\\n    \\\\\\\\n    \\\\\\\\ `.scss`, `.vue`, `.jsx`, etc.\\\\\\\\n- Documentation: `.md`, `.txt`,\\\n    \\ `.rst`\\\\\\\\n- Configuration:\\\\\\\\\\\\n    \\\\\\\\ `.json`, `.yaml`, `.toml`, `.ini`,\\\n    \\ `.cfg`\\\\\\\\n- Scripts: `.sh`, `.bash`, `.zsh`\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\n## Error Handling\\\\\\\n    \\\\n\\\\\\\\nThe tool handles errors gracefully:\\\\\\\\n\\\\\\\\n| Error Type | Behavior\\\\\\\n    \\\\\\\\n    \\\\\\\\ |\\\\\\\\n|------------|----------|\\\\\\\\n| **Permission errors** | Skipped\\\n    \\ with warning\\\\\\\\\\\\n    \\\\\\\\ |\\\\\\\\n| **Binary files** | Automatically detected\\\n    \\ and skipped |\\\\\\\\n| **Invalid paths**\\\\\\\\\\\\n    \\\\\\\\ | Clear error messages\\\n    \\ |\\\\\\\\n| **Non-git repositories** | Works fine, shows \\\\\\\\\\\\\\\"\\\\\\\\\\\\n    Not\\\n    \\ a git repository\\\\\\\\\\\\\\\" |\\\\\\\\n| **Unreadable files** | Marked as \\\\\\\\\\\\\\\"[Binary\\\n    \\ or unreadable\\\\\\\\\\\\n    \\\\\\\\ file]\\\\\\\\\\\\\\\" |\\\\\\\\n\\\\\\\\n## Development\\\\\\\\n\\\\\\\\\\\n    n### Project Structure\\\\\\\\n\\\\\\\\n```text\\\\\\\\nRepo-Contextor/\\\\\\\\n\\\\\\\\\\\\n    ├──\\\n    \\ src/rcpack/              # Main package\\\\\\\\n│   ├── __init__.py         # Package\\\\\\\n    \\\\\\\\n    \\\\\\\\ initialization\\\\\\\\n│   ├── cli.py              # Command-line interface\\\\\\\n    \\\\n│   ├──\\\\\\\\\\\\n    \\\\\\\\ discover.py         # File discovery logic\\\\\\\\n│   ├──\\\n    \\ gitinfo.py          # Git\\\\\\\\\\\\n    \\\\\\\\ repository analysis\\\\\\\\n│   ├── treeview.py\\\n    \\         # Directory tree generation\\\\\\\\n\\\\\\\\\\\\n    │   ├── packager.py     \\\n    \\    # Main orchestration\\\\\\\\n│   ├── io_utils.py        \\\\\\\\\\\\n    \\\\\\\\ # File\\\n    \\ I/O utilities\\\\\\\\n│   └── renderer/           # Output formatters\\\\\\\\n│   \\\\\\\n    \\\\\\\\n    \\\\\\\\    ├── markdown.py     # Markdown renderer\\\\\\\\n│       └── jsonyaml.py\\\n    \\     # JSON/YAML\\\\\\\\\\\\n    \\\\\\\\ renderers\\\\\\\\n├── pyproject.toml          # Project\\\n    \\ configuration\\\\\\\\n├── LICENSE\\\\\\\\\\\\n    \\\\\\\\                 # MIT License\\\\\\\n    \\\\n└── README.md              # This documentation\\\\\\\\n\\\\\\\\\\\\n    ```\\\\\\\\n\\\\\\\\\\\n    n### Running Tests\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Test on current repository\\\\\\\\nrepo-contextor\\\\\\\n    \\\\\\\\n    \\\\\\\\ . -o test-output.md\\\\\\\\n\\\\\\\\n# Test different formats\\\\\\\\nrepo-contextor\\\n    \\ . -f json |\\\\\\\\\\\\n    \\\\\\\\ head -20\\\\\\\\nrepo-contextor . -f yaml | head -20\\\\\\\n    \\\\n\\\\\\\\n# Test specific directory\\\\\\\\n\\\\\\\\\\\\n    repo-contextor src/ -o src-only.md\\\\\\\n    \\\\n```\\\\\\\\n\\\\\\\\n### Contributing\\\\\\\\n\\\\\\\\n1. **Fork the repository**\\\\\\\\n\\\\\\\\\\\\\\\n    n    2. **Clone your fork:**\\\\\\\\n   ```bash\\\\\\\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    \\\\n\\\\\\\\\\\\n    \\\\\\\\   cd Repo-Contextor\\\\\\\\n   ```\\\\\\\\n3. **Install for development:**\\\\\\\n    \\\\n   ```bash\\\\\\\\n \\\\\\\\\\\\n    \\\\\\\\  python -m venv .venv\\\\\\\\n   source .venv/bin/activate\\\\\\\n    \\\\n   pip install -e .\\\\\\\\n \\\\\\\\\\\\n    \\\\\\\\  ```\\\\\\\\n4. **Make your changes and\\\n    \\ test:**\\\\\\\\n   ```bash\\\\\\\\n   repo-contextor . -o\\\\\\\\\\\\n    \\\\\\\\ test.md\\\\\\\\\\\n    n   ```\\\\\\\\n5. **Submit a pull request**\\\\\\\\n\\\\\\\\n### Development Workflow\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\\\\\\n    ```bash\\\\\\\\n# 1. Setup development environment\\\\\\\\ngit clone\\\n    \\ https://github.com/yourusername/Repo-Contextor.git\\\\\\\\n\\\\\\\\\\\\n    cd Repo-Contextor\\\\\\\n    \\\\npython -m venv .venv\\\\\\\\nsource .venv/bin/activate\\\\\\\\npip install\\\\\\\\\\\\n \\\n    \\   \\\\\\\\ -e .\\\\\\\\n\\\\\\\\n# 2. Make changes to the code\\\\\\\\n# Edit files in src/rcpack/\\\\\\\n    \\\\n\\\\\\\\n# 3. Test\\\\\\\\\\\\n    \\\\\\\\ your changes\\\\\\\\nrepo-contextor . -o test-output.md\\\\\\\n    \\\\n\\\\\\\\n# 4. Test different formats\\\\\\\\n\\\\\\\\\\\\n    repo-contextor . -f json -o\\\n    \\ test.json\\\\\\\\nrepo-contextor . -f yaml -o test.yaml\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\n# 5.\\\n    \\ Commit and push changes\\\\\\\\ngit add .\\\\\\\\ngit commit -m \\\\\\\\\\\\\\\"Add new feature\\\\\\\n    \\\\\\\\\\\"\\\\\\\\n\\\\\\\\\\\\n    git push origin feature-branch\\\\\\\\n```\\\\\\\\n\\\\\\\\n## License\\\\\\\n    \\\\n\\\\\\\\nThis project is licensed\\\\\\\\\\\\n    \\\\\\\\ under the MIT License. See the\\\n    \\ [LICENSE](LICENSE) file for details.\\\\\\\\n\\\\\\\\n## Why\\\\\\\\\\\\n    \\\\\\\\ Repo-Contextor?\\\\\\\n    \\\\n\\\\\\\\nThe name \\\\\\\\\\\\\\\"Repo-Contextor\\\\\\\\\\\\\\\" combines \\\\\\\\\\\\\\\"Repository\\\\\\\\\\\n    \\\\\\\" + \\\\\\\\\\\\\\\"\\\\\\\\\\\\n    Context\\\\\\\\\\\\\\\" + \\\\\\\\\\\\\\\"or\\\\\\\\\\\\\\\", representing the\\\n    \\ tool's purpose of providing rich context\\\\\\\\\\\\n    \\\\\\\\ about code repositories\\\n    \\ in a format that's perfect for LLM interactions.\\\\\\\\n\\\\\\\\n\\\\\\\\\\\\n    ### Use\\\n    \\ Cases\\\\\\\\n\\\\\\\\n- **AI Assistance**: Get better help from ChatGPT, Claude, or\\\\\\\n    \\\\\\\\n    \\\\\\\\ GitHub Copilot\\\\\\\\n- **Code Reviews**: Share complete project context\\\n    \\ with team\\\\\\\\\\\\n    \\\\\\\\ members\\\\\\\\n- **Documentation**: Create comprehensive\\\n    \\ project snapshots\\\\\\\\n- **Onboarding**:\\\\\\\\\\\\n    \\\\\\\\ Help new team members\\\n    \\ understand project structure\\\\\\\\n- **Project Analysis**:\\\\\\\\\\\\n    \\\\\\\\ Understand\\\n    \\ repository structure and dependencies\\\\\\\\n\\\\\\\\n### Perfect for LLMs\\\\\\\\n\\\\\\\\\\\n    n\\\\\\\\\\\\n    The output format is specifically designed to work well with Large\\\n    \\ Language Models:\\\\\\\\n\\\\\\\\\\\\n    - Clear section headers for easy parsing\\\\\\\\\\\n    n- Syntax highlighting markers for code\\\\\\\\\\\\n    \\\\\\\\ blocks\\\\\\\\n- Structured\\\n    \\ metadata (git info, file locations)\\\\\\\\n- Complete project\\\\\\\\\\\\n    \\\\\\\\ context\\\n    \\ in a single file\\\\\\\\n- Multiple output formats (Markdown, JSON, YAML)\\\\\\\\n\\\\\\\n    \\\\\\\\n    - Optimized for token efficiency\\\\\\\\n\\\\\\\"\\\\n  pyproject.toml: \\\\\\\"[build-system]\\\\\\\n    \\\\nrequires = [\\\\\\\\\\\\\\\"setuptools>=68\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"wheel\\\\\\\\\\\\\\\"]\\\\\\\\nbuild-backend\\\\\\\n    \\\\\\\\n    \\\\\\\\ = \\\\\\\\\\\\\\\"setuptools.build_meta\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n[project]\\\\\\\\nname\\\n    \\ = \\\\\\\\\\\\\\\"rcpack\\\\\\\\\\\\\\\"\\\\\\\\nversion = \\\\\\\\\\\\\\\"0.1.0\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    \\\\\\\\\\\n    ndescription = \\\\\\\\\\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\\\\\\\\\"\\\\\\\\nreadme\\\n    \\ = \\\\\\\\\\\\\\\"README.md\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    \\\\\\\\nrequires-python = \\\\\\\\\\\\\\\">=3.9\\\\\\\n    \\\\\\\\\\\"\\\\\\\\nlicense = { text = \\\\\\\\\\\\\\\"MIT\\\\\\\\\\\\\\\" }\\\\\\\\ndependencies = [\\\\\\\\n\\\\\\\n    \\\\\\\\n    \\\\\\\\    \\\\\\\\\\\\\\\"PyYAML>=6.0\\\\\\\\\\\\\\\"\\\\\\\\n]\\\\\\\\n\\\\\\\\n[project.scripts]\\\\\\\n    \\\\nrepo-contextor = \\\\\\\\\\\\\\\"rcpack.cli:main\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    \\\\\\\\n\\\\\\\"\\\\n  src/rcpack/__init__.py:\\\n    \\ '\\\\\\\"\\\\\\\"\\\\\\\"Repository Context Packager - CLI tool for creating\\\\n    LLM-optimized\\\n    \\ repository context.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n\\\\n    __version__ = \\\\\\\"0.1.0\\\\\\\"\\\\n\\\\\\\n    n    __author__ = \\\\\\\"Abhinav\\\\\\\"\\\\n\\\\n    __description__ = \\\\\\\"Repository Context\\\n    \\ Packager CLI for LLMs\\\\\\\"'\\\\n  src/rcpack/__main__.py: \\\\\\\"#!/usr/bin/env python3\\\\\\\n    \\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Module entry point to enable\\\\\\\\\\\\n    \\\\\\\\ `python\\\n    \\ -m rcpack`.\\\\\\\\n\\\\\\\\nThis simply delegates to the CLI's main() function.\\\\\\\\\\\n    n\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom .cli import main\\\\\\\\n\\\\\\\\n\\\\\\\n    \\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\":\\\\\\\\n    main()\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\\\\n    n\\\\\\\\n\\\\\\\"\\\\n  src/rcpack/cli.py: \\\\\\\"#!/usr/bin/env python3\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\"CLI for Repository Context Packager.\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    \\\"\\\\\\\\n\\\\\\\\nfrom .config_loader import load_config\\\\\\\\n\\\\\\\\nimport argparse\\\\\\\\\\\n    nimport sys\\\\\\\\n\\\\\\\\\\\\n    from pathlib import Path\\\\\\\\nfrom .gitinfo import get_git_info\\\\\\\n    \\\\nfrom .discover import\\\\\\\\\\\\n    \\\\\\\\ discover_files\\\\\\\\nfrom .treeview import\\\n    \\ create_tree_view\\\\\\\\nfrom .renderer.markdown\\\\\\\\\\\\n    \\\\\\\\ import render_markdown\\\\\\\n    \\\\nfrom .renderer.jsonyaml import render_json, render_yaml\\\\\\\\n\\\\\\\\\\\\n    from\\\n    \\ .io_utils import write_output\\\\\\\\nfrom datetime import datetime, timedelta\\\\\\\n    \\\\n\\\\\\\\\\\\n    \\\\\\\\n\\\\\\\\ndef log_verbose(message: str, verbose: bool) -> None:\\\\\\\n    \\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Log a message\\\\\\\\\\\\n    \\\\\\\\ to stderr if verbose\\\n    \\ mode is enabled.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if verbose:\\\\\\\\n        print(message,\\\\\\\n    \\\\\\\\n    \\\\\\\\ file=sys.stderr)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef get_rendered_content(format_type:\\\n    \\ str, repo_path:\\\\\\\\\\\\n    \\\\\\\\ str, repo_info: dict, tree_text: str, \\\\\\\\n \\\n    \\                       files_data:\\\\\\\\\\\\n    \\\\\\\\ dict, total_files: int, total_lines:\\\n    \\ int, \\\\\\\\n                        recent_files_info:\\\\\\\\\\\\n    \\\\\\\\ dict, file_sizes:\\\n    \\ dict) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get rendered content based on\\\n    \\ the\\\\\\\\\\\\n    \\\\\\\\ specified format.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if format_type\\\n    \\ == \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\":\\\\\\\\n        return render_json(\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\\\\n    \\            repo_path, repo_info, tree_text, \\\\\\\\n            files_data, total_files,\\\\\\\n    \\\\\\\\n    \\\\\\\\ total_lines,\\\\\\\\n            recent_files=recent_files_info,\\\\\\\\\\\n    n            file_sizes=file_sizes\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        )\\\\\\\\n    elif format_type\\\n    \\ == \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\":\\\\\\\\n        return render_yaml(\\\\\\\\n \\\\\\\\\\\\n    \\\\\\\\\\\n    \\           repo_path, repo_info, tree_text, \\\\\\\\n            files_data, total_files,\\\\\\\n    \\\\\\\\n    \\\\\\\\ total_lines,\\\\\\\\n            recent_files=recent_files_info,\\\\\\\\\\\n    n            file_sizes=file_sizes\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        )\\\\\\\\n    else:\\\n    \\  # text/markdown\\\\\\\\n        return render_markdown(\\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\\\\n    \\        repo_path, repo_info, tree_text, \\\\\\\\n            files_data, total_files,\\\\\\\n    \\\\\\\\n    \\\\\\\\ total_lines,\\\\\\\\n            recent_files=recent_files_info,\\\\\\\\\\\n    n            file_sizes=file_sizes\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        )\\\\\\\\n\\\\\\\\n\\\\\\\\\\\n    ndef process_file(file_path: Path, repo_path: Path, verbose: bool)\\\\\\\\\\\\n    \\\\\\\n    \\\\ -> tuple[str, str, str]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Process a single file\\\n    \\ and return its data.\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    \\\\\\\\n    Returns:\\\\\\\\n        tuple:\\\n    \\ (relative_path_str, content, file_size)\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\"\\\\\\\\n    relative_path = file_path.relative_to(repo_path)\\\\\\\\n    relative_path_str\\\\\\\n    \\\\\\\\n    \\\\\\\\ = str(relative_path)\\\\\\\\n    \\\\\\\\n    log_verbose(f\\\\\\\\\\\\\\\"Reading\\\n    \\ file: {relative_path}\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    , verbose)\\\\\\\\n    file_size = file_path.stat().st_size\\\\\\\n    \\\\n    \\\\\\\\n    try:\\\\\\\\n       \\\\\\\\\\\\n    \\\\\\\\ with open(file_path, 'r', encoding='utf-8')\\\n    \\ as f:\\\\\\\\n            content = f.read()\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        return relative_path_str,\\\n    \\ content, str(file_size)\\\\\\\\n    except (UnicodeDecodeError,\\\\\\\\\\\\n    \\\\\\\\ PermissionError):\\\\\\\n    \\\\n        log_verbose(f\\\\\\\\\\\\\\\"Skipping binary/unreadable file: {relative_path}\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\n    , verbose)\\\\\\\\n        file_size = file_path.stat().st_size if\\\n    \\ file_path.exists()\\\\\\\\\\\\n    \\\\\\\\ else 0\\\\\\\\n        content = f\\\\\\\\\\\\\\\"[Binary\\\n    \\ or unreadable file: {file_path.name}]\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    \\\\\\\\n        return\\\n    \\ relative_path_str, content, str(file_size)\\\\\\\\n    except Exception:\\\\\\\\n\\\\\\\\\\\n    \\\\n    \\\\\\\\        log_verbose(f\\\\\\\\\\\\\\\"Error reading file: {relative_path}\\\\\\\\\\\n    \\\\\\\", verbose)\\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\    raise  # Re-raise to handle in calling\\\n    \\ code\\\\\\\\n\\\\\\\\n\\\\\\\\ndef handle_output(content:\\\\\\\\\\\\n    \\\\\\\\ str, output_path:\\\n    \\ str = None) -> None:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Handle output to either\\\n    \\ file\\\\\\\\\\\\n    \\\\\\\\ or stdout.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if output_path:\\\\\\\n    \\\\n        # Write to file\\\\\\\\n        write_output(output_path,\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ content)\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Context package created: {output_path}\\\\\\\n    \\\\\\\\\\\")\\\\\\\\n    else:\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        # Output to stdout\\\\\\\\n     \\\n    \\   print(content)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef main():\\\\\\\\n    parser\\\\\\\\\\\\n    \\\\\\\\ = argparse.ArgumentParser(\\\\\\\n    \\\\n        description=\\\\\\\\\\\\\\\"Package repository content\\\\\\\\\\\\n    \\\\\\\\ for LLM\\\n    \\ context\\\\\\\\\\\\\\\"\\\\\\\\n    )\\\\\\\\n    parser.add_argument(\\\\\\\\n        \\\\\\\\\\\\\\\"\\\n    path\\\\\\\\\\\\\\\", \\\\\\\\n   \\\\\\\\\\\\n    \\\\\\\\     nargs=\\\\\\\\\\\\\\\"?\\\\\\\\\\\\\\\", \\\\\\\\n     \\\n    \\   default=\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\", \\\\\\\\n        help=\\\\\\\\\\\\\\\"Repository path (default:\\\\\\\n    \\\\\\\\n    \\\\\\\\ current directory)\\\\\\\\\\\\\\\"\\\\\\\\n    )\\\\\\\\n    parser.add_argument(\\\\\\\n    \\\\n        \\\\\\\\\\\\\\\"-o\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--output\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    , \\\\\\\\n    \\\n    \\    help=\\\\\\\\\\\\\\\"Output file path (default: stdout)\\\\\\\\\\\\\\\"\\\\\\\\n    )\\\\\\\\n  \\\n    \\  parser.add_argument(\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        \\\\\\\\\\\\\\\"-f\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"\\\n    --format\\\\\\\\\\\\\\\", \\\\\\\\n        choices=[\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"json\\\\\\\\\\\n    \\\\\\\", \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    ], \\\\\\\\n        default=\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\n    \\\",\\\\\\\\n        help=\\\\\\\\\\\\\\\"Output format (default: text)\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    \\\\\\\n    \\\\n    )\\\\\\\\n\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" This will read -r from the console\\\n    \\ and able to search it\\\\\\\\\\\\n    \\\\\\\\ with this\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\n    \\    parser.add_argument(\\\\\\\\n    \\\\\\\\\\\\\\\"-r\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--recent\\\\\\\\\\\\\\\"\\\n    ,\\\\\\\\n    action=\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    store_true\\\\\\\\\\\\\\\",\\\\\\\\n    help=\\\\\\\\\\\\\\\"\\\n    Include only files modified in the last 7 days\\\\\\\\\\\\\\\"\\\\\\\\n \\\\\\\\\\\\n    \\\\\\\\  \\\n    \\ )\\\\\\\\n    parser.add_argument(\\\\\\\\n        \\\\\\\\\\\\\\\"-v\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--verbose\\\\\\\n    \\\\\\\\\\\",\\\\\\\\n        action=\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    store_true\\\\\\\\\\\\\\\",\\\\\\\\n       \\\n    \\ help=\\\\\\\\\\\\\\\"Print detailed progress information to stderr\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\\\\\\\\n    n    \\\\\\\\    )\\\\\\\\n    \\\\\\\\n    args = parser.parse_args()\\\\\\\\n    \\\\\\\\n    try:\\\\\\\n    \\\\n        repo_path\\\\\\\\\\\\n    \\\\\\\\ = Path(args.path).resolve()\\\\\\\\n        if\\\n    \\ not repo_path.exists():\\\\\\\\n          \\\\\\\\\\\\n    \\\\\\\\  print(f\\\\\\\\\\\\\\\"Error:\\\n    \\ Path {repo_path} does not exist\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\n     \\\\\\\\\\\\n \\\n    \\   \\\\\\\\       sys.exit(1)\\\\\\\\n            \\\\\\\\n        # Get repository information\\\\\\\n    \\\\n    \\\\\\\\\\\\n    \\\\\\\\    log_verbose(f\\\\\\\\\\\\\\\"Analyzing repository: {repo_path}\\\\\\\n    \\\\\\\\\\\", args.verbose)\\\\\\\\n     \\\\\\\\\\\\n    \\\\\\\\   repo_info = get_git_info(repo_path)\\\\\\\n    \\\\n        \\\\\\\\n        # Discover files\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        log_verbose(f\\\\\\\n    \\\\\\\\\\\"Discovering files in: {repo_path}\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n \\\\\\\\\\\\n  \\\n    \\  \\\\\\\\       discovered_files = discover_files([repo_path], repo_path, [], [])\\\\\\\n    \\\\n  \\\\\\\\\\\\n    \\\\\\\\      log_verbose(f\\\\\\\\\\\\\\\"Found {len(discovered_files)} files\\\\\\\n    \\\\\\\\\\\", args.verbose)\\\\\\\\n \\\\\\\\\\\\n    \\\\\\\\       \\\\\\\\n        # will check the\\\n    \\ file in last 7 days\\\\\\\\n        recent_files_info\\\\\\\\\\\\n    \\\\\\\\ = {}\\\\\\\\n \\\n    \\       if args.recent:\\\\\\\\n            seven_days_ago = datetime.now() -\\\\\\\\\\\\\\\n    n    \\\\\\\\ timedelta(days=7)\\\\\\\\n            recent_files = []\\\\\\\\n           \\\n    \\ for f in discovered_files:\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\                try:\\\\\\\\n    \\\n    \\                mtime = datetime.fromtimestamp(f.stat().st_mtime)\\\\\\\\n\\\\\\\\\\\\\\\n    n    \\\\\\\\                    if mtime >= seven_days_ago:\\\\\\\\n                \\\n    \\        recent_files.append(f)\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\                        recent_files_info[str(f.relative_to(repo_path))]\\\n    \\ = human_readable_age(mtime)\\\\\\\\\\\\n    \\\\\\\\     \\\\\\\\n                except Exception:\\\\\\\n    \\\\n                    continue\\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\        discovered_files\\\n    \\ = recent_files\\\\\\\\n        \\\\\\\\n        # Read file contents\\\\\\\\n\\\\\\\\\\\\n   \\\n    \\ \\\\\\\\        files_data = {}\\\\\\\\n        file_sizes = {}\\\\\\\\n        for file_path\\\n    \\ in discovered_files:\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\            try:\\\\\\\\n              \\\n    \\  relative_path_str, content, file_size = process_file(file_path,\\\\\\\\\\\\n    \\\\\\\n    \\\\ repo_path, args.verbose)\\\\\\\\n                files_data[relative_path_str]\\\n    \\ = content\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\                file_sizes[relative_path_str] =\\\n    \\ file_size\\\\\\\\n            except\\\\\\\\\\\\n    \\\\\\\\ Exception:\\\\\\\\n            \\\n    \\    continue\\\\\\\\n        \\\\\\\\n        # Create tree view\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\\\\n    \\        log_verbose(\\\\\\\\\\\\\\\"Generating directory tree\\\\\\\\\\\\\\\", args.verbose)\\\\\\\n    \\\\n        tree_text\\\\\\\\\\\\n    \\\\\\\\ = create_tree_view(repo_path, files_data)\\\\\\\n    \\\\n        \\\\\\\\n        # Count totals\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        total_files\\\n    \\ = len(files_data)\\\\\\\\n        total_lines = sum(len(content.splitlines())\\\\\\\\\\\n    \\\\n    \\\\\\\\ for _, content in files_data.items())\\\\\\\\n        \\\\\\\\n        # Render\\\n    \\ based on format\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        log_verbose(f\\\\\\\\\\\\\\\"Rendering output\\\n    \\ in {args.format} format\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        content\\\n    \\ = get_rendered_content(\\\\\\\\n            args.format, str(repo_path),\\\\\\\\\\\\n\\\n    \\    \\\\\\\\ repo_info, tree_text,\\\\\\\\n            files_data, total_files, total_lines,\\\\\\\n    \\\\n \\\\\\\\\\\\n    \\\\\\\\           recent_files_info if args.recent else {},\\\\\\\\n \\\n    \\           file_sizes\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        )\\\\\\\\n        \\\\\\\\n        handle_output(content,\\\n    \\ args.output)\\\\\\\\n        \\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    except Exception as e:\\\\\\\\\\\n    n        print(f\\\\\\\\\\\\\\\"Error: {e}\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\n    \\\\        sys.exit(1)\\\\\\\\n\\\\\\\\n# this will convert age and give us the difference\\\\\\\n    \\\\ndef\\\\\\\\\\\\n    \\\\\\\\ human_readable_age(mtime: datetime) -> str:\\\\\\\\n    delta\\\n    \\ = datetime.now() - mtime\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    days = delta.days\\\\\\\\n    seconds\\\n    \\ = delta.seconds\\\\\\\\n    if days > 0:\\\\\\\\n      \\\\\\\\\\\\n    \\\\\\\\  return f\\\\\\\\\\\n    \\\\\\\"{days} day{'s' if days != 1 else ''} ago\\\\\\\\\\\\\\\"\\\\\\\\n    elif seconds >= 3600:\\\\\\\n    \\\\n\\\\\\\\\\\\n    \\\\\\\\        hours = seconds // 3600\\\\\\\\n        return f\\\\\\\\\\\\\\\"\\\n    {hours} hour{'s' if hours\\\\\\\\\\\\n    \\\\\\\\ != 1 else ''} ago\\\\\\\\\\\\\\\"\\\\\\\\n    elif\\\n    \\ seconds >= 60:\\\\\\\\n        minutes = seconds // 60\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\     \\\n    \\   return f\\\\\\\\\\\\\\\"{minutes} minute{'s' if minutes != 1 else ''} ago\\\\\\\\\\\\\\\"\\\\\\\n    \\\\n    else:\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        return \\\\\\\\\\\\\\\"just now\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\n    \\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\":\\\\\\\\n    main()\\\\\\\\n\\\\\\\"\\\\n  src/rcpack/config_loader.py:\\\n    \\ \\\\\\\"# src/rcpack/config_loader.py\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nTOML config\\\\\\\n    \\\\\\\\n    \\\\\\\\ loader for Repo-Contextor.\\\\\\\\n\\\\\\\\nRules:\\\\\\\\n- Look for .repo-contextor.toml\\\n    \\ in the\\\\\\\\\\\\n    \\\\\\\\ CURRENT directory\\\\\\\\n- If missing: ignore\\\\\\\\n- If present\\\n    \\ but invalid: print a clear\\\\\\\\\\\\n    \\\\\\\\ error and exit(1)\\\\\\\\n- Only recognized\\\n    \\ keys are applied; unknown keys ignored\\\\\\\\n\\\\\\\\\\\\n    - Precedence: CLI > TOML\\\n    \\ > DEFAULTS\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nfrom __future__ import annotations\\\\\\\n    \\\\n\\\\\\\\\\\\n    import os, sys\\\\\\\\nfrom typing import Dict, Iterable, Any\\\\\\\\n\\\\\\\n    \\\\ntry:\\\\\\\\n    import tomllib\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    _loads = tomllib.loads\\\\\\\n    \\\\nexcept ModuleNotFoundError:\\\\\\\\n    try:\\\\\\\\n        import\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ tomli\\\\\\\\n        _loads = tomli.loads\\\\\\\\n    except ModuleNotFoundError:\\\\\\\n    \\\\n     \\\\\\\\\\\\n    \\\\\\\\   _loads = None\\\\\\\\n\\\\\\\\ndef _need_toml():\\\\\\\\n    if\\\n    \\ _loads is None:\\\\\\\\n        print(\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    Error: TOML parser not\\\n    \\ available. Use Python 3.11+ or `pip install tomli`.\\\\\\\\\\\\\\\",\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ file=sys.stderr)\\\\\\\\n        sys.exit(1)\\\\\\\\n\\\\\\\\ndef _load_toml(dotfile: str)\\\n    \\ -> Dict[str,\\\\\\\\\\\\n    \\\\\\\\ Any]:\\\\\\\\n    _need_toml()\\\\\\\\n    if not os.path.exists(dotfile):\\\\\\\n    \\\\n        return\\\\\\\\\\\\n    \\\\\\\\ {}\\\\\\\\n    try:\\\\\\\\n        with open(dotfile,\\\n    \\ \\\\\\\\\\\\\\\"rb\\\\\\\\\\\\\\\") as f:\\\\\\\\n            raw = f.read().decode(\\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\n    utf-8\\\\\\\\\\\\\\\", errors=\\\\\\\\\\\\\\\"strict\\\\\\\\\\\\\\\")\\\\\\\\n        data = _loads(raw)\\\\\\\n    \\\\n        return data if\\\\\\\\\\\\n    \\\\\\\\ isinstance(data, dict) else {}\\\\\\\\n \\\n    \\   except Exception as e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    Error: failed\\\n    \\ to parse {dotfile} as TOML.\\\\\\\\\\\\\\\\n{e}\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\n     \\\n    \\   sys.exit(1)\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\ndef _filter_known(d: Dict[str, Any], known:\\\n    \\ Iterable[str]) -> Dict[str, Any]:\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    ks = set(known)\\\\\\\\\\\n    n    return {k: v for k, v in d.items() if k in ks}\\\\\\\\n\\\\\\\\ndef\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str,\\\\\\\n    \\\\\\\\n    \\\\\\\\ Any], known: Iterable[str]) -> Dict[str, Any]:\\\\\\\\n    ks = set(known)\\\\\\\n    \\\\n    out:\\\\\\\\\\\\n    \\\\\\\\ Dict[str, Any] = {k: defaults.get(k) for k in ks}\\\\\\\n    \\\\n    for src in (filecfg,\\\\\\\\\\\\n    \\\\\\\\ clicfg):\\\\\\\\n        for k, v in src.items():\\\\\\\n    \\\\n            if k in ks and v is\\\\\\\\\\\\n    \\\\\\\\ not None:\\\\\\\\n             \\\n    \\   out[k] = v\\\\\\\\n    return out\\\\\\\\n\\\\\\\\ndef load_config(*,\\\\\\\\\\\\n    \\\\\\\\ dotfile:\\\n    \\ str = \\\\\\\\\\\\\\\".repo-contextor.toml\\\\\\\\\\\\\\\", defaults: Dict[str, Any] | None\\\n    \\ = None,\\\\\\\\\\\\n    \\\\\\\\ cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str]\\\n    \\ = ()) -> Dict[str,\\\\\\\\\\\\n    \\\\\\\\ Any]:\\\\\\\\n    defaults = defaults or {}\\\\\\\\\\\n    n    cli_cfg = cli_cfg or {}\\\\\\\\n    known\\\\\\\\\\\\n    \\\\\\\\ = tuple(known_keys)\\\\\\\n    \\\\n    filecfg = _filter_known(_load_toml(dotfile), known)\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\\\\n    \\    return _merge(defaults, filecfg, cli_cfg, known)\\\\\\\\n\\\\\\\"\\\\n  src/rcpack/discover.py:\\\n    \\ \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"File discovery module for repository analysis.\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing\\\n    \\ import List\\\\\\\\nimport fnmatch\\\\\\\\n\\\\\\\\n\\\\\\\\n\\\\\\\\\\\\n    def discover_files(\\\\\\\n    \\\\n    inputs: List[Path],\\\\\\\\n    root: Path,\\\\\\\\n    include_patterns:\\\\\\\\\\\\\\\n    n    \\\\\\\\ List[str],\\\\\\\\n    exclude_patterns: List[str],\\\\\\\\n) -> List[Path]:\\\\\\\n    \\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Discover\\\\\\\\\\\\n    \\\\\\\\ relevant files.\\\\\\\\n\\\\\\\\\\\n    n    - inputs: list of files/dirs to scan\\\\\\\\n    - root: common\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ project root; patterns are matched against POSIX paths relative to root\\\\\\\\\\\n    n  \\\\\\\\\\\\n    \\\\\\\\  - include_patterns: glob patterns to include (if empty, use\\\n    \\ sensible defaults)\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    - exclude_patterns: glob patterns\\\n    \\ to exclude\\\\\\\\n    Returns a list of absolute\\\\\\\\\\\\n    \\\\\\\\ Paths to files.\\\\\\\n    \\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    default_include_exts = {\\\\\\\\n   \\\n    \\     '.py',\\\\\\\\\\\\n    \\\\\\\\ '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c',\\\n    \\ '.h',\\\\\\\\n        '.cs', '.php',\\\\\\\\\\\\n    \\\\\\\\ '.rb', '.go', '.rs', '.swift',\\\n    \\ '.kt', '.scala',\\\\\\\\n        '.html', '.css', '.scss',\\\\\\\\\\\\n    \\\\\\\\ '.sass',\\\n    \\ '.less', '.vue', '.svelte',\\\\\\\\n        '.md', '.txt', '.rst', '.yaml',\\\\\\\\\\\\\\\n    n    \\\\\\\\ '.yml', '.json', '.toml', '.ini',\\\\\\\\n        '.cfg', '.conf', '.xml',\\\n    \\ '.sql',\\\\\\\\\\\\n    \\\\\\\\ '.sh', '.bash', '.zsh', '.fish',\\\\\\\\n    }\\\\\\\\n\\\\\\\\n\\\n    \\    always_include_names = {\\\\\\\\n  \\\\\\\\\\\\n    \\\\\\\\      'README', 'LICENSE',\\\n    \\ 'CHANGELOG', 'CONTRIBUTING', 'Makefile',\\\\\\\\n       \\\\\\\\\\\\n    \\\\\\\\ 'requirements.txt',\\\n    \\ 'package.json', 'Cargo.toml', 'pyproject.toml',\\\\\\\\n      \\\\\\\\\\\\n    \\\\\\\\  'setup.py',\\\n    \\ 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\\\\\\\n\\\\\\\n    \\\\\\\\n    \\\\\\\\    }\\\\\\\\n\\\\\\\\n    skip_dir_names = {\\\\\\\\n        '.git', '.svn',\\\n    \\ '.hg', '__pycache__',\\\\\\\\\\\\n    \\\\\\\\ '.pytest_cache',\\\\\\\\n        'node_modules',\\\n    \\ '.venv', 'venv', 'env', '.env',\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        'build', 'dist',\\\n    \\ 'target', 'out', '.next', '.nuxt',\\\\\\\\n        '.idea',\\\\\\\\\\\\n    \\\\\\\\ '.vscode',\\\n    \\ '.vs', 'coverage', '.coverage'\\\\\\\\n    }\\\\\\\\n\\\\\\\\n    def matches_any(patterns:\\\\\\\n    \\\\\\\\n    \\\\\\\\ List[str], rel_posix: str) -> bool:\\\\\\\\n        return any(fnmatch.fnmatch(rel_posix,\\\\\\\n    \\\\\\\\n    \\\\\\\\ pat) for pat in patterns)\\\\\\\\n\\\\\\\\n    def should_take(file_path:\\\n    \\ Path) -> bool:\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        rel_posix = file_path.relative_to(root).as_posix()\\\\\\\n    \\\\n        if exclude_patterns\\\\\\\\\\\\n    \\\\\\\\ and matches_any(exclude_patterns,\\\n    \\ rel_posix):\\\\\\\\n            return False\\\\\\\\n  \\\\\\\\\\\\n    \\\\\\\\      if include_patterns:\\\\\\\n    \\\\n            return matches_any(include_patterns,\\\\\\\\\\\\n    \\\\\\\\ rel_posix)\\\\\\\n    \\\\n        # default include logic\\\\\\\\n        return file_path.name in\\\\\\\\\\\\\\\n    n    \\\\\\\\ always_include_names or file_path.suffix.lower() in default_include_exts\\\\\\\n    \\\\n\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    discovered: list[Path] = []\\\\\\\\n    seen = set()\\\\\\\\\\\n    n\\\\\\\\n    for item in inputs:\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        p = item.resolve()\\\\\\\\\\\n    n        if p.is_file():\\\\\\\\n            # Skip if excluded\\\\\\\\\\\\n    \\\\\\\\ or\\\n    \\ in skipped directory\\\\\\\\n            if any(part in skip_dir_names for part\\\\\\\n    \\\\\\\\n    \\\\\\\\ in p.parts):\\\\\\\\n                continue\\\\\\\\n            if should_take(p):\\\\\\\n    \\\\n   \\\\\\\\\\\\n    \\\\\\\\             key = p.as_posix()\\\\\\\\n                if key\\\n    \\ not in seen:\\\\\\\\n      \\\\\\\\\\\\n    \\\\\\\\              seen.add(key)\\\\\\\\n     \\\n    \\               discovered.append(p)\\\\\\\\n     \\\\\\\\\\\\n    \\\\\\\\   elif p.is_dir():\\\\\\\n    \\\\n            for child in p.rglob('*'):\\\\\\\\n               \\\\\\\\\\\\n    \\\\\\\\ if\\\n    \\ not child.is_file():\\\\\\\\n                    continue\\\\\\\\n                if\\\n    \\ any(part\\\\\\\\\\\\n    \\\\\\\\ in skip_dir_names for part in child.parts):\\\\\\\\n   \\\n    \\                 continue\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\                if should_take(child):\\\\\\\n    \\\\n                    key = child.resolve().as_posix()\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\  \\\n    \\                  if key not in seen:\\\\\\\\n                        seen.add(key)\\\\\\\n    \\\\n\\\\\\\\\\\\n    \\\\\\\\                        discovered.append(child.resolve())\\\\\\\n    \\\\n\\\\\\\\n    return sorted(discovered)\\\\\\\"\\\\n  src/rcpack/gitinfo.py: \\\\\\\"from\\\n    \\ __future__ import annotations\\\\\\\\n\\\\\\\\nimport subprocess\\\\\\\\n\\\\\\\\\\\\n    from\\\n    \\ pathlib import Path\\\\\\\\nfrom typing import Dict, Any\\\\\\\\n\\\\\\\\n\\\\\\\\ndef _git(cmd:\\\n    \\ list[str],\\\\\\\\\\\\n    \\\\\\\\ cwd: Path) -> str:\\\\\\\\n    # Validate git commands\\\n    \\ to prevent injection\\\\\\\\n    allowed_commands\\\\\\\\\\\\n    \\\\\\\\ = {\\\\\\\\n      \\\n    \\  \\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"show\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"log\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\n    \\\"status\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"config\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    \\\\\\\\\\\n    n    }\\\\\\\\n    if not cmd or cmd[0] not in allowed_commands:\\\\\\\\n        raise\\\n    \\ ValueError(f\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    Git command not allowed: {cmd[0] if cmd else\\\n    \\ 'empty'}\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    out = subprocess.check_output([\\\\\\\\\\\\\\\"\\\\\\\n    \\\\\\\\n    git\\\\\\\\\\\\\\\", *cmd], cwd=str(cwd), timeout=30)\\\\\\\\n    return out.decode(\\\\\\\n    \\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", errors=\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    replace\\\\\\\\\\\\\\\").strip()\\\\\\\\n\\\\\\\n    \\\\n\\\\\\\\ndef is_git_repo(path: Path) -> bool:\\\\\\\\n    try:\\\\\\\\n     \\\\\\\\\\\\n   \\\n    \\ \\\\\\\\   flag = _git([\\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--is-inside-work-tree\\\\\\\n    \\\\\\\\\\\"], cwd=path)\\\\\\\\n      \\\\\\\\\\\\n    \\\\\\\\  return flag == \\\\\\\\\\\\\\\"true\\\\\\\\\\\\\\\n    \\\"\\\\\\\\n    except Exception:\\\\\\\\n        return False\\\\\\\\n\\\\\\\\n\\\\\\\\n\\\\\\\\\\\\n  \\\n    \\  def get_git_info(path: Path) -> Dict[str, Any]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\\\\"\\\\\\\\n    Return info for\\\\\\\\\\\\n    \\\\\\\\ the current HEAD of a repo rooted\\\n    \\ at `path`.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n       \\\\\\\\\\\\n\\\n    \\    \\\\\\\\ commit = _git([\\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"HEAD\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\n    \\\\n        branch = _git([\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    rev-parse\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--abbrev-ref\\\\\\\n    \\\\\\\\\\\", \\\\\\\\\\\\\\\"HEAD\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\\n        author = _git([\\\\\\\\\\\\\\\"\\\\\\\n    \\\\\\\\n    show\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"-s\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--format=%an <%ae>\\\\\\\\\\\\\\\"\\\n    ], cwd=path)\\\\\\\\n        date = _git([\\\\\\\\\\\\\\\"show\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    , \\\\\\\\\\\\\\\"\\\n    -s\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--date=local\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--format=%ad\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\n    \\\\n        return {\\\\\\\\n \\\\\\\\\\\\n    \\\\\\\\           \\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\": True,\\\\\\\n    \\\\n            \\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\": commit,\\\\\\\\n            \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    n    branch\\\\\\\\\\\\\\\": branch,\\\\\\\\n            \\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\": author,\\\\\\\n    \\\\n            \\\\\\\\\\\\\\\"date\\\\\\\\\\\\\\\": date,\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\            \\\\\\\\\\\n    \\\\\\\"note\\\\\\\\\\\\\\\": None,\\\\\\\\n        }\\\\\\\\n    except Exception:\\\\\\\\n        #\\\n    \\ treat\\\\\\\\\\\\n    \\\\\\\\ as not a repo if anything fails\\\\\\\\n        return {\\\\\\\\\\\n    n            \\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\":\\\\\\\\\\\\n    \\\\\\\\ False,\\\\\\\\n            \\\\\\\n    \\\\\\\\\\\"commit\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\": None,\\\\\\\\\\\n    n     \\\\\\\\\\\\n    \\\\\\\\       \\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\n    \\\\\\\"date\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"note\\\\\\\\\\\\\\\":\\\\\\\\\\\\n    \\\\\\\\ \\\\\\\n    \\\\\\\\\\\"Not a git repository\\\\\\\\\\\\\\\",\\\\\\\\n        }\\\\\\\\n\\\\\\\"\\\\n  src/rcpack/io_utils.py:\\\n    \\ \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"I/O utilities for file operations.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom\\\\\\\\\\\\n    \\\\\\\\ pathlib import Path\\\\\\\\nfrom typing import\\\n    \\ Tuple\\\\\\\\n\\\\\\\\n\\\\\\\\ndef write_output(output_path:\\\\\\\\\\\\n    \\\\\\\\ str, content:\\\n    \\ str) -> None:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Write content to output file.\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    output_file = Path(output_path)\\\\\\\n    \\\\n    \\\\\\\\n    # Create parent directories if\\\\\\\\\\\\n    \\\\\\\\ they don't exist\\\\\\\n    \\\\n    output_file.parent.mkdir(parents=True, exist_ok=True)\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\n    \\\\    \\\\\\\\n    # Write content\\\\\\\\n    with open(output_file, 'w', encoding='utf-8')\\\\\\\n    \\\\\\\\n    \\\\\\\\ as f:\\\\\\\\n        f.write(content)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef is_binary_file(path:\\\n    \\ Path, sniff_bytes:\\\\\\\\\\\\n    \\\\\\\\ int = 2048) -> bool:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\"Heuristically determine if a file is binary\\\\\\\\\\\\n    \\\\\\\\ by scanning\\\n    \\ for NUL bytes.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        with open(path,\\\n    \\ 'rb') as\\\\\\\\\\\\n    \\\\\\\\ fb:\\\\\\\\n            chunk = fb.read(sniff_bytes)\\\\\\\\\\\n    n        if b\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\x00\\\\\\\\\\\\\\\" in chunk:\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\       \\\n    \\     return True\\\\\\\\n        # If the chunk has a lot of non-text bytes,\\\\\\\\\\\\\\\n    n    \\\\\\\\ consider it binary\\\\\\\\n        text_byte_count = sum(32 <= b <= 126\\\n    \\ or b in (9,\\\\\\\\\\\\n    \\\\\\\\ 10, 13) for b in chunk)\\\\\\\\n        return (len(chunk)\\\n    \\ - text_byte_count) > max(1,\\\\\\\\\\\\n    \\\\\\\\ len(chunk) // 3)\\\\\\\\n    except Exception:\\\\\\\n    \\\\n        # If we cannot read, treat\\\\\\\\\\\\n    \\\\\\\\ as binary to avoid further\\\n    \\ processing\\\\\\\\n        return True\\\\\\\\n\\\\\\\\n\\\\\\\\ndef read_text_safely(path:\\\\\\\n    \\\\\\\\n    \\\\\\\\ Path, max_bytes: int = 16_384) -> Tuple[str, str, bool]:\\\\\\\\n  \\\n    \\  \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Read a text\\\\\\\\\\\\n    \\\\\\\\ file safely with size limit\\\n    \\ and encoding fallbacks.\\\\\\\\n\\\\\\\\n    Returns (content,\\\\\\\\\\\\n    \\\\\\\\ encoding_used,\\\n    \\ truncated).\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    truncated = False\\\\\\\\n\\\n    \\    raw: bytes\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    with open(path, 'rb') as fb:\\\\\\\\n     \\\n    \\   raw = fb.read(max_bytes + 1)\\\\\\\\n    if\\\\\\\\\\\\n    \\\\\\\\ len(raw) > max_bytes:\\\\\\\n    \\\\n        truncated = True\\\\\\\\n        raw = raw[:max_bytes]\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\n    \\\\n    for enc in (\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"utf-16\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"utf-16-le\\\\\\\n    \\\\\\\\\\\", \\\\\\\\\\\\\\\"utf-16-be\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"latin-1\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    ):\\\\\\\\n \\\n    \\       try:\\\\\\\\n            text = raw.decode(enc)\\\\\\\\n            return text,\\\\\\\n    \\\\\\\\n    \\\\\\\\ enc, truncated\\\\\\\\n        except Exception:\\\\\\\\n            continue\\\\\\\n    \\\\n    # Fallback:\\\\\\\\\\\\n    \\\\\\\\ replace errors with utf-8\\\\\\\\n    text = raw.decode(\\\\\\\n    \\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", errors=\\\\\\\\\\\\\\\"replace\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    )\\\\\\\\n    return\\\n    \\ text, \\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", truncated\\\\\\\"\\\\n  src/rcpack/packager.py: \\\\\\\"\\\n    from __future__ import annotations\\\\\\\\n\\\\\\\\nimport sys\\\\\\\\nfrom\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ pathlib import Path\\\\\\\\nfrom typing import Iterable, Tuple\\\\\\\\n\\\\\\\\nfrom rcpack.discover\\\\\\\n    \\\\\\\\n    \\\\\\\\ import discover_files\\\\\\\\nfrom rcpack.gitinfo import get_git_info,\\\n    \\ is_git_repo\\\\\\\\n\\\\\\\\\\\\n    from rcpack.io_utils import read_text_safely, is_binary_file\\\\\\\n    \\\\nfrom rcpack.renderer\\\\\\\\\\\\n    \\\\\\\\ import markdown as md_renderer\\\\\\\\nfrom\\\n    \\ rcpack.renderer.jsonyaml import render_json,\\\\\\\\\\\\n    \\\\\\\\ render_yaml\\\\\\\\\\\n    nfrom rcpack.treeview import render_tree\\\\\\\\n\\\\\\\\n\\\\\\\\ndef _find_root(inputs:\\\\\\\n    \\\\\\\\n    \\\\\\\\ list[str]) -> Path:\\\\\\\\n    paths = [Path(p) for p in inputs]\\\\\\\\\\\n    n    if len(paths)\\\\\\\\\\\\n    \\\\\\\\ == 1 and Path(paths[0]).is_dir():\\\\\\\\n     \\\n    \\   return paths[0].resolve()\\\\\\\\n    parents\\\\\\\\\\\\n    \\\\\\\\ = [p if p.is_dir()\\\n    \\ else p.parent for p in paths]\\\\\\\\n    root = Path(*Path.commonpath([str(p.resolve())\\\\\\\n    \\\\\\\\n    \\\\\\\\ for p in parents]).split(\\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\"))\\\\\\\\n    return root.resolve()\\\\\\\n    \\\\n\\\\\\\\n\\\\\\\\ndef build_package(\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    inputs: list[str],\\\\\\\\\\\n    n    include_patterns: list[str] | None,\\\\\\\\n    exclude_patterns:\\\\\\\\\\\\n    \\\\\\\n    \\\\ list[str] | None,\\\\\\\\n    max_file_bytes: int,\\\\\\\\n    fmt: str = \\\\\\\\\\\\\\\"\\\n    markdown\\\\\\\\\\\\\\\",\\\\\\\\n\\\\\\\\\\\\n    ) -> Tuple[str, dict]:\\\\\\\\n    root = _find_root(inputs)\\\\\\\n    \\\\n    root_abs = root.resolve()\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\n    repo_info = (\\\\\\\\n  \\\n    \\      get_git_info(root_abs) if is_git_repo(root_abs) else\\\\\\\\\\\\n    \\\\\\\\ {\\\\\\\n    \\\\n            \\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\": False,\\\\\\\\n            \\\\\\\\\\\\\\\"commit\\\\\\\n    \\\\\\\\\\\": None,\\\\\\\\n        \\\\\\\\\\\\n    \\\\\\\\    \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\": None,\\\\\\\\\\\n    n            \\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"date\\\\\\\\\\\\\\\"\\\n    : None,\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\            \\\\\\\\\\\\\\\"note\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Not a git\\\n    \\ repository\\\\\\\\\\\\\\\",\\\\\\\\n        }\\\\\\\\n    )\\\\\\\\n\\\\\\\\n    files\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ = discover_files(\\\\\\\\n        inputs=[Path(p) for p in inputs],\\\\\\\\n       \\\n    \\ root=root_abs,\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        include_patterns=include_patterns\\\n    \\ or [],\\\\\\\\n        exclude_patterns=exclude_patterns\\\\\\\\\\\\n    \\\\\\\\ or [],\\\\\\\n    \\\\n    )\\\\\\\\n    rel_files = [f.relative_to(root_abs) for f in files]\\\\\\\\n\\\\\\\\\\\n    n\\\\\\\\\\\\n    \\\\\\\\    project_tree = render_tree([p.as_posix() for p in rel_files])\\\\\\\n    \\\\n\\\\\\\\n    file_sections:\\\\\\\\\\\\n    \\\\\\\\ list[dict] = []\\\\\\\\n    total_lines\\\n    \\ = 0\\\\\\\\n    total_chars = 0\\\\\\\\n\\\\\\\\n    for f in files:\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\\\\n    \\        rel = f.relative_to(root_abs).as_posix()\\\\\\\\n        try:\\\\\\\\n      \\\n    \\      if\\\\\\\\\\\\n    \\\\\\\\ is_binary_file(f):\\\\\\\\n                content = f\\\\\\\\\\\n    \\\\\\\"[binary file skipped: {f.name},\\\\\\\\\\\\n    \\\\\\\\ {f.stat().st_size} bytes]\\\\\\\n    \\\\\\\\\\\"\\\\\\\\n                file_sections.append({\\\\\\\\n      \\\\\\\\\\\\n    \\\\\\\\  \\\n    \\            \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": rel,\\\\\\\\n                    \\\\\\\\\\\\\\\"language\\\\\\\n    \\\\\\\\\\\": _language_from_ext(f.suffix),\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\                    \\\\\\\n    \\\\\\\\\\\"content\\\\\\\\\\\\\\\": content,\\\\\\\\n                    \\\\\\\\\\\\\\\"is_truncated\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\n    : False,\\\\\\\\n                })\\\\\\\\n                total_chars\\\n    \\ += len(content)\\\\\\\\n  \\\\\\\\\\\\n    \\\\\\\\              continue\\\\\\\\n\\\\\\\\n      \\\n    \\      content, used_encoding, truncated = read_text_safely(f,\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ max_bytes=max_file_bytes)\\\\\\\\n            total_lines += content.count(\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    ) + (1 if content and not content.endswith(\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\") else 0)\\\\\\\\n            total_chars\\\\\\\\\\\\n    \\\\\\\\ += len(content)\\\\\\\n    \\\\n\\\\\\\\n            if truncated:\\\\\\\\n                note = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n[... TRUNCATED to first {max_file_bytes} bytes ...]\\\\\\\\\\\\\\\n    \\\"\\\\\\\\n                content\\\\\\\\\\\\n    \\\\\\\\ = content + note\\\\\\\\n          \\\n    \\      total_chars += len(note)\\\\\\\\n\\\\\\\\n            file_sections.append({\\\\\\\\\\\n    n\\\\\\\\\\\\n    \\\\\\\\                \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": rel,\\\\\\\\n              \\\n    \\  \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": _language_from_ext(f.suffix),\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\\\\n    \\                \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": content,\\\\\\\\n                \\\\\\\\\\\\\\\"\\\n    is_truncated\\\\\\\\\\\\\\\": truncated,\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\            })\\\\\\\\n      \\\n    \\  except Exception as exc:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"[rcpack]\\\\\\\\\\\\n   \\\n    \\ \\\\\\\\ error reading {rel}: {exc}\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\n            continue\\\\\\\n    \\\\n\\\\\\\\n   \\\\\\\\\\\\n    \\\\\\\\ # render in chosen format\\\\\\\\n    if fmt == \\\\\\\\\\\\\\\"\\\n    markdown\\\\\\\\\\\\\\\":\\\\\\\\n        out_text = md_renderer.render_markdown(\\\\\\\\n\\\\\\\\\\\n    \\\\n    \\\\\\\\            root=str(root_abs),\\\\\\\\n            repo_info=repo_info,\\\\\\\n    \\\\n         \\\\\\\\\\\\n    \\\\\\\\   tree_text=project_tree,\\\\\\\\n            files=file_sections,\\\\\\\n    \\\\n            total_files=len(file_sections),\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\           \\\n    \\ total_lines=total_lines,\\\\\\\\n        )\\\\\\\\n    elif fmt == \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\n    \\\":\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        out_text = render_json(\\\\\\\\n            root=str(root_abs),\\\\\\\n    \\\\n          \\\\\\\\\\\\n    \\\\\\\\  repo_info=repo_info,\\\\\\\\n            tree_text=project_tree,\\\\\\\n    \\\\n            files=file_sections,\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\            total_files=len(file_sections),\\\\\\\n    \\\\n            total_lines=total_lines,\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        )\\\\\\\\n    elif\\\n    \\ fmt == \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\":\\\\\\\\n        out_text = render_yaml(\\\\\\\\n     \\\\\\\n    \\\\\\\\n    \\\\\\\\       root=str(root_abs),\\\\\\\\n            repo_info=repo_info,\\\\\\\n    \\\\n            tree_text=project_tree,\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\            files=file_sections,\\\\\\\n    \\\\n            total_files=len(file_sections),\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\           \\\n    \\ total_lines=total_lines,\\\\\\\\n        )\\\\\\\\n    else:\\\\\\\\n        raise ValueError(f\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\n    Unsupported format: {fmt}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    stats = {\\\\\\\\\\\n    \\\\\\\"files\\\\\\\\\\\\\\\": len(file_sections), \\\\\\\\\\\\\\\"\\\\\\\\\\\\n    lines\\\\\\\\\\\\\\\": total_lines,\\\n    \\ \\\\\\\\\\\\\\\"chars\\\\\\\\\\\\\\\": total_chars}\\\\\\\\n    return out_text, stats\\\\\\\\n\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\\\\\\n    def _language_from_ext(ext: str) -> str:\\\\\\\\n    ext = ext.lower().lstrip(\\\\\\\n    \\\\\\\\\\\".\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    mapping = {\\\\\\\\n        \\\\\\\\\\\\\\\"py\\\\\\\\\\\n    \\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"js\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"javascript\\\\\\\\\\\\\\\",\\\n    \\ \\\\\\\\\\\\\\\"ts\\\\\\\\\\\\\\\":\\\\\\\\\\\\n    \\\\\\\\ \\\\\\\\\\\\\\\"typescript\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\n    \\\\\\\\\\\"json\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"md\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\n    \\\\\\\\\\\", \\\\\\\\\\\\\\\"yml\\\\\\\\\\\\\\\":\\\\\\\\\\\\n    \\\\\\\\ \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"yaml\\\\\\\n    \\\\\\\\\\\": \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"toml\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"toml\\\\\\\n    \\\\\\\\\\\", \\\\\\\\\\\\\\\"sh\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"bash\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    , \\\\\\\\\\\\\\\"c\\\\\\\\\\\\\\\"\\\n    : \\\\\\\\\\\\\\\"c\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"cpp\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"cpp\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\n    \\\\\\\"java\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"java\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"go\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"go\\\\\\\\\\\\\\\"\\\n    \\\\\\\\\\\\n    , \\\\\\\\\\\\\\\"rs\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"rust\\\\\\\\\\\\\\\",\\\\\\\\n    }\\\\\\\\n    return\\\n    \\ mapping.get(ext, \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\"\\\\n  src/rcpack/renderer/jsonyaml.py:\\\n    \\ \\\\\\\"from __future__ import annotations\\\\\\\\nimport json\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\ntry:\\\\\\\n    \\\\n    import yaml\\\\\\\\nexcept ImportError:\\\\\\\\n    yaml = None\\\\\\\\n\\\\\\\\n\\\\\\\\ndef\\\n    \\ render_json(root,\\\\\\\\\\\\n    \\\\\\\\ repo_info, tree_text, files, total_files, total_lines,recent_files=None,\\\n    \\ file_sizes=None)\\\\\\\\\\\\n    \\\\\\\\ -> str:\\\\\\\\n    data = {\\\\\\\\n        \\\\\\\\\\\\\\\"\\\n    root\\\\\\\\\\\\\\\": root,\\\\\\\\n        \\\\\\\\\\\\\\\"repo_info\\\\\\\\\\\\\\\": repo_info,\\\\\\\\n\\\\\\\\\\\n    \\\\n    \\\\\\\\        \\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\": tree_text,\\\\\\\\n        \\\\\\\\\\\\\\\"\\\n    recent_changes\\\\\\\\\\\\\\\": recent_files or\\\\\\\\\\\\n    \\\\\\\\ [],\\\\\\\\n        \\\\\\\\\\\\\\\"\\\n    files\\\\\\\\\\\\\\\": files,\\\\\\\\n        \\\\\\\\\\\\\\\"file_sizes\\\\\\\\\\\\\\\": file_sizes or {},\\\\\\\n    \\\\n\\\\\\\\\\\\n    \\\\\\\\        \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\"\\\n    : total_files, \\\\\\\\\\\\\\\"total_lines\\\\\\\\\\\\\\\": total_lines},\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\\\\n    \\        \\\\\\\\n    }\\\\\\\\n    return json.dumps(data, indent=2, ensure_ascii=False)\\\\\\\n    \\\\n\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\ndef render_yaml(root, repo_info, tree_text, files, total_files,\\\n    \\ total_lines,recent_files=None,\\\\\\\\\\\\n    \\\\\\\\ file_sizes=None) -> str:\\\\\\\\n\\\n    \\    if yaml is None:\\\\\\\\n        raise RuntimeError(\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    PyYAML\\\n    \\ not installed; run `pip install pyyaml`\\\\\\\\\\\\\\\")\\\\\\\\n    data = {\\\\\\\\n     \\\n    \\   \\\\\\\\\\\\\\\"root\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    : root,\\\\\\\\n        \\\\\\\\\\\\\\\"repo_info\\\\\\\\\\\\\\\n    \\\": repo_info,\\\\\\\\n        \\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\": tree_text,\\\\\\\\n\\\\\\\\\\\\n \\\n    \\   \\\\\\\\        \\\\\\\\\\\\\\\"recent_changes\\\\\\\\\\\\\\\": recent_files or [],\\\\\\\\n     \\\n    \\   \\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\": files,\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        \\\\\\\\\\\\\\\"file_sizes\\\\\\\n    \\\\\\\\\\\": file_sizes or {},\\\\\\\\n        \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"total_files\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\n    : total_files, \\\\\\\\\\\\\\\"total_lines\\\\\\\\\\\\\\\": total_lines},\\\\\\\\\\\n    n        \\\\\\\\n    }\\\\\\\\n    return yaml.safe_dump(data,\\\\\\\\\\\\n    \\\\\\\\ sort_keys=False,\\\n    \\ allow_unicode=True)\\\\\\\\n\\\\\\\"\\\\n  src/rcpack/renderer/markdown.py: \\\\\\\"\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Markdown renderer for repository context.\\\\\\\\\\\\\\\"\\\\\\\\\\\\n   \\\n    \\ \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom typing import Dict, Any\\\\\\\\n\\\\\\\\n\\\\\\\\ndef render_markdown(root:\\\n    \\ str, repo_info:\\\\\\\\\\\\n    \\\\\\\\ Dict[str, Any], tree_text: str, \\\\\\\\n       \\\n    \\            files: Dict[str, str],\\\\\\\\\\\\n    \\\\\\\\ total_files: int, total_lines:\\\n    \\ int, recent_files=None, file_sizes=None) -> str:\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    \\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Render repository context as markdown.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\\\\"\\\\\\\\n    \\\\\\\\n    lines = []\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    \\\\\\\\n    # Header\\\\\\\\\\\n    n    lines.append(f\\\\\\\\\\\\\\\"# Repository Context: {root}\\\\\\\\\\\\\\\")\\\\\\\\n   \\\\\\\\\\\\\\\n    n    \\\\\\\\ lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # Repository info\\\\\\\\\\\n    n    if repo_info.get(\\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    ):\\\\\\\\n        lines.append(\\\\\\\n    \\\\\\\\\\\"## Git Repository Information\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\"\\\n    \\\\\\\\\\\\n    - **Branch**: {repo_info.get('branch', 'N/A')}\\\\\\\\\\\\\\\")\\\\\\\\n      \\\n    \\  lines.append(f\\\\\\\\\\\\\\\"- **Commit**:\\\\\\\\\\\\n    \\\\\\\\ {repo_info.get('commit',\\\n    \\ 'N/A')}\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\"- **Author**: {repo_info.get('author',\\\\\\\n    \\\\\\\\n    \\\\\\\\ 'N/A')}\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\"- **Date**: {repo_info.get('date',\\\n    \\ 'N/A')}\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    )\\\\\\\\n    else:\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\"\\\n    ## Repository Information\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\"\\\\\\\\\\\\n \\\n    \\   - **Note**: {repo_info.get('note', 'Not a git repository')}\\\\\\\\\\\\\\\")\\\\\\\\n\\\n    \\    lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    \\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # Summary\\\\\\\\\\\n    n    lines.append(\\\\\\\\\\\\\\\"## Summary\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(f\\\\\\\\\\\\\\\"\\\\\\\n    \\\\\\\\n    - **Total Files**: {total_files}\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(f\\\\\\\\\\\\\\\n    \\\"- **Total Lines**: {total_lines}\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    )\\\\\\\\n    lines.append(\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # Directory structure\\\\\\\\n    lines.append(\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\n    ## Directory Structure\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"\\\n    ```\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(tree_text)\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    lines.append(\\\\\\\n    \\\\\\\\\\\"```\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # will\\\n    \\ produce recent\\\\\\\\\\\\n    \\\\\\\\ files \\\\\\\\n    # Recent files (fixed)\\\\\\\\n   \\\n    \\ if recent_files:\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    ## Recent Changes\\\\\\\n    \\\\\\\\\\\")\\\\\\\\n        for file, age in recent_files.items():\\\\\\\\n       \\\\\\\\\\\\n\\\n    \\    \\\\\\\\     lines.append(f\\\\\\\\\\\\\\\"- {file} (modified {age})\\\\\\\\\\\\\\\")\\\\\\\\n  \\\n    \\      lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    )\\\\\\\\n    \\\\\\\\n    # File contents\\\\\\\n    \\\\n    lines.append(\\\\\\\\\\\\\\\"## File Contents\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\n    \\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    for file_path, content in sorted(files.items()):\\\\\\\n    \\\\n        if file_sizes\\\\\\\\\\\\n    \\\\\\\\ and file_path in file_sizes:\\\\\\\\n    \\\n    \\        size_bytes = file_sizes[file_path]\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\            lines.append(f\\\\\\\n    \\\\\\\\\\\"### {file_path} ({size_bytes} bytes)\\\\\\\\\\\\\\\")\\\\\\\\n       \\\\\\\\\\\\n    \\\\\\\\\\\n    \\ else:\\\\\\\\n            lines.append(f\\\\\\\\\\\\\\\"### {file_path}\\\\\\\\\\\\\\\")\\\\\\\\n  \\\n    \\      lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    \\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Detect\\\n    \\ language for syntax highlighting\\\\\\\\n        ext\\\\\\\\\\\\n    \\\\\\\\ = file_path.split('.')[-1].lower()\\\n    \\ if '.' in file_path else ''\\\\\\\\n        lang_map\\\\\\\\\\\\n    \\\\\\\\ = {\\\\\\\\n   \\\n    \\         'py': 'python', 'js': 'javascript', 'ts': 'typescript',\\\\\\\\n \\\\\\\\\\\\\\\n    n    \\\\\\\\           'java': 'java', 'cpp': 'cpp', 'c': 'c', 'h': 'c',\\\\\\\\n   \\\n    \\         'cs':\\\\\\\\\\\\n    \\\\\\\\ 'csharp', 'php': 'php', 'rb': 'ruby',\\\\\\\\n    \\\n    \\        'go': 'go', 'rs': 'rust',\\\\\\\\\\\\n    \\\\\\\\ 'swift': 'swift',\\\\\\\\n     \\\n    \\       'html': 'html', 'css': 'css', 'scss': 'scss',\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    \\\n    \\        'json': 'json', 'yaml': 'yaml', 'yml': 'yaml',\\\\\\\\n            'xml':\\\\\\\n    \\\\\\\\n    \\\\\\\\ 'xml', 'sql': 'sql', 'sh': 'bash',\\\\\\\\n            'md': 'markdown',\\\n    \\ 'dockerfile':\\\\\\\\\\\\n    \\\\\\\\ 'dockerfile'\\\\\\\\n        }\\\\\\\\n        \\\\\\\\n  \\\n    \\      language = lang_map.get(ext, '')\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        lines.append(f\\\\\\\n    \\\\\\\\\\\"```{language}\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(content)\\\\\\\\n   \\\\\\\\\\\\n\\\n    \\    \\\\\\\\     lines.append(\\\\\\\\\\\\\\\"```\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\".join(lines)\\\\\\\n    \\\\n\\\\\\\"\\\\n  src/rcpack/treeview.py: \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Tree view generation\\\n    \\ for repository structure.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom pathlib\\\n    \\ import Path\\\\\\\\nfrom typing import Dict, List\\\\\\\\n\\\\\\\\n\\\\\\\\ndef create_tree_view(repo_path:\\\\\\\n    \\\\\\\\n    \\\\\\\\ Path, files_data: Dict[str, str]) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\"Create a tree view of the\\\\\\\\\\\\n    \\\\\\\\ repository structure.\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    paths = list(files_data.keys())\\\\\\\\n    return\\\\\\\\\\\\\\\n    n    \\\\\\\\ render_tree(paths)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef render_tree(paths: List[str]) ->\\\n    \\ str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    Render a tree view from a list\\\n    \\ of relative POSIX paths.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    tree_structure:\\\\\\\\\\\n    \\\\n    \\\\\\\\ dict = {}\\\\\\\\n\\\\\\\\n    for p in paths:\\\\\\\\n        parts = Path(p).parts\\\\\\\n    \\\\n        current\\\\\\\\\\\\n    \\\\\\\\ = tree_structure\\\\\\\\n        for part in parts[:-1]:\\\\\\\n    \\\\n            if part not in\\\\\\\\\\\\n    \\\\\\\\ current:\\\\\\\\n                current[part]\\\n    \\ = {}\\\\\\\\n            current = current[part]\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        if parts:\\\\\\\n    \\\\n            current[parts[-1]] = None\\\\\\\\n\\\\\\\\n    def _render(structure:\\\\\\\n    \\\\\\\\n    \\\\\\\\ dict, prefix: str = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\") -> str:\\\\\\\\n        lines\\\n    \\ = []\\\\\\\\n        items = sorted(structure.items(),\\\\\\\\\\\\n    \\\\\\\\ key=lambda\\\n    \\ x: (x[1] is None, x[0]))\\\\\\\\n        for i, (name, subtree) in enumerate(items):\\\\\\\n    \\\\n\\\\\\\\\\\\n    \\\\\\\\            is_last = i == len(items) - 1\\\\\\\\n            lines.append(f\\\\\\\n    \\\\\\\\\\\"{prefix}{'└──\\\\\\\\\\\\n    \\\\\\\\ ' if is_last else '├── '}{name}\\\\\\\\\\\\\\\")\\\\\\\\\\\n    n            if subtree is not None:\\\\\\\\n  \\\\\\\\\\\\n    \\\\\\\\              extension\\\n    \\ = (\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\" if is_last else \\\\\\\\\\\\\\\"│   \\\\\\\\\\\\\\\")\\\\\\\\n         \\\n    \\    \\\\\\\\\\\\n    \\\\\\\\   lines.append(_render(subtree, prefix + extension))\\\\\\\\\\\n    n        return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    .join(filter(None, lines))\\\\\\\n    \\\\n\\\\\\\\n    if not tree_structure:\\\\\\\\n        return \\\\\\\\\\\\\\\"No\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ files found\\\\\\\\\\\\\\\"\\\\\\\\n    return _render(tree_structure)\\\\\\\"\\\\n  test-output.json:\\\n    \\ \\\\\\\"{\\\\\\\\n  \\\\\\\\\\\\\\\"root\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"/Users/abhinavbhardwaj/Desktop/Semester\\\n    \\ 5/OSD600/Repo-Contextor\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    ,\\\\\\\\n  \\\\\\\\\\\\\\\"repo_info\\\\\\\\\\\\\\\"\\\n    : {\\\\\\\\n    \\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\": true,\\\\\\\\n    \\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\": \\\\\\\\\\\n    \\\\\\\"682153b169db66d3a72e9cabdd1f3448a3b2986d\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    ,\\\\\\\\n    \\\\\\\\\\\\\\\n    \\\"branch\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"refactoring\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\"\\\n    : \\\\\\\\\\\\\\\"Abhinav <abhinavbhardwaj2002@gmail.com>\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    ,\\\\\\\\n   \\\n    \\ \\\\\\\\\\\\\\\"date\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Fri Oct 3 18:45:48 2025\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\n    \\\"note\\\\\\\\\\\\\\\": null\\\\\\\\n  },\\\\\\\\n  \\\\\\\\\\\\\\\"\\\\\\\\\\\\n    structure\\\\\\\\\\\\\\\": \\\\\\\\\\\n    \\\\\\\"├── src\\\\\\\\\\\\\\\\n│   └── rcpack\\\\\\\\\\\\\\\\n│       ├── renderer\\\\\\\\\\\\\\\\n│    \\\n    \\   │   ├──\\\\\\\\\\\\n    \\\\\\\\ jsonyaml.py\\\\\\\\\\\\\\\\n│       │   └── markdown.py\\\\\\\\\\\n    \\\\\\\\n│       ├── __init__.py\\\\\\\\\\\\\\\\n│    \\\\\\\\\\\\n    \\\\\\\\   ├── __main__.py\\\\\\\\\\\n    \\\\\\\\n│       ├── cli.py\\\\\\\\\\\\\\\\n│       ├── config_loader.py\\\\\\\\\\\\\\\\n│  \\\\\\\\\\\\\\\n    n    \\\\\\\\     ├── discover.py\\\\\\\\\\\\\\\\n│       ├── gitinfo.py\\\\\\\\\\\\\\\\n│       ├──\\\n    \\ io_utils.py\\\\\\\\\\\\\\\\n│ \\\\\\\\\\\\n    \\\\\\\\      ├── packager.py\\\\\\\\\\\\\\\\n│       └──\\\n    \\ treeview.py\\\\\\\\\\\\\\\\n├── LICENSE\\\\\\\\\\\\\\\\n├── README.md\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n└──\\\n    \\ pyproject.toml\\\\\\\\\\\\\\\",\\\\\\\\n  \\\\\\\\\\\\\\\"recent_changes\\\\\\\\\\\\\\\": [],\\\\\\\\n  \\\\\\\\\\\n    \\\\\\\"files\\\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\\\"LICENSE\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    : \\\\\\\\\\\\\\\"MIT License\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\nCopyright (c) 2025 Abhinav\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nPermission is hereby\\\n    \\ granted,\\\\\\\\\\\\n    \\\\\\\\ free of charge, to any person obtaining a copy\\\\\\\\\\\\\\\n    \\\\nof this software and associated\\\\\\\\\\\\n    \\\\\\\\ documentation files (the \\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"Software\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"), to deal\\\\\\\\\\\\\\\\nin the Software without\\\\\\\n    \\\\\\\\n    \\\\\\\\ restriction, including without limitation the rights\\\\\\\\\\\\\\\\nto\\\n    \\ use, copy, modify,\\\\\\\\\\\\n    \\\\\\\\ merge, publish, distribute, sublicense, and/or\\\n    \\ sell\\\\\\\\\\\\\\\\ncopies of the Software,\\\\\\\\\\\\n    \\\\\\\\ and to permit persons to\\\n    \\ whom the Software is\\\\\\\\\\\\\\\\nfurnished to do so, subject\\\\\\\\\\\\n    \\\\\\\\ to the\\\n    \\ following conditions:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe above copyright notice and this permission\\\\\\\n    \\\\\\\\n    \\\\\\\\ notice shall be included in all\\\\\\\\\\\\\\\\ncopies or substantial portions\\\n    \\ of the Software.\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\nTHE SOFTWARE IS PROVIDED \\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\"AS IS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\\\\\\\\\\\\n\\\n    \\    \\\\\\\\ OR\\\\\\\\\\\\\\\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO\\\n    \\ EVENT SHALL THE\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR\\\n    \\ ANY CLAIM, DAMAGES OR OTHER\\\\\\\\\\\\\\\\nLIABILITY,\\\\\\\\\\\\n    \\\\\\\\ WHETHER IN AN\\\n    \\ ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\\\\\\\\\\\\\nOUT OF\\\\\\\\\\\\n \\\n    \\   \\\\\\\\ OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\\\\n    \\\\\\\\\\\\nSOFTWARE.\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"README.md\\\\\\\\\\\\\\\"\\\n    : \\\\\\\\\\\\\\\"# Repo-Contextor\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\nA powerful Repository Context Packager CLI tool that\\\n    \\ analyzes local git repositories\\\\\\\\\\\\n    \\\\\\\\ and creates comprehensive text\\\n    \\ files containing repository content optimized\\\\\\\\\\\\n    \\\\\\\\ for sharing with\\\n    \\ Large Language Models (LLMs).\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Overview\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\n    nWhen developers\\\\\\\\\\\\n    \\\\\\\\ want to get help from ChatGPT, Claude, or other\\\n    \\ LLMs about their code, they\\\\\\\\\\\\n    \\\\\\\\ often struggle with how to share\\\n    \\ their codebase effectively. Common problems\\\\\\\\\\\\n    \\\\\\\\ include:\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n- **Lost Context**: Copy-pasting individual files loses important\\\\\\\\\\\n    \\\\n    \\\\\\\\ project structure and relationships\\\\\\\\\\\\\\\\n- **Missing Dependencies**:\\\n    \\ LLMs can't\\\\\\\\\\\\n    \\\\\\\\ see how files connect or what libraries are used\\\\\\\n    \\\\\\\\\\\\n- **Incomplete Picture**:\\\\\\\\\\\\n    \\\\\\\\ Hard to convey the overall architecture\\\n    \\ and organization\\\\\\\\\\\\\\\\n- **Manual Work**:\\\\\\\\\\\\n    \\\\\\\\ Time-consuming to\\\n    \\ gather and format relevant code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Repo-Contextor** solves\\\\\\\n    \\\\\\\\n    \\\\\\\\ this by automatically collecting and formatting repository content\\\n    \\ into a single,\\\\\\\\\\\\n    \\\\\\\\ well-structured text file that provides rich context\\\n    \\ to LLMs, enabling them\\\\\\\\\\\\n    \\\\\\\\ to give much better assistance with your\\\n    \\ code.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Features\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n- **Git\\\\\\\\\\\\n    \\\\\\\\ Integration**:\\\n    \\ Extracts commit SHA, branch, author, and date information\\\\\\\\\\\\\\\\n-\\\\\\\\\\\\n \\\n    \\   \\\\\\\\ **Project Structure**: Generates a clear directory tree visualization\\\\\\\n    \\\\\\\\\\\\n- **File\\\\\\\\\\\\n    \\\\\\\\ Content Packaging**: Includes file contents with\\\n    \\ syntax highlighting\\\\\\\\\\\\\\\\n- **Smart\\\\\\\\\\\\n    \\\\\\\\ File Discovery**: Recursively\\\n    \\ scans directories with intelligent filtering\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n- **Binary File\\\n    \\ Detection**: Automatically skips binary files\\\\\\\\\\\\\\\\n- **Error Handling**:\\\\\\\n    \\\\\\\\n    \\\\\\\\ Gracefully handles permission errors and provides helpful messages\\\\\\\n    \\\\\\\\\\\\n- **Multiple\\\\\\\\\\\\n    \\\\\\\\ Output Formats**: Supports Markdown, JSON,\\\n    \\ and YAML formats\\\\\\\\\\\\\\\\n- **Flexible Output**:\\\\\\\\\\\\n    \\\\\\\\ Write to stdout\\\n    \\ or save to a file\\\\\\\\\\\\\\\\n- **Recent Changes Filter**: Give the files\\\\\\\\\\\\\\\n    n    \\\\\\\\ which are updated in last 7days with the time when it was recently modified.\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n## Installation\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Prerequisites\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\n- Python 3.9 or higher\\\\\\\\\\\\\\\\n- Git\\\\\\\\\\\\n    \\\\\\\\ (for git repository\\\n    \\ analysis)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### For End Users\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\n    n# Clone\\\\\\\\\\\\n    \\\\\\\\ and install\\\\\\\\\\\\\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    ncd Repo-Contextor\\\\\\\\\\\\\\\\npip install -e .\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\n    \\\\n\\\\\\\\\\\\\\\\n### For Contributors & Local\\\\\\\\\\\\n    \\\\\\\\ Development\\\\\\\\\\\\\\\\n\\\\\\\n    \\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Clone the repository\\\\\\\\\\\\\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    ncd Repo-Contextor\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Create virtual environment\\\\\\\n    \\\\\\\\\\\\npython -m venv .venv\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    nsource .venv/bin/activate  # On\\\n    \\ Windows: .venv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Scripts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\activate\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\n    \\\\n#\\\\\\\\\\\\n    \\\\\\\\ Install in development mode\\\\\\\\\\\\\\\\npip install -e .\\\\\\\\\\\\\\\n    \\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Usage\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n###\\\\\\\\\\\\n    \\\\\\\\ Basic Examples\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Package current directory to terminal\\\\\\\\\\\\\\\\\\\n    nrepo-contextor\\\\\\\\\\\\n    \\\\\\\\ .\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Package a specific directory\\\\\\\n    \\\\\\\\\\\\nrepo-contextor /path/to/your/project\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n# Save\\\n    \\ output to a file\\\\\\\\\\\\\\\\nrepo-contextor . -o my-project-context.md\\\\\\\\\\\\\\\\n\\\\\\\n    \\\\\\\\\\\\n#\\\\\\\\\\\\n    \\\\\\\\ Generate JSON format\\\\\\\\\\\\\\\\nrepo-contextor . -f json\\\n    \\ -o context.json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Generate\\\\\\\\\\\\n    \\\\\\\\ YAML format\\\\\\\\\\\\\\\n    \\\\nrepo-contextor . -f yaml -o context.yaml\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Include only files\\\\\\\n    \\\\\\\\n    \\\\\\\\ modified in the last 7 days\\\\\\\\\\\\\\\\nrepo-contextor . --recent\\\\\\\\\\\n    \\\\\\\\n\\\\\\\\\\\\\\\\n# Combine with\\\\\\\\\\\\n    \\\\\\\\ output file\\\\\\\\\\\\\\\\nrepo-contextor\\\n    \\ . --recent -o recent-changes.md\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n###\\\\\\\\\\\\n    \\\\\\\n    \\\\ Command Line Options\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n| Option | Short | Description | Example\\\n    \\ |\\\\\\\\\\\\\\\\n|--------|-------|-------------|---------|\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n| `path`\\\n    \\ | - | Repository path to analyze (default: current directory) | `repo-contextor\\\\\\\n    \\\\\\\\n    \\\\\\\\ /path/to/project` |\\\\\\\\\\\\\\\\n| `--output` | `-o` | Output file path\\\n    \\ (default: stdout)\\\\\\\\\\\\n    \\\\\\\\ | `-o context.md` |\\\\\\\\\\\\\\\\n| `--format` |\\\n    \\ `-f` | Output format: text, json, yaml\\\\\\\\\\\\n    \\\\\\\\ (default: text) | `-f\\\n    \\ json` |\\\\\\\\\\\\\\\\n| `--help` | `-h` | Show help message | `-h`\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ |\\\\\\\\\\\\\\\\n| `--recent`  | `-r`  | Include only files modified in the last 7\\\n    \\ days \\\\\\\\\\\\n    \\\\\\\\   | `repo-contextor . -r -o recent.md` |\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\n    \\\\n### Advanced Examples\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n# Analyze\\\n    \\ different repository\\\\\\\\\\\\\\\\nrepo-contextor /path/to/other/project -o other-project.md\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n# Generate JSON for API consumption\\\\\\\\\\\\\\\\nrepo-contextor\\\n    \\ . -f json -o api-context.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n# Create YAML configuration\\\\\\\n    \\\\\\\\\\\\nrepo-contextor . -f yaml -o project-config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\n    \\\\\\\\n# Generate files which are changed recently in 7 days\\\\\\\\\\\\\\\\nrepo-contextor\\\n    \\ . -r\\\\\\\\\\\\n    \\\\\\\\ --output recent-changes.txt\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\n    n## Configuration via TOML\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nRepo-Contextor\\\\\\\\\\\\n    \\\\\\\\ supports\\\n    \\ configuration through a `.repo-contextor.toml` file in the current\\\\\\\\\\\\n  \\\n    \\  \\\\\\\\ working directory.  \\\\\\\\\\\\\\\\nThis file allows you to avoid typing the\\\n    \\ same CLI arguments\\\\\\\\\\\\n    \\\\\\\\ every time.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nExample `.repo-contextor.toml`:\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```toml\\\\\\\\\\\\\\\\n# Output file\\\\\\\\\\\\n    \\\\\\\\ to write results\\\\\\\n    \\\\\\\\\\\\noutput = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"context.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\n    n# Output format: text,\\\\\\\\\\\\n    \\\\\\\\ json, or yaml\\\\\\\\\\\\\\\\nformat = \\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Limit to files modified in the\\\\\\\n    \\\\\\\\n    \\\\\\\\ last 7 days\\\\\\\\\\\\\\\\nrecent = true\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Repository\\\n    \\ path to analyze (default = current\\\\\\\\\\\\n    \\\\\\\\ directory)\\\\\\\\\\\\\\\\npath =\\\n    \\ \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n### Rules\\\\\\\\\\\\\\\\n- If\\\n    \\ the `.repo-contextor.toml`\\\\\\\\\\\\n    \\\\\\\\ file is **missing**, the tool falls\\\n    \\ back to defaults.  \\\\\\\\\\\\\\\\n- If the file is **present\\\\\\\\\\\\n    \\\\\\\\ but invalid\\\n    \\ TOML**, the tool prints a clear error message and exits with status\\\\\\\\\\\\n \\\n    \\   \\\\\\\\ code 1.  \\\\\\\\\\\\\\\\n- **Unknown keys** in the TOML file are ignored (safe\\\n    \\ for future\\\\\\\\\\\\n    \\\\\\\\ extensions).  \\\\\\\\\\\\\\\\n- **Precedence** of settings\\\n    \\ is:\\\\\\\\\\\\\\\\n  1. Command-line arguments\\\\\\\\\\\\n    \\\\\\\\ (highest priority)  \\\\\\\n    \\\\\\\\\\\\n  2. Values from `.repo-contextor.toml`  \\\\\\\\\\\\\\\\n  3. Built-in\\\\\\\\\\\\n\\\n    \\    \\\\\\\\ defaults (lowest priority)\\\\\\\\\\\\\\\\n     \\\\\\\\\\\\\\\\n## Output Format\\\\\\\\\\\n    \\\\\\\\n\\\\\\\\\\\\\\\\nThe tool generates\\\\\\\\\\\\n    \\\\\\\\ a structured text file with the\\\n    \\ following sections:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 1. Repository Context\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ Header\\\\\\\\\\\\\\\\nProject path and identification\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 2. Git Repository\\\n    \\ Information\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n- Current branch\\\\\\\\\\\\\\\\n- Latest commit SHA\\\\\\\n    \\\\\\\\\\\\n- Last commit author\\\\\\\\\\\\\\\\n- Last commit\\\\\\\\\\\\n    \\\\\\\\ date\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n### 3. Summary Statistics\\\\\\\\\\\\\\\\n- Total number of files processed\\\\\\\n    \\\\\\\\\\\\n-\\\\\\\\\\\\n    \\\\\\\\ Total lines of code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 4. Directory\\\n    \\ Structure\\\\\\\\\\\\\\\\nClean tree visualization\\\\\\\\\\\\n    \\\\\\\\ showing project organization\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 5. Recent Changes (if `--recent` is used)\\\\\\\\\\\\\\\\\\\\\\\\\\\\n \\\n    \\   n\\\\\\\\\\\\\\\\n- Lists files modified in the last 7 days.\\\\\\\\\\\\\\\\n- Shows relative\\\n    \\ file paths along\\\\\\\\\\\\n    \\\\\\\\ with how long ago each file was modified\\\\\\\\\\\n    \\\\\\\\n- Helps focus on recently updated\\\\\\\\\\\\n    \\\\\\\\ parts of the project.\\\\\\\\\\\n    \\\\\\\\n- Can be combined with `--output` or `--format` to save\\\\\\\\\\\\n    \\\\\\\\ or\\\n    \\ change the output type.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 5. File Contents\\\\\\\\\\\\\\\n    \\\\nEach file's content\\\\\\\\\\\\n    \\\\\\\\ with:\\\\\\\\\\\\\\\\n- Clear file path headers\\\\\\\n    \\\\\\\\\\\\n- Appropriate syntax highlighting language\\\\\\\\\\\\n    \\\\\\\\ tags\\\\\\\\\\\\\\\\\\\n    n- Complete file contents\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Example Output\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\n    nWhen you run `repo-contextor\\\\\\\\\\\\n    \\\\\\\\ .`, the output looks like this:\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\n````markdown\\\\\\\\\\\\\\\\n# Repository Context: /path/to/your/project\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n## Git Repository Information\\\\\\\\\\\\\\\\n- **Branch**:\\\n    \\ main\\\\\\\\\\\\\\\\n- **Commit**: a1b2c3d4e5f6789...\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n- **Author**:\\\n    \\ John Doe <john@example.com>\\\\\\\\\\\\\\\\n- **Date**: Fri Sep 12 14:30:15 2025\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n## Summary\\\\\\\\\\\\\\\\n- **Total Files**: 15\\\\\\\\\\\\\\\\n- **Total\\\n    \\ Lines**: 1,247\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Directory\\\\\\\\\\\\n    \\\\\\\\ Structure\\\\\\\\\\\\\\\\\\\n    n```\\\\\\\\\\\\\\\\n├── src/\\\\\\\\\\\\\\\\n│   ├── main.py\\\\\\\\\\\\\\\\n│   └── utils.py\\\\\\\\\\\\\\\\\\\n    n├── tests/\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n│   └── test_main.py\\\\\\\\\\\\\\\\n├── README.md\\\\\\\\\\\\\\\n    \\\\n└── requirements.txt\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n## Recent\\\\\\\\\\\\n    \\\\\\\\ Changes\\\\\\\n    \\\\\\\\\\\\n- src/main.py (modified 2 days ago)\\\\\\\\\\\\\\\\n- src/utils/helpers.py (modified\\\\\\\n    \\\\\\\\n    \\\\\\\\ 5 days ago)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## File Contents\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n###\\\n    \\ src/main.py\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\ndef\\\\\\\\\\\\n    \\\\\\\\ main():\\\\\\\\\\\n    \\\\\\\\n    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello, World!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\n    nif __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\n    \\    main()\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### README.md\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```markdown\\\\\\\n    \\\\\\\\\\\\n# My Project\\\\\\\\\\\\\\\\nThis\\\\\\\\\\\\n    \\\\\\\\ is a sample project.\\\\\\\\\\\\\\\\n```\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Summary\\\\\\\\\\\\\\\\n- Total files: 15\\\\\\\\\\\\\\\\n- Total lines:\\\\\\\\\\\n    \\\\n    \\\\\\\\ 1,247\\\\\\\\\\\\\\\\n````\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## What Files Are Included\\\\\\\\\\\n    \\\\\\\\n\\\\\\\\\\\\\\\\nThe tool includes most text\\\\\\\\\\\\n    \\\\\\\\ files but automatically\\\n    \\ excludes:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Excluded Directories\\\\\\\\\\\\\\\\n- `.git`,\\\\\\\\\\\\\\\n    n    \\\\\\\\ `.svn`, `.hg` (version control)\\\\\\\\\\\\\\\\n- `__pycache__`, `.pytest_cache`\\\n    \\ (Python cache)\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n- `node_modules`, `.venv`, `venv` (dependencies/environments)\\\\\\\n    \\\\\\\\\\\\n- `.vscode`,\\\\\\\\\\\\n    \\\\\\\\ `.idea` (IDE directories)\\\\\\\\\\\\\\\\n- `build`,\\\n    \\ `dist`, `target` (build directories)\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n### File Handling\\\n    \\ Rules\\\\\\\\\\\\\\\\n- **Text files**: All readable text files with common\\\\\\\\\\\\n \\\n    \\   \\\\\\\\ extensions\\\\\\\\\\\\\\\\n- **Binary files**: Automatically detected and skipped\\\\\\\n    \\\\\\\\\\\\n- **Permission\\\\\\\\\\\\n    \\\\\\\\ errors**: Skipped with graceful handling\\\\\\\n    \\\\\\\\\\\\n- **Configuration files**: Includes\\\\\\\\\\\\n    \\\\\\\\ pyproject.toml, package.json,\\\n    \\ etc.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Included File Types\\\\\\\\\\\\\\\\n- Source code:\\\\\\\\\\\\n\\\n    \\    \\\\\\\\ `.py`, `.js`, `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\\\\\\\\\\\\\\n    \\\\n- Web files:\\\\\\\\\\\\n    \\\\\\\\ `.html`, `.css`, `.scss`, `.vue`, `.jsx`, etc.\\\\\\\n    \\\\\\\\\\\\n- Documentation: `.md`, `.txt`,\\\\\\\\\\\\n    \\\\\\\\ `.rst`\\\\\\\\\\\\\\\\n- Configuration:\\\n    \\ `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\\\\\\\\\\\\\\\n- Scripts:\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ `.sh`, `.bash`, `.zsh`\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Error Handling\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe\\\n    \\ tool handles errors gracefully:\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n| Error Type | Behavior\\\n    \\ |\\\\\\\\\\\\\\\\n|------------|----------|\\\\\\\\\\\\\\\\n| **Permission errors**\\\\\\\\\\\\n \\\n    \\   \\\\\\\\ | Skipped with warning |\\\\\\\\\\\\\\\\n| **Binary files** | Automatically detected\\\n    \\ and skipped\\\\\\\\\\\\n    \\\\\\\\ |\\\\\\\\\\\\\\\\n| **Invalid paths** | Clear error messages\\\n    \\ |\\\\\\\\\\\\\\\\n| **Non-git repositories**\\\\\\\\\\\\n    \\\\\\\\ | Works fine, shows \\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"Not a git repository\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" |\\\\\\\\\\\\\\\\n| **Unreadable files**\\\\\\\n    \\\\\\\\n    \\\\\\\\ | Marked as \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[Binary or unreadable file]\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\" |\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Development\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n###\\\\\\\\\\\\n    \\\\\\\\ Project\\\n    \\ Structure\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```text\\\\\\\\\\\\\\\\nRepo-Contextor/\\\\\\\\\\\\\\\\n├── src/rcpack/\\\n    \\         \\\\\\\\\\\\n    \\\\\\\\     # Main package\\\\\\\\\\\\\\\\n│   ├── __init__.py     \\\n    \\    # Package initialization\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n│   ├── cli.py              #\\\n    \\ Command-line interface\\\\\\\\\\\\\\\\n│   ├── discover.py  \\\\\\\\\\\\n    \\\\\\\\       #\\\n    \\ File discovery logic\\\\\\\\\\\\\\\\n│   ├── gitinfo.py          # Git repository\\\\\\\\\\\n    \\\\n    \\\\\\\\ analysis\\\\\\\\\\\\\\\\n│   ├── treeview.py         # Directory tree generation\\\\\\\n    \\\\\\\\\\\\n│   ├──\\\\\\\\\\\\n    \\\\\\\\ packager.py         # Main orchestration\\\\\\\\\\\\\\\\\\\n    n│   ├── io_utils.py         # File\\\\\\\\\\\\n    \\\\\\\\ I/O utilities\\\\\\\\\\\\\\\\n│   └──\\\n    \\ renderer/           # Output formatters\\\\\\\\\\\\\\\\n│       ├──\\\\\\\\\\\\n    \\\\\\\\ markdown.py\\\n    \\     # Markdown renderer\\\\\\\\\\\\\\\\n│       └── jsonyaml.py     # JSON/YAML\\\\\\\\\\\\\\\n    n    \\\\\\\\ renderers\\\\\\\\\\\\\\\\n├── pyproject.toml          # Project configuration\\\\\\\n    \\\\\\\\\\\\n├── LICENSE\\\\\\\\\\\\n    \\\\\\\\                 # MIT License\\\\\\\\\\\\\\\\n└── README.md\\\n    \\              # This documentation\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n###\\\n    \\ Running Tests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Test on current repository\\\\\\\n    \\\\\\\\\\\\nrepo-contextor\\\\\\\\\\\\n    \\\\\\\\ . -o test-output.md\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Test\\\n    \\ different formats\\\\\\\\\\\\\\\\nrepo-contextor . -f json\\\\\\\\\\\\n    \\\\\\\\ | head -20\\\\\\\n    \\\\\\\\\\\\nrepo-contextor . -f yaml | head -20\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Test specific directory\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    nrepo-contextor src/ -o src-only.md\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\n    \\\\n### Contributing\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **Fork\\\\\\\\\\\\n    \\\\\\\\ the repository**\\\\\\\n    \\\\\\\\\\\\n2. **Clone your fork:**\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n   cd Repo-Contextor\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\n3. **Install for\\\n    \\ development:**\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n   python -m venv .venv\\\\\\\n    \\\\\\\\\\\\n   source .venv/bin/activate\\\\\\\\\\\\\\\\n   pip install -e .\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    n   ```\\\\\\\\\\\\\\\\n4. **Make your changes and test:**\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\n    \\\\\\\\n   repo-contextor\\\\\\\\\\\\n    \\\\\\\\ . -o test.md\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\n5. **Submit\\\n    \\ a pull request**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Development Workflow\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\n    \\  n\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# 1. Setup development environment\\\\\\\\\\\\\\\\ngit clone\\\n    \\ https://github.com/yourusername/Repo-Contextor.git\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ncd Repo-Contextor\\\\\\\n    \\\\\\\\\\\\npython -m venv .venv\\\\\\\\\\\\\\\\nsource .venv/bin/activate\\\\\\\\\\\\\\\\npip install\\\\\\\n    \\\\\\\\n    \\\\\\\\ -e .\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# 2. Make changes to the code\\\\\\\\\\\\\\\\n# Edit\\\n    \\ files in src/rcpack/\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#\\\\\\\\\\\\n    \\\\\\\\ 3. Test your changes\\\\\\\n    \\\\\\\\\\\\nrepo-contextor . -o test-output.md\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# 4. Test different\\\\\\\n    \\\\\\\\n    \\\\\\\\ formats\\\\\\\\\\\\\\\\nrepo-contextor . -f json -o test.json\\\\\\\\\\\\\\\\nrepo-contextor\\\n    \\ . -f yaml -o\\\\\\\\\\\\n    \\\\\\\\ test.yaml\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# 5. Commit and push\\\n    \\ changes\\\\\\\\\\\\\\\\ngit add .\\\\\\\\\\\\\\\\ngit commit -m \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    Add\\\n    \\ new feature\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\ngit push origin feature-branch\\\\\\\\\\\\\\\\n```\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## License\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    nThis project is licensed\\\n    \\ under the MIT License. See the [LICENSE](LICENSE) file\\\\\\\\\\\\n    \\\\\\\\ for details.\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Why Repo-Contextor?\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe name \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\"Repo-Contextor\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    \\\\\\\\ combines \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\" + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"or\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\", representing the\\\\\\\\\\\\n    \\\\\\\\ tool's purpose of providing rich\\\n    \\ context about code repositories in a format\\\\\\\\\\\\n    \\\\\\\\ that's perfect for\\\n    \\ LLM interactions.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Use Cases\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n- **AI Assistance**:\\\\\\\n    \\\\\\\\n    \\\\\\\\ Get better help from ChatGPT, Claude, or GitHub Copilot\\\\\\\\\\\\\\\\\\\n    n- **Code Reviews**:\\\\\\\\\\\\n    \\\\\\\\ Share complete project context with team members\\\\\\\n    \\\\\\\\\\\\n- **Documentation**: Create\\\\\\\\\\\\n    \\\\\\\\ comprehensive project snapshots\\\\\\\n    \\\\\\\\\\\\n- **Onboarding**: Help new team members understand\\\\\\\\\\\\n    \\\\\\\\ project\\\n    \\ structure\\\\\\\\\\\\\\\\n- **Project Analysis**: Understand repository structure\\\\\\\\\\\n    \\\\n    \\\\\\\\ and dependencies\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Perfect for LLMs\\\\\\\\\\\\\\\\n\\\\\\\\\\\n    \\\\\\\\nThe output format is specifically\\\\\\\\\\\\n    \\\\\\\\ designed to work well with\\\n    \\ Large Language Models:\\\\\\\\\\\\\\\\n- Clear section headers\\\\\\\\\\\\n    \\\\\\\\ for easy\\\n    \\ parsing\\\\\\\\\\\\\\\\n- Syntax highlighting markers for code blocks\\\\\\\\\\\\\\\\n- Structured\\\\\\\n    \\\\\\\\n    \\\\\\\\ metadata (git info, file locations)\\\\\\\\\\\\\\\\n- Complete project context\\\n    \\ in a single\\\\\\\\\\\\n    \\\\\\\\ file\\\\\\\\\\\\\\\\n- Multiple output formats (Markdown,\\\n    \\ JSON, YAML)\\\\\\\\\\\\\\\\n- Optimized for token\\\\\\\\\\\\n    \\\\\\\\ efficiency\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"pyproject.toml\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"[build-system]\\\\\\\\\\\\\\\n    \\\\nrequires = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    setuptools>=68\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"wheel\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\nbuild-backend = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"setuptools.build_meta\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n[project]\\\\\\\\\\\\\\\\nname = \\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"rcpack\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nversion = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"0.1.0\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\\ndescription\\\\\\\\\\\\n    \\\\\\\\ = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository Context\\\n    \\ Packager CLI for LLMs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nreadme = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"README.md\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nrequires-python = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">=3.9\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nlicense = { text = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MIT\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" }\\\\\\\\\\\n    \\\\\\\\ndependencies\\\\\\\\\\\\n    \\\\\\\\ = [\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"PyYAML>=6.0\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n[project.scripts]\\\\\\\\\\\\\\\\nrepo-contextor\\\n    \\ =\\\\\\\\\\\\n    \\\\\\\\ \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"rcpack.cli:main\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\n    \\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/__init__.py\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    Repository Context Packager - CLI tool\\\n    \\ for creating LLM-optimized repository context.\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n__version__ = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"0.1.0\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n__author__ = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Abhinav\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\\\\\n__description__\\\\\\\\\\\\n    \\\\\\\\ = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository Context Packager\\\n    \\ CLI for LLMs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/__main__.py\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\n    : \\\\\\\\\\\\\\\"#!/usr/bin/env python3\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Module entry point to enable `python\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ -m rcpack`.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis simply delegates to the CLI's main() function.\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\n    \\\\\\\\nfrom .cli import main\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\    main()\\\\\\\\\\\\\\\\n\\\\\\\\\\\n    \\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/cli.py\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"#!/usr/bin/env\\\n    \\ python3\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    CLI for Repository Context Packager.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom .config_loader\\\\\\\\\\\\n    \\\\\\\\ import load_config\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport argparse\\\\\\\\\\\\\\\\nimport sys\\\\\\\\\\\\\\\\nfrom pathlib import\\\n    \\ Path\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    nfrom .gitinfo import get_git_info\\\\\\\\\\\\\\\\nfrom .discover\\\n    \\ import discover_files\\\\\\\\\\\\\\\\nfrom\\\\\\\\\\\\n    \\\\\\\\ .treeview import create_tree_view\\\\\\\n    \\\\\\\\\\\\nfrom .renderer.markdown import render_markdown\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    nfrom\\\n    \\ .renderer.jsonyaml import render_json, render_yaml\\\\\\\\\\\\\\\\nfrom .io_utils import\\\\\\\n    \\\\\\\\n    \\\\\\\\ write_output\\\\\\\\\\\\\\\\nfrom datetime import datetime, timedelta\\\\\\\\\\\n    \\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef log_verbose(message:\\\\\\\\\\\\n    \\\\\\\\ str, verbose: bool)\\\n    \\ -> None:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Log a message\\\n    \\ to stderr if verbose\\\\\\\\\\\\n    \\\\\\\\ mode is enabled.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if verbose:\\\\\\\\\\\\\\\\n        print(message,\\\n    \\ file=sys.stderr)\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef get_rendered_content(format_type:\\\n    \\ str, repo_path: str, repo_info: dict,\\\\\\\\\\\\n    \\\\\\\\ tree_text: str, \\\\\\\\\\\\\\\\\\\n    n                        files_data: dict, total_files: int,\\\\\\\\\\\\n    \\\\\\\\ total_lines:\\\n    \\ int, \\\\\\\\\\\\\\\\n                        recent_files_info: dict, file_sizes:\\\\\\\n    \\\\\\\\n    \\\\\\\\ dict) -> str:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\"Get rendered content based on the specified\\\\\\\\\\\\n    \\\\\\\\ format.\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if format_type == \\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n        return render_json(\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\n    n            repo_path, repo_info, tree_text, \\\\\\\\\\\\\\\\n           \\\n    \\ files_data, total_files,\\\\\\\\\\\\n    \\\\\\\\ total_lines,\\\\\\\\\\\\\\\\n            recent_files=recent_files_info,\\\\\\\n    \\\\\\\\\\\\n            file_sizes=file_sizes\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n        )\\\\\\\\\\\\\\\\\\\n    n    elif format_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n      \\\n    \\  return render_yaml(\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n            repo_path, repo_info, tree_text,\\\n    \\ \\\\\\\\\\\\\\\\n            files_data, total_files,\\\\\\\\\\\\n    \\\\\\\\ total_lines,\\\\\\\\\\\n    \\\\\\\\n            recent_files=recent_files_info,\\\\\\\\\\\\\\\\n            file_sizes=file_sizes\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n        )\\\\\\\\\\\\\\\\n    else:  # text/markdown\\\\\\\\\\\\\\\\n      \\\n    \\  return render_markdown(\\\\\\\\\\\\\\\\n \\\\\\\\\\\\n    \\\\\\\\           repo_path, repo_info,\\\n    \\ tree_text, \\\\\\\\\\\\\\\\n            files_data, total_files,\\\\\\\\\\\\n    \\\\\\\\ total_lines,\\\\\\\n    \\\\\\\\\\\\n            recent_files=recent_files_info,\\\\\\\\\\\\\\\\n            file_sizes=file_sizes\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef process_file(file_path:\\\n    \\ Path, repo_path: Path, verbose:\\\\\\\\\\\\n    \\\\\\\\ bool) -> tuple[str, str, str]:\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Process a single file\\\n    \\ and return\\\\\\\\\\\\n    \\\\\\\\ its data.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\n    n        tuple: (relative_path_str, content,\\\\\\\\\\\\n    \\\\\\\\ file_size)\\\\\\\\\\\\\\\\\\\n    n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    relative_path\\\n    \\ = file_path.relative_to(repo_path)\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    relative_path_str\\\n    \\ = str(relative_path)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    log_verbose(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    Reading\\\\\\\\\\\\n    \\\\\\\\ file: {relative_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", verbose)\\\\\\\\\\\\\\\\\\\n    n    file_size = file_path.stat().st_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    \\\\\\\\\\\\\\\\n   \\\n    \\ try:\\\\\\\\\\\\\\\\n        with open(file_path, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    n            content = f.read()\\\\\\\\\\\\\\\\n        return relative_path_str,\\\n    \\ content, str(file_size)\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    except (UnicodeDecodeError, PermissionError):\\\\\\\n    \\\\\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    Skipping binary/unreadable\\\n    \\ file: {relative_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", verbose)\\\\\\\\\\\\\\\\n        file_size\\\\\\\\\\\n    \\\\n    \\\\\\\\ = file_path.stat().st_size if file_path.exists() else 0\\\\\\\\\\\\\\\\n \\\n    \\       content =\\\\\\\\\\\\n    \\\\\\\\ f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[Binary or unreadable file:\\\n    \\ {file_path.name}]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return relative_path_str,\\\\\\\n    \\\\\\\\n    \\\\\\\\ content, str(file_size)\\\\\\\\\\\\\\\\n    except Exception:\\\\\\\\\\\\\\\\n \\\n    \\       log_verbose(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    Error reading file: {relative_path}\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\", verbose)\\\\\\\\\\\\\\\\n        raise  # Re-raise\\\\\\\\\\\\n    \\\\\\\\ to handle\\\n    \\ in calling code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef handle_output(content: str, output_path:\\\\\\\n    \\\\\\\\n    \\\\\\\\ str = None) -> None:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Handle output to either file or stdout.\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if output_path:\\\\\\\\\\\\\\\\n    \\\n    \\    # Write to file\\\\\\\\\\\\\\\\n        write_output(output_path,\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ content)\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Context package created: {output_path}\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    else:\\\\\\\\\\\\\\\\n        # Output to stdout\\\\\\\n    \\\\\\\\\\\\n        print(content)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef main():\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\n    n    parser = argparse.ArgumentParser(\\\\\\\\\\\\\\\\n        description=\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"Package repository\\\\\\\\\\\\n    \\\\\\\\ content for LLM context\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n    )\\\\\\\\\\\\\\\\n    parser.add_argument(\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\n    path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\n        nargs=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\"?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\n        default=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    , \\\\\\\\\\\\\\\\n      \\\\\\\\\\\\n    \\\\\\\\  help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository path (default:\\\n    \\ current directory)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    )\\\\\\\\\\\\\\\\n    parser.add_argument(\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    --output\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\n        help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Output file path\\\n    \\ (default:\\\\\\\\\\\\n    \\\\\\\\ stdout)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    )\\\\\\\\\\\\\\\\n    parser.add_argument(\\\\\\\n    \\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--format\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\n        choices=[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"], \\\\\\\\\\\\\\\\n       \\\\\\\\\\\\n    \\\\\\\\ default=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\",\\\\\\\\\\\\\\\\n        help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Output format (default: text)\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" This will read -r from the console and able to search\\\\\\\n    \\\\\\\\n    \\\\\\\\ it with this\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\\\\\n    parser.add_argument(\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-r\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\n    \\ \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--recent\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    action=\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"store_true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Include\\\n    \\ only files modified\\\\\\\\\\\\n    \\\\\\\\ in the last 7 days\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\n    n    )\\\\\\\\\\\\\\\\n    parser.add_argument(\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-v\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--verbose\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n \\\n    \\       action=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"store_true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        help=\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    Print detailed progress information to stderr\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    )\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    args =\\\\\\\\\\\\n    \\\\\\\\ parser.parse_args()\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        repo_path = Path(args.path).resolve()\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n        if not repo_path.exists():\\\\\\\\\\\\\\\\n            print(f\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"Error: Path {repo_path}\\\\\\\\\\\\n    \\\\\\\\ does not exist\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\", file=sys.stderr)\\\\\\\\\\\\\\\\n            sys.exit(1)\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\n    n    \\\\\\\\  \\\\\\\\\\\\\\\\n        # Get repository information\\\\\\\\\\\\\\\\n        log_verbose(f\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyzing\\\\\\\\\\\\n    \\\\\\\\ repository: {repo_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    , args.verbose)\\\\\\\\\\\\\\\\n        repo_info = get_git_info(repo_path)\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\n    n        \\\\\\\\\\\\\\\\n        # Discover files\\\\\\\\\\\\\\\\n        log_verbose(f\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"Discovering files\\\\\\\\\\\\n    \\\\\\\\ in: {repo_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    , args.verbose)\\\\\\\\\\\\\\\\n        discovered_files = discover_files([repo_path],\\\\\\\n    \\\\\\\\n    \\\\\\\\ repo_path, [], [])\\\\\\\\\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    Found {len(discovered_files)}\\\\\\\\\\\\n    \\\\\\\\ files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", args.verbose)\\\\\\\n    \\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # will check the file in last\\\\\\\\\\\\n    \\\\\\\\ 7\\\n    \\ days\\\\\\\\\\\\\\\\n        recent_files_info = {}\\\\\\\\\\\\\\\\n        if args.recent:\\\\\\\n    \\\\\\\\\\\\n       \\\\\\\\\\\\n    \\\\\\\\     seven_days_ago = datetime.now() - timedelta(days=7)\\\\\\\n    \\\\\\\\\\\\n            recent_files\\\\\\\\\\\\n    \\\\\\\\ = []\\\\\\\\\\\\\\\\n            for f\\\n    \\ in discovered_files:\\\\\\\\\\\\\\\\n                try:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\\\\n    \\                mtime = datetime.fromtimestamp(f.stat().st_mtime)\\\\\\\\\\\\\\\\n  \\\n    \\      \\\\\\\\\\\\n    \\\\\\\\            if mtime >= seven_days_ago:\\\\\\\\\\\\\\\\n       \\\n    \\                 recent_files.append(f)\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n                 \\\n    \\       recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)\\\\\\\n    \\\\\\\\n    \\\\\\\\     \\\\\\\\\\\\\\\\n                except Exception:\\\\\\\\\\\\\\\\n        \\\n    \\            continue\\\\\\\\\\\\\\\\n \\\\\\\\\\\\n    \\\\\\\\           discovered_files = recent_files\\\\\\\n    \\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Read file contents\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n     \\\n    \\   files_data = {}\\\\\\\\\\\\\\\\n        file_sizes = {}\\\\\\\\\\\\\\\\n        for file_path\\\n    \\ in\\\\\\\\\\\\n    \\\\\\\\ discovered_files:\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n      \\\n    \\          relative_path_str, content,\\\\\\\\\\\\n    \\\\\\\\ file_size = process_file(file_path,\\\n    \\ repo_path, args.verbose)\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\n    \\\\\\\\    files_data[relative_path_str]\\\n    \\ = content\\\\\\\\\\\\\\\\n                file_sizes[relative_path_str]\\\\\\\\\\\\n    \\\\\\\n    \\\\ = file_size\\\\\\\\\\\\\\\\n            except Exception:\\\\\\\\\\\\\\\\n                continue\\\\\\\n    \\\\\\\\\\\\n  \\\\\\\\\\\\n    \\\\\\\\      \\\\\\\\\\\\\\\\n        # Create tree view\\\\\\\\\\\\\\\\n   \\\n    \\     log_verbose(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generating directory\\\\\\\\\\\\n    \\\\\\\\ tree\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\\\\\\\\\n        tree_text = create_tree_view(repo_path,\\\n    \\ files_data)\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n        \\\\\\\\\\\\\\\\n        # Count totals\\\\\\\\\\\\\\\n    \\\\n        total_files = len(files_data)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        total_lines\\\n    \\ = sum(len(content.splitlines()) for _, content in files_data.items())\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\n    n        \\\\\\\\\\\\\\\\n        # Render based on format\\\\\\\\\\\\\\\\n       \\\n    \\ log_verbose(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Rendering\\\\\\\\\\\\n    \\\\\\\\ output in {args.format}\\\n    \\ format\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\\\\\\\\\n        content = get_rendered_content(\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n            args.format, str(repo_path), repo_info, tree_text,\\\\\\\n    \\\\\\\\\\\\n           \\\\\\\\\\\\n    \\\\\\\\ files_data, total_files, total_lines,\\\\\\\\\\\\\\\\\\\n    n            recent_files_info if args.recent\\\\\\\\\\\\n    \\\\\\\\ else {},\\\\\\\\\\\\\\\\\\\n    n            file_sizes\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        handle_output(content,\\\\\\\n    \\\\\\\\n    \\\\\\\\ args.output)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\n    \\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error:\\\\\\\\\\\\n    \\\\\\\\ {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    , file=sys.stderr)\\\\\\\\\\\\\\\\n        sys.exit(1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# this will convert\\\n    \\ age\\\\\\\\\\\\n    \\\\\\\\ and give us the difference\\\\\\\\\\\\\\\\ndef human_readable_age(mtime:\\\n    \\ datetime) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    delta = datetime.now() - mtime\\\\\\\\\\\\\\\n    \\\\n    days = delta.days\\\\\\\\\\\\\\\\n    seconds = delta.seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\n    \\  n    if days > 0:\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{days} day{'s' if\\\n    \\ days != 1 else ''} ago\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    elif seconds >=\\\n    \\ 3600:\\\\\\\\\\\\\\\\n        hours = seconds // 3600\\\\\\\\\\\\\\\\n        return\\\\\\\\\\\\n\\\n    \\    \\\\\\\\ f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{hours} hour{'s' if hours != 1 else ''} ago\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    elif seconds >= 60:\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n        minutes =\\\n    \\ seconds // 60\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{minutes} minute{'s' if\\\\\\\n    \\\\\\\\n    \\\\\\\\ minutes != 1 else ''} ago\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    else:\\\\\\\\\\\\\\\n    \\\\n        return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"just now\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\n    \\\\\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n    main()\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/config_loader.py\\\\\\\\\\\\\\\"\\\\\\\\\\\\n  \\\n    \\  : \\\\\\\\\\\\\\\"# src/rcpack/config_loader.py\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTOML config loader for Repo-Contextor.\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\n    n\\\\\\\\\\\\\\\\nRules:\\\\\\\\\\\\\\\\n- Look for .repo-contextor.toml in the CURRENT\\\n    \\ directory\\\\\\\\\\\\\\\\n- If missing:\\\\\\\\\\\\n    \\\\\\\\ ignore\\\\\\\\\\\\\\\\n- If present but\\\n    \\ invalid: print a clear error and exit(1)\\\\\\\\\\\\\\\\n- Only\\\\\\\\\\\\n    \\\\\\\\ recognized\\\n    \\ keys are applied; unknown keys ignored\\\\\\\\\\\\\\\\n- Precedence: CLI > TOML\\\\\\\\\\\\\\\n    n    \\\\\\\\ > DEFAULTS\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\n    \\\\\\\\\\\\nfrom __future__ import annotations\\\\\\\\\\\\\\\\nimport os,\\\\\\\\\\\\n    \\\\\\\\ sys\\\\\\\n    \\\\\\\\\\\\nfrom typing import Dict, Iterable, Any\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ntry:\\\\\\\\\\\\\\\\n \\\n    \\   import tomllib\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    _loads = tomllib.loads\\\\\\\\\\\\\\\\nexcept\\\n    \\ ModuleNotFoundError:\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\n    \\\\\\\\  import\\\n    \\ tomli\\\\\\\\\\\\\\\\n        _loads = tomli.loads\\\\\\\\\\\\\\\\n    except ModuleNotFoundError:\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n        _loads = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _need_toml():\\\\\\\\\\\n    \\\\\\\\n    if _loads is None:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\"Error: TOML parser not available. Use Python 3.11+ or `pip install\\\\\\\\\\\\n  \\\n    \\  \\\\\\\\ tomli`.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\\\\\\\\\n        sys.exit(1)\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _load_toml(dotfile:\\\\\\\\\\\\n    \\\\\\\\ str) -> Dict[str, Any]:\\\\\\\n    \\\\\\\\\\\\n    _need_toml()\\\\\\\\\\\\\\\\n    if not os.path.exists(dotfile):\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\n    n        return {}\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        with open(dotfile,\\\n    \\ \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"rb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n            raw\\\n    \\ = f.read().decode(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", errors=\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\"strict\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\n    \\\\\\\\      data = _loads(raw)\\\\\\\n    \\\\\\\\\\\\n        return data if isinstance(data, dict) else\\\\\\\\\\\\n    \\\\\\\\ {}\\\\\\\\\\\n    \\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error:\\\n    \\ failed to parse\\\\\\\\\\\\n    \\\\\\\\ {dotfile} as TOML.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n{e}\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\\\\\\\\\n        sys.exit(1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str,\\\n    \\ Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    ks = set(known)\\\\\\\\\\\\\\\\n    return {k: v for k,\\\n    \\ v in d.items() if k in ks}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ndef _merge(defaults:\\\n    \\ Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str,\\\\\\\\\\\\n    \\\\\\\\ Any],\\\n    \\ known: Iterable[str]) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n    ks = set(known)\\\\\\\\\\\\\\\\\\\n    n    out:\\\\\\\\\\\\n    \\\\\\\\ Dict[str, Any] = {k: defaults.get(k) for k in ks}\\\\\\\\\\\n    \\\\\\\\n    for src in (filecfg,\\\\\\\\\\\\n    \\\\\\\\ clicfg):\\\\\\\\\\\\\\\\n        for k, v\\\n    \\ in src.items():\\\\\\\\\\\\\\\\n            if k in ks and v is\\\\\\\\\\\\n    \\\\\\\\ not None:\\\\\\\n    \\\\\\\\\\\\n                out[k] = v\\\\\\\\\\\\\\\\n    return out\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef\\\n    \\ load_config(*,\\\\\\\\\\\\n    \\\\\\\\ dotfile: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".repo-contextor.toml\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\", defaults: Dict[str, Any] | None\\\\\\\\\\\\n    \\\\\\\\ = None, cli_cfg:\\\n    \\ Dict[str, Any] | None = None, known_keys: Iterable[str] = ())\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ -> Dict[str, Any]:\\\\\\\\\\\\\\\\n    defaults = defaults or {}\\\\\\\\\\\\\\\\n    cli_cfg\\\n    \\ = cli_cfg or\\\\\\\\\\\\n    \\\\\\\\ {}\\\\\\\\\\\\\\\\n    known = tuple(known_keys)\\\\\\\\\\\\\\\\\\\n    n    filecfg = _filter_known(_load_toml(dotfile),\\\\\\\\\\\\n    \\\\\\\\ known)\\\\\\\\\\\\\\\\\\\n    n    return _merge(defaults, filecfg, cli_cfg, known)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n \\\n    \\   \\\\\\\\\\\\\\\"\\\\\\\\\\\\n    src/rcpack/discover.py\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"File discovery module for repository analysis.\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom\\\n    \\ pathlib import Path\\\\\\\\\\\\\\\\nfrom typing import List\\\\\\\\\\\\\\\\nimport fnmatch\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef discover_files(\\\\\\\\\\\\\\\\n    inputs: List[Path],\\\\\\\n    \\\\\\\\\\\\n    root: Path,\\\\\\\\\\\\\\\\n    include_patterns:\\\\\\\\\\\\n    \\\\\\\\ List[str],\\\\\\\n    \\\\\\\\\\\\n    exclude_patterns: List[str],\\\\\\\\\\\\\\\\n) -> List[Path]:\\\\\\\\\\\\\\\\n    \\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Discover relevant files.\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    - inputs: list of files/dirs to scan\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n \\\n    \\   - root: common project root; patterns are matched against POSIX paths relative\\\\\\\n    \\\\\\\\n    \\\\\\\\ to root\\\\\\\\\\\\\\\\n    - include_patterns: glob patterns to include\\\n    \\ (if empty, use sensible\\\\\\\\\\\\n    \\\\\\\\ defaults)\\\\\\\\\\\\\\\\n    - exclude_patterns:\\\n    \\ glob patterns to exclude\\\\\\\\\\\\\\\\n    Returns a\\\\\\\\\\\\n    \\\\\\\\ list of absolute\\\n    \\ Paths to files.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    default_include_exts\\\\\\\\\\\\n    \\\\\\\\ = {\\\\\\\\\\\\\\\\n       \\\n    \\ '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\n    n        '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\\\\\\n    \\\\\\\\\\\\n   \\\\\\\\\\\\n    \\\\\\\\     '.html', '.css', '.scss', '.sass', '.less', '.vue',\\\n    \\ '.svelte',\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\n    \\\\\\\\  '.md', '.txt', '.rst', '.yaml', '.yml',\\\n    \\ '.json', '.toml', '.ini',\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\n    \\\\\\\\  '.cfg', '.conf', '.xml',\\\n    \\ '.sql', '.sh', '.bash', '.zsh', '.fish',\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\n    \\\\\\\\\\\\n    always_include_names = {\\\\\\\\\\\\\\\\n        'README', 'LICENSE', 'CHANGELOG',\\\n    \\ 'CONTRIBUTING',\\\\\\\\\\\\n    \\\\\\\\ 'Makefile',\\\\\\\\\\\\\\\\n        'requirements.txt',\\\n    \\ 'package.json', 'Cargo.toml', 'pyproject.toml',\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n        'setup.py',\\\n    \\ 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    n    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    skip_dir_names = {\\\\\\\\\\\\\\\\n        '.git',\\\n    \\ '.svn', '.hg', '__pycache__',\\\\\\\\\\\\n    \\\\\\\\ '.pytest_cache',\\\\\\\\\\\\\\\\n     \\\n    \\   'node_modules', '.venv', 'venv', 'env', '.env',\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n      \\\n    \\  'build', 'dist', 'target', 'out', '.next', '.nuxt',\\\\\\\\\\\\\\\\n        '.idea',\\\\\\\n    \\\\\\\\n    \\\\\\\\ '.vscode', '.vs', 'coverage', '.coverage'\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n    def matches_any(patterns:\\\\\\\\\\\\n    \\\\\\\\ List[str], rel_posix: str)\\\n    \\ -> bool:\\\\\\\\\\\\\\\\n        return any(fnmatch.fnmatch(rel_posix,\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ pat) for pat in patterns)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def should_take(file_path: Path)\\\n    \\ -> bool:\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n        rel_posix = file_path.relative_to(root).as_posix()\\\\\\\n    \\\\\\\\\\\\n        if exclude_patterns\\\\\\\\\\\\n    \\\\\\\\ and matches_any(exclude_patterns,\\\n    \\ rel_posix):\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\       \\\n    \\ if include_patterns:\\\\\\\\\\\\\\\\n            return matches_any(include_patterns,\\\\\\\n    \\\\\\\\n    \\\\\\\\ rel_posix)\\\\\\\\\\\\\\\\n        # default include logic\\\\\\\\\\\\\\\\n    \\\n    \\    return file_path.name\\\\\\\\\\\\n    \\\\\\\\ in always_include_names or file_path.suffix.lower()\\\n    \\ in default_include_exts\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n    discovered: list[Path]\\\n    \\ = []\\\\\\\\\\\\\\\\n    seen = set()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    for item in inputs:\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    n        p = item.resolve()\\\\\\\\\\\\\\\\n        if p.is_file():\\\\\\\\\\\\\\\n    \\\\n            # Skip if\\\\\\\\\\\\n    \\\\\\\\ excluded or in skipped directory\\\\\\\\\\\\\\\n    \\\\n            if any(part in skip_dir_names\\\\\\\\\\\\n    \\\\\\\\ for part in p.parts):\\\\\\\n    \\\\\\\\\\\\n                continue\\\\\\\\\\\\\\\\n            if should_take(p):\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\n    n                key = p.as_posix()\\\\\\\\\\\\\\\\n                if key\\\n    \\ not in seen:\\\\\\\\\\\\\\\\n \\\\\\\\\\\\n    \\\\\\\\                   seen.add(key)\\\\\\\\\\\\\\\\\\\n    n                    discovered.append(p)\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n        elif p.is_dir():\\\\\\\n    \\\\\\\\\\\\n            for child in p.rglob('*'):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\n    \\\\\\\\\\\n    \\        if not child.is_file():\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\\\\n    n           \\\\\\\\\\\\n    \\\\\\\\     if any(part in skip_dir_names for part in child.parts):\\\\\\\n    \\\\\\\\\\\\n             \\\\\\\\\\\\n    \\\\\\\\       continue\\\\\\\\\\\\\\\\n                if\\\n    \\ should_take(child):\\\\\\\\\\\\\\\\n                 \\\\\\\\\\\\n    \\\\\\\\   key = child.resolve().as_posix()\\\\\\\n    \\\\\\\\\\\\n                    if key not in seen:\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n           \\\n    \\             seen.add(key)\\\\\\\\\\\\\\\\n                        discovered.append(child.resolve())\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n    return sorted(discovered)\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\n    \\\\\\\"src/rcpack/gitinfo.py\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from __future__\\\\\\\\\\\\n    \\\\\\\\ import\\\n    \\ annotations\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport subprocess\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\n    \\\\\\\\\\\\nfrom\\\\\\\\\\\\n    \\\\\\\\ typing import Dict, Any\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef\\\n    \\ _git(cmd: list[str], cwd: Path) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    # Validate git\\\n    \\ commands to prevent injection\\\\\\\\\\\\\\\\n    allowed_commands = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"show\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"log\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\"config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n    if not cmd or cmd[0] not in\\\n    \\ allowed_commands:\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n        raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\"Git command not allowed: {cmd[0] if cmd else 'empty'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\n    \\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    out = subprocess.check_output([\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", *cmd], cwd=str(cwd),\\\\\\\\\\\\n    \\\\\\\\ timeout=30)\\\\\\\\\\\\\\\\n\\\n    \\    return out.decode(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", errors=\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"replace\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\").strip()\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef\\\n    \\ is_git_repo(path: Path) -> bool:\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        flag = _git([\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--is-inside-work-tree\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\\\\\\\\\\n        return flag\\\\\\\\\\\\n    \\\\\\\\ == \\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\"true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    except Exception:\\\\\\\\\\\\\\\\n        return\\\n    \\ False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef get_git_info(path:\\\\\\\\\\\\n    \\\\\\\\ Path)\\\n    \\ -> Dict[str, Any]:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\\n    Return info for the current\\\\\\\\\\\\n    \\\\\\\\ HEAD of a repo rooted\\\n    \\ at `path`.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    \\\\n    try:\\\\\\\\\\\\\\\\n        commit\\\\\\\\\\\\n    \\\\\\\\ = _git([\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"rev-parse\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"HEAD\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\\\\\\\\\\n    \\\n    \\    branch = _git([\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"--abbrev-ref\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"HEAD\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    ], cwd=path)\\\\\\\\\\\\\\\\n        author\\\\\\\\\\\\n    \\\\\\\\ = _git([\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"show\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--format=%an\\\n    \\ <%ae>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\        date = _git([\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"show\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\"--date=local\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--format=%ad\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\n    \\\\\\\\\\\\\\\"], cwd=path)\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": True,\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\       \\\n    \\ \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": commit,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": branch,\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\        \\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": author,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\"date\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": date,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\n    \\\\\\\\    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\"note\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": None,\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n    except Exception:\\\\\\\n    \\\\\\\\\\\\n        # treat\\\\\\\\\\\\n    \\\\\\\\ as not a repo if anything fails\\\\\\\\\\\\\\\\\\\n    n        return {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\\\\\\\\\\\\\\n \\\n    \\   \\\\\\\\\\\\\\\": False,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    : None,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": None,\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": None,\\\\\\\\\\\\\\\\\\\n    n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"date\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": None,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\n    n    \\\\\\\\      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"note\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Not a git\\\n    \\ repository\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\n    \\\\\\\"src/rcpack/io_utils.py\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    : \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I/O utilities for file operations.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom pathlib\\\\\\\\\\\\n    \\\\\\\\ import\\\n    \\ Path\\\\\\\\\\\\\\\\nfrom typing import Tuple\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef write_output(output_path:\\\\\\\n    \\\\\\\\n    \\\\\\\\ str, content: str) -> None:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Write content to output file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    output_file = Path(output_path)\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Create parent\\\\\\\\\\\\n    \\\\\\\\ directories if they don't\\\n    \\ exist\\\\\\\\\\\\\\\\n    output_file.parent.mkdir(parents=True,\\\\\\\\\\\\n    \\\\\\\\ exist_ok=True)\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Write content\\\\\\\\\\\\\\\\n    with open(output_file, 'w',\\\\\\\n    \\\\\\\\n    \\\\\\\\ encoding='utf-8') as f:\\\\\\\\\\\\\\\\n        f.write(content)\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef is_binary_file(path:\\\\\\\\\\\\n    \\\\\\\\ Path, sniff_bytes:\\\n    \\ int = 2048) -> bool:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\"Heuristically determine\\\\\\\\\\\\n    \\\\\\\\ if a file is binary by scanning for\\\n    \\ NUL bytes.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\n    \\\\\\\\\\\\n   \\\\\\\\\\\\n    \\\\\\\\     with open(path, 'rb') as fb:\\\\\\\\\\\\\\\\n          \\\n    \\  chunk = fb.read(sniff_bytes)\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n        if b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\x00\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in chunk:\\\\\\\\\\\\\\\\n            return True\\\\\\\n    \\\\\\\\\\\\n        # If\\\\\\\\\\\\n    \\\\\\\\ the chunk has a lot of non-text bytes, consider\\\n    \\ it binary\\\\\\\\\\\\\\\\n        text_byte_count\\\\\\\\\\\\n    \\\\\\\\ = sum(32 <= b <= 126\\\n    \\ or b in (9, 10, 13) for b in chunk)\\\\\\\\\\\\\\\\n        return (len(chunk)\\\\\\\\\\\\\\\n    n    \\\\\\\\ - text_byte_count) > max(1, len(chunk) // 3)\\\\\\\\\\\\\\\\n    except Exception:\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\    # If we cannot read, treat as binary to avoid further\\\n    \\ processing\\\\\\\\\\\\\\\\n     \\\\\\\\\\\\n    \\\\\\\\   return True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\n    \\\\ndef read_text_safely(path: Path, max_bytes: int = 16_384)\\\\\\\\\\\\n    \\\\\\\\ ->\\\n    \\ Tuple[str, str, bool]:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"Read a text file safely with size\\\\\\\\\\\\n    \\\\\\\\ limit and encoding fallbacks.\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns (content, encoding_used, truncated).\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    truncated\\\n    \\ = False\\\\\\\\\\\\\\\\n    raw: bytes\\\\\\\\\\\\\\\\n    with open(path,\\\\\\\\\\\\n    \\\\\\\\ 'rb')\\\n    \\ as fb:\\\\\\\\\\\\\\\\n        raw = fb.read(max_bytes + 1)\\\\\\\\\\\\\\\\n    if len(raw)\\\n    \\ > max_bytes:\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n        truncated = True\\\\\\\\\\\\\\\\n        raw\\\n    \\ = raw[:max_bytes]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    for enc in\\\\\\\\\\\\n    \\\\\\\\ (\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-16\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"utf-16-le\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-16-be\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"latin-1\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\n    n            text = raw.decode(enc)\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ text, enc, truncated\\\\\\\\\\\\\\\\n        except Exception:\\\\\\\\\\\\\\\\n            continue\\\\\\\n    \\\\\\\\\\\\n \\\\\\\\\\\\n    \\\\\\\\   # Fallback: replace errors with utf-8\\\\\\\\\\\\\\\\n    text\\\n    \\ = raw.decode(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    , errors=\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\"replace\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    return text, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-8\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\", truncated\\\\\\\\\\\\\\\",\\\\\\\\n   \\\\\\\\\\\\n    \\\\\\\\ \\\\\\\\\\\\\\\"src/rcpack/packager.py\\\\\\\n    \\\\\\\\\\\": \\\\\\\\\\\\\\\"from __future__ import annotations\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport\\\\\\\\\\\n    \\\\n    \\\\\\\\ sys\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\nfrom typing import Iterable,\\\n    \\ Tuple\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom\\\\\\\\\\\\n    \\\\\\\\ rcpack.discover import discover_files\\\\\\\n    \\\\\\\\\\\\nfrom rcpack.gitinfo import get_git_info,\\\\\\\\\\\\n    \\\\\\\\ is_git_repo\\\\\\\\\\\n    \\\\\\\\nfrom rcpack.io_utils import read_text_safely, is_binary_file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    nfrom rcpack.renderer import markdown as md_renderer\\\\\\\\\\\\\\\\nfrom rcpack.renderer.jsonyaml\\\\\\\n    \\\\\\\\n    \\\\\\\\ import render_json, render_yaml\\\\\\\\\\\\\\\\nfrom rcpack.treeview import\\\n    \\ render_tree\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _find_root(inputs: list[str])\\\n    \\ -> Path:\\\\\\\\\\\\\\\\n    paths = [Path(p) for p\\\\\\\\\\\\n    \\\\\\\\ in inputs]\\\\\\\\\\\\\\\\\\\n    n    if len(paths) == 1 and Path(paths[0]).is_dir():\\\\\\\\\\\\\\\\n        return\\\\\\\\\\\n    \\\\n    \\\\\\\\ paths[0].resolve()\\\\\\\\\\\\\\\\n    parents = [p if p.is_dir() else p.parent\\\n    \\ for p in paths]\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    root = Path(*Path.commonpath([str(p.resolve())\\\n    \\ for p in parents]).split(\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\n    \\\\n    return root.resolve()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef build_package(\\\\\\\\\\\\\\\n    \\\\n    inputs:\\\\\\\\\\\\n    \\\\\\\\ list[str],\\\\\\\\\\\\\\\\n    include_patterns: list[str]\\\n    \\ | None,\\\\\\\\\\\\\\\\n    exclude_patterns:\\\\\\\\\\\\n    \\\\\\\\ list[str] | None,\\\\\\\\\\\\\\\n    \\\\n    max_file_bytes: int,\\\\\\\\\\\\\\\\n    fmt: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"markdown\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n) -> Tuple[str, dict]:\\\\\\\\\\\\\\\\n    root = _find_root(inputs)\\\\\\\n    \\\\\\\\\\\\n    root_abs =\\\\\\\\\\\\n    \\\\\\\\ root.resolve()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    repo_info\\\n    \\ = (\\\\\\\\\\\\\\\\n        get_git_info(root_abs) if is_git_repo(root_abs)\\\\\\\\\\\\n \\\n    \\   \\\\\\\\ else {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": False,\\\\\\\n    \\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": None,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": None,\\\\\\\\\\\\\\\\n     \\\n    \\       \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": None,\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\n    \\\\        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"date\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": None,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"note\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Not a git repository\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    files\\\n    \\ = discover_files(\\\\\\\\\\\\\\\\n        inputs=[Path(p)\\\\\\\\\\\\n    \\\\\\\\ for p in inputs],\\\\\\\n    \\\\\\\\\\\\n        root=root_abs,\\\\\\\\\\\\\\\\n        include_patterns=include_patterns\\\\\\\n    \\\\\\\\n    \\\\\\\\ or [],\\\\\\\\\\\\\\\\n        exclude_patterns=exclude_patterns or [],\\\\\\\n    \\\\\\\\\\\\n    )\\\\\\\\\\\\\\\\n    rel_files\\\\\\\\\\\\n    \\\\\\\\ = [f.relative_to(root_abs) for\\\n    \\ f in files]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    project_tree = render_tree([p.as_posix()\\\\\\\\\\\n    \\\\n    \\\\\\\\ for p in rel_files])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    file_sections: list[dict]\\\n    \\ = []\\\\\\\\\\\\\\\\n    total_lines\\\\\\\\\\\\n    \\\\\\\\ = 0\\\\\\\\\\\\\\\\n    total_chars = 0\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    for f in files:\\\\\\\\\\\\\\\\n        rel = f.relative_to(root_abs).as_posix()\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n        try:\\\\\\\\\\\\\\\\n            if is_binary_file(f):\\\\\\\\\\\\\\\n    \\\\n                content =\\\\\\\\\\\\n    \\\\\\\\ f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[binary file skipped:\\\n    \\ {f.name}, {f.stat().st_size} bytes]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\n  \\\n    \\  \\\\\\\\          file_sections.append({\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": rel,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\                    \\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": _language_from_ext(f.suffix),\\\\\\\\\\\\\\\\\\\n    n      \\\\\\\\\\\\n    \\\\\\\\              \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": content,\\\\\\\n    \\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"is_truncated\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\n    \\\\\\\": False,\\\\\\\\\\\\\\\\n                })\\\\\\\\\\\\\\\\n                total_chars +=\\\n    \\ len(content)\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n                continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n \\\n    \\           content, used_encoding, truncated =\\\\\\\\\\\\n    \\\\\\\\ read_text_safely(f,\\\n    \\ max_bytes=max_file_bytes)\\\\\\\\\\\\\\\\n            total_lines += content.count(\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") + (1 if content and\\\n    \\ not content.endswith(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") else\\\n    \\ 0)\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n            total_chars += len(content)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\n    \\\\n            if truncated:\\\\\\\\\\\\\\\\n   \\\\\\\\\\\\n    \\\\\\\\             note = f\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n[... TRUNCATED to first {max_file_bytes}\\\n    \\ bytes\\\\\\\\\\\\n    \\\\\\\\ ...]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                content =\\\n    \\ content + note\\\\\\\\\\\\\\\\n                total_chars\\\\\\\\\\\\n    \\\\\\\\ += len(note)\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            file_sections.append({\\\\\\\\\\\\\\\\n                \\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": rel,\\\\\\\\\\\\\\\\n                \\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": _language_from_ext(f.suffix),\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\n    n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": content,\\\\\\\\\\\\\\\n    \\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"is_truncated\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\": truncated,\\\\\\\n    \\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\n        except Exception as exc:\\\\\\\\\\\\\\\\n      \\\n    \\  \\\\\\\\\\\\n    \\\\\\\\    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[rcpack] error reading {rel}: {exc}\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\\\\\\\\\n \\\\\\\\\\\\n    \\\\\\\\           continue\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # render in chosen format\\\\\\\\\\\\\\\\n    if fmt == \\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"markdown\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n        out_text = md_renderer.render_markdown(\\\\\\\n    \\\\\\\\\\\\n            root=str(root_abs),\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n            repo_info=repo_info,\\\\\\\n    \\\\\\\\\\\\n            tree_text=project_tree,\\\\\\\\\\\\\\\\n   \\\\\\\\\\\\n    \\\\\\\\        \\\n    \\ files=file_sections,\\\\\\\\\\\\\\\\n            total_files=len(file_sections),\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\n    n            total_lines=total_lines,\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\n    n    elif fmt == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n   \\\n    \\     out_text = render_json(\\\\\\\\\\\\\\\\n            root=str(root_abs),\\\\\\\\\\\\\\\\\\\n    n   \\\\\\\\\\\\n    \\\\\\\\         repo_info=repo_info,\\\\\\\\\\\\\\\\n            tree_text=project_tree,\\\\\\\n    \\\\\\\\\\\\n      \\\\\\\\\\\\n    \\\\\\\\      files=file_sections,\\\\\\\\\\\\\\\\n            total_files=len(file_sections),\\\\\\\n    \\\\\\\\\\\\n \\\\\\\\\\\\n    \\\\\\\\           total_lines=total_lines,\\\\\\\\\\\\\\\\n        )\\\\\\\n    \\\\\\\\\\\\n    elif fmt == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    :\\\\\\\\\\\\\\\\\\\n    n        out_text = render_yaml(\\\\\\\\\\\\\\\\n            root=str(root_abs),\\\\\\\\\\\\\\\n    \\\\n     \\\\\\\\\\\\n    \\\\\\\\       repo_info=repo_info,\\\\\\\\\\\\\\\\n            tree_text=project_tree,\\\\\\\n    \\\\\\\\\\\\n        \\\\\\\\\\\\n    \\\\\\\\    files=file_sections,\\\\\\\\\\\\\\\\n            total_files=len(file_sections),\\\\\\\n    \\\\\\\\\\\\n   \\\\\\\\\\\\n    \\\\\\\\         total_lines=total_lines,\\\\\\\\\\\\\\\\n        )\\\\\\\n    \\\\\\\\\\\\n    else:\\\\\\\\\\\\\\\\n        raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\n    Unsupported format: {fmt}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    stats = {\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": len(file_sections),\\\\\\\\\\\\n    \\\\\\\\ \\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"lines\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": total_lines, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chars\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    : total_chars}\\\\\\\\\\\\\\\\n    return out_text,\\\\\\\\\\\\n    \\\\\\\\ stats\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\n    \\\\n\\\\\\\\\\\\\\\\ndef _language_from_ext(ext: str) -> str:\\\\\\\\\\\\\\\\n    ext = ext.lower().lstrip(\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    mapping = {\\\\\\\\\\\\\\\\n \\\n    \\       \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"js\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"javascript\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"typescript\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\n    json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"yml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    n    : \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    toml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"toml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sh\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    , \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\"c\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"c\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cpp\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cpp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\"java\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    java\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"go\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"go\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"rs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"rust\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    }\\\\\\\n    \\\\\\\\\\\\n    return\\\\\\\\\\\\n    \\\\\\\\ mapping.get(ext, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/renderer/jsonyaml.py\\\\\\\\\\\\\\\"\\\n    : \\\\\\\\\\\\\\\"\\\\\\\\\\\\n    from __future__ import annotations\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\n    \\\\\\\\n\\\\\\\\\\\\\\\\ntry:\\\\\\\\\\\\\\\\n    import yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    nexcept ImportError:\\\\\\\n    \\\\\\\\\\\\n    yaml = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef render_json(root, repo_info,\\\\\\\n    \\\\\\\\n    \\\\\\\\ tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None)\\\\\\\n    \\\\\\\\n    \\\\\\\\ -> str:\\\\\\\\\\\\\\\\n    data = {\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"root\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\": root,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repo_info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    \\\\\\\\\\\\\\\": repo_info,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\": tree_text,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"recent_changes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    \\\\\\\\\\\\\\\": recent_files or [],\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\": files,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_sizes\\\\\\\\\\\\\\\\\\\\\\\\\\\\n \\\n    \\   \\\\\\\\\\\\\\\": file_sizes or {},\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": total_files,\\\\\\\\\\\\n  \\\n    \\  \\\\\\\\ \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_lines\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": total_lines},\\\\\\\\\\\\\\\\n  \\\n    \\      \\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n    return json.dumps(data,\\\\\\\\\\\\n    \\\\\\\\ indent=2,\\\n    \\ ensure_ascii=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef render_yaml(root, repo_info,\\\n    \\ tree_text,\\\\\\\\\\\\n    \\\\\\\\ files, total_files, total_lines,recent_files=None,\\\n    \\ file_sizes=None) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    if yaml is None:\\\\\\\\\\\\\\\\n  \\\n    \\      raise RuntimeError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"PyYAML not installed; run\\\\\\\\\\\\n   \\\n    \\ \\\\\\\\ `pip install pyyaml`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    data = {\\\\\\\\\\\\\\\\n   \\\n    \\     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"root\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": root,\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\n    \\\\\\\\  \\\n    \\    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repo_info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": repo_info,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": tree_text,\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n        \\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"recent_changes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": recent_files or [],\\\\\\\\\\\\\\\\n   \\\n    \\     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\n    \\\\\\\\ files,\\\\\\\\\\\\\\\\n  \\\n    \\      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_sizes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": file_sizes or {},\\\\\\\\\\\\\\\\n\\\n    \\        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\n    total_files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": total_files, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_lines\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\": total_lines},\\\\\\\\\\\\\\\\n \\\\\\\\\\\\n    \\\\\\\\       \\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n \\\n    \\   return yaml.safe_dump(data, sort_keys=False, allow_unicode=True)\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\n    n\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/renderer/markdown.py\\\\\\\\\\\\\\\": \\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Markdown renderer\\\\\\\\\\\\\\\n    n    \\\\\\\\ for repository context.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom typing import Dict, Any\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\n    ndef render_markdown(root: str, repo_info: Dict[str, Any], tree_text: str,\\\n    \\ \\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n                   files: Dict[str, str], total_files: int,\\\n    \\ total_lines: int,\\\\\\\\\\\\n    \\\\\\\\ recent_files=None, file_sizes=None) -> str:\\\\\\\n    \\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Render repository\\\\\\\n    \\\\\\\\n    \\\\\\\\ context as markdown.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    lines = []\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Header\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\n    n    lines.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# Repository Context: {root}\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Repository info\\\\\\\\\\\\\\\\n    if repo_info.get(\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    ):\\\\\\\\\\\\\\\\n        lines.append(\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"## Git Repository Information\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        lines.append(f\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"- **Branch**: {repo_info.get('branch', 'N/A')}\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"- **Commit**:\\\n    \\ {repo_info.get('commit', 'N/A')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        lines.append(f\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"- **Author**: {repo_info.get('author', 'N/A')}\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"- **Date**:\\\n    \\ {repo_info.get('date', 'N/A')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    else:\\\\\\\\\\\\\\\\n \\\n    \\       lines.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"## Repository Information\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- **Note**: {repo_info.get('note',\\\\\\\n    \\\\\\\\n    \\\\\\\\ 'Not a git repository')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    lines.append(\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Summary\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\n    n    lines.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"## Summary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\n    \\    lines.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- **Total Files**:\\\\\\\\\\\\n    \\\\\\\\ {total_files}\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    lines.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- **Total Lines**: {total_lines}\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Directory structure\\\\\\\\\\\\\\\\n    lines.append(\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"## Directory Structure\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    lines.append(\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    lines.append(tree_text)\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\n    n    lines.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n   \\\n    \\ lines.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # will produce\\\\\\\n    \\\\\\\\n    \\\\\\\\ recent files \\\\\\\\\\\\\\\\n    # Recent files (fixed)\\\\\\\\\\\\\\\\n    if\\\n    \\ recent_files:\\\\\\\\\\\\\\\\n       \\\\\\\\\\\\n    \\\\\\\\ lines.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"##\\\n    \\ Recent Changes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        for file, age in recent_files.items():\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n            lines.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- {file} (modified\\\n    \\ {age})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # File contents\\\\\\\\\\\\\\\\n    lines.append(\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"## File Contents\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    lines.append(\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    for file_path, content\\\n    \\ in sorted(files.items()):\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n        if file_sizes and file_path\\\n    \\ in file_sizes:\\\\\\\\\\\\\\\\n            size_bytes =\\\\\\\\\\\\n    \\\\\\\\ file_sizes[file_path]\\\\\\\n    \\\\\\\\\\\\n            lines.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"### {file_path} ({size_bytes}\\\\\\\n    \\\\\\\\n    \\\\\\\\ bytes)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n         \\\n    \\   lines.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"### {file_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\")\\\\\\\n    \\\\\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n       \\\n    \\ \\\\\\\\\\\\\\\\n        # Detect language for\\\\\\\\\\\\n    \\\\\\\\ syntax highlighting\\\\\\\\\\\n    \\\\\\\\n        ext = file_path.split('.')[-1].lower() if '.'\\\\\\\\\\\\n    \\\\\\\\ in file_path\\\n    \\ else ''\\\\\\\\\\\\\\\\n        lang_map = {\\\\\\\\\\\\\\\\n            'py': 'python', 'js':\\\\\\\n    \\\\\\\\n    \\\\\\\\ 'javascript', 'ts': 'typescript',\\\\\\\\\\\\\\\\n            'java': 'java',\\\n    \\ 'cpp': 'cpp',\\\\\\\\\\\\n    \\\\\\\\ 'c': 'c', 'h': 'c',\\\\\\\\\\\\\\\\n            'cs': 'csharp',\\\n    \\ 'php': 'php', 'rb': 'ruby',\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n            'go': 'go', 'rs':\\\n    \\ 'rust', 'swift': 'swift',\\\\\\\\\\\\\\\\n            'html':\\\\\\\\\\\\n    \\\\\\\\ 'html',\\\n    \\ 'css': 'css', 'scss': 'scss',\\\\\\\\\\\\\\\\n            'json': 'json', 'yaml':\\\\\\\\\\\n    \\\\n    \\\\\\\\ 'yaml', 'yml': 'yaml',\\\\\\\\\\\\\\\\n            'xml': 'xml', 'sql': 'sql',\\\n    \\ 'sh': 'bash',\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n            'md': 'markdown', 'dockerfile':\\\n    \\ 'dockerfile'\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n     \\\\\\\\\\\\n    \\\\\\\\   \\\\\\\\\\\\\\\\n    \\\n    \\    language = lang_map.get(ext, '')\\\\\\\\\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"```{language}\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        lines.append(content)\\\\\\\n    \\\\\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n   \\\\\\\n    \\\\\\\\n    \\\\\\\\     lines.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\n    \\\\\\\\\\\\n    return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join(lines)\\\\\\\n    \\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    ,\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/treeview.py\\\\\\\\\\\\\\\": \\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Tree view generation for\\\n    \\ repository\\\\\\\\\\\\n    \\\\\\\\ structure.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\nfrom typing import\\\n    \\ Dict,\\\\\\\\\\\\n    \\\\\\\\ List\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef create_tree_view(repo_path:\\\n    \\ Path, files_data: Dict[str, str])\\\\\\\\\\\\n    \\\\\\\\ -> str:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create a tree view of the repository structure.\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    paths =\\\n    \\ list(files_data.keys())\\\\\\\\\\\\\\\\n    return render_tree(paths)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    n    n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef render_tree(paths: List[str]) -> str:\\\\\\\\\\\\\\\\n   \\\n    \\ \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Render a tree\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ view from a list of relative POSIX paths.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    tree_structure:\\\\\\\\\\\\n    \\\\\\\\ dict = {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\n    \\\\\\\\n    for p in paths:\\\\\\\\\\\\\\\\n        parts = Path(p).parts\\\\\\\\\\\\\\\\n      \\\\\\\n    \\\\\\\\n    \\\\\\\\  current = tree_structure\\\\\\\\\\\\\\\\n        for part in parts[:-1]:\\\\\\\n    \\\\\\\\\\\\n            if\\\\\\\\\\\\n    \\\\\\\\ part not in current:\\\\\\\\\\\\\\\\n           \\\n    \\     current[part] = {}\\\\\\\\\\\\\\\\n            current\\\\\\\\\\\\n    \\\\\\\\ = current[part]\\\\\\\n    \\\\\\\\\\\\n        if parts:\\\\\\\\\\\\\\\\n            current[parts[-1]] = None\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\n    n\\\\\\\\\\\\\\\\n    def _render(structure: dict, prefix: str = \\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> str:\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\n    \\\\\\\\  lines = []\\\\\\\\\\\\\\\n    \\\\n        items = sorted(structure.items(), key=lambda x: (x[1]\\\\\\\\\\\\n    \\\\\\\\\\\n    \\ is None, x[0]))\\\\\\\\\\\\\\\\n        for i, (name, subtree) in enumerate(items):\\\\\\\n    \\\\\\\\\\\\n   \\\\\\\\\\\\n    \\\\\\\\         is_last = i == len(items) - 1\\\\\\\\\\\\\\\\n     \\\n    \\       lines.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{prefix}{'└──\\\\\\\\\\\\n    \\\\\\\\ ' if is_last\\\n    \\ else '├── '}{name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            if subtree is not None:\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\n    n                extension = (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\" if is_last else \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"│   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\n \\\n    \\   \\\\\\\\              lines.append(_render(subtree, prefix + extension))\\\\\\\\\\\\\\\n    \\\\n        return\\\\\\\\\\\\n    \\\\\\\\ \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\".join(filter(None, lines))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    if not tree_structure:\\\\\\\\\\\n    \\\\\\\\n \\\\\\\\\\\\n    \\\\\\\\       return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No files found\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\\n    return _render(tree_structure)\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\\\\\n    \\\\\\\\  },\\\\\\\n    \\\\n  \\\\\\\\\\\\\\\"file_sizes\\\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\\\"LICENSE\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"1064\\\\\\\n    \\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"README.md\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\n    11164\\\\\\\\\\\\\\\",\\\\\\\n    \\\\n    \\\\\\\\\\\\\\\"pyproject.toml\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"361\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/__init__.py\\\\\\\n    \\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\n    198\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/__main__.py\\\\\\\n    \\\\\\\\\\\": \\\\\\\\\\\\\\\"197\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/cli.py\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\n    7087\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/config_loader.py\\\\\\\\\\\\\\\"\\\n    : \\\\\\\\\\\\\\\"2099\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/discover.py\\\\\\\\\\\\\\\"\\\\\\\\\\\\n\\\n    \\    : \\\\\\\\\\\\\\\"3067\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/gitinfo.py\\\\\\\\\\\\\\\": \\\\\\\n    \\\\\\\\\\\"1653\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/io_utils.py\\\\\\\\\\\\\\\"\\\\\\\\\\\\n    :\\\n    \\ \\\\\\\\\\\\\\\"1817\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/packager.py\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\n    \\\"4430\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/renderer/jsonyaml.py\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    n    : \\\\\\\\\\\\\\\"1176\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/renderer/markdown.py\\\\\\\n    \\\\\\\\\\\": \\\\\\\\\\\\\\\"2829\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"src/rcpack/treeview.py\\\\\\\\\\\\\\\"\\\\\\\n    \\\\\\\\n    : \\\\\\\\\\\\\\\"1371\\\\\\\\\\\\\\\"\\\\\\\\n  },\\\\\\\\n  \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": {\\\\\\\\\\\n    n    \\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\": 14,\\\\\\\\n    \\\\\\\\\\\\\\\"total_lines\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    n    : 1180\\\\\\\\n  }\\\\\\\\n}\\\\\\\"\\\\nfile_sizes:\\\\n  LICENSE: '1064'\\\\n  README.md:\\\n    \\ '11164'\\\\n  pyproject.toml: '361'\\\\n  src/rcpack/__init__.py: '198'\\\\n  src/rcpack/__main__.py:\\\n    \\ '197'\\\\n  src/rcpack/cli.py: '7087'\\\\n  src/rcpack/config_loader.py: '2099'\\\\\\\n    n  src/rcpack/discover.py: '3067'\\\\n  src/rcpack/gitinfo.py: '1653'\\\\n  src/rcpack/io_utils.py:\\\n    \\ '1817'\\\\n  src/rcpack/packager.py: '4430'\\\\n  src/rcpack/renderer/jsonyaml.py:\\\n    \\ '1176'\\\\n  src/rcpack/renderer/markdown.py: '2829'\\\\n  src/rcpack/treeview.py:\\\n    \\ '1371'\\\\n  test-output.json: '42249'\\\\nsummary:\\\\n  total_files: 15\\\\n  total_lines:\\\n    \\ 1229\\\\n\\\"\\n  },\\n  \\\"file_sizes\\\": {\\n    \\\"LICENSE\\\": \\\"1064\\\",\\n    \\\"README.md\\\"\\\n    : \\\"11164\\\",\\n    \\\"pyproject.toml\\\": \\\"361\\\",\\n    \\\"src/rcpack/__init__.py\\\"\\\n    : \\\"198\\\",\\n    \\\"src/rcpack/__main__.py\\\": \\\"197\\\",\\n    \\\"src/rcpack/cli.py\\\"\\\n    : \\\"7087\\\",\\n    \\\"src/rcpack/config_loader.py\\\": \\\"2099\\\",\\n    \\\"src/rcpack/discover.py\\\"\\\n    : \\\"3067\\\",\\n    \\\"src/rcpack/gitinfo.py\\\": \\\"1653\\\",\\n    \\\"src/rcpack/io_utils.py\\\"\\\n    : \\\"1817\\\",\\n    \\\"src/rcpack/packager.py\\\": \\\"4121\\\",\\n    \\\"src/rcpack/renderer/jsonyaml.py\\\"\\\n    : \\\"1154\\\",\\n    \\\"src/rcpack/renderer/markdown.py\\\": \\\"2318\\\",\\n    \\\"src/rcpack/treeview.py\\\"\\\n    : \\\"1371\\\",\\n    \\\"src/rcpack/utils.py\\\": \\\"3500\\\",\\n    \\\"test-output.json\\\"\\\n    : \\\"42249\\\",\\n    \\\"test-yaml.yaml\\\": \\\"93888\\\"\\n  },\\n  \\\"summary\\\": {\\n    \\\"\\\n    total_files\\\": 17,\\n    \\\"total_lines\\\": 2456\\n  }\\n}\"\n  test-output.json: \"{\\n  \\\"root\\\": \\\"/Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\\\"\\\n    ,\\n  \\\"repo_info\\\": {\\n    \\\"is_repo\\\": true,\\n    \\\"commit\\\": \\\"682153b169db66d3a72e9cabdd1f3448a3b2986d\\\"\\\n    ,\\n    \\\"branch\\\": \\\"refactoring\\\",\\n    \\\"author\\\": \\\"Abhinav <abhinavbhardwaj2002@gmail.com>\\\"\\\n    ,\\n    \\\"date\\\": \\\"Fri Oct 3 18:45:48 2025\\\",\\n    \\\"note\\\": null\\n  },\\n  \\\"\\\n    structure\\\": \\\"├── src\\\\n│   └── rcpack\\\\n│       ├── renderer\\\\n│       │   ├──\\\n    \\ jsonyaml.py\\\\n│       │   └── markdown.py\\\\n│       ├── __init__.py\\\\n│    \\\n    \\   ├── __main__.py\\\\n│       ├── cli.py\\\\n│       ├── config_loader.py\\\\n│  \\\n    \\     ├── discover.py\\\\n│       ├── gitinfo.py\\\\n│       ├── io_utils.py\\\\n│ \\\n    \\      ├── packager.py\\\\n│       └── treeview.py\\\\n├── LICENSE\\\\n├── README.md\\\\\\\n    n└── pyproject.toml\\\",\\n  \\\"recent_changes\\\": [],\\n  \\\"files\\\": {\\n    \\\"LICENSE\\\"\\\n    : \\\"MIT License\\\\n\\\\nCopyright (c) 2025 Abhinav\\\\n\\\\nPermission is hereby granted,\\\n    \\ free of charge, to any person obtaining a copy\\\\nof this software and associated\\\n    \\ documentation files (the \\\\\\\"Software\\\\\\\"), to deal\\\\nin the Software without\\\n    \\ restriction, including without limitation the rights\\\\nto use, copy, modify,\\\n    \\ merge, publish, distribute, sublicense, and/or sell\\\\ncopies of the Software,\\\n    \\ and to permit persons to whom the Software is\\\\nfurnished to do so, subject\\\n    \\ to the following conditions:\\\\n\\\\nThe above copyright notice and this permission\\\n    \\ notice shall be included in all\\\\ncopies or substantial portions of the Software.\\\\\\\n    n\\\\nTHE SOFTWARE IS PROVIDED \\\\\\\"AS IS\\\\\\\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\\\n    \\ OR\\\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\\\\n    nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\\\\n    nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\nLIABILITY,\\\n    \\ WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\nOUT OF\\\n    \\ OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\nSOFTWARE.\\\\\\\n    n\\\",\\n    \\\"README.md\\\": \\\"# Repo-Contextor\\\\n\\\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\\\\\\n    n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\\\\\\n    n\\\\nA powerful Repository Context Packager CLI tool that analyzes local git repositories\\\n    \\ and creates comprehensive text files containing repository content optimized\\\n    \\ for sharing with Large Language Models (LLMs).\\\\n\\\\n## Overview\\\\n\\\\nWhen developers\\\n    \\ want to get help from ChatGPT, Claude, or other LLMs about their code, they\\\n    \\ often struggle with how to share their codebase effectively. Common problems\\\n    \\ include:\\\\n\\\\n- **Lost Context**: Copy-pasting individual files loses important\\\n    \\ project structure and relationships\\\\n- **Missing Dependencies**: LLMs can't\\\n    \\ see how files connect or what libraries are used\\\\n- **Incomplete Picture**:\\\n    \\ Hard to convey the overall architecture and organization\\\\n- **Manual Work**:\\\n    \\ Time-consuming to gather and format relevant code\\\\n\\\\n**Repo-Contextor** solves\\\n    \\ this by automatically collecting and formatting repository content into a single,\\\n    \\ well-structured text file that provides rich context to LLMs, enabling them\\\n    \\ to give much better assistance with your code.\\\\n\\\\n## Features\\\\n\\\\n- **Git\\\n    \\ Integration**: Extracts commit SHA, branch, author, and date information\\\\n-\\\n    \\ **Project Structure**: Generates a clear directory tree visualization\\\\n- **File\\\n    \\ Content Packaging**: Includes file contents with syntax highlighting\\\\n- **Smart\\\n    \\ File Discovery**: Recursively scans directories with intelligent filtering\\\\\\\n    n- **Binary File Detection**: Automatically skips binary files\\\\n- **Error Handling**:\\\n    \\ Gracefully handles permission errors and provides helpful messages\\\\n- **Multiple\\\n    \\ Output Formats**: Supports Markdown, JSON, and YAML formats\\\\n- **Flexible Output**:\\\n    \\ Write to stdout or save to a file\\\\n- **Recent Changes Filter**: Give the files\\\n    \\ which are updated in last 7days with the time when it was recently modified.\\\\\\\n    n\\\\n## Installation\\\\n\\\\n### Prerequisites\\\\n\\\\n- Python 3.9 or higher\\\\n- Git\\\n    \\ (for git repository analysis)\\\\n\\\\n### For End Users\\\\n\\\\n```bash\\\\n# Clone\\\n    \\ and install\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    ncd Repo-Contextor\\\\npip install -e .\\\\n```\\\\n\\\\n### For Contributors & Local\\\n    \\ Development\\\\n\\\\n```bash\\\\n# Clone the repository\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    ncd Repo-Contextor\\\\n\\\\n# Create virtual environment\\\\npython -m venv .venv\\\\\\\n    nsource .venv/bin/activate  # On Windows: .venv\\\\\\\\Scripts\\\\\\\\activate\\\\n\\\\n#\\\n    \\ Install in development mode\\\\npip install -e .\\\\n```\\\\n\\\\n## Usage\\\\n\\\\n###\\\n    \\ Basic Examples\\\\n\\\\n```bash\\\\n# Package current directory to terminal\\\\nrepo-contextor\\\n    \\ .\\\\n\\\\n# Package a specific directory\\\\nrepo-contextor /path/to/your/project\\\\\\\n    n\\\\n# Save output to a file\\\\nrepo-contextor . -o my-project-context.md\\\\n\\\\n#\\\n    \\ Generate JSON format\\\\nrepo-contextor . -f json -o context.json\\\\n\\\\n# Generate\\\n    \\ YAML format\\\\nrepo-contextor . -f yaml -o context.yaml\\\\n\\\\n# Include only files\\\n    \\ modified in the last 7 days\\\\nrepo-contextor . --recent\\\\n\\\\n# Combine with\\\n    \\ output file\\\\nrepo-contextor . --recent -o recent-changes.md\\\\n```\\\\n\\\\n###\\\n    \\ Command Line Options\\\\n\\\\n| Option | Short | Description | Example |\\\\n|--------|-------|-------------|---------|\\\\\\\n    n| `path` | - | Repository path to analyze (default: current directory) | `repo-contextor\\\n    \\ /path/to/project` |\\\\n| `--output` | `-o` | Output file path (default: stdout)\\\n    \\ | `-o context.md` |\\\\n| `--format` | `-f` | Output format: text, json, yaml\\\n    \\ (default: text) | `-f json` |\\\\n| `--help` | `-h` | Show help message | `-h`\\\n    \\ |\\\\n| `--recent`  | `-r`  | Include only files modified in the last 7 days \\\n    \\   | `repo-contextor . -r -o recent.md` |\\\\n\\\\n### Advanced Examples\\\\n\\\\n```bash\\\\\\\n    n# Analyze different repository\\\\nrepo-contextor /path/to/other/project -o other-project.md\\\\\\\n    n\\\\n# Generate JSON for API consumption\\\\nrepo-contextor . -f json -o api-context.json\\\\\\\n    n\\\\n# Create YAML configuration\\\\nrepo-contextor . -f yaml -o project-config.yaml\\\\\\\n    n\\\\n# Generate files which are changed recently in 7 days\\\\nrepo-contextor . -r\\\n    \\ --output recent-changes.txt\\\\n\\\\n```\\\\n## Configuration via TOML\\\\n\\\\nRepo-Contextor\\\n    \\ supports configuration through a `.repo-contextor.toml` file in the current\\\n    \\ working directory.  \\\\nThis file allows you to avoid typing the same CLI arguments\\\n    \\ every time.\\\\n\\\\nExample `.repo-contextor.toml`:\\\\n\\\\n```toml\\\\n# Output file\\\n    \\ to write results\\\\noutput = \\\\\\\"context.yaml\\\\\\\"\\\\n\\\\n# Output format: text,\\\n    \\ json, or yaml\\\\nformat = \\\\\\\"yaml\\\\\\\"\\\\n\\\\n# Limit to files modified in the\\\n    \\ last 7 days\\\\nrecent = true\\\\n\\\\n# Repository path to analyze (default = current\\\n    \\ directory)\\\\npath = \\\\\\\".\\\\\\\"\\\\n```\\\\n### Rules\\\\n- If the `.repo-contextor.toml`\\\n    \\ file is **missing**, the tool falls back to defaults.  \\\\n- If the file is **present\\\n    \\ but invalid TOML**, the tool prints a clear error message and exits with status\\\n    \\ code 1.  \\\\n- **Unknown keys** in the TOML file are ignored (safe for future\\\n    \\ extensions).  \\\\n- **Precedence** of settings is:\\\\n  1. Command-line arguments\\\n    \\ (highest priority)  \\\\n  2. Values from `.repo-contextor.toml`  \\\\n  3. Built-in\\\n    \\ defaults (lowest priority)\\\\n     \\\\n## Output Format\\\\n\\\\nThe tool generates\\\n    \\ a structured text file with the following sections:\\\\n\\\\n### 1. Repository Context\\\n    \\ Header\\\\nProject path and identification\\\\n\\\\n### 2. Git Repository Information\\\\\\\n    n- Current branch\\\\n- Latest commit SHA\\\\n- Last commit author\\\\n- Last commit\\\n    \\ date\\\\n\\\\n### 3. Summary Statistics\\\\n- Total number of files processed\\\\n-\\\n    \\ Total lines of code\\\\n\\\\n### 4. Directory Structure\\\\nClean tree visualization\\\n    \\ showing project organization\\\\n\\\\n### 5. Recent Changes (if `--recent` is used)\\\\\\\n    n\\\\n- Lists files modified in the last 7 days.\\\\n- Shows relative file paths along\\\n    \\ with how long ago each file was modified\\\\n- Helps focus on recently updated\\\n    \\ parts of the project.\\\\n- Can be combined with `--output` or `--format` to save\\\n    \\ or change the output type.\\\\n\\\\n\\\\n### 5. File Contents\\\\nEach file's content\\\n    \\ with:\\\\n- Clear file path headers\\\\n- Appropriate syntax highlighting language\\\n    \\ tags\\\\n- Complete file contents\\\\n\\\\n## Example Output\\\\n\\\\nWhen you run `repo-contextor\\\n    \\ .`, the output looks like this:\\\\n\\\\n````markdown\\\\n# Repository Context: /path/to/your/project\\\\\\\n    n\\\\n## Git Repository Information\\\\n- **Branch**: main\\\\n- **Commit**: a1b2c3d4e5f6789...\\\\\\\n    n- **Author**: John Doe <john@example.com>\\\\n- **Date**: Fri Sep 12 14:30:15 2025\\\\\\\n    n\\\\n## Summary\\\\n- **Total Files**: 15\\\\n- **Total Lines**: 1,247\\\\n\\\\n## Directory\\\n    \\ Structure\\\\n```\\\\n├── src/\\\\n│   ├── main.py\\\\n│   └── utils.py\\\\n├── tests/\\\\\\\n    n│   └── test_main.py\\\\n├── README.md\\\\n└── requirements.txt\\\\n```\\\\n## Recent\\\n    \\ Changes\\\\n- src/main.py (modified 2 days ago)\\\\n- src/utils/helpers.py (modified\\\n    \\ 5 days ago)\\\\n\\\\n## File Contents\\\\n\\\\n### src/main.py\\\\n\\\\n```python\\\\ndef\\\n    \\ main():\\\\n    print(\\\\\\\"Hello, World!\\\\\\\")\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\n    \\\":\\\\n    main()\\\\n```\\\\n\\\\n### README.md\\\\n\\\\n```markdown\\\\n# My Project\\\\nThis\\\n    \\ is a sample project.\\\\n```\\\\n\\\\n## Summary\\\\n- Total files: 15\\\\n- Total lines:\\\n    \\ 1,247\\\\n````\\\\n\\\\n## What Files Are Included\\\\n\\\\nThe tool includes most text\\\n    \\ files but automatically excludes:\\\\n\\\\n### Excluded Directories\\\\n- `.git`,\\\n    \\ `.svn`, `.hg` (version control)\\\\n- `__pycache__`, `.pytest_cache` (Python cache)\\\\\\\n    n- `node_modules`, `.venv`, `venv` (dependencies/environments)\\\\n- `.vscode`,\\\n    \\ `.idea` (IDE directories)\\\\n- `build`, `dist`, `target` (build directories)\\\\\\\n    n\\\\n### File Handling Rules\\\\n- **Text files**: All readable text files with common\\\n    \\ extensions\\\\n- **Binary files**: Automatically detected and skipped\\\\n- **Permission\\\n    \\ errors**: Skipped with graceful handling\\\\n- **Configuration files**: Includes\\\n    \\ pyproject.toml, package.json, etc.\\\\n\\\\n### Included File Types\\\\n- Source code:\\\n    \\ `.py`, `.js`, `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\\\n- Web files:\\\n    \\ `.html`, `.css`, `.scss`, `.vue`, `.jsx`, etc.\\\\n- Documentation: `.md`, `.txt`,\\\n    \\ `.rst`\\\\n- Configuration: `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\\\n- Scripts:\\\n    \\ `.sh`, `.bash`, `.zsh`\\\\n\\\\n## Error Handling\\\\n\\\\nThe tool handles errors gracefully:\\\\\\\n    n\\\\n| Error Type | Behavior |\\\\n|------------|----------|\\\\n| **Permission errors**\\\n    \\ | Skipped with warning |\\\\n| **Binary files** | Automatically detected and skipped\\\n    \\ |\\\\n| **Invalid paths** | Clear error messages |\\\\n| **Non-git repositories**\\\n    \\ | Works fine, shows \\\\\\\"Not a git repository\\\\\\\" |\\\\n| **Unreadable files**\\\n    \\ | Marked as \\\\\\\"[Binary or unreadable file]\\\\\\\" |\\\\n\\\\n## Development\\\\n\\\\n###\\\n    \\ Project Structure\\\\n\\\\n```text\\\\nRepo-Contextor/\\\\n├── src/rcpack/         \\\n    \\     # Main package\\\\n│   ├── __init__.py         # Package initialization\\\\\\\n    n│   ├── cli.py              # Command-line interface\\\\n│   ├── discover.py  \\\n    \\       # File discovery logic\\\\n│   ├── gitinfo.py          # Git repository\\\n    \\ analysis\\\\n│   ├── treeview.py         # Directory tree generation\\\\n│   ├──\\\n    \\ packager.py         # Main orchestration\\\\n│   ├── io_utils.py         # File\\\n    \\ I/O utilities\\\\n│   └── renderer/           # Output formatters\\\\n│       ├──\\\n    \\ markdown.py     # Markdown renderer\\\\n│       └── jsonyaml.py     # JSON/YAML\\\n    \\ renderers\\\\n├── pyproject.toml          # Project configuration\\\\n├── LICENSE\\\n    \\                 # MIT License\\\\n└── README.md              # This documentation\\\\\\\n    n```\\\\n\\\\n### Running Tests\\\\n\\\\n```bash\\\\n# Test on current repository\\\\nrepo-contextor\\\n    \\ . -o test-output.md\\\\n\\\\n# Test different formats\\\\nrepo-contextor . -f json\\\n    \\ | head -20\\\\nrepo-contextor . -f yaml | head -20\\\\n\\\\n# Test specific directory\\\\\\\n    nrepo-contextor src/ -o src-only.md\\\\n```\\\\n\\\\n### Contributing\\\\n\\\\n1. **Fork\\\n    \\ the repository**\\\\n2. **Clone your fork:**\\\\n   ```bash\\\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    n   cd Repo-Contextor\\\\n   ```\\\\n3. **Install for development:**\\\\n   ```bash\\\\\\\n    n   python -m venv .venv\\\\n   source .venv/bin/activate\\\\n   pip install -e .\\\\\\\n    n   ```\\\\n4. **Make your changes and test:**\\\\n   ```bash\\\\n   repo-contextor\\\n    \\ . -o test.md\\\\n   ```\\\\n5. **Submit a pull request**\\\\n\\\\n### Development Workflow\\\\\\\n    n\\\\n```bash\\\\n# 1. Setup development environment\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    ncd Repo-Contextor\\\\npython -m venv .venv\\\\nsource .venv/bin/activate\\\\npip install\\\n    \\ -e .\\\\n\\\\n# 2. Make changes to the code\\\\n# Edit files in src/rcpack/\\\\n\\\\n#\\\n    \\ 3. Test your changes\\\\nrepo-contextor . -o test-output.md\\\\n\\\\n# 4. Test different\\\n    \\ formats\\\\nrepo-contextor . -f json -o test.json\\\\nrepo-contextor . -f yaml -o\\\n    \\ test.yaml\\\\n\\\\n# 5. Commit and push changes\\\\ngit add .\\\\ngit commit -m \\\\\\\"\\\n    Add new feature\\\\\\\"\\\\ngit push origin feature-branch\\\\n```\\\\n\\\\n## License\\\\n\\\\\\\n    nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file\\\n    \\ for details.\\\\n\\\\n## Why Repo-Contextor?\\\\n\\\\nThe name \\\\\\\"Repo-Contextor\\\\\\\"\\\n    \\ combines \\\\\\\"Repository\\\\\\\" + \\\\\\\"Context\\\\\\\" + \\\\\\\"or\\\\\\\", representing the\\\n    \\ tool's purpose of providing rich context about code repositories in a format\\\n    \\ that's perfect for LLM interactions.\\\\n\\\\n### Use Cases\\\\n\\\\n- **AI Assistance**:\\\n    \\ Get better help from ChatGPT, Claude, or GitHub Copilot\\\\n- **Code Reviews**:\\\n    \\ Share complete project context with team members\\\\n- **Documentation**: Create\\\n    \\ comprehensive project snapshots\\\\n- **Onboarding**: Help new team members understand\\\n    \\ project structure\\\\n- **Project Analysis**: Understand repository structure\\\n    \\ and dependencies\\\\n\\\\n### Perfect for LLMs\\\\n\\\\nThe output format is specifically\\\n    \\ designed to work well with Large Language Models:\\\\n- Clear section headers\\\n    \\ for easy parsing\\\\n- Syntax highlighting markers for code blocks\\\\n- Structured\\\n    \\ metadata (git info, file locations)\\\\n- Complete project context in a single\\\n    \\ file\\\\n- Multiple output formats (Markdown, JSON, YAML)\\\\n- Optimized for token\\\n    \\ efficiency\\\\n\\\",\\n    \\\"pyproject.toml\\\": \\\"[build-system]\\\\nrequires = [\\\\\\\"\\\n    setuptools>=68\\\\\\\", \\\\\\\"wheel\\\\\\\"]\\\\nbuild-backend = \\\\\\\"setuptools.build_meta\\\\\\\n    \\\"\\\\n\\\\n[project]\\\\nname = \\\\\\\"rcpack\\\\\\\"\\\\nversion = \\\\\\\"0.1.0\\\\\\\"\\\\ndescription\\\n    \\ = \\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\"\\\\nreadme = \\\\\\\"README.md\\\\\\\n    \\\"\\\\nrequires-python = \\\\\\\">=3.9\\\\\\\"\\\\nlicense = { text = \\\\\\\"MIT\\\\\\\" }\\\\ndependencies\\\n    \\ = [\\\\n    \\\\\\\"PyYAML>=6.0\\\\\\\"\\\\n]\\\\n\\\\n[project.scripts]\\\\nrepo-contextor =\\\n    \\ \\\\\\\"rcpack.cli:main\\\\\\\"\\\\n\\\",\\n    \\\"src/rcpack/__init__.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\n    Repository Context Packager - CLI tool for creating LLM-optimized repository context.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n\\\\n__version__ = \\\\\\\"0.1.0\\\\\\\"\\\\n__author__ = \\\\\\\"Abhinav\\\\\\\"\\\\n__description__\\\n    \\ = \\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\"\\\",\\n    \\\"src/rcpack/__main__.py\\\"\\\n    : \\\"#!/usr/bin/env python3\\\\n\\\\\\\"\\\\\\\"\\\\\\\"Module entry point to enable `python\\\n    \\ -m rcpack`.\\\\n\\\\nThis simply delegates to the CLI's main() function.\\\\n\\\\\\\"\\\\\\\n    \\\"\\\\\\\"\\\\n\\\\nfrom .cli import main\\\\n\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\n    \\    main()\\\\n\\\\n\\\\n\\\",\\n    \\\"src/rcpack/cli.py\\\": \\\"#!/usr/bin/env python3\\\\\\\n    n\\\\\\\"\\\\\\\"\\\\\\\"CLI for Repository Context Packager.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom .config_loader\\\n    \\ import load_config\\\\n\\\\nimport argparse\\\\nimport sys\\\\nfrom pathlib import Path\\\\\\\n    nfrom .gitinfo import get_git_info\\\\nfrom .discover import discover_files\\\\nfrom\\\n    \\ .treeview import create_tree_view\\\\nfrom .renderer.markdown import render_markdown\\\\\\\n    nfrom .renderer.jsonyaml import render_json, render_yaml\\\\nfrom .io_utils import\\\n    \\ write_output\\\\nfrom datetime import datetime, timedelta\\\\n\\\\n\\\\ndef log_verbose(message:\\\n    \\ str, verbose: bool) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Log a message to stderr if verbose\\\n    \\ mode is enabled.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if verbose:\\\\n        print(message, file=sys.stderr)\\\\\\\n    n\\\\n\\\\ndef get_rendered_content(format_type: str, repo_path: str, repo_info: dict,\\\n    \\ tree_text: str, \\\\n                        files_data: dict, total_files: int,\\\n    \\ total_lines: int, \\\\n                        recent_files_info: dict, file_sizes:\\\n    \\ dict) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Get rendered content based on the specified\\\n    \\ format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if format_type == \\\\\\\"json\\\\\\\":\\\\n        return render_json(\\\\\\\n    n            repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\n    \\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\\\\n    n        )\\\\n    elif format_type == \\\\\\\"yaml\\\\\\\":\\\\n        return render_yaml(\\\\\\\n    n            repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\n    \\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\\\\n    n        )\\\\n    else:  # text/markdown\\\\n        return render_markdown(\\\\n \\\n    \\           repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\n    \\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\\\\n    n        )\\\\n\\\\n\\\\ndef process_file(file_path: Path, repo_path: Path, verbose:\\\n    \\ bool) -> tuple[str, str, str]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Process a single file and return\\\n    \\ its data.\\\\n    \\\\n    Returns:\\\\n        tuple: (relative_path_str, content,\\\n    \\ file_size)\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    relative_path = file_path.relative_to(repo_path)\\\\\\\n    n    relative_path_str = str(relative_path)\\\\n    \\\\n    log_verbose(f\\\\\\\"Reading\\\n    \\ file: {relative_path}\\\\\\\", verbose)\\\\n    file_size = file_path.stat().st_size\\\\\\\n    n    \\\\n    try:\\\\n        with open(file_path, 'r', encoding='utf-8') as f:\\\\\\\n    n            content = f.read()\\\\n        return relative_path_str, content, str(file_size)\\\\\\\n    n    except (UnicodeDecodeError, PermissionError):\\\\n        log_verbose(f\\\\\\\"\\\n    Skipping binary/unreadable file: {relative_path}\\\\\\\", verbose)\\\\n        file_size\\\n    \\ = file_path.stat().st_size if file_path.exists() else 0\\\\n        content =\\\n    \\ f\\\\\\\"[Binary or unreadable file: {file_path.name}]\\\\\\\"\\\\n        return relative_path_str,\\\n    \\ content, str(file_size)\\\\n    except Exception:\\\\n        log_verbose(f\\\\\\\"\\\n    Error reading file: {relative_path}\\\\\\\", verbose)\\\\n        raise  # Re-raise\\\n    \\ to handle in calling code\\\\n\\\\n\\\\ndef handle_output(content: str, output_path:\\\n    \\ str = None) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Handle output to either file or stdout.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n    if output_path:\\\\n        # Write to file\\\\n        write_output(output_path,\\\n    \\ content)\\\\n        print(f\\\\\\\"Context package created: {output_path}\\\\\\\")\\\\\\\n    n    else:\\\\n        # Output to stdout\\\\n        print(content)\\\\n\\\\n\\\\ndef main():\\\\\\\n    n    parser = argparse.ArgumentParser(\\\\n        description=\\\\\\\"Package repository\\\n    \\ content for LLM context\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"\\\n    path\\\\\\\", \\\\n        nargs=\\\\\\\"?\\\\\\\", \\\\n        default=\\\\\\\".\\\\\\\", \\\\n      \\\n    \\  help=\\\\\\\"Repository path (default: current directory)\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\\\\n    n        \\\\\\\"-o\\\\\\\", \\\\\\\"--output\\\\\\\", \\\\n        help=\\\\\\\"Output file path (default:\\\n    \\ stdout)\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"-f\\\\\\\", \\\\\\\"--format\\\\\\\n    \\\", \\\\n        choices=[\\\\\\\"text\\\\\\\", \\\\\\\"json\\\\\\\", \\\\\\\"yaml\\\\\\\"], \\\\n       \\\n    \\ default=\\\\\\\"text\\\\\\\",\\\\n        help=\\\\\\\"Output format (default: text)\\\\\\\"\\\\\\\n    n    )\\\\n\\\\n    \\\\\\\"\\\\\\\"\\\\\\\" This will read -r from the console and able to search\\\n    \\ it with this\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    parser.add_argument(\\\\n    \\\\\\\"-r\\\\\\\", \\\\\\\"--recent\\\\\\\n    \\\",\\\\n    action=\\\\\\\"store_true\\\\\\\",\\\\n    help=\\\\\\\"Include only files modified\\\n    \\ in the last 7 days\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"-v\\\\\\\n    \\\", \\\\\\\"--verbose\\\\\\\",\\\\n        action=\\\\\\\"store_true\\\\\\\",\\\\n        help=\\\\\\\"\\\n    Print detailed progress information to stderr\\\\\\\"\\\\n    )\\\\n    \\\\n    args =\\\n    \\ parser.parse_args()\\\\n    \\\\n    try:\\\\n        repo_path = Path(args.path).resolve()\\\\\\\n    n        if not repo_path.exists():\\\\n            print(f\\\\\\\"Error: Path {repo_path}\\\n    \\ does not exist\\\\\\\", file=sys.stderr)\\\\n            sys.exit(1)\\\\n          \\\n    \\  \\\\n        # Get repository information\\\\n        log_verbose(f\\\\\\\"Analyzing\\\n    \\ repository: {repo_path}\\\\\\\", args.verbose)\\\\n        repo_info = get_git_info(repo_path)\\\\\\\n    n        \\\\n        # Discover files\\\\n        log_verbose(f\\\\\\\"Discovering files\\\n    \\ in: {repo_path}\\\\\\\", args.verbose)\\\\n        discovered_files = discover_files([repo_path],\\\n    \\ repo_path, [], [])\\\\n        log_verbose(f\\\\\\\"Found {len(discovered_files)}\\\n    \\ files\\\\\\\", args.verbose)\\\\n        \\\\n        # will check the file in last\\\n    \\ 7 days\\\\n        recent_files_info = {}\\\\n        if args.recent:\\\\n       \\\n    \\     seven_days_ago = datetime.now() - timedelta(days=7)\\\\n            recent_files\\\n    \\ = []\\\\n            for f in discovered_files:\\\\n                try:\\\\n    \\\n    \\                mtime = datetime.fromtimestamp(f.stat().st_mtime)\\\\n        \\\n    \\            if mtime >= seven_days_ago:\\\\n                        recent_files.append(f)\\\\\\\n    n                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)\\\n    \\     \\\\n                except Exception:\\\\n                    continue\\\\n \\\n    \\           discovered_files = recent_files\\\\n        \\\\n        # Read file contents\\\\\\\n    n        files_data = {}\\\\n        file_sizes = {}\\\\n        for file_path in\\\n    \\ discovered_files:\\\\n            try:\\\\n                relative_path_str, content,\\\n    \\ file_size = process_file(file_path, repo_path, args.verbose)\\\\n            \\\n    \\    files_data[relative_path_str] = content\\\\n                file_sizes[relative_path_str]\\\n    \\ = file_size\\\\n            except Exception:\\\\n                continue\\\\n  \\\n    \\      \\\\n        # Create tree view\\\\n        log_verbose(\\\\\\\"Generating directory\\\n    \\ tree\\\\\\\", args.verbose)\\\\n        tree_text = create_tree_view(repo_path, files_data)\\\\\\\n    n        \\\\n        # Count totals\\\\n        total_files = len(files_data)\\\\n\\\n    \\        total_lines = sum(len(content.splitlines()) for _, content in files_data.items())\\\\\\\n    n        \\\\n        # Render based on format\\\\n        log_verbose(f\\\\\\\"Rendering\\\n    \\ output in {args.format} format\\\\\\\", args.verbose)\\\\n        content = get_rendered_content(\\\\\\\n    n            args.format, str(repo_path), repo_info, tree_text,\\\\n           \\\n    \\ files_data, total_files, total_lines,\\\\n            recent_files_info if args.recent\\\n    \\ else {},\\\\n            file_sizes\\\\n        )\\\\n        \\\\n        handle_output(content,\\\n    \\ args.output)\\\\n        \\\\n    except Exception as e:\\\\n        print(f\\\\\\\"Error:\\\n    \\ {e}\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\n# this will convert age\\\n    \\ and give us the difference\\\\ndef human_readable_age(mtime: datetime) -> str:\\\\\\\n    n    delta = datetime.now() - mtime\\\\n    days = delta.days\\\\n    seconds = delta.seconds\\\\\\\n    n    if days > 0:\\\\n        return f\\\\\\\"{days} day{'s' if days != 1 else ''} ago\\\\\\\n    \\\"\\\\n    elif seconds >= 3600:\\\\n        hours = seconds // 3600\\\\n        return\\\n    \\ f\\\\\\\"{hours} hour{'s' if hours != 1 else ''} ago\\\\\\\"\\\\n    elif seconds >= 60:\\\\\\\n    n        minutes = seconds // 60\\\\n        return f\\\\\\\"{minutes} minute{'s' if\\\n    \\ minutes != 1 else ''} ago\\\\\\\"\\\\n    else:\\\\n        return \\\\\\\"just now\\\\\\\"\\\\\\\n    n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\\n\\\",\\n    \\\"src/rcpack/config_loader.py\\\"\\\n    : \\\"# src/rcpack/config_loader.py\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nTOML config loader for Repo-Contextor.\\\\\\\n    n\\\\nRules:\\\\n- Look for .repo-contextor.toml in the CURRENT directory\\\\n- If missing:\\\n    \\ ignore\\\\n- If present but invalid: print a clear error and exit(1)\\\\n- Only\\\n    \\ recognized keys are applied; unknown keys ignored\\\\n- Precedence: CLI > TOML\\\n    \\ > DEFAULTS\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nfrom __future__ import annotations\\\\nimport os,\\\n    \\ sys\\\\nfrom typing import Dict, Iterable, Any\\\\n\\\\ntry:\\\\n    import tomllib\\\\\\\n    n    _loads = tomllib.loads\\\\nexcept ModuleNotFoundError:\\\\n    try:\\\\n      \\\n    \\  import tomli\\\\n        _loads = tomli.loads\\\\n    except ModuleNotFoundError:\\\\\\\n    n        _loads = None\\\\n\\\\ndef _need_toml():\\\\n    if _loads is None:\\\\n    \\\n    \\    print(\\\\\\\"Error: TOML parser not available. Use Python 3.11+ or `pip install\\\n    \\ tomli`.\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\ndef _load_toml(dotfile:\\\n    \\ str) -> Dict[str, Any]:\\\\n    _need_toml()\\\\n    if not os.path.exists(dotfile):\\\\\\\n    n        return {}\\\\n    try:\\\\n        with open(dotfile, \\\\\\\"rb\\\\\\\") as f:\\\\\\\n    n            raw = f.read().decode(\\\\\\\"utf-8\\\\\\\", errors=\\\\\\\"strict\\\\\\\")\\\\n  \\\n    \\      data = _loads(raw)\\\\n        return data if isinstance(data, dict) else\\\n    \\ {}\\\\n    except Exception as e:\\\\n        print(f\\\\\\\"Error: failed to parse\\\n    \\ {dotfile} as TOML.\\\\\\\\n{e}\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\\\\n    ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\\\\\\n    n    ks = set(known)\\\\n    return {k: v for k, v in d.items() if k in ks}\\\\n\\\\\\\n    ndef _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str,\\\n    \\ Any], known: Iterable[str]) -> Dict[str, Any]:\\\\n    ks = set(known)\\\\n    out:\\\n    \\ Dict[str, Any] = {k: defaults.get(k) for k in ks}\\\\n    for src in (filecfg,\\\n    \\ clicfg):\\\\n        for k, v in src.items():\\\\n            if k in ks and v is\\\n    \\ not None:\\\\n                out[k] = v\\\\n    return out\\\\n\\\\ndef load_config(*,\\\n    \\ dotfile: str = \\\\\\\".repo-contextor.toml\\\\\\\", defaults: Dict[str, Any] | None\\\n    \\ = None, cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ())\\\n    \\ -> Dict[str, Any]:\\\\n    defaults = defaults or {}\\\\n    cli_cfg = cli_cfg or\\\n    \\ {}\\\\n    known = tuple(known_keys)\\\\n    filecfg = _filter_known(_load_toml(dotfile),\\\n    \\ known)\\\\n    return _merge(defaults, filecfg, cli_cfg, known)\\\\n\\\",\\n    \\\"\\\n    src/rcpack/discover.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"File discovery module for repository analysis.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom pathlib import Path\\\\nfrom typing import List\\\\nimport fnmatch\\\\\\\n    n\\\\n\\\\ndef discover_files(\\\\n    inputs: List[Path],\\\\n    root: Path,\\\\n    include_patterns:\\\n    \\ List[str],\\\\n    exclude_patterns: List[str],\\\\n) -> List[Path]:\\\\n    \\\\\\\"\\\\\\\n    \\\"\\\\\\\"Discover relevant files.\\\\n\\\\n    - inputs: list of files/dirs to scan\\\\\\\n    n    - root: common project root; patterns are matched against POSIX paths relative\\\n    \\ to root\\\\n    - include_patterns: glob patterns to include (if empty, use sensible\\\n    \\ defaults)\\\\n    - exclude_patterns: glob patterns to exclude\\\\n    Returns a\\\n    \\ list of absolute Paths to files.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    default_include_exts\\\n    \\ = {\\\\n        '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\\\\\\\n    n        '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\\\n   \\\n    \\     '.html', '.css', '.scss', '.sass', '.less', '.vue', '.svelte',\\\\n      \\\n    \\  '.md', '.txt', '.rst', '.yaml', '.yml', '.json', '.toml', '.ini',\\\\n      \\\n    \\  '.cfg', '.conf', '.xml', '.sql', '.sh', '.bash', '.zsh', '.fish',\\\\n    }\\\\\\\n    n\\\\n    always_include_names = {\\\\n        'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING',\\\n    \\ 'Makefile',\\\\n        'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\\\\\\\n    n        'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\\\\\\n    n    }\\\\n\\\\n    skip_dir_names = {\\\\n        '.git', '.svn', '.hg', '__pycache__',\\\n    \\ '.pytest_cache',\\\\n        'node_modules', '.venv', 'venv', 'env', '.env',\\\\\\\n    n        'build', 'dist', 'target', 'out', '.next', '.nuxt',\\\\n        '.idea',\\\n    \\ '.vscode', '.vs', 'coverage', '.coverage'\\\\n    }\\\\n\\\\n    def matches_any(patterns:\\\n    \\ List[str], rel_posix: str) -> bool:\\\\n        return any(fnmatch.fnmatch(rel_posix,\\\n    \\ pat) for pat in patterns)\\\\n\\\\n    def should_take(file_path: Path) -> bool:\\\\\\\n    n        rel_posix = file_path.relative_to(root).as_posix()\\\\n        if exclude_patterns\\\n    \\ and matches_any(exclude_patterns, rel_posix):\\\\n            return False\\\\n\\\n    \\        if include_patterns:\\\\n            return matches_any(include_patterns,\\\n    \\ rel_posix)\\\\n        # default include logic\\\\n        return file_path.name\\\n    \\ in always_include_names or file_path.suffix.lower() in default_include_exts\\\\\\\n    n\\\\n    discovered: list[Path] = []\\\\n    seen = set()\\\\n\\\\n    for item in inputs:\\\\\\\n    n        p = item.resolve()\\\\n        if p.is_file():\\\\n            # Skip if\\\n    \\ excluded or in skipped directory\\\\n            if any(part in skip_dir_names\\\n    \\ for part in p.parts):\\\\n                continue\\\\n            if should_take(p):\\\\\\\n    n                key = p.as_posix()\\\\n                if key not in seen:\\\\n \\\n    \\                   seen.add(key)\\\\n                    discovered.append(p)\\\\\\\n    n        elif p.is_dir():\\\\n            for child in p.rglob('*'):\\\\n        \\\n    \\        if not child.is_file():\\\\n                    continue\\\\n           \\\n    \\     if any(part in skip_dir_names for part in child.parts):\\\\n             \\\n    \\       continue\\\\n                if should_take(child):\\\\n                 \\\n    \\   key = child.resolve().as_posix()\\\\n                    if key not in seen:\\\\\\\n    n                        seen.add(key)\\\\n                        discovered.append(child.resolve())\\\\\\\n    n\\\\n    return sorted(discovered)\\\",\\n    \\\"src/rcpack/gitinfo.py\\\": \\\"from __future__\\\n    \\ import annotations\\\\n\\\\nimport subprocess\\\\nfrom pathlib import Path\\\\nfrom\\\n    \\ typing import Dict, Any\\\\n\\\\n\\\\ndef _git(cmd: list[str], cwd: Path) -> str:\\\\\\\n    n    # Validate git commands to prevent injection\\\\n    allowed_commands = {\\\\\\\n    n        \\\\\\\"rev-parse\\\\\\\", \\\\\\\"show\\\\\\\", \\\\\\\"log\\\\\\\", \\\\\\\"status\\\\\\\", \\\\\\\"branch\\\\\\\n    \\\", \\\\\\\"config\\\\\\\"\\\\n    }\\\\n    if not cmd or cmd[0] not in allowed_commands:\\\\\\\n    n        raise ValueError(f\\\\\\\"Git command not allowed: {cmd[0] if cmd else 'empty'}\\\\\\\n    \\\")\\\\n    \\\\n    out = subprocess.check_output([\\\\\\\"git\\\\\\\", *cmd], cwd=str(cwd),\\\n    \\ timeout=30)\\\\n    return out.decode(\\\\\\\"utf-8\\\\\\\", errors=\\\\\\\"replace\\\\\\\").strip()\\\\\\\n    n\\\\n\\\\ndef is_git_repo(path: Path) -> bool:\\\\n    try:\\\\n        flag = _git([\\\\\\\n    \\\"rev-parse\\\\\\\", \\\\\\\"--is-inside-work-tree\\\\\\\"], cwd=path)\\\\n        return flag\\\n    \\ == \\\\\\\"true\\\\\\\"\\\\n    except Exception:\\\\n        return False\\\\n\\\\n\\\\ndef get_git_info(path:\\\n    \\ Path) -> Dict[str, Any]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Return info for the current\\\n    \\ HEAD of a repo rooted at `path`.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        commit\\\n    \\ = _git([\\\\\\\"rev-parse\\\\\\\", \\\\\\\"HEAD\\\\\\\"], cwd=path)\\\\n        branch = _git([\\\\\\\n    \\\"rev-parse\\\\\\\", \\\\\\\"--abbrev-ref\\\\\\\", \\\\\\\"HEAD\\\\\\\"], cwd=path)\\\\n        author\\\n    \\ = _git([\\\\\\\"show\\\\\\\", \\\\\\\"-s\\\\\\\", \\\\\\\"--format=%an <%ae>\\\\\\\"], cwd=path)\\\\n\\\n    \\        date = _git([\\\\\\\"show\\\\\\\", \\\\\\\"-s\\\\\\\", \\\\\\\"--date=local\\\\\\\", \\\\\\\"--format=%ad\\\\\\\n    \\\"], cwd=path)\\\\n        return {\\\\n            \\\\\\\"is_repo\\\\\\\": True,\\\\n    \\\n    \\        \\\\\\\"commit\\\\\\\": commit,\\\\n            \\\\\\\"branch\\\\\\\": branch,\\\\n    \\\n    \\        \\\\\\\"author\\\\\\\": author,\\\\n            \\\\\\\"date\\\\\\\": date,\\\\n        \\\n    \\    \\\\\\\"note\\\\\\\": None,\\\\n        }\\\\n    except Exception:\\\\n        # treat\\\n    \\ as not a repo if anything fails\\\\n        return {\\\\n            \\\\\\\"is_repo\\\\\\\n    \\\": False,\\\\n            \\\\\\\"commit\\\\\\\": None,\\\\n            \\\\\\\"branch\\\\\\\": None,\\\\\\\n    n            \\\\\\\"author\\\\\\\": None,\\\\n            \\\\\\\"date\\\\\\\": None,\\\\n      \\\n    \\      \\\\\\\"note\\\\\\\": \\\\\\\"Not a git repository\\\\\\\",\\\\n        }\\\\n\\\",\\n    \\\"src/rcpack/io_utils.py\\\"\\\n    : \\\"\\\\\\\"\\\\\\\"\\\\\\\"I/O utilities for file operations.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom pathlib\\\n    \\ import Path\\\\nfrom typing import Tuple\\\\n\\\\n\\\\ndef write_output(output_path:\\\n    \\ str, content: str) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Write content to output file.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n    output_file = Path(output_path)\\\\n    \\\\n    # Create parent\\\n    \\ directories if they don't exist\\\\n    output_file.parent.mkdir(parents=True,\\\n    \\ exist_ok=True)\\\\n    \\\\n    # Write content\\\\n    with open(output_file, 'w',\\\n    \\ encoding='utf-8') as f:\\\\n        f.write(content)\\\\n\\\\n\\\\ndef is_binary_file(path:\\\n    \\ Path, sniff_bytes: int = 2048) -> bool:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Heuristically determine\\\n    \\ if a file is binary by scanning for NUL bytes.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n   \\\n    \\     with open(path, 'rb') as fb:\\\\n            chunk = fb.read(sniff_bytes)\\\\\\\n    n        if b\\\\\\\"\\\\\\\\x00\\\\\\\" in chunk:\\\\n            return True\\\\n        # If\\\n    \\ the chunk has a lot of non-text bytes, consider it binary\\\\n        text_byte_count\\\n    \\ = sum(32 <= b <= 126 or b in (9, 10, 13) for b in chunk)\\\\n        return (len(chunk)\\\n    \\ - text_byte_count) > max(1, len(chunk) // 3)\\\\n    except Exception:\\\\n    \\\n    \\    # If we cannot read, treat as binary to avoid further processing\\\\n     \\\n    \\   return True\\\\n\\\\n\\\\ndef read_text_safely(path: Path, max_bytes: int = 16_384)\\\n    \\ -> Tuple[str, str, bool]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Read a text file safely with size\\\n    \\ limit and encoding fallbacks.\\\\n\\\\n    Returns (content, encoding_used, truncated).\\\\\\\n    n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    truncated = False\\\\n    raw: bytes\\\\n    with open(path,\\\n    \\ 'rb') as fb:\\\\n        raw = fb.read(max_bytes + 1)\\\\n    if len(raw) > max_bytes:\\\\\\\n    n        truncated = True\\\\n        raw = raw[:max_bytes]\\\\n\\\\n    for enc in\\\n    \\ (\\\\\\\"utf-8\\\\\\\", \\\\\\\"utf-16\\\\\\\", \\\\\\\"utf-16-le\\\\\\\", \\\\\\\"utf-16-be\\\\\\\", \\\\\\\"latin-1\\\\\\\n    \\\"):\\\\n        try:\\\\n            text = raw.decode(enc)\\\\n            return\\\n    \\ text, enc, truncated\\\\n        except Exception:\\\\n            continue\\\\n \\\n    \\   # Fallback: replace errors with utf-8\\\\n    text = raw.decode(\\\\\\\"utf-8\\\\\\\"\\\n    , errors=\\\\\\\"replace\\\\\\\")\\\\n    return text, \\\\\\\"utf-8\\\\\\\", truncated\\\",\\n   \\\n    \\ \\\"src/rcpack/packager.py\\\": \\\"from __future__ import annotations\\\\n\\\\nimport\\\n    \\ sys\\\\nfrom pathlib import Path\\\\nfrom typing import Iterable, Tuple\\\\n\\\\nfrom\\\n    \\ rcpack.discover import discover_files\\\\nfrom rcpack.gitinfo import get_git_info,\\\n    \\ is_git_repo\\\\nfrom rcpack.io_utils import read_text_safely, is_binary_file\\\\\\\n    nfrom rcpack.renderer import markdown as md_renderer\\\\nfrom rcpack.renderer.jsonyaml\\\n    \\ import render_json, render_yaml\\\\nfrom rcpack.treeview import render_tree\\\\\\\n    n\\\\n\\\\ndef _find_root(inputs: list[str]) -> Path:\\\\n    paths = [Path(p) for p\\\n    \\ in inputs]\\\\n    if len(paths) == 1 and Path(paths[0]).is_dir():\\\\n        return\\\n    \\ paths[0].resolve()\\\\n    parents = [p if p.is_dir() else p.parent for p in paths]\\\\\\\n    n    root = Path(*Path.commonpath([str(p.resolve()) for p in parents]).split(\\\\\\\n    \\\"/\\\\\\\"))\\\\n    return root.resolve()\\\\n\\\\n\\\\ndef build_package(\\\\n    inputs:\\\n    \\ list[str],\\\\n    include_patterns: list[str] | None,\\\\n    exclude_patterns:\\\n    \\ list[str] | None,\\\\n    max_file_bytes: int,\\\\n    fmt: str = \\\\\\\"markdown\\\\\\\n    \\\",\\\\n) -> Tuple[str, dict]:\\\\n    root = _find_root(inputs)\\\\n    root_abs =\\\n    \\ root.resolve()\\\\n\\\\n    repo_info = (\\\\n        get_git_info(root_abs) if is_git_repo(root_abs)\\\n    \\ else {\\\\n            \\\\\\\"is_repo\\\\\\\": False,\\\\n            \\\\\\\"commit\\\\\\\": None,\\\\\\\n    n            \\\\\\\"branch\\\\\\\": None,\\\\n            \\\\\\\"author\\\\\\\": None,\\\\n    \\\n    \\        \\\\\\\"date\\\\\\\": None,\\\\n            \\\\\\\"note\\\\\\\": \\\\\\\"Not a git repository\\\\\\\n    \\\",\\\\n        }\\\\n    )\\\\n\\\\n    files = discover_files(\\\\n        inputs=[Path(p)\\\n    \\ for p in inputs],\\\\n        root=root_abs,\\\\n        include_patterns=include_patterns\\\n    \\ or [],\\\\n        exclude_patterns=exclude_patterns or [],\\\\n    )\\\\n    rel_files\\\n    \\ = [f.relative_to(root_abs) for f in files]\\\\n\\\\n    project_tree = render_tree([p.as_posix()\\\n    \\ for p in rel_files])\\\\n\\\\n    file_sections: list[dict] = []\\\\n    total_lines\\\n    \\ = 0\\\\n    total_chars = 0\\\\n\\\\n    for f in files:\\\\n        rel = f.relative_to(root_abs).as_posix()\\\\\\\n    n        try:\\\\n            if is_binary_file(f):\\\\n                content =\\\n    \\ f\\\\\\\"[binary file skipped: {f.name}, {f.stat().st_size} bytes]\\\\\\\"\\\\n      \\\n    \\          file_sections.append({\\\\n                    \\\\\\\"path\\\\\\\": rel,\\\\n\\\n    \\                    \\\\\\\"language\\\\\\\": _language_from_ext(f.suffix),\\\\n      \\\n    \\              \\\\\\\"content\\\\\\\": content,\\\\n                    \\\\\\\"is_truncated\\\\\\\n    \\\": False,\\\\n                })\\\\n                total_chars += len(content)\\\\\\\n    n                continue\\\\n\\\\n            content, used_encoding, truncated =\\\n    \\ read_text_safely(f, max_bytes=max_file_bytes)\\\\n            total_lines += content.count(\\\\\\\n    \\\"\\\\\\\\n\\\\\\\") + (1 if content and not content.endswith(\\\\\\\"\\\\\\\\n\\\\\\\") else 0)\\\\\\\n    n            total_chars += len(content)\\\\n\\\\n            if truncated:\\\\n   \\\n    \\             note = f\\\\\\\"\\\\\\\\n\\\\\\\\n[... TRUNCATED to first {max_file_bytes} bytes\\\n    \\ ...]\\\\\\\"\\\\n                content = content + note\\\\n                total_chars\\\n    \\ += len(note)\\\\n\\\\n            file_sections.append({\\\\n                \\\\\\\"\\\n    path\\\\\\\": rel,\\\\n                \\\\\\\"language\\\\\\\": _language_from_ext(f.suffix),\\\\\\\n    n                \\\\\\\"content\\\\\\\": content,\\\\n                \\\\\\\"is_truncated\\\\\\\n    \\\": truncated,\\\\n            })\\\\n        except Exception as exc:\\\\n        \\\n    \\    print(f\\\\\\\"[rcpack] error reading {rel}: {exc}\\\\\\\", file=sys.stderr)\\\\n \\\n    \\           continue\\\\n\\\\n    # render in chosen format\\\\n    if fmt == \\\\\\\"markdown\\\\\\\n    \\\":\\\\n        out_text = md_renderer.render_markdown(\\\\n            root=str(root_abs),\\\\\\\n    n            repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n   \\\n    \\         files=file_sections,\\\\n            total_files=len(file_sections),\\\\\\\n    n            total_lines=total_lines,\\\\n        )\\\\n    elif fmt == \\\\\\\"json\\\\\\\n    \\\":\\\\n        out_text = render_json(\\\\n            root=str(root_abs),\\\\n   \\\n    \\         repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n      \\\n    \\      files=file_sections,\\\\n            total_files=len(file_sections),\\\\n \\\n    \\           total_lines=total_lines,\\\\n        )\\\\n    elif fmt == \\\\\\\"yaml\\\\\\\"\\\n    :\\\\n        out_text = render_yaml(\\\\n            root=str(root_abs),\\\\n     \\\n    \\       repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n        \\\n    \\    files=file_sections,\\\\n            total_files=len(file_sections),\\\\n   \\\n    \\         total_lines=total_lines,\\\\n        )\\\\n    else:\\\\n        raise ValueError(f\\\\\\\n    \\\"Unsupported format: {fmt}\\\\\\\")\\\\n\\\\n    stats = {\\\\\\\"files\\\\\\\": len(file_sections),\\\n    \\ \\\\\\\"lines\\\\\\\": total_lines, \\\\\\\"chars\\\\\\\": total_chars}\\\\n    return out_text,\\\n    \\ stats\\\\n\\\\n\\\\ndef _language_from_ext(ext: str) -> str:\\\\n    ext = ext.lower().lstrip(\\\\\\\n    \\\".\\\\\\\")\\\\n    mapping = {\\\\n        \\\\\\\"py\\\\\\\": \\\\\\\"python\\\\\\\", \\\\\\\"js\\\\\\\": \\\\\\\n    \\\"javascript\\\\\\\", \\\\\\\"ts\\\\\\\": \\\\\\\"typescript\\\\\\\",\\\\n        \\\\\\\"json\\\\\\\": \\\\\\\"\\\n    json\\\\\\\", \\\\\\\"md\\\\\\\": \\\\\\\"markdown\\\\\\\", \\\\\\\"yml\\\\\\\": \\\\\\\"yaml\\\\\\\", \\\\\\\"yaml\\\\\\\"\\\n    : \\\\\\\"yaml\\\\\\\",\\\\n        \\\\\\\"toml\\\\\\\": \\\\\\\"toml\\\\\\\", \\\\\\\"sh\\\\\\\": \\\\\\\"bash\\\\\\\"\\\n    , \\\\\\\"c\\\\\\\": \\\\\\\"c\\\\\\\", \\\\\\\"cpp\\\\\\\": \\\\\\\"cpp\\\\\\\",\\\\n        \\\\\\\"java\\\\\\\": \\\\\\\"\\\n    java\\\\\\\", \\\\\\\"go\\\\\\\": \\\\\\\"go\\\\\\\", \\\\\\\"rs\\\\\\\": \\\\\\\"rust\\\\\\\",\\\\n    }\\\\n    return\\\n    \\ mapping.get(ext, \\\\\\\"\\\\\\\")\\\\n\\\",\\n    \\\"src/rcpack/renderer/jsonyaml.py\\\": \\\"\\\n    from __future__ import annotations\\\\nimport json\\\\n\\\\ntry:\\\\n    import yaml\\\\\\\n    nexcept ImportError:\\\\n    yaml = None\\\\n\\\\n\\\\ndef render_json(root, repo_info,\\\n    \\ tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None)\\\n    \\ -> str:\\\\n    data = {\\\\n        \\\\\\\"root\\\\\\\": root,\\\\n        \\\\\\\"repo_info\\\\\\\n    \\\": repo_info,\\\\n        \\\\\\\"structure\\\\\\\": tree_text,\\\\n        \\\\\\\"recent_changes\\\\\\\n    \\\": recent_files or [],\\\\n        \\\\\\\"files\\\\\\\": files,\\\\n        \\\\\\\"file_sizes\\\\\\\n    \\\": file_sizes or {},\\\\n        \\\\\\\"summary\\\\\\\": {\\\\\\\"total_files\\\\\\\": total_files,\\\n    \\ \\\\\\\"total_lines\\\\\\\": total_lines},\\\\n        \\\\n    }\\\\n    return json.dumps(data,\\\n    \\ indent=2, ensure_ascii=False)\\\\n\\\\n\\\\ndef render_yaml(root, repo_info, tree_text,\\\n    \\ files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\\\\\\\n    n    if yaml is None:\\\\n        raise RuntimeError(\\\\\\\"PyYAML not installed; run\\\n    \\ `pip install pyyaml`\\\\\\\")\\\\n    data = {\\\\n        \\\\\\\"root\\\\\\\": root,\\\\n  \\\n    \\      \\\\\\\"repo_info\\\\\\\": repo_info,\\\\n        \\\\\\\"structure\\\\\\\": tree_text,\\\\\\\n    n        \\\\\\\"recent_changes\\\\\\\": recent_files or [],\\\\n        \\\\\\\"files\\\\\\\":\\\n    \\ files,\\\\n        \\\\\\\"file_sizes\\\\\\\": file_sizes or {},\\\\n        \\\\\\\"summary\\\\\\\n    \\\": {\\\\\\\"total_files\\\\\\\": total_files, \\\\\\\"total_lines\\\\\\\": total_lines},\\\\n \\\n    \\       \\\\n    }\\\\n    return yaml.safe_dump(data, sort_keys=False, allow_unicode=True)\\\\\\\n    n\\\",\\n    \\\"src/rcpack/renderer/markdown.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Markdown renderer\\\n    \\ for repository context.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom typing import Dict, Any\\\\n\\\\n\\\\\\\n    ndef render_markdown(root: str, repo_info: Dict[str, Any], tree_text: str, \\\\\\\n    n                   files: Dict[str, str], total_files: int, total_lines: int,\\\n    \\ recent_files=None, file_sizes=None) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Render repository\\\n    \\ context as markdown.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    lines = []\\\\n    \\\\n    # Header\\\\\\\n    n    lines.append(f\\\\\\\"# Repository Context: {root}\\\\\\\")\\\\n    lines.append(\\\\\\\n    \\\"\\\\\\\")\\\\n    \\\\n    # Repository info\\\\n    if repo_info.get(\\\\\\\"is_repo\\\\\\\"\\\n    ):\\\\n        lines.append(\\\\\\\"## Git Repository Information\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Branch**: {repo_info.get('branch', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Commit**: {repo_info.get('commit', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Author**: {repo_info.get('author', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Date**: {repo_info.get('date', 'N/A')}\\\\\\\")\\\\n    else:\\\\n        lines.append(\\\\\\\n    \\\"## Repository Information\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Note**: {repo_info.get('note',\\\n    \\ 'Not a git repository')}\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Summary\\\\\\\n    n    lines.append(\\\\\\\"## Summary\\\\\\\")\\\\n    lines.append(f\\\\\\\"- **Total Files**:\\\n    \\ {total_files}\\\\\\\")\\\\n    lines.append(f\\\\\\\"- **Total Lines**: {total_lines}\\\\\\\n    \\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Directory structure\\\\n    lines.append(\\\\\\\n    \\\"## Directory Structure\\\\\\\")\\\\n    lines.append(\\\\\\\"```\\\\\\\")\\\\n    lines.append(tree_text)\\\\\\\n    n    lines.append(\\\\\\\"```\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n\\\\n    # will produce\\\n    \\ recent files \\\\n    # Recent files (fixed)\\\\n    if recent_files:\\\\n       \\\n    \\ lines.append(\\\\\\\"## Recent Changes\\\\\\\")\\\\n        for file, age in recent_files.items():\\\\\\\n    n            lines.append(f\\\\\\\"- {file} (modified {age})\\\\\\\")\\\\n        lines.append(\\\\\\\n    \\\"\\\\\\\")\\\\n    \\\\n    # File contents\\\\n    lines.append(\\\\\\\"## File Contents\\\\\\\n    \\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    for file_path, content in sorted(files.items()):\\\\\\\n    n        if file_sizes and file_path in file_sizes:\\\\n            size_bytes =\\\n    \\ file_sizes[file_path]\\\\n            lines.append(f\\\\\\\"### {file_path} ({size_bytes}\\\n    \\ bytes)\\\\\\\")\\\\n        else:\\\\n            lines.append(f\\\\\\\"### {file_path}\\\\\\\n    \\\")\\\\n        lines.append(\\\\\\\"\\\\\\\")\\\\n        \\\\n        # Detect language for\\\n    \\ syntax highlighting\\\\n        ext = file_path.split('.')[-1].lower() if '.'\\\n    \\ in file_path else ''\\\\n        lang_map = {\\\\n            'py': 'python', 'js':\\\n    \\ 'javascript', 'ts': 'typescript',\\\\n            'java': 'java', 'cpp': 'cpp',\\\n    \\ 'c': 'c', 'h': 'c',\\\\n            'cs': 'csharp', 'php': 'php', 'rb': 'ruby',\\\\\\\n    n            'go': 'go', 'rs': 'rust', 'swift': 'swift',\\\\n            'html':\\\n    \\ 'html', 'css': 'css', 'scss': 'scss',\\\\n            'json': 'json', 'yaml':\\\n    \\ 'yaml', 'yml': 'yaml',\\\\n            'xml': 'xml', 'sql': 'sql', 'sh': 'bash',\\\\\\\n    n            'md': 'markdown', 'dockerfile': 'dockerfile'\\\\n        }\\\\n     \\\n    \\   \\\\n        language = lang_map.get(ext, '')\\\\n        lines.append(f\\\\\\\"```{language}\\\\\\\n    \\\")\\\\n        lines.append(content)\\\\n        lines.append(\\\\\\\"```\\\\\\\")\\\\n   \\\n    \\     lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    return \\\\\\\"\\\\\\\\n\\\\\\\".join(lines)\\\\n\\\"\\\n    ,\\n    \\\"src/rcpack/treeview.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Tree view generation for repository\\\n    \\ structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom pathlib import Path\\\\nfrom typing import Dict,\\\n    \\ List\\\\n\\\\n\\\\ndef create_tree_view(repo_path: Path, files_data: Dict[str, str])\\\n    \\ -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create a tree view of the repository structure.\\\\\\\"\\\n    \\\\\\\"\\\\\\\"\\\\n    paths = list(files_data.keys())\\\\n    return render_tree(paths)\\\\\\\n    n\\\\n\\\\ndef render_tree(paths: List[str]) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Render a tree\\\n    \\ view from a list of relative POSIX paths.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    tree_structure:\\\n    \\ dict = {}\\\\n\\\\n    for p in paths:\\\\n        parts = Path(p).parts\\\\n      \\\n    \\  current = tree_structure\\\\n        for part in parts[:-1]:\\\\n            if\\\n    \\ part not in current:\\\\n                current[part] = {}\\\\n            current\\\n    \\ = current[part]\\\\n        if parts:\\\\n            current[parts[-1]] = None\\\\\\\n    n\\\\n    def _render(structure: dict, prefix: str = \\\\\\\"\\\\\\\") -> str:\\\\n      \\\n    \\  lines = []\\\\n        items = sorted(structure.items(), key=lambda x: (x[1]\\\n    \\ is None, x[0]))\\\\n        for i, (name, subtree) in enumerate(items):\\\\n   \\\n    \\         is_last = i == len(items) - 1\\\\n            lines.append(f\\\\\\\"{prefix}{'└──\\\n    \\ ' if is_last else '├── '}{name}\\\\\\\")\\\\n            if subtree is not None:\\\\\\\n    n                extension = (\\\\\\\"    \\\\\\\" if is_last else \\\\\\\"│   \\\\\\\")\\\\n  \\\n    \\              lines.append(_render(subtree, prefix + extension))\\\\n        return\\\n    \\ \\\\\\\"\\\\\\\\n\\\\\\\".join(filter(None, lines))\\\\n\\\\n    if not tree_structure:\\\\n \\\n    \\       return \\\\\\\"No files found\\\\\\\"\\\\n    return _render(tree_structure)\\\"\\n\\\n    \\  },\\n  \\\"file_sizes\\\": {\\n    \\\"LICENSE\\\": \\\"1064\\\",\\n    \\\"README.md\\\": \\\"\\\n    11164\\\",\\n    \\\"pyproject.toml\\\": \\\"361\\\",\\n    \\\"src/rcpack/__init__.py\\\": \\\"\\\n    198\\\",\\n    \\\"src/rcpack/__main__.py\\\": \\\"197\\\",\\n    \\\"src/rcpack/cli.py\\\": \\\"\\\n    7087\\\",\\n    \\\"src/rcpack/config_loader.py\\\": \\\"2099\\\",\\n    \\\"src/rcpack/discover.py\\\"\\\n    : \\\"3067\\\",\\n    \\\"src/rcpack/gitinfo.py\\\": \\\"1653\\\",\\n    \\\"src/rcpack/io_utils.py\\\"\\\n    : \\\"1817\\\",\\n    \\\"src/rcpack/packager.py\\\": \\\"4430\\\",\\n    \\\"src/rcpack/renderer/jsonyaml.py\\\"\\\n    : \\\"1176\\\",\\n    \\\"src/rcpack/renderer/markdown.py\\\": \\\"2829\\\",\\n    \\\"src/rcpack/treeview.py\\\"\\\n    : \\\"1371\\\"\\n  },\\n  \\\"summary\\\": {\\n    \\\"total_files\\\": 14,\\n    \\\"total_lines\\\"\\\n    : 1180\\n  }\\n}\"\n  test-yaml.yaml: \"root: /Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\\n\\\n    repo_info:\\n  is_repo: true\\n  commit: 682153b169db66d3a72e9cabdd1f3448a3b2986d\\n\\\n    \\  branch: refactoring\\n  author: Abhinav <abhinavbhardwaj2002@gmail.com>\\n  date:\\\n    \\ Fri Oct 3 18:45:48 2025\\n  note: null\\nstructure: '├── src\\n\\n  │   └── rcpack\\n\\\n    \\n  │       ├── renderer\\n\\n  │       │   ├── jsonyaml.py\\n\\n  │       │   └──\\\n    \\ markdown.py\\n\\n  │       ├── __init__.py\\n\\n  │       ├── __main__.py\\n\\n  │\\\n    \\       ├── cli.py\\n\\n  │       ├── config_loader.py\\n\\n  │       ├── discover.py\\n\\\n    \\n  │       ├── gitinfo.py\\n\\n  │       ├── io_utils.py\\n\\n  │       ├── packager.py\\n\\\n    \\n  │       └── treeview.py\\n\\n  ├── LICENSE\\n\\n  ├── README.md\\n\\n  ├── pyproject.toml\\n\\\n    \\n  └── test-output.json'\\nrecent_changes: []\\nfiles:\\n  LICENSE: 'MIT License\\n\\\n    \\n\\n    Copyright (c) 2025 Abhinav\\n\\n\\n    Permission is hereby granted, free\\\n    \\ of charge, to any person obtaining a copy\\n\\n    of this software and associated\\\n    \\ documentation files (the \\\"Software\\\"), to deal\\n\\n    in the Software without\\\n    \\ restriction, including without limitation the rights\\n\\n    to use, copy, modify,\\\n    \\ merge, publish, distribute, sublicense, and/or sell\\n\\n    copies of the Software,\\\n    \\ and to permit persons to whom the Software is\\n\\n    furnished to do so, subject\\\n    \\ to the following conditions:\\n\\n\\n    The above copyright notice and this permission\\\n    \\ notice shall be included in all\\n\\n    copies or substantial portions of the\\\n    \\ Software.\\n\\n\\n    THE SOFTWARE IS PROVIDED \\\"AS IS\\\", WITHOUT WARRANTY OF ANY\\\n    \\ KIND, EXPRESS OR\\n\\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\\\n    \\ OF MERCHANTABILITY,\\n\\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\\\n    \\ IN NO EVENT SHALL THE\\n\\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\\\n    \\ CLAIM, DAMAGES OR OTHER\\n\\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\\\n    \\ TORT OR OTHERWISE, ARISING FROM,\\n\\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE\\\n    \\ OR THE USE OR OTHER DEALINGS IN THE\\n\\n    SOFTWARE.\\n\\n    '\\n  README.md:\\\n    \\ \\\"# Repo-Contextor\\\\n\\\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\\\\\\n    n\\\\\\n    [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\\\\\\n    n\\\\\\n    \\\\nA powerful Repository Context Packager CLI tool that analyzes local\\\n    \\ git repositories\\\\\\n    \\\\ and creates comprehensive text files containing repository\\\n    \\ content optimized\\\\\\n    \\\\ for sharing with Large Language Models (LLMs).\\\\\\\n    n\\\\n## Overview\\\\n\\\\nWhen developers\\\\\\n    \\\\ want to get help from ChatGPT,\\\n    \\ Claude, or other LLMs about their code, they\\\\\\n    \\\\ often struggle with how\\\n    \\ to share their codebase effectively. Common problems\\\\\\n    \\\\ include:\\\\n\\\\\\\n    n- **Lost Context**: Copy-pasting individual files loses important\\\\\\n    \\\\ project\\\n    \\ structure and relationships\\\\n- **Missing Dependencies**: LLMs can't\\\\\\n   \\\n    \\ \\\\ see how files connect or what libraries are used\\\\n- **Incomplete Picture**:\\\\\\\n    \\n    \\\\ Hard to convey the overall architecture and organization\\\\n- **Manual\\\n    \\ Work**:\\\\\\n    \\\\ Time-consuming to gather and format relevant code\\\\n\\\\n**Repo-Contextor**\\\n    \\ solves\\\\\\n    \\\\ this by automatically collecting and formatting repository\\\n    \\ content into a single,\\\\\\n    \\\\ well-structured text file that provides rich\\\n    \\ context to LLMs, enabling them\\\\\\n    \\\\ to give much better assistance with\\\n    \\ your code.\\\\n\\\\n## Features\\\\n\\\\n- **Git Integration**:\\\\\\n    \\\\ Extracts commit\\\n    \\ SHA, branch, author, and date information\\\\n- **Project Structure**:\\\\\\n   \\\n    \\ \\\\ Generates a clear directory tree visualization\\\\n- **File Content Packaging**:\\\\\\\n    \\n    \\\\ Includes file contents with syntax highlighting\\\\n- **Smart File Discovery**:\\\\\\\n    \\n    \\\\ Recursively scans directories with intelligent filtering\\\\n- **Binary\\\n    \\ File Detection**:\\\\\\n    \\\\ Automatically skips binary files\\\\n- **Error Handling**:\\\n    \\ Gracefully handles permission\\\\\\n    \\\\ errors and provides helpful messages\\\\\\\n    n- **Multiple Output Formats**: Supports\\\\\\n    \\\\ Markdown, JSON, and YAML formats\\\\\\\n    n- **Flexible Output**: Write to stdout or\\\\\\n    \\\\ save to a file\\\\n- **Recent\\\n    \\ Changes Filter**: Give the files which are updated\\\\\\n    \\\\ in last 7days with\\\n    \\ the time when it was recently modified.\\\\n\\\\n## Installation\\\\n\\\\\\n    \\\\n###\\\n    \\ Prerequisites\\\\n\\\\n- Python 3.9 or higher\\\\n- Git (for git repository analysis)\\\\\\\n    n\\\\\\n    \\\\n### For End Users\\\\n\\\\n```bash\\\\n# Clone and install\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    n\\\\\\n    cd Repo-Contextor\\\\npip install -e .\\\\n```\\\\n\\\\n### For Contributors\\\n    \\ & Local Development\\\\n\\\\\\n    \\\\n```bash\\\\n# Clone the repository\\\\ngit clone\\\n    \\ https://github.com/yourusername/Repo-Contextor.git\\\\n\\\\\\n    cd Repo-Contextor\\\\\\\n    n\\\\n# Create virtual environment\\\\npython -m venv .venv\\\\nsource\\\\\\n    \\\\ .venv/bin/activate\\\n    \\  # On Windows: .venv\\\\\\\\Scripts\\\\\\\\activate\\\\n\\\\n# Install in development\\\\\\n\\\n    \\    \\\\ mode\\\\npip install -e .\\\\n```\\\\n\\\\n## Usage\\\\n\\\\n### Basic Examples\\\\\\\n    n\\\\n```bash\\\\n#\\\\\\n    \\\\ Package current directory to terminal\\\\nrepo-contextor\\\n    \\ .\\\\n\\\\n# Package a specific\\\\\\n    \\\\ directory\\\\nrepo-contextor /path/to/your/project\\\\\\\n    n\\\\n# Save output to a file\\\\n\\\\\\n    repo-contextor . -o my-project-context.md\\\\\\\n    n\\\\n# Generate JSON format\\\\nrepo-contextor\\\\\\n    \\\\ . -f json -o context.json\\\\\\\n    n\\\\n# Generate YAML format\\\\nrepo-contextor . -f yaml\\\\\\n    \\\\ -o context.yaml\\\\\\\n    n\\\\n# Include only files modified in the last 7 days\\\\nrepo-contextor\\\\\\n    \\\\\\\n    \\ . --recent\\\\n\\\\n# Combine with output file\\\\nrepo-contextor . --recent -o recent-changes.md\\\\\\\n    n\\\\\\n    ```\\\\n\\\\n### Command Line Options\\\\n\\\\n| Option | Short | Description\\\n    \\ | Example |\\\\n\\\\\\n    |--------|-------|-------------|---------|\\\\n| `path`\\\n    \\ | - | Repository path to\\\\\\n    \\\\ analyze (default: current directory) | `repo-contextor\\\n    \\ /path/to/project` |\\\\n\\\\\\n    | `--output` | `-o` | Output file path (default:\\\n    \\ stdout) | `-o context.md` |\\\\n\\\\\\n    | `--format` | `-f` | Output format: text,\\\n    \\ json, yaml (default: text) | `-f json`\\\\\\n    \\\\ |\\\\n| `--help` | `-h` | Show\\\n    \\ help message | `-h` |\\\\n| `--recent`  | `-r`  | Include\\\\\\n    \\\\ only files\\\n    \\ modified in the last 7 days    | `repo-contextor . -r -o recent.md`\\\\\\n    \\\\\\\n    \\ |\\\\n\\\\n### Advanced Examples\\\\n\\\\n```bash\\\\n# Analyze different repository\\\\\\\n    nrepo-contextor\\\\\\n    \\\\ /path/to/other/project -o other-project.md\\\\n\\\\n# Generate\\\n    \\ JSON for API consumption\\\\n\\\\\\n    repo-contextor . -f json -o api-context.json\\\\\\\n    n\\\\n# Create YAML configuration\\\\n\\\\\\n    repo-contextor . -f yaml -o project-config.yaml\\\\\\\n    n\\\\n# Generate files which are\\\\\\n    \\\\ changed recently in 7 days\\\\nrepo-contextor\\\n    \\ . -r --output recent-changes.txt\\\\n\\\\\\n    \\\\n```\\\\n## Configuration via TOML\\\\\\\n    n\\\\nRepo-Contextor supports configuration through\\\\\\n    \\\\ a `.repo-contextor.toml`\\\n    \\ file in the current working directory.  \\\\nThis file\\\\\\n    \\\\ allows you to\\\n    \\ avoid typing the same CLI arguments every time.\\\\n\\\\nExample `.repo-contextor.toml`:\\\\\\\n    n\\\\\\n    \\\\n```toml\\\\n# Output file to write results\\\\noutput = \\\\\\\"context.yaml\\\\\\\n    \\\"\\\\n\\\\n# Output\\\\\\n    \\\\ format: text, json, or yaml\\\\nformat = \\\\\\\"yaml\\\\\\\"\\\n    \\\\n\\\\n# Limit to files modified\\\\\\n    \\\\ in the last 7 days\\\\nrecent = true\\\\\\\n    n\\\\n# Repository path to analyze (default =\\\\\\n    \\\\ current directory)\\\\npath\\\n    \\ = \\\\\\\".\\\\\\\"\\\\n```\\\\n### Rules\\\\n- If the `.repo-contextor.toml`\\\\\\n    \\\\ file\\\n    \\ is **missing**, the tool falls back to defaults.  \\\\n- If the file is **present\\\\\\\n    \\n    \\\\ but invalid TOML**, the tool prints a clear error message and exits with\\\n    \\ status\\\\\\n    \\\\ code 1.  \\\\n- **Unknown keys** in the TOML file are ignored\\\n    \\ (safe for future\\\\\\n    \\\\ extensions).  \\\\n- **Precedence** of settings is:\\\\\\\n    n  1. Command-line arguments\\\\\\n    \\\\ (highest priority)  \\\\n  2. Values from\\\n    \\ `.repo-contextor.toml`  \\\\n  3. Built-in\\\\\\n    \\\\ defaults (lowest priority)\\\\\\\n    n     \\\\n## Output Format\\\\n\\\\nThe tool generates a\\\\\\n    \\\\ structured text\\\n    \\ file with the following sections:\\\\n\\\\n### 1. Repository Context\\\\\\n    \\\\ Header\\\\\\\n    nProject path and identification\\\\n\\\\n### 2. Git Repository Information\\\\n\\\\\\n\\\n    \\    - Current branch\\\\n- Latest commit SHA\\\\n- Last commit author\\\\n- Last commit\\\n    \\ date\\\\n\\\\\\n    \\\\n### 3. Summary Statistics\\\\n- Total number of files processed\\\\\\\n    n- Total lines\\\\\\n    \\\\ of code\\\\n\\\\n### 4. Directory Structure\\\\nClean tree\\\n    \\ visualization showing project\\\\\\n    \\\\ organization\\\\n\\\\n### 5. Recent Changes\\\n    \\ (if `--recent` is used)\\\\n\\\\n- Lists files\\\\\\n    \\\\ modified in the last 7\\\n    \\ days.\\\\n- Shows relative file paths along with how long\\\\\\n    \\\\ ago each file\\\n    \\ was modified\\\\n- Helps focus on recently updated parts of the project.\\\\n\\\\\\n\\\n    \\    - Can be combined with `--output` or `--format` to save or change the output\\\n    \\ type.\\\\n\\\\\\n    \\\\n\\\\n### 5. File Contents\\\\nEach file's content with:\\\\n- Clear\\\n    \\ file path headers\\\\n\\\\\\n    - Appropriate syntax highlighting language tags\\\\\\\n    n- Complete file contents\\\\n\\\\n\\\\\\n    ## Example Output\\\\n\\\\nWhen you run `repo-contextor\\\n    \\ .`, the output looks like this:\\\\n\\\\\\n    \\\\n````markdown\\\\n# Repository Context:\\\n    \\ /path/to/your/project\\\\n\\\\n## Git Repository\\\\\\n    \\\\ Information\\\\n- **Branch**:\\\n    \\ main\\\\n- **Commit**: a1b2c3d4e5f6789...\\\\n- **Author**:\\\\\\n    \\\\ John Doe <john@example.com>\\\\\\\n    n- **Date**: Fri Sep 12 14:30:15 2025\\\\n\\\\n## Summary\\\\n\\\\\\n    - **Total Files**:\\\n    \\ 15\\\\n- **Total Lines**: 1,247\\\\n\\\\n## Directory Structure\\\\n```\\\\n\\\\\\n    ├──\\\n    \\ src/\\\\n│   ├── main.py\\\\n│   └── utils.py\\\\n├── tests/\\\\n│   └── test_main.py\\\\\\\n    n\\\\\\n    ├── README.md\\\\n└── requirements.txt\\\\n```\\\\n## Recent Changes\\\\n- src/main.py\\\n    \\ (modified\\\\\\n    \\\\ 2 days ago)\\\\n- src/utils/helpers.py (modified 5 days ago)\\\\\\\n    n\\\\n## File Contents\\\\n\\\\\\n    \\\\n### src/main.py\\\\n\\\\n```python\\\\ndef main():\\\\\\\n    n    print(\\\\\\\"Hello, World!\\\\\\\")\\\\n\\\\n\\\\\\n    if __name__ == \\\\\\\"__main__\\\\\\\"\\\n    :\\\\n    main()\\\\n```\\\\n\\\\n### README.md\\\\n\\\\n```markdown\\\\n\\\\\\n    # My Project\\\\\\\n    nThis is a sample project.\\\\n```\\\\n\\\\n## Summary\\\\n- Total files: 15\\\\n\\\\\\n  \\\n    \\  - Total lines: 1,247\\\\n````\\\\n\\\\n## What Files Are Included\\\\n\\\\nThe tool includes\\\\\\\n    \\n    \\\\ most text files but automatically excludes:\\\\n\\\\n### Excluded Directories\\\\\\\n    n- `.git`,\\\\\\n    \\\\ `.svn`, `.hg` (version control)\\\\n- `__pycache__`, `.pytest_cache`\\\n    \\ (Python cache)\\\\n\\\\\\n    - `node_modules`, `.venv`, `venv` (dependencies/environments)\\\\\\\n    n- `.vscode`, `.idea`\\\\\\n    \\\\ (IDE directories)\\\\n- `build`, `dist`, `target`\\\n    \\ (build directories)\\\\n\\\\n### File\\\\\\n    \\\\ Handling Rules\\\\n- **Text files**:\\\n    \\ All readable text files with common extensions\\\\n\\\\\\n    - **Binary files**:\\\n    \\ Automatically detected and skipped\\\\n- **Permission errors**:\\\\\\n    \\\\ Skipped\\\n    \\ with graceful handling\\\\n- **Configuration files**: Includes pyproject.toml,\\\\\\\n    \\n    \\\\ package.json, etc.\\\\n\\\\n### Included File Types\\\\n- Source code: `.py`,\\\n    \\ `.js`,\\\\\\n    \\\\ `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\\\n- Web files:\\\n    \\ `.html`, `.css`,\\\\\\n    \\\\ `.scss`, `.vue`, `.jsx`, etc.\\\\n- Documentation:\\\n    \\ `.md`, `.txt`, `.rst`\\\\n- Configuration:\\\\\\n    \\\\ `.json`, `.yaml`, `.toml`,\\\n    \\ `.ini`, `.cfg`\\\\n- Scripts: `.sh`, `.bash`, `.zsh`\\\\n\\\\\\n    \\\\n## Error Handling\\\\\\\n    n\\\\nThe tool handles errors gracefully:\\\\n\\\\n| Error Type | Behavior\\\\\\n    \\\\\\\n    \\ |\\\\n|------------|----------|\\\\n| **Permission errors** | Skipped with warning\\\\\\\n    \\n    \\\\ |\\\\n| **Binary files** | Automatically detected and skipped |\\\\n| **Invalid\\\n    \\ paths**\\\\\\n    \\\\ | Clear error messages |\\\\n| **Non-git repositories** | Works\\\n    \\ fine, shows \\\\\\\"\\\\\\n    Not a git repository\\\\\\\" |\\\\n| **Unreadable files**\\\n    \\ | Marked as \\\\\\\"[Binary or unreadable\\\\\\n    \\\\ file]\\\\\\\" |\\\\n\\\\n## Development\\\\\\\n    n\\\\n### Project Structure\\\\n\\\\n```text\\\\nRepo-Contextor/\\\\n\\\\\\n    ├── src/rcpack/\\\n    \\              # Main package\\\\n│   ├── __init__.py         # Package\\\\\\n    \\\\\\\n    \\ initialization\\\\n│   ├── cli.py              # Command-line interface\\\\n│  \\\n    \\ ├──\\\\\\n    \\\\ discover.py         # File discovery logic\\\\n│   ├── gitinfo.py\\\n    \\          # Git\\\\\\n    \\\\ repository analysis\\\\n│   ├── treeview.py         #\\\n    \\ Directory tree generation\\\\n\\\\\\n    │   ├── packager.py         # Main orchestration\\\\\\\n    n│   ├── io_utils.py        \\\\\\n    \\\\ # File I/O utilities\\\\n│   └── renderer/\\\n    \\           # Output formatters\\\\n│   \\\\\\n    \\\\    ├── markdown.py     # Markdown\\\n    \\ renderer\\\\n│       └── jsonyaml.py     # JSON/YAML\\\\\\n    \\\\ renderers\\\\n├──\\\n    \\ pyproject.toml          # Project configuration\\\\n├── LICENSE\\\\\\n    \\\\    \\\n    \\             # MIT License\\\\n└── README.md              # This documentation\\\\\\\n    n\\\\\\n    ```\\\\n\\\\n### Running Tests\\\\n\\\\n```bash\\\\n# Test on current repository\\\\\\\n    nrepo-contextor\\\\\\n    \\\\ . -o test-output.md\\\\n\\\\n# Test different formats\\\\\\\n    nrepo-contextor . -f json |\\\\\\n    \\\\ head -20\\\\nrepo-contextor . -f yaml | head\\\n    \\ -20\\\\n\\\\n# Test specific directory\\\\n\\\\\\n    repo-contextor src/ -o src-only.md\\\\\\\n    n```\\\\n\\\\n### Contributing\\\\n\\\\n1. **Fork the repository**\\\\n\\\\\\n    2. **Clone\\\n    \\ your fork:**\\\\n   ```bash\\\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    n\\\\\\n    \\\\   cd Repo-Contextor\\\\n   ```\\\\n3. **Install for development:**\\\\n\\\n    \\   ```bash\\\\n \\\\\\n    \\\\  python -m venv .venv\\\\n   source .venv/bin/activate\\\\\\\n    n   pip install -e .\\\\n \\\\\\n    \\\\  ```\\\\n4. **Make your changes and test:**\\\\\\\n    n   ```bash\\\\n   repo-contextor . -o\\\\\\n    \\\\ test.md\\\\n   ```\\\\n5. **Submit\\\n    \\ a pull request**\\\\n\\\\n### Development Workflow\\\\n\\\\n\\\\\\n    ```bash\\\\n# 1. Setup\\\n    \\ development environment\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    n\\\\\\n    cd Repo-Contextor\\\\npython -m venv .venv\\\\nsource .venv/bin/activate\\\\\\\n    npip install\\\\\\n    \\\\ -e .\\\\n\\\\n# 2. Make changes to the code\\\\n# Edit files\\\n    \\ in src/rcpack/\\\\n\\\\n# 3. Test\\\\\\n    \\\\ your changes\\\\nrepo-contextor . -o test-output.md\\\\\\\n    n\\\\n# 4. Test different formats\\\\n\\\\\\n    repo-contextor . -f json -o test.json\\\\\\\n    nrepo-contextor . -f yaml -o test.yaml\\\\n\\\\\\n    \\\\n# 5. Commit and push changes\\\\\\\n    ngit add .\\\\ngit commit -m \\\\\\\"Add new feature\\\\\\\"\\\\n\\\\\\n    git push origin feature-branch\\\\\\\n    n```\\\\n\\\\n## License\\\\n\\\\nThis project is licensed\\\\\\n    \\\\ under the MIT License.\\\n    \\ See the [LICENSE](LICENSE) file for details.\\\\n\\\\n## Why\\\\\\n    \\\\ Repo-Contextor?\\\\\\\n    n\\\\nThe name \\\\\\\"Repo-Contextor\\\\\\\" combines \\\\\\\"Repository\\\\\\\" + \\\\\\\"\\\\\\n   \\\n    \\ Context\\\\\\\" + \\\\\\\"or\\\\\\\", representing the tool's purpose of providing rich\\\n    \\ context\\\\\\n    \\\\ about code repositories in a format that's perfect for LLM\\\n    \\ interactions.\\\\n\\\\n\\\\\\n    ### Use Cases\\\\n\\\\n- **AI Assistance**: Get better\\\n    \\ help from ChatGPT, Claude, or\\\\\\n    \\\\ GitHub Copilot\\\\n- **Code Reviews**:\\\n    \\ Share complete project context with team\\\\\\n    \\\\ members\\\\n- **Documentation**:\\\n    \\ Create comprehensive project snapshots\\\\n- **Onboarding**:\\\\\\n    \\\\ Help new\\\n    \\ team members understand project structure\\\\n- **Project Analysis**:\\\\\\n    \\\\\\\n    \\ Understand repository structure and dependencies\\\\n\\\\n### Perfect for LLMs\\\\\\\n    n\\\\n\\\\\\n    The output format is specifically designed to work well with Large\\\n    \\ Language Models:\\\\n\\\\\\n    - Clear section headers for easy parsing\\\\n- Syntax\\\n    \\ highlighting markers for code\\\\\\n    \\\\ blocks\\\\n- Structured metadata (git\\\n    \\ info, file locations)\\\\n- Complete project\\\\\\n    \\\\ context in a single file\\\\\\\n    n- Multiple output formats (Markdown, JSON, YAML)\\\\n\\\\\\n    - Optimized for token\\\n    \\ efficiency\\\\n\\\"\\n  pyproject.toml: \\\"[build-system]\\\\nrequires = [\\\\\\\"setuptools>=68\\\\\\\n    \\\", \\\\\\\"wheel\\\\\\\"]\\\\nbuild-backend\\\\\\n    \\\\ = \\\\\\\"setuptools.build_meta\\\\\\\"\\\\\\\n    n\\\\n[project]\\\\nname = \\\\\\\"rcpack\\\\\\\"\\\\nversion = \\\\\\\"0.1.0\\\\\\\"\\\\\\n    \\\\ndescription\\\n    \\ = \\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\"\\\\nreadme = \\\\\\\"README.md\\\\\\\n    \\\"\\\\\\n    \\\\nrequires-python = \\\\\\\">=3.9\\\\\\\"\\\\nlicense = { text = \\\\\\\"MIT\\\\\\\"\\\n    \\ }\\\\ndependencies = [\\\\n\\\\\\n    \\\\    \\\\\\\"PyYAML>=6.0\\\\\\\"\\\\n]\\\\n\\\\n[project.scripts]\\\\\\\n    nrepo-contextor = \\\\\\\"rcpack.cli:main\\\\\\\"\\\\\\n    \\\\n\\\"\\n  src/rcpack/__init__.py:\\\n    \\ '\\\"\\\"\\\"Repository Context Packager - CLI tool for creating\\n    LLM-optimized\\\n    \\ repository context.\\\"\\\"\\\"\\n\\n\\n    __version__ = \\\"0.1.0\\\"\\n\\n    __author__\\\n    \\ = \\\"Abhinav\\\"\\n\\n    __description__ = \\\"Repository Context Packager CLI for\\\n    \\ LLMs\\\"'\\n  src/rcpack/__main__.py: \\\"#!/usr/bin/env python3\\\\n\\\\\\\"\\\\\\\"\\\\\\\"Module\\\n    \\ entry point to enable\\\\\\n    \\\\ `python -m rcpack`.\\\\n\\\\nThis simply delegates\\\n    \\ to the CLI's main() function.\\\\n\\\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom .cli import main\\\\\\\n    n\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\\n\\\\\\n    \\\\n\\\\n\\\"\\n  src/rcpack/cli.py:\\\n    \\ \\\"#!/usr/bin/env python3\\\\n\\\\\\\"\\\\\\\"\\\\\\\"CLI for Repository Context Packager.\\\\\\\n    \\\"\\\\\\n    \\\\\\\"\\\\\\\"\\\\n\\\\nfrom .config_loader import load_config\\\\n\\\\nimport argparse\\\\\\\n    nimport sys\\\\n\\\\\\n    from pathlib import Path\\\\nfrom .gitinfo import get_git_info\\\\\\\n    nfrom .discover import\\\\\\n    \\\\ discover_files\\\\nfrom .treeview import create_tree_view\\\\\\\n    nfrom .renderer.markdown\\\\\\n    \\\\ import render_markdown\\\\nfrom .renderer.jsonyaml\\\n    \\ import render_json, render_yaml\\\\n\\\\\\n    from .io_utils import write_output\\\\\\\n    nfrom datetime import datetime, timedelta\\\\n\\\\\\n    \\\\n\\\\ndef log_verbose(message:\\\n    \\ str, verbose: bool) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Log a message\\\\\\n    \\\\ to stderr\\\n    \\ if verbose mode is enabled.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if verbose:\\\\n        print(message,\\\\\\\n    \\n    \\\\ file=sys.stderr)\\\\n\\\\n\\\\ndef get_rendered_content(format_type: str, repo_path:\\\\\\\n    \\n    \\\\ str, repo_info: dict, tree_text: str, \\\\n                        files_data:\\\\\\\n    \\n    \\\\ dict, total_files: int, total_lines: int, \\\\n                       \\\n    \\ recent_files_info:\\\\\\n    \\\\ dict, file_sizes: dict) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\n    \\\"Get rendered content based on the\\\\\\n    \\\\ specified format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\\\\n    n    if format_type == \\\\\\\"json\\\\\\\":\\\\n        return render_json(\\\\n\\\\\\n    \\\\\\\n    \\            repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\\\\\n    \\n    \\\\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n       \\\n    \\     file_sizes=file_sizes\\\\n\\\\\\n    \\\\        )\\\\n    elif format_type == \\\\\\\n    \\\"yaml\\\\\\\":\\\\n        return render_yaml(\\\\n \\\\\\n    \\\\           repo_path, repo_info,\\\n    \\ tree_text, \\\\n            files_data, total_files,\\\\\\n    \\\\ total_lines,\\\\\\\n    n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\\\\n    n\\\\\\n    \\\\        )\\\\n    else:  # text/markdown\\\\n        return render_markdown(\\\\\\\n    n    \\\\\\n    \\\\        repo_path, repo_info, tree_text, \\\\n            files_data,\\\n    \\ total_files,\\\\\\n    \\\\ total_lines,\\\\n            recent_files=recent_files_info,\\\\\\\n    n            file_sizes=file_sizes\\\\n\\\\\\n    \\\\        )\\\\n\\\\n\\\\ndef process_file(file_path:\\\n    \\ Path, repo_path: Path, verbose: bool)\\\\\\n    \\\\ -> tuple[str, str, str]:\\\\n\\\n    \\    \\\\\\\"\\\\\\\"\\\\\\\"Process a single file and return its data.\\\\n\\\\\\n    \\\\    \\\\\\\n    n    Returns:\\\\n        tuple: (relative_path_str, content, file_size)\\\\n\\\\\\n\\\n    \\    \\\\    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    relative_path = file_path.relative_to(repo_path)\\\\\\\n    n    relative_path_str\\\\\\n    \\\\ = str(relative_path)\\\\n    \\\\n    log_verbose(f\\\\\\\n    \\\"Reading file: {relative_path}\\\\\\\"\\\\\\n    , verbose)\\\\n    file_size = file_path.stat().st_size\\\\\\\n    n    \\\\n    try:\\\\n       \\\\\\n    \\\\ with open(file_path, 'r', encoding='utf-8')\\\n    \\ as f:\\\\n            content = f.read()\\\\n\\\\\\n    \\\\        return relative_path_str,\\\n    \\ content, str(file_size)\\\\n    except (UnicodeDecodeError,\\\\\\n    \\\\ PermissionError):\\\\\\\n    n        log_verbose(f\\\\\\\"Skipping binary/unreadable file: {relative_path}\\\\\\\"\\\n    \\\\\\n    , verbose)\\\\n        file_size = file_path.stat().st_size if file_path.exists()\\\\\\\n    \\n    \\\\ else 0\\\\n        content = f\\\\\\\"[Binary or unreadable file: {file_path.name}]\\\\\\\n    \\\"\\\\\\n    \\\\n        return relative_path_str, content, str(file_size)\\\\n    except\\\n    \\ Exception:\\\\n\\\\\\n    \\\\        log_verbose(f\\\\\\\"Error reading file: {relative_path}\\\\\\\n    \\\", verbose)\\\\n    \\\\\\n    \\\\    raise  # Re-raise to handle in calling code\\\\\\\n    n\\\\n\\\\ndef handle_output(content:\\\\\\n    \\\\ str, output_path: str = None) -> None:\\\\\\\n    n    \\\\\\\"\\\\\\\"\\\\\\\"Handle output to either file\\\\\\n    \\\\ or stdout.\\\\\\\"\\\\\\\"\\\\\\\"\\\n    \\\\n    if output_path:\\\\n        # Write to file\\\\n        write_output(output_path,\\\\\\\n    \\n    \\\\ content)\\\\n        print(f\\\\\\\"Context package created: {output_path}\\\\\\\n    \\\")\\\\n    else:\\\\n\\\\\\n    \\\\        # Output to stdout\\\\n        print(content)\\\\\\\n    n\\\\n\\\\ndef main():\\\\n    parser\\\\\\n    \\\\ = argparse.ArgumentParser(\\\\n      \\\n    \\  description=\\\\\\\"Package repository content\\\\\\n    \\\\ for LLM context\\\\\\\"\\\\\\\n    n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"path\\\\\\\", \\\\n   \\\\\\n    \\\\   \\\n    \\  nargs=\\\\\\\"?\\\\\\\", \\\\n        default=\\\\\\\".\\\\\\\", \\\\n        help=\\\\\\\"Repository\\\n    \\ path (default:\\\\\\n    \\\\ current directory)\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\\\\n    n        \\\\\\\"-o\\\\\\\", \\\\\\\"--output\\\\\\\"\\\\\\n    , \\\\n        help=\\\\\\\"Output file\\\n    \\ path (default: stdout)\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n\\\\\\n    \\\\ \\\n    \\       \\\\\\\"-f\\\\\\\", \\\\\\\"--format\\\\\\\", \\\\n        choices=[\\\\\\\"text\\\\\\\", \\\\\\\"json\\\\\\\n    \\\", \\\\\\\"yaml\\\\\\\"\\\\\\n    ], \\\\n        default=\\\\\\\"text\\\\\\\",\\\\n        help=\\\\\\\"\\\n    Output format (default: text)\\\\\\\"\\\\\\n    \\\\n    )\\\\n\\\\n    \\\\\\\"\\\\\\\"\\\\\\\" This will\\\n    \\ read -r from the console and able to search it\\\\\\n    \\\\ with this\\\\\\\"\\\\\\\"\\\\\\\n    \\\"\\\\n    parser.add_argument(\\\\n    \\\\\\\"-r\\\\\\\", \\\\\\\"--recent\\\\\\\",\\\\n    action=\\\\\\\n    \\\"\\\\\\n    store_true\\\\\\\",\\\\n    help=\\\\\\\"Include only files modified in the last\\\n    \\ 7 days\\\\\\\"\\\\n \\\\\\n    \\\\   )\\\\n    parser.add_argument(\\\\n        \\\\\\\"-v\\\\\\\"\\\n    , \\\\\\\"--verbose\\\\\\\",\\\\n        action=\\\\\\\"\\\\\\n    store_true\\\\\\\",\\\\n        help=\\\\\\\n    \\\"Print detailed progress information to stderr\\\\\\\"\\\\n\\\\\\n    \\\\    )\\\\n    \\\\\\\n    n    args = parser.parse_args()\\\\n    \\\\n    try:\\\\n        repo_path\\\\\\n    \\\\\\\n    \\ = Path(args.path).resolve()\\\\n        if not repo_path.exists():\\\\n        \\\n    \\  \\\\\\n    \\\\  print(f\\\\\\\"Error: Path {repo_path} does not exist\\\\\\\", file=sys.stderr)\\\\\\\n    n     \\\\\\n    \\\\       sys.exit(1)\\\\n            \\\\n        # Get repository information\\\\\\\n    n    \\\\\\n    \\\\    log_verbose(f\\\\\\\"Analyzing repository: {repo_path}\\\\\\\", args.verbose)\\\\\\\n    n     \\\\\\n    \\\\   repo_info = get_git_info(repo_path)\\\\n        \\\\n        #\\\n    \\ Discover files\\\\n\\\\\\n    \\\\        log_verbose(f\\\\\\\"Discovering files in: {repo_path}\\\\\\\n    \\\", args.verbose)\\\\n \\\\\\n    \\\\       discovered_files = discover_files([repo_path],\\\n    \\ repo_path, [], [])\\\\n  \\\\\\n    \\\\      log_verbose(f\\\\\\\"Found {len(discovered_files)}\\\n    \\ files\\\\\\\", args.verbose)\\\\n \\\\\\n    \\\\       \\\\n        # will check the file\\\n    \\ in last 7 days\\\\n        recent_files_info\\\\\\n    \\\\ = {}\\\\n        if args.recent:\\\\\\\n    n            seven_days_ago = datetime.now() -\\\\\\n    \\\\ timedelta(days=7)\\\\n\\\n    \\            recent_files = []\\\\n            for f in discovered_files:\\\\n\\\\\\n\\\n    \\    \\\\                try:\\\\n                    mtime = datetime.fromtimestamp(f.stat().st_mtime)\\\\\\\n    n\\\\\\n    \\\\                    if mtime >= seven_days_ago:\\\\n                \\\n    \\        recent_files.append(f)\\\\n\\\\\\n    \\\\                        recent_files_info[str(f.relative_to(repo_path))]\\\n    \\ = human_readable_age(mtime)\\\\\\n    \\\\     \\\\n                except Exception:\\\\\\\n    n                    continue\\\\n    \\\\\\n    \\\\        discovered_files = recent_files\\\\\\\n    n        \\\\n        # Read file contents\\\\n\\\\\\n    \\\\        files_data = {}\\\\\\\n    n        file_sizes = {}\\\\n        for file_path in discovered_files:\\\\n\\\\\\n \\\n    \\   \\\\            try:\\\\n                relative_path_str, content, file_size\\\n    \\ = process_file(file_path,\\\\\\n    \\\\ repo_path, args.verbose)\\\\n            \\\n    \\    files_data[relative_path_str] = content\\\\n\\\\\\n    \\\\                file_sizes[relative_path_str]\\\n    \\ = file_size\\\\n            except\\\\\\n    \\\\ Exception:\\\\n                continue\\\\\\\n    n        \\\\n        # Create tree view\\\\n\\\\\\n    \\\\        log_verbose(\\\\\\\"Generating\\\n    \\ directory tree\\\\\\\", args.verbose)\\\\n        tree_text\\\\\\n    \\\\ = create_tree_view(repo_path,\\\n    \\ files_data)\\\\n        \\\\n        # Count totals\\\\n\\\\\\n    \\\\        total_files\\\n    \\ = len(files_data)\\\\n        total_lines = sum(len(content.splitlines())\\\\\\n\\\n    \\    \\\\ for _, content in files_data.items())\\\\n        \\\\n        # Render based\\\n    \\ on format\\\\n\\\\\\n    \\\\        log_verbose(f\\\\\\\"Rendering output in {args.format}\\\n    \\ format\\\\\\\", args.verbose)\\\\n\\\\\\n    \\\\        content = get_rendered_content(\\\\\\\n    n            args.format, str(repo_path),\\\\\\n    \\\\ repo_info, tree_text,\\\\n \\\n    \\           files_data, total_files, total_lines,\\\\n \\\\\\n    \\\\           recent_files_info\\\n    \\ if args.recent else {},\\\\n            file_sizes\\\\n\\\\\\n    \\\\        )\\\\n  \\\n    \\      \\\\n        handle_output(content, args.output)\\\\n        \\\\n\\\\\\n    \\\\\\\n    \\    except Exception as e:\\\\n        print(f\\\\\\\"Error: {e}\\\\\\\", file=sys.stderr)\\\\\\\n    n\\\\\\n    \\\\        sys.exit(1)\\\\n\\\\n# this will convert age and give us the difference\\\\\\\n    ndef\\\\\\n    \\\\ human_readable_age(mtime: datetime) -> str:\\\\n    delta = datetime.now()\\\n    \\ - mtime\\\\n\\\\\\n    \\\\    days = delta.days\\\\n    seconds = delta.seconds\\\\n \\\n    \\   if days > 0:\\\\n      \\\\\\n    \\\\  return f\\\\\\\"{days} day{'s' if days != 1 else\\\n    \\ ''} ago\\\\\\\"\\\\n    elif seconds >= 3600:\\\\n\\\\\\n    \\\\        hours = seconds\\\n    \\ // 3600\\\\n        return f\\\\\\\"{hours} hour{'s' if hours\\\\\\n    \\\\ != 1 else\\\n    \\ ''} ago\\\\\\\"\\\\n    elif seconds >= 60:\\\\n        minutes = seconds // 60\\\\n\\\\\\\n    \\n    \\\\        return f\\\\\\\"{minutes} minute{'s' if minutes != 1 else ''} ago\\\\\\\n    \\\"\\\\n    else:\\\\n\\\\\\n    \\\\        return \\\\\\\"just now\\\\\\\"\\\\n\\\\nif __name__ ==\\\n    \\ \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\\n\\\"\\n  src/rcpack/config_loader.py: \\\"# src/rcpack/config_loader.py\\\\\\\n    n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nTOML config\\\\\\n    \\\\ loader for Repo-Contextor.\\\\n\\\\nRules:\\\\\\\n    n- Look for .repo-contextor.toml in the\\\\\\n    \\\\ CURRENT directory\\\\n- If missing:\\\n    \\ ignore\\\\n- If present but invalid: print a clear\\\\\\n    \\\\ error and exit(1)\\\\\\\n    n- Only recognized keys are applied; unknown keys ignored\\\\n\\\\\\n    - Precedence:\\\n    \\ CLI > TOML > DEFAULTS\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nfrom __future__ import annotations\\\\\\\n    n\\\\\\n    import os, sys\\\\nfrom typing import Dict, Iterable, Any\\\\n\\\\ntry:\\\\n\\\n    \\    import tomllib\\\\n\\\\\\n    \\\\    _loads = tomllib.loads\\\\nexcept ModuleNotFoundError:\\\\\\\n    n    try:\\\\n        import\\\\\\n    \\\\ tomli\\\\n        _loads = tomli.loads\\\\n \\\n    \\   except ModuleNotFoundError:\\\\n     \\\\\\n    \\\\   _loads = None\\\\n\\\\ndef _need_toml():\\\\\\\n    n    if _loads is None:\\\\n        print(\\\\\\\"\\\\\\n    Error: TOML parser not available.\\\n    \\ Use Python 3.11+ or `pip install tomli`.\\\\\\\",\\\\\\n    \\\\ file=sys.stderr)\\\\n\\\n    \\        sys.exit(1)\\\\n\\\\ndef _load_toml(dotfile: str) -> Dict[str,\\\\\\n    \\\\\\\n    \\ Any]:\\\\n    _need_toml()\\\\n    if not os.path.exists(dotfile):\\\\n        return\\\\\\\n    \\n    \\\\ {}\\\\n    try:\\\\n        with open(dotfile, \\\\\\\"rb\\\\\\\") as f:\\\\n     \\\n    \\       raw = f.read().decode(\\\\\\\"\\\\\\n    utf-8\\\\\\\", errors=\\\\\\\"strict\\\\\\\")\\\\\\\n    n        data = _loads(raw)\\\\n        return data if\\\\\\n    \\\\ isinstance(data,\\\n    \\ dict) else {}\\\\n    except Exception as e:\\\\n        print(f\\\\\\\"\\\\\\n    Error:\\\n    \\ failed to parse {dotfile} as TOML.\\\\\\\\n{e}\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\\\\n    n\\\\\\n    \\\\ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str,\\\n    \\ Any]:\\\\n\\\\\\n    \\\\    ks = set(known)\\\\n    return {k: v for k, v in d.items()\\\n    \\ if k in ks}\\\\n\\\\ndef\\\\\\n    \\\\ _merge(defaults: Dict[str, Any], filecfg: Dict[str,\\\n    \\ Any], clicfg: Dict[str,\\\\\\n    \\\\ Any], known: Iterable[str]) -> Dict[str, Any]:\\\\\\\n    n    ks = set(known)\\\\n    out:\\\\\\n    \\\\ Dict[str, Any] = {k: defaults.get(k)\\\n    \\ for k in ks}\\\\n    for src in (filecfg,\\\\\\n    \\\\ clicfg):\\\\n        for k,\\\n    \\ v in src.items():\\\\n            if k in ks and v is\\\\\\n    \\\\ not None:\\\\n \\\n    \\               out[k] = v\\\\n    return out\\\\n\\\\ndef load_config(*,\\\\\\n    \\\\\\\n    \\ dotfile: str = \\\\\\\".repo-contextor.toml\\\\\\\", defaults: Dict[str, Any] | None\\\n    \\ = None,\\\\\\n    \\\\ cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str]\\\n    \\ = ()) -> Dict[str,\\\\\\n    \\\\ Any]:\\\\n    defaults = defaults or {}\\\\n    cli_cfg\\\n    \\ = cli_cfg or {}\\\\n    known\\\\\\n    \\\\ = tuple(known_keys)\\\\n    filecfg = _filter_known(_load_toml(dotfile),\\\n    \\ known)\\\\n\\\\\\n    \\\\    return _merge(defaults, filecfg, cli_cfg, known)\\\\n\\\"\\\n    \\n  src/rcpack/discover.py: \\\"\\\\\\\"\\\\\\\"\\\\\\\"File discovery module for repository\\\n    \\ analysis.\\\\\\\"\\\\\\\"\\\\\\n    \\\\\\\"\\\\n\\\\nfrom pathlib import Path\\\\nfrom typing import\\\n    \\ List\\\\nimport fnmatch\\\\n\\\\n\\\\n\\\\\\n    def discover_files(\\\\n    inputs: List[Path],\\\\\\\n    n    root: Path,\\\\n    include_patterns:\\\\\\n    \\\\ List[str],\\\\n    exclude_patterns:\\\n    \\ List[str],\\\\n) -> List[Path]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Discover\\\\\\n    \\\\ relevant\\\n    \\ files.\\\\n\\\\n    - inputs: list of files/dirs to scan\\\\n    - root: common\\\\\\n\\\n    \\    \\\\ project root; patterns are matched against POSIX paths relative to root\\\\\\\n    n  \\\\\\n    \\\\  - include_patterns: glob patterns to include (if empty, use sensible\\\n    \\ defaults)\\\\n\\\\\\n    \\\\    - exclude_patterns: glob patterns to exclude\\\\n  \\\n    \\  Returns a list of absolute\\\\\\n    \\\\ Paths to files.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\\\\n    n    default_include_exts = {\\\\n        '.py',\\\\\\n    \\\\ '.js', '.ts', '.jsx',\\\n    \\ '.tsx', '.java', '.cpp', '.c', '.h',\\\\n        '.cs', '.php',\\\\\\n    \\\\ '.rb',\\\n    \\ '.go', '.rs', '.swift', '.kt', '.scala',\\\\n        '.html', '.css', '.scss',\\\\\\\n    \\n    \\\\ '.sass', '.less', '.vue', '.svelte',\\\\n        '.md', '.txt', '.rst',\\\n    \\ '.yaml',\\\\\\n    \\\\ '.yml', '.json', '.toml', '.ini',\\\\n        '.cfg', '.conf',\\\n    \\ '.xml', '.sql',\\\\\\n    \\\\ '.sh', '.bash', '.zsh', '.fish',\\\\n    }\\\\n\\\\n   \\\n    \\ always_include_names = {\\\\n  \\\\\\n    \\\\      'README', 'LICENSE', 'CHANGELOG',\\\n    \\ 'CONTRIBUTING', 'Makefile',\\\\n       \\\\\\n    \\\\ 'requirements.txt', 'package.json',\\\n    \\ 'Cargo.toml', 'pyproject.toml',\\\\n      \\\\\\n    \\\\  'setup.py', 'setup.cfg',\\\n    \\ 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\\\n\\\\\\n    \\\\    }\\\\\\\n    n\\\\n    skip_dir_names = {\\\\n        '.git', '.svn', '.hg', '__pycache__',\\\\\\n\\\n    \\    \\\\ '.pytest_cache',\\\\n        'node_modules', '.venv', 'venv', 'env', '.env',\\\\\\\n    n\\\\\\n    \\\\        'build', 'dist', 'target', 'out', '.next', '.nuxt',\\\\n    \\\n    \\    '.idea',\\\\\\n    \\\\ '.vscode', '.vs', 'coverage', '.coverage'\\\\n    }\\\\n\\\\\\\n    n    def matches_any(patterns:\\\\\\n    \\\\ List[str], rel_posix: str) -> bool:\\\\\\\n    n        return any(fnmatch.fnmatch(rel_posix,\\\\\\n    \\\\ pat) for pat in patterns)\\\\\\\n    n\\\\n    def should_take(file_path: Path) -> bool:\\\\n\\\\\\n    \\\\        rel_posix\\\n    \\ = file_path.relative_to(root).as_posix()\\\\n        if exclude_patterns\\\\\\n \\\n    \\   \\\\ and matches_any(exclude_patterns, rel_posix):\\\\n            return False\\\\\\\n    n  \\\\\\n    \\\\      if include_patterns:\\\\n            return matches_any(include_patterns,\\\\\\\n    \\n    \\\\ rel_posix)\\\\n        # default include logic\\\\n        return file_path.name\\\n    \\ in\\\\\\n    \\\\ always_include_names or file_path.suffix.lower() in default_include_exts\\\\\\\n    n\\\\n\\\\\\n    \\\\    discovered: list[Path] = []\\\\n    seen = set()\\\\n\\\\n    for\\\n    \\ item in inputs:\\\\n\\\\\\n    \\\\        p = item.resolve()\\\\n        if p.is_file():\\\\\\\n    n            # Skip if excluded\\\\\\n    \\\\ or in skipped directory\\\\n         \\\n    \\   if any(part in skip_dir_names for part\\\\\\n    \\\\ in p.parts):\\\\n         \\\n    \\       continue\\\\n            if should_take(p):\\\\n   \\\\\\n    \\\\            \\\n    \\ key = p.as_posix()\\\\n                if key not in seen:\\\\n      \\\\\\n    \\\\\\\n    \\              seen.add(key)\\\\n                    discovered.append(p)\\\\n   \\\n    \\  \\\\\\n    \\\\   elif p.is_dir():\\\\n            for child in p.rglob('*'):\\\\n \\\n    \\              \\\\\\n    \\\\ if not child.is_file():\\\\n                    continue\\\\\\\n    n                if any(part\\\\\\n    \\\\ in skip_dir_names for part in child.parts):\\\\\\\n    n                    continue\\\\n\\\\\\n    \\\\                if should_take(child):\\\\\\\n    n                    key = child.resolve().as_posix()\\\\n\\\\\\n    \\\\           \\\n    \\         if key not in seen:\\\\n                        seen.add(key)\\\\n\\\\\\n \\\n    \\   \\\\                        discovered.append(child.resolve())\\\\n\\\\n    return\\\n    \\ sorted(discovered)\\\"\\n  src/rcpack/gitinfo.py: \\\"from __future__ import annotations\\\\\\\n    n\\\\nimport subprocess\\\\n\\\\\\n    from pathlib import Path\\\\nfrom typing import\\\n    \\ Dict, Any\\\\n\\\\n\\\\ndef _git(cmd: list[str],\\\\\\n    \\\\ cwd: Path) -> str:\\\\n \\\n    \\   # Validate git commands to prevent injection\\\\n    allowed_commands\\\\\\n  \\\n    \\  \\\\ = {\\\\n        \\\\\\\"rev-parse\\\\\\\", \\\\\\\"show\\\\\\\", \\\\\\\"log\\\\\\\", \\\\\\\"status\\\\\\\n    \\\", \\\\\\\"branch\\\\\\\", \\\\\\\"config\\\\\\\"\\\\\\n    \\\\n    }\\\\n    if not cmd or cmd[0]\\\n    \\ not in allowed_commands:\\\\n        raise ValueError(f\\\\\\\"\\\\\\n    Git command\\\n    \\ not allowed: {cmd[0] if cmd else 'empty'}\\\\\\\")\\\\n    \\\\n    out = subprocess.check_output([\\\\\\\n    \\\"\\\\\\n    git\\\\\\\", *cmd], cwd=str(cwd), timeout=30)\\\\n    return out.decode(\\\\\\\n    \\\"utf-8\\\\\\\", errors=\\\\\\\"\\\\\\n    replace\\\\\\\").strip()\\\\n\\\\n\\\\ndef is_git_repo(path:\\\n    \\ Path) -> bool:\\\\n    try:\\\\n     \\\\\\n    \\\\   flag = _git([\\\\\\\"rev-parse\\\\\\\"\\\n    , \\\\\\\"--is-inside-work-tree\\\\\\\"], cwd=path)\\\\n      \\\\\\n    \\\\  return flag ==\\\n    \\ \\\\\\\"true\\\\\\\"\\\\n    except Exception:\\\\n        return False\\\\n\\\\n\\\\n\\\\\\n   \\\n    \\ def get_git_info(path: Path) -> Dict[str, Any]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Return\\\n    \\ info for\\\\\\n    \\\\ the current HEAD of a repo rooted at `path`.\\\\n    \\\\\\\"\\\\\\\n    \\\"\\\\\\\"\\\\n    try:\\\\n       \\\\\\n    \\\\ commit = _git([\\\\\\\"rev-parse\\\\\\\", \\\\\\\"HEAD\\\\\\\n    \\\"], cwd=path)\\\\n        branch = _git([\\\\\\\"\\\\\\n    rev-parse\\\\\\\", \\\\\\\"--abbrev-ref\\\\\\\n    \\\", \\\\\\\"HEAD\\\\\\\"], cwd=path)\\\\n        author = _git([\\\\\\\"\\\\\\n    show\\\\\\\", \\\\\\\n    \\\"-s\\\\\\\", \\\\\\\"--format=%an <%ae>\\\\\\\"], cwd=path)\\\\n        date = _git([\\\\\\\"show\\\\\\\n    \\\"\\\\\\n    , \\\\\\\"-s\\\\\\\", \\\\\\\"--date=local\\\\\\\", \\\\\\\"--format=%ad\\\\\\\"], cwd=path)\\\\\\\n    n        return {\\\\n \\\\\\n    \\\\           \\\\\\\"is_repo\\\\\\\": True,\\\\n          \\\n    \\  \\\\\\\"commit\\\\\\\": commit,\\\\n            \\\\\\\"\\\\\\n    branch\\\\\\\": branch,\\\\n  \\\n    \\          \\\\\\\"author\\\\\\\": author,\\\\n            \\\\\\\"date\\\\\\\": date,\\\\n\\\\\\n  \\\n    \\  \\\\            \\\\\\\"note\\\\\\\": None,\\\\n        }\\\\n    except Exception:\\\\n  \\\n    \\      # treat\\\\\\n    \\\\ as not a repo if anything fails\\\\n        return {\\\\\\\n    n            \\\\\\\"is_repo\\\\\\\":\\\\\\n    \\\\ False,\\\\n            \\\\\\\"commit\\\\\\\": None,\\\\\\\n    n            \\\\\\\"branch\\\\\\\": None,\\\\n     \\\\\\n    \\\\       \\\\\\\"author\\\\\\\": None,\\\\\\\n    n            \\\\\\\"date\\\\\\\": None,\\\\n            \\\\\\\"note\\\\\\\":\\\\\\n    \\\\ \\\\\\\"Not\\\n    \\ a git repository\\\\\\\",\\\\n        }\\\\n\\\"\\n  src/rcpack/io_utils.py: \\\"\\\\\\\"\\\\\\\"\\\n    \\\\\\\"I/O utilities for file operations.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom\\\\\\n    \\\\ pathlib\\\n    \\ import Path\\\\nfrom typing import Tuple\\\\n\\\\n\\\\ndef write_output(output_path:\\\\\\\n    \\n    \\\\ str, content: str) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Write content to output\\\n    \\ file.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\\\n    \\\\    output_file = Path(output_path)\\\\n    \\\\n\\\n    \\    # Create parent directories if\\\\\\n    \\\\ they don't exist\\\\n    output_file.parent.mkdir(parents=True,\\\n    \\ exist_ok=True)\\\\n\\\\\\n    \\\\    \\\\n    # Write content\\\\n    with open(output_file,\\\n    \\ 'w', encoding='utf-8')\\\\\\n    \\\\ as f:\\\\n        f.write(content)\\\\n\\\\n\\\\ndef\\\n    \\ is_binary_file(path: Path, sniff_bytes:\\\\\\n    \\\\ int = 2048) -> bool:\\\\n  \\\n    \\  \\\\\\\"\\\\\\\"\\\\\\\"Heuristically determine if a file is binary\\\\\\n    \\\\ by scanning\\\n    \\ for NUL bytes.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        with open(path, 'rb') as\\\\\\n\\\n    \\    \\\\ fb:\\\\n            chunk = fb.read(sniff_bytes)\\\\n        if b\\\\\\\"\\\\\\\\\\\n    x00\\\\\\\" in chunk:\\\\n\\\\\\n    \\\\            return True\\\\n        # If the chunk\\\n    \\ has a lot of non-text bytes,\\\\\\n    \\\\ consider it binary\\\\n        text_byte_count\\\n    \\ = sum(32 <= b <= 126 or b in (9,\\\\\\n    \\\\ 10, 13) for b in chunk)\\\\n      \\\n    \\  return (len(chunk) - text_byte_count) > max(1,\\\\\\n    \\\\ len(chunk) // 3)\\\\\\\n    n    except Exception:\\\\n        # If we cannot read, treat\\\\\\n    \\\\ as binary\\\n    \\ to avoid further processing\\\\n        return True\\\\n\\\\n\\\\ndef read_text_safely(path:\\\\\\\n    \\n    \\\\ Path, max_bytes: int = 16_384) -> Tuple[str, str, bool]:\\\\n    \\\\\\\"\\\\\\\n    \\\"\\\\\\\"Read a text\\\\\\n    \\\\ file safely with size limit and encoding fallbacks.\\\\\\\n    n\\\\n    Returns (content,\\\\\\n    \\\\ encoding_used, truncated).\\\\n    \\\\\\\"\\\\\\\"\\\\\\\n    \\\"\\\\n    truncated = False\\\\n    raw: bytes\\\\n\\\\\\n    \\\\    with open(path, 'rb')\\\n    \\ as fb:\\\\n        raw = fb.read(max_bytes + 1)\\\\n    if\\\\\\n    \\\\ len(raw) >\\\n    \\ max_bytes:\\\\n        truncated = True\\\\n        raw = raw[:max_bytes]\\\\n\\\\\\n\\\n    \\    \\\\n    for enc in (\\\\\\\"utf-8\\\\\\\", \\\\\\\"utf-16\\\\\\\", \\\\\\\"utf-16-le\\\\\\\", \\\\\\\"\\\n    utf-16-be\\\\\\\", \\\\\\\"latin-1\\\\\\\"\\\\\\n    ):\\\\n        try:\\\\n            text = raw.decode(enc)\\\\\\\n    n            return text,\\\\\\n    \\\\ enc, truncated\\\\n        except Exception:\\\\\\\n    n            continue\\\\n    # Fallback:\\\\\\n    \\\\ replace errors with utf-8\\\\\\\n    n    text = raw.decode(\\\\\\\"utf-8\\\\\\\", errors=\\\\\\\"replace\\\\\\\"\\\\\\n    )\\\\n    return\\\n    \\ text, \\\\\\\"utf-8\\\\\\\", truncated\\\"\\n  src/rcpack/packager.py: \\\"from __future__\\\n    \\ import annotations\\\\n\\\\nimport sys\\\\nfrom\\\\\\n    \\\\ pathlib import Path\\\\nfrom\\\n    \\ typing import Iterable, Tuple\\\\n\\\\nfrom rcpack.discover\\\\\\n    \\\\ import discover_files\\\\\\\n    nfrom rcpack.gitinfo import get_git_info, is_git_repo\\\\n\\\\\\n    from rcpack.io_utils\\\n    \\ import read_text_safely, is_binary_file\\\\nfrom rcpack.renderer\\\\\\n    \\\\ import\\\n    \\ markdown as md_renderer\\\\nfrom rcpack.renderer.jsonyaml import render_json,\\\\\\\n    \\n    \\\\ render_yaml\\\\nfrom rcpack.treeview import render_tree\\\\n\\\\n\\\\ndef _find_root(inputs:\\\\\\\n    \\n    \\\\ list[str]) -> Path:\\\\n    paths = [Path(p) for p in inputs]\\\\n    if\\\n    \\ len(paths)\\\\\\n    \\\\ == 1 and Path(paths[0]).is_dir():\\\\n        return paths[0].resolve()\\\\\\\n    n    parents\\\\\\n    \\\\ = [p if p.is_dir() else p.parent for p in paths]\\\\n   \\\n    \\ root = Path(*Path.commonpath([str(p.resolve())\\\\\\n    \\\\ for p in parents]).split(\\\\\\\n    \\\"/\\\\\\\"))\\\\n    return root.resolve()\\\\n\\\\n\\\\ndef build_package(\\\\n\\\\\\n    \\\\\\\n    \\    inputs: list[str],\\\\n    include_patterns: list[str] | None,\\\\n    exclude_patterns:\\\\\\\n    \\n    \\\\ list[str] | None,\\\\n    max_file_bytes: int,\\\\n    fmt: str = \\\\\\\"markdown\\\\\\\n    \\\",\\\\n\\\\\\n    ) -> Tuple[str, dict]:\\\\n    root = _find_root(inputs)\\\\n    root_abs\\\n    \\ = root.resolve()\\\\n\\\\\\n    \\\\n    repo_info = (\\\\n        get_git_info(root_abs)\\\n    \\ if is_git_repo(root_abs) else\\\\\\n    \\\\ {\\\\n            \\\\\\\"is_repo\\\\\\\": False,\\\\\\\n    n            \\\\\\\"commit\\\\\\\": None,\\\\n        \\\\\\n    \\\\    \\\\\\\"branch\\\\\\\": None,\\\\\\\n    n            \\\\\\\"author\\\\\\\": None,\\\\n            \\\\\\\"date\\\\\\\": None,\\\\n\\\\\\n  \\\n    \\  \\\\            \\\\\\\"note\\\\\\\": \\\\\\\"Not a git repository\\\\\\\",\\\\n        }\\\\n  \\\n    \\  )\\\\n\\\\n    files\\\\\\n    \\\\ = discover_files(\\\\n        inputs=[Path(p) for\\\n    \\ p in inputs],\\\\n        root=root_abs,\\\\n\\\\\\n    \\\\        include_patterns=include_patterns\\\n    \\ or [],\\\\n        exclude_patterns=exclude_patterns\\\\\\n    \\\\ or [],\\\\n    )\\\\\\\n    n    rel_files = [f.relative_to(root_abs) for f in files]\\\\n\\\\n\\\\\\n    \\\\    project_tree\\\n    \\ = render_tree([p.as_posix() for p in rel_files])\\\\n\\\\n    file_sections:\\\\\\n\\\n    \\    \\\\ list[dict] = []\\\\n    total_lines = 0\\\\n    total_chars = 0\\\\n\\\\n    for\\\n    \\ f in files:\\\\n\\\\\\n    \\\\        rel = f.relative_to(root_abs).as_posix()\\\\n\\\n    \\        try:\\\\n            if\\\\\\n    \\\\ is_binary_file(f):\\\\n               \\\n    \\ content = f\\\\\\\"[binary file skipped: {f.name},\\\\\\n    \\\\ {f.stat().st_size}\\\n    \\ bytes]\\\\\\\"\\\\n                file_sections.append({\\\\n      \\\\\\n    \\\\     \\\n    \\         \\\\\\\"path\\\\\\\": rel,\\\\n                    \\\\\\\"language\\\\\\\": _language_from_ext(f.suffix),\\\\\\\n    n\\\\\\n    \\\\                    \\\\\\\"content\\\\\\\": content,\\\\n                  \\\n    \\  \\\\\\\"is_truncated\\\\\\\"\\\\\\n    : False,\\\\n                })\\\\n              \\\n    \\  total_chars += len(content)\\\\n  \\\\\\n    \\\\              continue\\\\n\\\\n    \\\n    \\        content, used_encoding, truncated = read_text_safely(f,\\\\\\n    \\\\ max_bytes=max_file_bytes)\\\\\\\n    n            total_lines += content.count(\\\\\\\"\\\\\\\\n\\\\\\\"\\\\\\n    ) + (1 if content\\\n    \\ and not content.endswith(\\\\\\\"\\\\\\\\n\\\\\\\") else 0)\\\\n            total_chars\\\\\\n\\\n    \\    \\\\ += len(content)\\\\n\\\\n            if truncated:\\\\n                note\\\n    \\ = f\\\\\\\"\\\\\\\\n\\\\\\\\\\\\\\n    n[... TRUNCATED to first {max_file_bytes} bytes ...]\\\\\\\n    \\\"\\\\n                content\\\\\\n    \\\\ = content + note\\\\n                total_chars\\\n    \\ += len(note)\\\\n\\\\n            file_sections.append({\\\\n\\\\\\n    \\\\          \\\n    \\      \\\\\\\"path\\\\\\\": rel,\\\\n                \\\\\\\"language\\\\\\\": _language_from_ext(f.suffix),\\\\\\\n    n\\\\\\n    \\\\                \\\\\\\"content\\\\\\\": content,\\\\n                \\\\\\\"is_truncated\\\\\\\n    \\\": truncated,\\\\n\\\\\\n    \\\\            })\\\\n        except Exception as exc:\\\\\\\n    n            print(f\\\\\\\"[rcpack]\\\\\\n    \\\\ error reading {rel}: {exc}\\\\\\\", file=sys.stderr)\\\\\\\n    n            continue\\\\n\\\\n   \\\\\\n    \\\\ # render in chosen format\\\\n    if fmt\\\n    \\ == \\\\\\\"markdown\\\\\\\":\\\\n        out_text = md_renderer.render_markdown(\\\\n\\\\\\n\\\n    \\    \\\\            root=str(root_abs),\\\\n            repo_info=repo_info,\\\\n \\\n    \\        \\\\\\n    \\\\   tree_text=project_tree,\\\\n            files=file_sections,\\\\\\\n    n            total_files=len(file_sections),\\\\n\\\\\\n    \\\\            total_lines=total_lines,\\\\\\\n    n        )\\\\n    elif fmt == \\\\\\\"json\\\\\\\":\\\\n\\\\\\n    \\\\        out_text = render_json(\\\\\\\n    n            root=str(root_abs),\\\\n          \\\\\\n    \\\\  repo_info=repo_info,\\\\\\\n    n            tree_text=project_tree,\\\\n            files=file_sections,\\\\n\\\\\\n\\\n    \\    \\\\            total_files=len(file_sections),\\\\n            total_lines=total_lines,\\\\\\\n    n\\\\\\n    \\\\        )\\\\n    elif fmt == \\\\\\\"yaml\\\\\\\":\\\\n        out_text = render_yaml(\\\\\\\n    n     \\\\\\n    \\\\       root=str(root_abs),\\\\n            repo_info=repo_info,\\\\\\\n    n            tree_text=project_tree,\\\\n\\\\\\n    \\\\            files=file_sections,\\\\\\\n    n            total_files=len(file_sections),\\\\n\\\\\\n    \\\\            total_lines=total_lines,\\\\\\\n    n        )\\\\n    else:\\\\n        raise ValueError(f\\\\\\\"\\\\\\n    Unsupported format:\\\n    \\ {fmt}\\\\\\\")\\\\n\\\\n    stats = {\\\\\\\"files\\\\\\\": len(file_sections), \\\\\\\"\\\\\\n   \\\n    \\ lines\\\\\\\": total_lines, \\\\\\\"chars\\\\\\\": total_chars}\\\\n    return out_text, stats\\\\\\\n    n\\\\n\\\\n\\\\\\n    def _language_from_ext(ext: str) -> str:\\\\n    ext = ext.lower().lstrip(\\\\\\\n    \\\".\\\\\\\")\\\\n\\\\\\n    \\\\    mapping = {\\\\n        \\\\\\\"py\\\\\\\": \\\\\\\"python\\\\\\\", \\\\\\\"\\\n    js\\\\\\\": \\\\\\\"javascript\\\\\\\", \\\\\\\"ts\\\\\\\":\\\\\\n    \\\\ \\\\\\\"typescript\\\\\\\",\\\\n     \\\n    \\   \\\\\\\"json\\\\\\\": \\\\\\\"json\\\\\\\", \\\\\\\"md\\\\\\\": \\\\\\\"markdown\\\\\\\", \\\\\\\"yml\\\\\\\":\\\\\\n\\\n    \\    \\\\ \\\\\\\"yaml\\\\\\\", \\\\\\\"yaml\\\\\\\": \\\\\\\"yaml\\\\\\\",\\\\n        \\\\\\\"toml\\\\\\\": \\\\\\\"\\\n    toml\\\\\\\", \\\\\\\"sh\\\\\\\": \\\\\\\"bash\\\\\\\"\\\\\\n    , \\\\\\\"c\\\\\\\": \\\\\\\"c\\\\\\\", \\\\\\\"cpp\\\\\\\"\\\n    : \\\\\\\"cpp\\\\\\\",\\\\n        \\\\\\\"java\\\\\\\": \\\\\\\"java\\\\\\\", \\\\\\\"go\\\\\\\": \\\\\\\"go\\\\\\\"\\\\\\n\\\n    \\    , \\\\\\\"rs\\\\\\\": \\\\\\\"rust\\\\\\\",\\\\n    }\\\\n    return mapping.get(ext, \\\\\\\"\\\\\\\"\\\n    )\\\\n\\\"\\n  src/rcpack/renderer/jsonyaml.py: \\\"from __future__ import annotations\\\\\\\n    nimport json\\\\n\\\\\\n    \\\\ntry:\\\\n    import yaml\\\\nexcept ImportError:\\\\n    yaml\\\n    \\ = None\\\\n\\\\n\\\\ndef render_json(root,\\\\\\n    \\\\ repo_info, tree_text, files,\\\n    \\ total_files, total_lines,recent_files=None, file_sizes=None)\\\\\\n    \\\\ -> str:\\\\\\\n    n    data = {\\\\n        \\\\\\\"root\\\\\\\": root,\\\\n        \\\\\\\"repo_info\\\\\\\": repo_info,\\\\\\\n    n\\\\\\n    \\\\        \\\\\\\"structure\\\\\\\": tree_text,\\\\n        \\\\\\\"recent_changes\\\\\\\n    \\\": recent_files or\\\\\\n    \\\\ [],\\\\n        \\\\\\\"files\\\\\\\": files,\\\\n        \\\\\\\n    \\\"file_sizes\\\\\\\": file_sizes or {},\\\\n\\\\\\n    \\\\        \\\\\\\"summary\\\\\\\": {\\\\\\\"\\\n    total_files\\\\\\\": total_files, \\\\\\\"total_lines\\\\\\\": total_lines},\\\\n\\\\\\n    \\\\\\\n    \\        \\\\n    }\\\\n    return json.dumps(data, indent=2, ensure_ascii=False)\\\\\\\n    n\\\\n\\\\\\n    \\\\ndef render_yaml(root, repo_info, tree_text, files, total_files,\\\n    \\ total_lines,recent_files=None,\\\\\\n    \\\\ file_sizes=None) -> str:\\\\n    if yaml\\\n    \\ is None:\\\\n        raise RuntimeError(\\\\\\\"\\\\\\n    PyYAML not installed; run\\\n    \\ `pip install pyyaml`\\\\\\\")\\\\n    data = {\\\\n        \\\\\\\"root\\\\\\\"\\\\\\n    : root,\\\\\\\n    n        \\\\\\\"repo_info\\\\\\\": repo_info,\\\\n        \\\\\\\"structure\\\\\\\": tree_text,\\\\\\\n    n\\\\\\n    \\\\        \\\\\\\"recent_changes\\\\\\\": recent_files or [],\\\\n        \\\\\\\"\\\n    files\\\\\\\": files,\\\\n\\\\\\n    \\\\        \\\\\\\"file_sizes\\\\\\\": file_sizes or {},\\\\\\\n    n        \\\\\\\"summary\\\\\\\": {\\\\\\\"total_files\\\\\\\"\\\\\\n    : total_files, \\\\\\\"total_lines\\\\\\\n    \\\": total_lines},\\\\n        \\\\n    }\\\\n    return yaml.safe_dump(data,\\\\\\n   \\\n    \\ \\\\ sort_keys=False, allow_unicode=True)\\\\n\\\"\\n  src/rcpack/renderer/markdown.py:\\\n    \\ \\\"\\\\\\\"\\\\\\\"\\\\\\\"Markdown renderer for repository context.\\\\\\\"\\\\\\n    \\\\\\\"\\\\\\\"\\\\\\\n    n\\\\nfrom typing import Dict, Any\\\\n\\\\n\\\\ndef render_markdown(root: str, repo_info:\\\\\\\n    \\n    \\\\ Dict[str, Any], tree_text: str, \\\\n                   files: Dict[str,\\\n    \\ str],\\\\\\n    \\\\ total_files: int, total_lines: int, recent_files=None, file_sizes=None)\\\n    \\ -> str:\\\\n\\\\\\n    \\\\    \\\\\\\"\\\\\\\"\\\\\\\"Render repository context as markdown.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    lines = []\\\\n\\\\\\n    \\\\    \\\\n    # Header\\\\n    lines.append(f\\\\\\\n    \\\"# Repository Context: {root}\\\\\\\")\\\\n   \\\\\\n    \\\\ lines.append(\\\\\\\"\\\\\\\")\\\\n\\\n    \\    \\\\n    # Repository info\\\\n    if repo_info.get(\\\\\\\"is_repo\\\\\\\"\\\\\\n    ):\\\\\\\n    n        lines.append(\\\\\\\"## Git Repository Information\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"\\\\\\n    - **Branch**: {repo_info.get('branch', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Commit**:\\\\\\n    \\\\ {repo_info.get('commit', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Author**: {repo_info.get('author',\\\\\\n    \\\\ 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Date**: {repo_info.get('date', 'N/A')}\\\\\\\"\\\\\\n    )\\\\n    else:\\\\n     \\\n    \\   lines.append(\\\\\\\"## Repository Information\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"\\\\\\n    - **Note**: {repo_info.get('note', 'Not a git repository')}\\\\\\\")\\\\n\\\n    \\    lines.append(\\\\\\\"\\\\\\n    \\\\\\\")\\\\n    \\\\n    # Summary\\\\n    lines.append(\\\\\\\n    \\\"## Summary\\\\\\\")\\\\n    lines.append(f\\\\\\\"\\\\\\n    - **Total Files**: {total_files}\\\\\\\n    \\\")\\\\n    lines.append(f\\\\\\\"- **Total Lines**: {total_lines}\\\\\\\"\\\\\\n    )\\\\n \\\n    \\   lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Directory structure\\\\n    lines.append(\\\\\\\n    \\\"\\\\\\n    ## Directory Structure\\\\\\\")\\\\n    lines.append(\\\\\\\"```\\\\\\\")\\\\n    lines.append(tree_text)\\\\\\\n    n\\\\\\n    \\\\    lines.append(\\\\\\\"```\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n\\\\n  \\\n    \\  # will produce recent\\\\\\n    \\\\ files \\\\n    # Recent files (fixed)\\\\n    if\\\n    \\ recent_files:\\\\n        lines.append(\\\\\\\"\\\\\\n    ## Recent Changes\\\\\\\")\\\\n \\\n    \\       for file, age in recent_files.items():\\\\n       \\\\\\n    \\\\     lines.append(f\\\\\\\n    \\\"- {file} (modified {age})\\\\\\\")\\\\n        lines.append(\\\\\\\"\\\\\\\"\\\\\\n    )\\\\n \\\n    \\   \\\\n    # File contents\\\\n    lines.append(\\\\\\\"## File Contents\\\\\\\")\\\\n   \\\n    \\ lines.append(\\\\\\\"\\\\\\n    \\\\\\\")\\\\n    \\\\n    for file_path, content in sorted(files.items()):\\\\\\\n    n        if file_sizes\\\\\\n    \\\\ and file_path in file_sizes:\\\\n            size_bytes\\\n    \\ = file_sizes[file_path]\\\\n\\\\\\n    \\\\            lines.append(f\\\\\\\"### {file_path}\\\n    \\ ({size_bytes} bytes)\\\\\\\")\\\\n       \\\\\\n    \\\\ else:\\\\n            lines.append(f\\\\\\\n    \\\"### {file_path}\\\\\\\")\\\\n        lines.append(\\\\\\\"\\\\\\n    \\\\\\\")\\\\n        \\\\n\\\n    \\        # Detect language for syntax highlighting\\\\n        ext\\\\\\n    \\\\ = file_path.split('.')[-1].lower()\\\n    \\ if '.' in file_path else ''\\\\n        lang_map\\\\\\n    \\\\ = {\\\\n            'py':\\\n    \\ 'python', 'js': 'javascript', 'ts': 'typescript',\\\\n \\\\\\n    \\\\           'java':\\\n    \\ 'java', 'cpp': 'cpp', 'c': 'c', 'h': 'c',\\\\n            'cs':\\\\\\n    \\\\ 'csharp',\\\n    \\ 'php': 'php', 'rb': 'ruby',\\\\n            'go': 'go', 'rs': 'rust',\\\\\\n    \\\\\\\n    \\ 'swift': 'swift',\\\\n            'html': 'html', 'css': 'css', 'scss': 'scss',\\\\\\\n    n\\\\\\n    \\\\            'json': 'json', 'yaml': 'yaml', 'yml': 'yaml',\\\\n     \\\n    \\       'xml':\\\\\\n    \\\\ 'xml', 'sql': 'sql', 'sh': 'bash',\\\\n            'md':\\\n    \\ 'markdown', 'dockerfile':\\\\\\n    \\\\ 'dockerfile'\\\\n        }\\\\n        \\\\n \\\n    \\       language = lang_map.get(ext, '')\\\\n\\\\\\n    \\\\        lines.append(f\\\\\\\"\\\n    ```{language}\\\\\\\")\\\\n        lines.append(content)\\\\n   \\\\\\n    \\\\     lines.append(\\\\\\\n    \\\"```\\\\\\\")\\\\n        lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    return \\\\\\\"\\\\\\\\\\\\\\n \\\n    \\   n\\\\\\\".join(lines)\\\\n\\\"\\n  src/rcpack/treeview.py: \\\"\\\\\\\"\\\\\\\"\\\\\\\"Tree view\\\n    \\ generation for repository structure.\\\\\\\"\\\\\\\"\\\\\\n    \\\\\\\"\\\\n\\\\nfrom pathlib import\\\n    \\ Path\\\\nfrom typing import Dict, List\\\\n\\\\n\\\\ndef create_tree_view(repo_path:\\\\\\\n    \\n    \\\\ Path, files_data: Dict[str, str]) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create a\\\n    \\ tree view of the\\\\\\n    \\\\ repository structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    paths = list(files_data.keys())\\\\\\\n    n    return\\\\\\n    \\\\ render_tree(paths)\\\\n\\\\n\\\\ndef render_tree(paths: List[str])\\\n    \\ -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\\\n    Render a tree view from a list of relative\\\n    \\ POSIX paths.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    tree_structure:\\\\\\n    \\\\ dict = {}\\\\n\\\\n   \\\n    \\ for p in paths:\\\\n        parts = Path(p).parts\\\\n        current\\\\\\n    \\\\\\\n    \\ = tree_structure\\\\n        for part in parts[:-1]:\\\\n            if part not\\\n    \\ in\\\\\\n    \\\\ current:\\\\n                current[part] = {}\\\\n            current\\\n    \\ = current[part]\\\\n\\\\\\n    \\\\        if parts:\\\\n            current[parts[-1]]\\\n    \\ = None\\\\n\\\\n    def _render(structure:\\\\\\n    \\\\ dict, prefix: str = \\\\\\\"\\\\\\\"\\\n    ) -> str:\\\\n        lines = []\\\\n        items = sorted(structure.items(),\\\\\\n\\\n    \\    \\\\ key=lambda x: (x[1] is None, x[0]))\\\\n        for i, (name, subtree) in\\\n    \\ enumerate(items):\\\\n\\\\\\n    \\\\            is_last = i == len(items) - 1\\\\n \\\n    \\           lines.append(f\\\\\\\"{prefix}{'└──\\\\\\n    \\\\ ' if is_last else '├── '}{name}\\\\\\\n    \\\")\\\\n            if subtree is not None:\\\\n  \\\\\\n    \\\\              extension\\\n    \\ = (\\\\\\\"    \\\\\\\" if is_last else \\\\\\\"│   \\\\\\\")\\\\n             \\\\\\n    \\\\   lines.append(_render(subtree,\\\n    \\ prefix + extension))\\\\n        return \\\\\\\"\\\\\\\\n\\\\\\\"\\\\\\n    .join(filter(None,\\\n    \\ lines))\\\\n\\\\n    if not tree_structure:\\\\n        return \\\\\\\"No\\\\\\n    \\\\ files\\\n    \\ found\\\\\\\"\\\\n    return _render(tree_structure)\\\"\\n  test-output.json: \\\"{\\\\\\\n    n  \\\\\\\"root\\\\\\\": \\\\\\\"/Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\\\\\\\n    \\\"\\\\\\n    ,\\\\n  \\\\\\\"repo_info\\\\\\\": {\\\\n    \\\\\\\"is_repo\\\\\\\": true,\\\\n    \\\\\\\"commit\\\\\\\n    \\\": \\\\\\\"682153b169db66d3a72e9cabdd1f3448a3b2986d\\\\\\\"\\\\\\n    ,\\\\n    \\\\\\\"branch\\\\\\\n    \\\": \\\\\\\"refactoring\\\\\\\",\\\\n    \\\\\\\"author\\\\\\\": \\\\\\\"Abhinav <abhinavbhardwaj2002@gmail.com>\\\\\\\n    \\\"\\\\\\n    ,\\\\n    \\\\\\\"date\\\\\\\": \\\\\\\"Fri Oct 3 18:45:48 2025\\\\\\\",\\\\n    \\\\\\\"note\\\\\\\n    \\\": null\\\\n  },\\\\n  \\\\\\\"\\\\\\n    structure\\\\\\\": \\\\\\\"├── src\\\\\\\\n│   └── rcpack\\\\\\\n    \\\\n│       ├── renderer\\\\\\\\n│       │   ├──\\\\\\n    \\\\ jsonyaml.py\\\\\\\\n│      \\\n    \\ │   └── markdown.py\\\\\\\\n│       ├── __init__.py\\\\\\\\n│    \\\\\\n    \\\\   ├── __main__.py\\\\\\\n    \\\\n│       ├── cli.py\\\\\\\\n│       ├── config_loader.py\\\\\\\\n│  \\\\\\n    \\\\     ├──\\\n    \\ discover.py\\\\\\\\n│       ├── gitinfo.py\\\\\\\\n│       ├── io_utils.py\\\\\\\\n│ \\\\\\n\\\n    \\    \\\\      ├── packager.py\\\\\\\\n│       └── treeview.py\\\\\\\\n├── LICENSE\\\\\\\\n├──\\\n    \\ README.md\\\\\\\\\\\\\\n    n└── pyproject.toml\\\\\\\",\\\\n  \\\\\\\"recent_changes\\\\\\\": [],\\\\\\\n    n  \\\\\\\"files\\\\\\\": {\\\\n    \\\\\\\"LICENSE\\\\\\\"\\\\\\n    : \\\\\\\"MIT License\\\\\\\\n\\\\\\\\nCopyright\\\n    \\ (c) 2025 Abhinav\\\\\\\\n\\\\\\\\nPermission is hereby granted,\\\\\\n    \\\\ free of charge,\\\n    \\ to any person obtaining a copy\\\\\\\\nof this software and associated\\\\\\n    \\\\\\\n    \\ documentation files (the \\\\\\\\\\\\\\\"Software\\\\\\\\\\\\\\\"), to deal\\\\\\\\nin the Software\\\n    \\ without\\\\\\n    \\\\ restriction, including without limitation the rights\\\\\\\\nto\\\n    \\ use, copy, modify,\\\\\\n    \\\\ merge, publish, distribute, sublicense, and/or\\\n    \\ sell\\\\\\\\ncopies of the Software,\\\\\\n    \\\\ and to permit persons to whom the\\\n    \\ Software is\\\\\\\\nfurnished to do so, subject\\\\\\n    \\\\ to the following conditions:\\\\\\\n    \\\\n\\\\\\\\nThe above copyright notice and this permission\\\\\\n    \\\\ notice shall\\\n    \\ be included in all\\\\\\\\ncopies or substantial portions of the Software.\\\\\\\\\\\\\\\n    \\n    n\\\\\\\\nTHE SOFTWARE IS PROVIDED \\\\\\\\\\\\\\\"AS IS\\\\\\\\\\\\\\\", WITHOUT WARRANTY OF\\\n    \\ ANY KIND, EXPRESS\\\\\\n    \\\\ OR\\\\\\\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE\\\n    \\ WARRANTIES OF MERCHANTABILITY,\\\\\\\\\\\\\\n    nFITNESS FOR A PARTICULAR PURPOSE\\\n    \\ AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\\\\\\\\\\\n    nAUTHORS OR COPYRIGHT\\\n    \\ HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\\\\\nLIABILITY,\\\\\\n    \\\\ WHETHER\\\n    \\ IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\\\\\nOUT OF\\\\\\n  \\\n    \\  \\\\ OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\\\\n    \\\\nSOFTWARE.\\\\\\\\\\\\\\n    n\\\\\\\",\\\\n    \\\\\\\"README.md\\\\\\\": \\\\\\\"# Repo-Contextor\\\\\\\n    \\\\n\\\\\\\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\\\\\\n    \\\\\\\\\\n    n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\\\\\\n    \\\\\\\\\\n    n\\\\\\\\nA powerful Repository Context Packager CLI tool that analyzes\\\n    \\ local git repositories\\\\\\n    \\\\ and creates comprehensive text files containing\\\n    \\ repository content optimized\\\\\\n    \\\\ for sharing with Large Language Models\\\n    \\ (LLMs).\\\\\\\\n\\\\\\\\n## Overview\\\\\\\\n\\\\\\\\nWhen developers\\\\\\n    \\\\ want to get\\\n    \\ help from ChatGPT, Claude, or other LLMs about their code, they\\\\\\n    \\\\ often\\\n    \\ struggle with how to share their codebase effectively. Common problems\\\\\\n \\\n    \\   \\\\ include:\\\\\\\\n\\\\\\\\n- **Lost Context**: Copy-pasting individual files loses\\\n    \\ important\\\\\\n    \\\\ project structure and relationships\\\\\\\\n- **Missing Dependencies**:\\\n    \\ LLMs can't\\\\\\n    \\\\ see how files connect or what libraries are used\\\\\\\\n-\\\n    \\ **Incomplete Picture**:\\\\\\n    \\\\ Hard to convey the overall architecture and\\\n    \\ organization\\\\\\\\n- **Manual Work**:\\\\\\n    \\\\ Time-consuming to gather and format\\\n    \\ relevant code\\\\\\\\n\\\\\\\\n**Repo-Contextor** solves\\\\\\n    \\\\ this by automatically\\\n    \\ collecting and formatting repository content into a single,\\\\\\n    \\\\ well-structured\\\n    \\ text file that provides rich context to LLMs, enabling them\\\\\\n    \\\\ to give\\\n    \\ much better assistance with your code.\\\\\\\\n\\\\\\\\n## Features\\\\\\\\n\\\\\\\\n- **Git\\\\\\\n    \\n    \\\\ Integration**: Extracts commit SHA, branch, author, and date information\\\\\\\n    \\\\n-\\\\\\n    \\\\ **Project Structure**: Generates a clear directory tree visualization\\\\\\\n    \\\\n- **File\\\\\\n    \\\\ Content Packaging**: Includes file contents with syntax\\\n    \\ highlighting\\\\\\\\n- **Smart\\\\\\n    \\\\ File Discovery**: Recursively scans directories\\\n    \\ with intelligent filtering\\\\\\\\\\\\\\n    n- **Binary File Detection**: Automatically\\\n    \\ skips binary files\\\\\\\\n- **Error Handling**:\\\\\\n    \\\\ Gracefully handles permission\\\n    \\ errors and provides helpful messages\\\\\\\\n- **Multiple\\\\\\n    \\\\ Output Formats**:\\\n    \\ Supports Markdown, JSON, and YAML formats\\\\\\\\n- **Flexible Output**:\\\\\\n   \\\n    \\ \\\\ Write to stdout or save to a file\\\\\\\\n- **Recent Changes Filter**: Give the\\\n    \\ files\\\\\\n    \\\\ which are updated in last 7days with the time when it was recently\\\n    \\ modified.\\\\\\\\\\\\\\n    n\\\\\\\\n## Installation\\\\\\\\n\\\\\\\\n### Prerequisites\\\\\\\\n\\\\\\\n    \\\\n- Python 3.9 or higher\\\\\\\\n- Git\\\\\\n    \\\\ (for git repository analysis)\\\\\\\\\\\n    n\\\\\\\\n### For End Users\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Clone\\\\\\n    \\\\ and install\\\\\\\\\\\n    ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\\\\\\\\n    ncd Repo-Contextor\\\\\\\n    \\\\npip install -e .\\\\\\\\n```\\\\\\\\n\\\\\\\\n### For Contributors & Local\\\\\\n    \\\\ Development\\\\\\\n    \\\\n\\\\\\\\n```bash\\\\\\\\n# Clone the repository\\\\\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    \\\\\\\\\\n    ncd Repo-Contextor\\\\\\\\n\\\\\\\\n# Create virtual environment\\\\\\\\npython\\\n    \\ -m venv .venv\\\\\\\\\\\\\\n    nsource .venv/bin/activate  # On Windows: .venv\\\\\\\\\\\n    \\\\\\\\Scripts\\\\\\\\\\\\\\\\activate\\\\\\\\n\\\\\\\\n#\\\\\\n    \\\\ Install in development mode\\\\\\\n    \\\\npip install -e .\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Usage\\\\\\\\n\\\\\\\\n###\\\\\\n    \\\\ Basic Examples\\\\\\\n    \\\\n\\\\\\\\n```bash\\\\\\\\n# Package current directory to terminal\\\\\\\\nrepo-contextor\\\\\\\n    \\n    \\\\ .\\\\\\\\n\\\\\\\\n# Package a specific directory\\\\\\\\nrepo-contextor /path/to/your/project\\\\\\\n    \\\\\\\\\\n    n\\\\\\\\n# Save output to a file\\\\\\\\nrepo-contextor . -o my-project-context.md\\\\\\\n    \\\\n\\\\\\\\n#\\\\\\n    \\\\ Generate JSON format\\\\\\\\nrepo-contextor . -f json -o context.json\\\\\\\n    \\\\n\\\\\\\\n# Generate\\\\\\n    \\\\ YAML format\\\\\\\\nrepo-contextor . -f yaml -o context.yaml\\\\\\\n    \\\\n\\\\\\\\n# Include only files\\\\\\n    \\\\ modified in the last 7 days\\\\\\\\nrepo-contextor\\\n    \\ . --recent\\\\\\\\n\\\\\\\\n# Combine with\\\\\\n    \\\\ output file\\\\\\\\nrepo-contextor\\\n    \\ . --recent -o recent-changes.md\\\\\\\\n```\\\\\\\\n\\\\\\\\n###\\\\\\n    \\\\ Command Line\\\n    \\ Options\\\\\\\\n\\\\\\\\n| Option | Short | Description | Example |\\\\\\\\n|--------|-------|-------------|---------|\\\\\\\n    \\\\\\\\\\n    n| `path` | - | Repository path to analyze (default: current directory)\\\n    \\ | `repo-contextor\\\\\\n    \\\\ /path/to/project` |\\\\\\\\n| `--output` | `-o` | Output\\\n    \\ file path (default: stdout)\\\\\\n    \\\\ | `-o context.md` |\\\\\\\\n| `--format` |\\\n    \\ `-f` | Output format: text, json, yaml\\\\\\n    \\\\ (default: text) | `-f json`\\\n    \\ |\\\\\\\\n| `--help` | `-h` | Show help message | `-h`\\\\\\n    \\\\ |\\\\\\\\n| `--recent`\\\n    \\  | `-r`  | Include only files modified in the last 7 days \\\\\\n    \\\\   | `repo-contextor\\\n    \\ . -r -o recent.md` |\\\\\\\\n\\\\\\\\n### Advanced Examples\\\\\\\\n\\\\\\\\n```bash\\\\\\\\\\\\\\n\\\n    \\    n# Analyze different repository\\\\\\\\nrepo-contextor /path/to/other/project\\\n    \\ -o other-project.md\\\\\\\\\\\\\\n    n\\\\\\\\n# Generate JSON for API consumption\\\\\\\\\\\n    nrepo-contextor . -f json -o api-context.json\\\\\\\\\\\\\\n    n\\\\\\\\n# Create YAML configuration\\\\\\\n    \\\\nrepo-contextor . -f yaml -o project-config.yaml\\\\\\\\\\\\\\n    n\\\\\\\\n# Generate\\\n    \\ files which are changed recently in 7 days\\\\\\\\nrepo-contextor . -r\\\\\\n    \\\\\\\n    \\ --output recent-changes.txt\\\\\\\\n\\\\\\\\n```\\\\\\\\n## Configuration via TOML\\\\\\\\n\\\\\\\n    \\\\nRepo-Contextor\\\\\\n    \\\\ supports configuration through a `.repo-contextor.toml`\\\n    \\ file in the current\\\\\\n    \\\\ working directory.  \\\\\\\\nThis file allows you\\\n    \\ to avoid typing the same CLI arguments\\\\\\n    \\\\ every time.\\\\\\\\n\\\\\\\\nExample\\\n    \\ `.repo-contextor.toml`:\\\\\\\\n\\\\\\\\n```toml\\\\\\\\n# Output file\\\\\\n    \\\\ to write\\\n    \\ results\\\\\\\\noutput = \\\\\\\\\\\\\\\"context.yaml\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Output format:\\\n    \\ text,\\\\\\n    \\\\ json, or yaml\\\\\\\\nformat = \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Limit\\\n    \\ to files modified in the\\\\\\n    \\\\ last 7 days\\\\\\\\nrecent = true\\\\\\\\n\\\\\\\\n#\\\n    \\ Repository path to analyze (default = current\\\\\\n    \\\\ directory)\\\\\\\\npath\\\n    \\ = \\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n### Rules\\\\\\\\n- If the `.repo-contextor.toml`\\\\\\\n    \\n    \\\\ file is **missing**, the tool falls back to defaults.  \\\\\\\\n- If the\\\n    \\ file is **present\\\\\\n    \\\\ but invalid TOML**, the tool prints a clear error\\\n    \\ message and exits with status\\\\\\n    \\\\ code 1.  \\\\\\\\n- **Unknown keys** in\\\n    \\ the TOML file are ignored (safe for future\\\\\\n    \\\\ extensions).  \\\\\\\\n- **Precedence**\\\n    \\ of settings is:\\\\\\\\n  1. Command-line arguments\\\\\\n    \\\\ (highest priority)\\\n    \\  \\\\\\\\n  2. Values from `.repo-contextor.toml`  \\\\\\\\n  3. Built-in\\\\\\n    \\\\\\\n    \\ defaults (lowest priority)\\\\\\\\n     \\\\\\\\n## Output Format\\\\\\\\n\\\\\\\\nThe tool\\\n    \\ generates\\\\\\n    \\\\ a structured text file with the following sections:\\\\\\\\\\\n    n\\\\\\\\n### 1. Repository Context\\\\\\n    \\\\ Header\\\\\\\\nProject path and identification\\\\\\\n    \\\\n\\\\\\\\n### 2. Git Repository Information\\\\\\\\\\\\\\n    n- Current branch\\\\\\\\n- Latest\\\n    \\ commit SHA\\\\\\\\n- Last commit author\\\\\\\\n- Last commit\\\\\\n    \\\\ date\\\\\\\\n\\\\\\\\\\\n    n### 3. Summary Statistics\\\\\\\\n- Total number of files processed\\\\\\\\n-\\\\\\n   \\\n    \\ \\\\ Total lines of code\\\\\\\\n\\\\\\\\n### 4. Directory Structure\\\\\\\\nClean tree visualization\\\\\\\n    \\n    \\\\ showing project organization\\\\\\\\n\\\\\\\\n### 5. Recent Changes (if `--recent`\\\n    \\ is used)\\\\\\\\\\\\\\n    n\\\\\\\\n- Lists files modified in the last 7 days.\\\\\\\\n- Shows\\\n    \\ relative file paths along\\\\\\n    \\\\ with how long ago each file was modified\\\\\\\n    \\\\n- Helps focus on recently updated\\\\\\n    \\\\ parts of the project.\\\\\\\\n- Can\\\n    \\ be combined with `--output` or `--format` to save\\\\\\n    \\\\ or change the output\\\n    \\ type.\\\\\\\\n\\\\\\\\n\\\\\\\\n### 5. File Contents\\\\\\\\nEach file's content\\\\\\n    \\\\ with:\\\\\\\n    \\\\n- Clear file path headers\\\\\\\\n- Appropriate syntax highlighting language\\\\\\n\\\n    \\    \\\\ tags\\\\\\\\n- Complete file contents\\\\\\\\n\\\\\\\\n## Example Output\\\\\\\\n\\\\\\\\\\\n    nWhen you run `repo-contextor\\\\\\n    \\\\ .`, the output looks like this:\\\\\\\\n\\\\\\\n    \\\\n````markdown\\\\\\\\n# Repository Context: /path/to/your/project\\\\\\\\\\\\\\n    n\\\\\\\n    \\\\n## Git Repository Information\\\\\\\\n- **Branch**: main\\\\\\\\n- **Commit**: a1b2c3d4e5f6789...\\\\\\\n    \\\\\\\\\\n    n- **Author**: John Doe <john@example.com>\\\\\\\\n- **Date**: Fri Sep 12\\\n    \\ 14:30:15 2025\\\\\\\\\\\\\\n    n\\\\\\\\n## Summary\\\\\\\\n- **Total Files**: 15\\\\\\\\n- **Total\\\n    \\ Lines**: 1,247\\\\\\\\n\\\\\\\\n## Directory\\\\\\n    \\\\ Structure\\\\\\\\n```\\\\\\\\n├── src/\\\\\\\n    \\\\n│   ├── main.py\\\\\\\\n│   └── utils.py\\\\\\\\n├── tests/\\\\\\\\\\\\\\n    n│   └── test_main.py\\\\\\\n    \\\\n├── README.md\\\\\\\\n└── requirements.txt\\\\\\\\n```\\\\\\\\n## Recent\\\\\\n    \\\\ Changes\\\\\\\n    \\\\n- src/main.py (modified 2 days ago)\\\\\\\\n- src/utils/helpers.py (modified\\\\\\n\\\n    \\    \\\\ 5 days ago)\\\\\\\\n\\\\\\\\n## File Contents\\\\\\\\n\\\\\\\\n### src/main.py\\\\\\\\n\\\\\\\\\\\n    n```python\\\\\\\\ndef\\\\\\n    \\\\ main():\\\\\\\\n    print(\\\\\\\\\\\\\\\"Hello, World!\\\\\\\\\\\\\\\n    \\\")\\\\\\\\n\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\n    \\\\\\\":\\\\\\\\n    main()\\\\\\\n    \\\\n```\\\\\\\\n\\\\\\\\n### README.md\\\\\\\\n\\\\\\\\n```markdown\\\\\\\\n# My Project\\\\\\\\nThis\\\\\\\n    \\n    \\\\ is a sample project.\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Summary\\\\\\\\n- Total files: 15\\\\\\\n    \\\\n- Total lines:\\\\\\n    \\\\ 1,247\\\\\\\\n````\\\\\\\\n\\\\\\\\n## What Files Are Included\\\\\\\n    \\\\n\\\\\\\\nThe tool includes most text\\\\\\n    \\\\ files but automatically excludes:\\\\\\\n    \\\\n\\\\\\\\n### Excluded Directories\\\\\\\\n- `.git`,\\\\\\n    \\\\ `.svn`, `.hg` (version\\\n    \\ control)\\\\\\\\n- `__pycache__`, `.pytest_cache` (Python cache)\\\\\\\\\\\\\\n    n- `node_modules`,\\\n    \\ `.venv`, `venv` (dependencies/environments)\\\\\\\\n- `.vscode`,\\\\\\n    \\\\ `.idea`\\\n    \\ (IDE directories)\\\\\\\\n- `build`, `dist`, `target` (build directories)\\\\\\\\\\\\\\n\\\n    \\    n\\\\\\\\n### File Handling Rules\\\\\\\\n- **Text files**: All readable text files\\\n    \\ with common\\\\\\n    \\\\ extensions\\\\\\\\n- **Binary files**: Automatically detected\\\n    \\ and skipped\\\\\\\\n- **Permission\\\\\\n    \\\\ errors**: Skipped with graceful handling\\\\\\\n    \\\\n- **Configuration files**: Includes\\\\\\n    \\\\ pyproject.toml, package.json,\\\n    \\ etc.\\\\\\\\n\\\\\\\\n### Included File Types\\\\\\\\n- Source code:\\\\\\n    \\\\ `.py`, `.js`,\\\n    \\ `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\\\\\\\n- Web files:\\\\\\n    \\\\\\\n    \\ `.html`, `.css`, `.scss`, `.vue`, `.jsx`, etc.\\\\\\\\n- Documentation: `.md`, `.txt`,\\\\\\\n    \\n    \\\\ `.rst`\\\\\\\\n- Configuration: `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\\\\\\n    \\\\n- Scripts:\\\\\\n    \\\\ `.sh`, `.bash`, `.zsh`\\\\\\\\n\\\\\\\\n## Error Handling\\\\\\\\\\\n    n\\\\\\\\nThe tool handles errors gracefully:\\\\\\\\\\\\\\n    n\\\\\\\\n| Error Type | Behavior\\\n    \\ |\\\\\\\\n|------------|----------|\\\\\\\\n| **Permission errors**\\\\\\n    \\\\ | Skipped\\\n    \\ with warning |\\\\\\\\n| **Binary files** | Automatically detected and skipped\\\\\\\n    \\n    \\\\ |\\\\\\\\n| **Invalid paths** | Clear error messages |\\\\\\\\n| **Non-git repositories**\\\\\\\n    \\n    \\\\ | Works fine, shows \\\\\\\\\\\\\\\"Not a git repository\\\\\\\\\\\\\\\" |\\\\\\\\n| **Unreadable\\\n    \\ files**\\\\\\n    \\\\ | Marked as \\\\\\\\\\\\\\\"[Binary or unreadable file]\\\\\\\\\\\\\\\" |\\\\\\\n    \\\\n\\\\\\\\n## Development\\\\\\\\n\\\\\\\\n###\\\\\\n    \\\\ Project Structure\\\\\\\\n\\\\\\\\n```text\\\\\\\n    \\\\nRepo-Contextor/\\\\\\\\n├── src/rcpack/         \\\\\\n    \\\\     # Main package\\\\\\\n    \\\\n│   ├── __init__.py         # Package initialization\\\\\\\\\\\\\\n    n│   ├── cli.py\\\n    \\              # Command-line interface\\\\\\\\n│   ├── discover.py  \\\\\\n    \\\\  \\\n    \\     # File discovery logic\\\\\\\\n│   ├── gitinfo.py          # Git repository\\\\\\\n    \\n    \\\\ analysis\\\\\\\\n│   ├── treeview.py         # Directory tree generation\\\\\\\n    \\\\n│   ├──\\\\\\n    \\\\ packager.py         # Main orchestration\\\\\\\\n│   ├── io_utils.py\\\n    \\         # File\\\\\\n    \\\\ I/O utilities\\\\\\\\n│   └── renderer/           # Output\\\n    \\ formatters\\\\\\\\n│       ├──\\\\\\n    \\\\ markdown.py     # Markdown renderer\\\\\\\\\\\n    n│       └── jsonyaml.py     # JSON/YAML\\\\\\n    \\\\ renderers\\\\\\\\n├── pyproject.toml\\\n    \\          # Project configuration\\\\\\\\n├── LICENSE\\\\\\n    \\\\                 #\\\n    \\ MIT License\\\\\\\\n└── README.md              # This documentation\\\\\\\\\\\\\\n    n```\\\\\\\n    \\\\n\\\\\\\\n### Running Tests\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Test on current repository\\\\\\\\\\\n    nrepo-contextor\\\\\\n    \\\\ . -o test-output.md\\\\\\\\n\\\\\\\\n# Test different formats\\\\\\\n    \\\\nrepo-contextor . -f json\\\\\\n    \\\\ | head -20\\\\\\\\nrepo-contextor . -f yaml\\\n    \\ | head -20\\\\\\\\n\\\\\\\\n# Test specific directory\\\\\\\\\\\\\\n    nrepo-contextor src/\\\n    \\ -o src-only.md\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Contributing\\\\\\\\n\\\\\\\\n1. **Fork\\\\\\n    \\\\\\\n    \\ the repository**\\\\\\\\n2. **Clone your fork:**\\\\\\\\n   ```bash\\\\\\\\n   git clone\\\n    \\ https://github.com/yourusername/Repo-Contextor.git\\\\\\\\\\\\\\n    n   cd Repo-Contextor\\\\\\\n    \\\\n   ```\\\\\\\\n3. **Install for development:**\\\\\\\\n   ```bash\\\\\\\\\\\\\\n    n   python\\\n    \\ -m venv .venv\\\\\\\\n   source .venv/bin/activate\\\\\\\\n   pip install -e .\\\\\\\\\\\\\\\n    \\n    n   ```\\\\\\\\n4. **Make your changes and test:**\\\\\\\\n   ```bash\\\\\\\\n   repo-contextor\\\\\\\n    \\n    \\\\ . -o test.md\\\\\\\\n   ```\\\\\\\\n5. **Submit a pull request**\\\\\\\\n\\\\\\\\n###\\\n    \\ Development Workflow\\\\\\\\\\\\\\n    n\\\\\\\\n```bash\\\\\\\\n# 1. Setup development environment\\\\\\\n    \\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\\\\\\\\n    ncd\\\n    \\ Repo-Contextor\\\\\\\\npython -m venv .venv\\\\\\\\nsource .venv/bin/activate\\\\\\\\npip\\\n    \\ install\\\\\\n    \\\\ -e .\\\\\\\\n\\\\\\\\n# 2. Make changes to the code\\\\\\\\n# Edit files\\\n    \\ in src/rcpack/\\\\\\\\n\\\\\\\\n#\\\\\\n    \\\\ 3. Test your changes\\\\\\\\nrepo-contextor\\\n    \\ . -o test-output.md\\\\\\\\n\\\\\\\\n# 4. Test different\\\\\\n    \\\\ formats\\\\\\\\nrepo-contextor\\\n    \\ . -f json -o test.json\\\\\\\\nrepo-contextor . -f yaml -o\\\\\\n    \\\\ test.yaml\\\\\\\n    \\\\n\\\\\\\\n# 5. Commit and push changes\\\\\\\\ngit add .\\\\\\\\ngit commit -m \\\\\\\\\\\\\\\"\\\\\\\n    \\n    Add new feature\\\\\\\\\\\\\\\"\\\\\\\\ngit push origin feature-branch\\\\\\\\n```\\\\\\\\n\\\\\\\n    \\\\n## License\\\\\\\\n\\\\\\\\\\\\\\n    nThis project is licensed under the MIT License.\\\n    \\ See the [LICENSE](LICENSE) file\\\\\\n    \\\\ for details.\\\\\\\\n\\\\\\\\n## Why Repo-Contextor?\\\\\\\n    \\\\n\\\\\\\\nThe name \\\\\\\\\\\\\\\"Repo-Contextor\\\\\\\\\\\\\\\"\\\\\\n    \\\\ combines \\\\\\\\\\\\\\\"Repository\\\\\\\n    \\\\\\\\\\\" + \\\\\\\\\\\\\\\"Context\\\\\\\\\\\\\\\" + \\\\\\\\\\\\\\\"or\\\\\\\\\\\\\\\", representing the\\\\\\n  \\\n    \\  \\\\ tool's purpose of providing rich context about code repositories in a format\\\\\\\n    \\n    \\\\ that's perfect for LLM interactions.\\\\\\\\n\\\\\\\\n### Use Cases\\\\\\\\n\\\\\\\\\\\n    n- **AI Assistance**:\\\\\\n    \\\\ Get better help from ChatGPT, Claude, or GitHub\\\n    \\ Copilot\\\\\\\\n- **Code Reviews**:\\\\\\n    \\\\ Share complete project context with\\\n    \\ team members\\\\\\\\n- **Documentation**: Create\\\\\\n    \\\\ comprehensive project\\\n    \\ snapshots\\\\\\\\n- **Onboarding**: Help new team members understand\\\\\\n    \\\\ project\\\n    \\ structure\\\\\\\\n- **Project Analysis**: Understand repository structure\\\\\\n  \\\n    \\  \\\\ and dependencies\\\\\\\\n\\\\\\\\n### Perfect for LLMs\\\\\\\\n\\\\\\\\nThe output format\\\n    \\ is specifically\\\\\\n    \\\\ designed to work well with Large Language Models:\\\\\\\n    \\\\n- Clear section headers\\\\\\n    \\\\ for easy parsing\\\\\\\\n- Syntax highlighting\\\n    \\ markers for code blocks\\\\\\\\n- Structured\\\\\\n    \\\\ metadata (git info, file\\\n    \\ locations)\\\\\\\\n- Complete project context in a single\\\\\\n    \\\\ file\\\\\\\\n- Multiple\\\n    \\ output formats (Markdown, JSON, YAML)\\\\\\\\n- Optimized for token\\\\\\n    \\\\ efficiency\\\\\\\n    \\\\n\\\\\\\",\\\\n    \\\\\\\"pyproject.toml\\\\\\\": \\\\\\\"[build-system]\\\\\\\\nrequires = [\\\\\\\\\\\n    \\\\\\\"\\\\\\n    setuptools>=68\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"wheel\\\\\\\\\\\\\\\"]\\\\\\\\nbuild-backend =\\\n    \\ \\\\\\\\\\\\\\\"setuptools.build_meta\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\n\\\\\\\\n[project]\\\\\\\\nname =\\\n    \\ \\\\\\\\\\\\\\\"rcpack\\\\\\\\\\\\\\\"\\\\\\\\nversion = \\\\\\\\\\\\\\\"0.1.0\\\\\\\\\\\\\\\"\\\\\\\\ndescription\\\\\\\n    \\n    \\\\ = \\\\\\\\\\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\\\\\\\\\"\\\\\\\\nreadme\\\n    \\ = \\\\\\\\\\\\\\\"README.md\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\nrequires-python = \\\\\\\\\\\\\\\">=3.9\\\\\\\\\\\\\\\n    \\\"\\\\\\\\nlicense = { text = \\\\\\\\\\\\\\\"MIT\\\\\\\\\\\\\\\" }\\\\\\\\ndependencies\\\\\\n    \\\\ = [\\\\\\\n    \\\\n    \\\\\\\\\\\\\\\"PyYAML>=6.0\\\\\\\\\\\\\\\"\\\\\\\\n]\\\\\\\\n\\\\\\\\n[project.scripts]\\\\\\\\nrepo-contextor\\\n    \\ =\\\\\\n    \\\\ \\\\\\\\\\\\\\\"rcpack.cli:main\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/__init__.py\\\\\\\n    \\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\n    Repository Context Packager - CLI tool\\\n    \\ for creating LLM-optimized repository context.\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    \\\"\\\\\\\\n\\\\\\\\n__version__ = \\\\\\\\\\\\\\\"0.1.0\\\\\\\\\\\\\\\"\\\\\\\\n__author__ = \\\\\\\\\\\\\\\"Abhinav\\\\\\\n    \\\\\\\\\\\"\\\\\\\\n__description__\\\\\\n    \\\\ = \\\\\\\\\\\\\\\"Repository Context Packager CLI\\\n    \\ for LLMs\\\\\\\\\\\\\\\"\\\\\\\",\\\\n    \\\\\\\"src/rcpack/__main__.py\\\\\\\"\\\\\\n    : \\\\\\\"#!/usr/bin/env\\\n    \\ python3\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Module entry point to enable `python\\\\\\n\\\n    \\    \\\\ -m rcpack`.\\\\\\\\n\\\\\\\\nThis simply delegates to the CLI's main() function.\\\\\\\n    \\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom .cli import main\\\\\\\\n\\\\\\\\n\\\\\\\n    \\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\":\\\\\\\\n\\\\\\n    \\\\    main()\\\\\\\\n\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/cli.py\\\\\\\": \\\\\\\"#!/usr/bin/env python3\\\\\\\\\\\\\\n\\\n    \\    n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"CLI for Repository Context Packager.\\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom .config_loader\\\\\\n    \\\\ import load_config\\\\\\\\n\\\\\\\\\\\n    nimport argparse\\\\\\\\nimport sys\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\n    nfrom\\\n    \\ .gitinfo import get_git_info\\\\\\\\nfrom .discover import discover_files\\\\\\\\nfrom\\\\\\\n    \\n    \\\\ .treeview import create_tree_view\\\\\\\\nfrom .renderer.markdown import\\\n    \\ render_markdown\\\\\\\\\\\\\\n    nfrom .renderer.jsonyaml import render_json, render_yaml\\\\\\\n    \\\\nfrom .io_utils import\\\\\\n    \\\\ write_output\\\\\\\\nfrom datetime import datetime,\\\n    \\ timedelta\\\\\\\\n\\\\\\\\n\\\\\\\\ndef log_verbose(message:\\\\\\n    \\\\ str, verbose: bool)\\\n    \\ -> None:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Log a message to stderr if verbose\\\\\\\n    \\n    \\\\ mode is enabled.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if verbose:\\\\\\\\n   \\\n    \\     print(message, file=sys.stderr)\\\\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\\ndef get_rendered_content(format_type:\\\n    \\ str, repo_path: str, repo_info: dict,\\\\\\n    \\\\ tree_text: str, \\\\\\\\n      \\\n    \\                  files_data: dict, total_files: int,\\\\\\n    \\\\ total_lines:\\\n    \\ int, \\\\\\\\n                        recent_files_info: dict, file_sizes:\\\\\\n \\\n    \\   \\\\ dict) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get rendered content based\\\n    \\ on the specified\\\\\\n    \\\\ format.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if format_type\\\n    \\ == \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\":\\\\\\\\n        return render_json(\\\\\\\\\\\\\\n    n      \\\n    \\      repo_path, repo_info, tree_text, \\\\\\\\n            files_data, total_files,\\\\\\\n    \\n    \\\\ total_lines,\\\\\\\\n            recent_files=recent_files_info,\\\\\\\\n   \\\n    \\         file_sizes=file_sizes\\\\\\\\\\\\\\n    n        )\\\\\\\\n    elif format_type\\\n    \\ == \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\":\\\\\\\\n        return render_yaml(\\\\\\\\\\\\\\n    n      \\\n    \\      repo_path, repo_info, tree_text, \\\\\\\\n            files_data, total_files,\\\\\\\n    \\n    \\\\ total_lines,\\\\\\\\n            recent_files=recent_files_info,\\\\\\\\n   \\\n    \\         file_sizes=file_sizes\\\\\\\\\\\\\\n    n        )\\\\\\\\n    else:  # text/markdown\\\\\\\n    \\\\n        return render_markdown(\\\\\\\\n \\\\\\n    \\\\           repo_path, repo_info,\\\n    \\ tree_text, \\\\\\\\n            files_data, total_files,\\\\\\n    \\\\ total_lines,\\\\\\\n    \\\\n            recent_files=recent_files_info,\\\\\\\\n            file_sizes=file_sizes\\\\\\\n    \\\\\\\\\\n    n        )\\\\\\\\n\\\\\\\\n\\\\\\\\ndef process_file(file_path: Path, repo_path:\\\n    \\ Path, verbose:\\\\\\n    \\\\ bool) -> tuple[str, str, str]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"Process a single file and return\\\\\\n    \\\\ its data.\\\\\\\\n    \\\\\\\\\\\n    n    Returns:\\\\\\\\n        tuple: (relative_path_str, content,\\\\\\n    \\\\ file_size)\\\\\\\n    \\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    relative_path = file_path.relative_to(repo_path)\\\\\\\n    \\\\\\\\\\n    n    relative_path_str = str(relative_path)\\\\\\\\n    \\\\\\\\n    log_verbose(f\\\\\\\n    \\\\\\\\\\\"Reading\\\\\\n    \\\\ file: {relative_path}\\\\\\\\\\\\\\\", verbose)\\\\\\\\n    file_size\\\n    \\ = file_path.stat().st_size\\\\\\\\\\\\\\n    n    \\\\\\\\n    try:\\\\\\\\n        with open(file_path,\\\n    \\ 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\n    n            content = f.read()\\\\\\\\\\\n    n        return relative_path_str, content, str(file_size)\\\\\\\\\\\\\\n    n    except\\\n    \\ (UnicodeDecodeError, PermissionError):\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\"\\\\\\n\\\n    \\    Skipping binary/unreadable file: {relative_path}\\\\\\\\\\\\\\\", verbose)\\\\\\\\n \\\n    \\       file_size\\\\\\n    \\\\ = file_path.stat().st_size if file_path.exists() else\\\n    \\ 0\\\\\\\\n        content =\\\\\\n    \\\\ f\\\\\\\\\\\\\\\"[Binary or unreadable file: {file_path.name}]\\\\\\\n    \\\\\\\\\\\"\\\\\\\\n        return relative_path_str,\\\\\\n    \\\\ content, str(file_size)\\\\\\\n    \\\\n    except Exception:\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\"\\\\\\n    Error reading\\\n    \\ file: {relative_path}\\\\\\\\\\\\\\\", verbose)\\\\\\\\n        raise  # Re-raise\\\\\\n  \\\n    \\  \\\\ to handle in calling code\\\\\\\\n\\\\\\\\n\\\\\\\\ndef handle_output(content: str,\\\n    \\ output_path:\\\\\\n    \\\\ str = None) -> None:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\n    Handle output to either file or stdout.\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n \\\n    \\   if output_path:\\\\\\\\n        # Write to file\\\\\\\\n        write_output(output_path,\\\\\\\n    \\n    \\\\ content)\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Context package created: {output_path}\\\\\\\n    \\\\\\\\\\\")\\\\\\\\\\\\\\n    n    else:\\\\\\\\n        # Output to stdout\\\\\\\\n        print(content)\\\\\\\n    \\\\n\\\\\\\\n\\\\\\\\ndef main():\\\\\\\\\\\\\\n    n    parser = argparse.ArgumentParser(\\\\\\\\\\\n    n        description=\\\\\\\\\\\\\\\"Package repository\\\\\\n    \\\\ content for LLM context\\\\\\\n    \\\\\\\\\\\"\\\\\\\\n    )\\\\\\\\n    parser.add_argument(\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\n    path\\\\\\\n    \\\\\\\\\\\", \\\\\\\\n        nargs=\\\\\\\\\\\\\\\"?\\\\\\\\\\\\\\\", \\\\\\\\n        default=\\\\\\\\\\\\\\\".\\\\\\\n    \\\\\\\\\\\", \\\\\\\\n      \\\\\\n    \\\\  help=\\\\\\\\\\\\\\\"Repository path (default: current\\\n    \\ directory)\\\\\\\\\\\\\\\"\\\\\\\\n    )\\\\\\\\n    parser.add_argument(\\\\\\\\\\\\\\n    n     \\\n    \\   \\\\\\\\\\\\\\\"-o\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--output\\\\\\\\\\\\\\\", \\\\\\\\n        help=\\\\\\\\\\\\\\\"Output\\\n    \\ file path (default:\\\\\\n    \\\\ stdout)\\\\\\\\\\\\\\\"\\\\\\\\n    )\\\\\\\\n    parser.add_argument(\\\\\\\n    \\\\n        \\\\\\\\\\\\\\\"-f\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--format\\\\\\\\\\\\\\n    \\\\\\\", \\\\\\\\n       \\\n    \\ choices=[\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\"],\\\n    \\ \\\\\\\\n       \\\\\\n    \\\\ default=\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\",\\\\\\\\n        help=\\\\\\\\\\\\\\\n    \\\"Output format (default: text)\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\n    n    )\\\\\\\\n\\\\\\\\n    \\\\\\\\\\\\\\\"\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" This will read -r from the console and able to search\\\\\\n   \\\n    \\ \\\\ it with this\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    parser.add_argument(\\\\\\\\n  \\\n    \\  \\\\\\\\\\\\\\\"-r\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--recent\\\\\\\\\\\\\\n    \\\\\\\",\\\\\\\\n    action=\\\\\\\\\\\\\\\n    \\\"store_true\\\\\\\\\\\\\\\",\\\\\\\\n    help=\\\\\\\\\\\\\\\"Include only files modified\\\\\\n   \\\n    \\ \\\\ in the last 7 days\\\\\\\\\\\\\\\"\\\\\\\\n    )\\\\\\\\n    parser.add_argument(\\\\\\\\n  \\\n    \\      \\\\\\\\\\\\\\\"-v\\\\\\\\\\\\\\n    \\\\\\\", \\\\\\\\\\\\\\\"--verbose\\\\\\\\\\\\\\\",\\\\\\\\n        action=\\\\\\\n    \\\\\\\\\\\"store_true\\\\\\\\\\\\\\\",\\\\\\\\n        help=\\\\\\\\\\\\\\\"\\\\\\n    Print detailed progress\\\n    \\ information to stderr\\\\\\\\\\\\\\\"\\\\\\\\n    )\\\\\\\\n    \\\\\\\\n    args =\\\\\\n    \\\\ parser.parse_args()\\\\\\\n    \\\\n    \\\\\\\\n    try:\\\\\\\\n        repo_path = Path(args.path).resolve()\\\\\\\\\\\\\\n\\\n    \\    n        if not repo_path.exists():\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error:\\\n    \\ Path {repo_path}\\\\\\n    \\\\ does not exist\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\n   \\\n    \\         sys.exit(1)\\\\\\\\n          \\\\\\n    \\\\  \\\\\\\\n        # Get repository\\\n    \\ information\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\"Analyzing\\\\\\n    \\\\ repository:\\\n    \\ {repo_path}\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n        repo_info = get_git_info(repo_path)\\\\\\\n    \\\\\\\\\\n    n        \\\\\\\\n        # Discover files\\\\\\\\n        log_verbose(f\\\\\\\\\\\n    \\\\\\\"Discovering files\\\\\\n    \\\\ in: {repo_path}\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n  \\\n    \\      discovered_files = discover_files([repo_path],\\\\\\n    \\\\ repo_path, [],\\\n    \\ [])\\\\\\\\n        log_verbose(f\\\\\\\\\\\\\\\"Found {len(discovered_files)}\\\\\\n    \\\\\\\n    \\ files\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n        \\\\\\\\n        # will check the file\\\n    \\ in last\\\\\\n    \\\\ 7 days\\\\\\\\n        recent_files_info = {}\\\\\\\\n        if args.recent:\\\\\\\n    \\\\n       \\\\\\n    \\\\     seven_days_ago = datetime.now() - timedelta(days=7)\\\\\\\n    \\\\n            recent_files\\\\\\n    \\\\ = []\\\\\\\\n            for f in discovered_files:\\\\\\\n    \\\\n                try:\\\\\\\\n    \\\\\\n    \\\\                mtime = datetime.fromtimestamp(f.stat().st_mtime)\\\\\\\n    \\\\n        \\\\\\n    \\\\            if mtime >= seven_days_ago:\\\\\\\\n            \\\n    \\            recent_files.append(f)\\\\\\\\\\\\\\n    n                        recent_files_info[str(f.relative_to(repo_path))]\\\n    \\ = human_readable_age(mtime)\\\\\\n    \\\\     \\\\\\\\n                except Exception:\\\\\\\n    \\\\n                    continue\\\\\\\\n \\\\\\n    \\\\           discovered_files = recent_files\\\\\\\n    \\\\n        \\\\\\\\n        # Read file contents\\\\\\\\\\\\\\n    n        files_data =\\\n    \\ {}\\\\\\\\n        file_sizes = {}\\\\\\\\n        for file_path in\\\\\\n    \\\\ discovered_files:\\\\\\\n    \\\\n            try:\\\\\\\\n                relative_path_str, content,\\\\\\n    \\\\\\\n    \\ file_size = process_file(file_path, repo_path, args.verbose)\\\\\\\\n          \\\n    \\  \\\\\\n    \\\\    files_data[relative_path_str] = content\\\\\\\\n                file_sizes[relative_path_str]\\\\\\\n    \\n    \\\\ = file_size\\\\\\\\n            except Exception:\\\\\\\\n                continue\\\\\\\n    \\\\n  \\\\\\n    \\\\      \\\\\\\\n        # Create tree view\\\\\\\\n        log_verbose(\\\\\\\n    \\\\\\\\\\\"Generating directory\\\\\\n    \\\\ tree\\\\\\\\\\\\\\\", args.verbose)\\\\\\\\n        tree_text\\\n    \\ = create_tree_view(repo_path, files_data)\\\\\\\\\\\\\\n    n        \\\\\\\\n        #\\\n    \\ Count totals\\\\\\\\n        total_files = len(files_data)\\\\\\\\n\\\\\\n    \\\\      \\\n    \\  total_lines = sum(len(content.splitlines()) for _, content in files_data.items())\\\\\\\n    \\\\\\\\\\n    n        \\\\\\\\n        # Render based on format\\\\\\\\n        log_verbose(f\\\\\\\n    \\\\\\\\\\\"Rendering\\\\\\n    \\\\ output in {args.format} format\\\\\\\\\\\\\\\", args.verbose)\\\\\\\n    \\\\n        content = get_rendered_content(\\\\\\\\\\\\\\n    n            args.format,\\\n    \\ str(repo_path), repo_info, tree_text,\\\\\\\\n           \\\\\\n    \\\\ files_data,\\\n    \\ total_files, total_lines,\\\\\\\\n            recent_files_info if args.recent\\\\\\\n    \\n    \\\\ else {},\\\\\\\\n            file_sizes\\\\\\\\n        )\\\\\\\\n        \\\\\\\\n \\\n    \\       handle_output(content,\\\\\\n    \\\\ args.output)\\\\\\\\n        \\\\\\\\n    except\\\n    \\ Exception as e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Error:\\\\\\n    \\\\ {e}\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\n    \\\\n        sys.exit(1)\\\\\\\\n\\\\\\\\n# this will convert age\\\\\\n    \\\\ and give us\\\n    \\ the difference\\\\\\\\ndef human_readable_age(mtime: datetime) -> str:\\\\\\\\\\\\\\n \\\n    \\   n    delta = datetime.now() - mtime\\\\\\\\n    days = delta.days\\\\\\\\n    seconds\\\n    \\ = delta.seconds\\\\\\\\\\\\\\n    n    if days > 0:\\\\\\\\n        return f\\\\\\\\\\\\\\\"{days}\\\n    \\ day{'s' if days != 1 else ''} ago\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\n    elif seconds >= 3600:\\\\\\\n    \\\\n        hours = seconds // 3600\\\\\\\\n        return\\\\\\n    \\\\ f\\\\\\\\\\\\\\\"{hours}\\\n    \\ hour{'s' if hours != 1 else ''} ago\\\\\\\\\\\\\\\"\\\\\\\\n    elif seconds >= 60:\\\\\\\\\\\\\\\n    \\n    n        minutes = seconds // 60\\\\\\\\n        return f\\\\\\\\\\\\\\\"{minutes} minute{'s'\\\n    \\ if\\\\\\n    \\\\ minutes != 1 else ''} ago\\\\\\\\\\\\\\\"\\\\\\\\n    else:\\\\\\\\n        return\\\n    \\ \\\\\\\\\\\\\\\"just now\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\n    n\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\n    \\\\\\\":\\\\\\\\n    main()\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/config_loader.py\\\\\\\"\\\\\\n \\\n    \\   : \\\\\\\"# src/rcpack/config_loader.py\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nTOML\\\n    \\ config loader for Repo-Contextor.\\\\\\\\\\\\\\n    n\\\\\\\\nRules:\\\\\\\\n- Look for .repo-contextor.toml\\\n    \\ in the CURRENT directory\\\\\\\\n- If missing:\\\\\\n    \\\\ ignore\\\\\\\\n- If present\\\n    \\ but invalid: print a clear error and exit(1)\\\\\\\\n- Only\\\\\\n    \\\\ recognized\\\n    \\ keys are applied; unknown keys ignored\\\\\\\\n- Precedence: CLI > TOML\\\\\\n    \\\\\\\n    \\ > DEFAULTS\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nfrom __future__ import annotations\\\\\\\n    \\\\nimport os,\\\\\\n    \\\\ sys\\\\\\\\nfrom typing import Dict, Iterable, Any\\\\\\\\n\\\\\\\\\\\n    ntry:\\\\\\\\n    import tomllib\\\\\\\\\\\\\\n    n    _loads = tomllib.loads\\\\\\\\nexcept\\\n    \\ ModuleNotFoundError:\\\\\\\\n    try:\\\\\\\\n      \\\\\\n    \\\\  import tomli\\\\\\\\n  \\\n    \\      _loads = tomli.loads\\\\\\\\n    except ModuleNotFoundError:\\\\\\\\\\\\\\n    n \\\n    \\       _loads = None\\\\\\\\n\\\\\\\\ndef _need_toml():\\\\\\\\n    if _loads is None:\\\\\\\\\\\n    n    \\\\\\n    \\\\    print(\\\\\\\\\\\\\\\"Error: TOML parser not available. Use Python\\\n    \\ 3.11+ or `pip install\\\\\\n    \\\\ tomli`.\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\n     \\\n    \\   sys.exit(1)\\\\\\\\n\\\\\\\\ndef _load_toml(dotfile:\\\\\\n    \\\\ str) -> Dict[str, Any]:\\\\\\\n    \\\\n    _need_toml()\\\\\\\\n    if not os.path.exists(dotfile):\\\\\\\\\\\\\\n    n     \\\n    \\   return {}\\\\\\\\n    try:\\\\\\\\n        with open(dotfile, \\\\\\\\\\\\\\\"rb\\\\\\\\\\\\\\\")\\\n    \\ as f:\\\\\\\\\\\\\\n    n            raw = f.read().decode(\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", errors=\\\\\\\n    \\\\\\\\\\\"strict\\\\\\\\\\\\\\\")\\\\\\\\n  \\\\\\n    \\\\      data = _loads(raw)\\\\\\\\n        return\\\n    \\ data if isinstance(data, dict) else\\\\\\n    \\\\ {}\\\\\\\\n    except Exception as\\\n    \\ e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Error: failed to parse\\\\\\n    \\\\ {dotfile} as\\\n    \\ TOML.\\\\\\\\\\\\\\\\n{e}\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\\n        sys.exit(1)\\\\\\\\n\\\\\\\\\\\n    \\\\\\n    ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str,\\\n    \\ Any]:\\\\\\\\\\\\\\n    n    ks = set(known)\\\\\\\\n    return {k: v for k, v in d.items()\\\n    \\ if k in ks}\\\\\\\\n\\\\\\\\\\\\\\n    ndef _merge(defaults: Dict[str, Any], filecfg: Dict[str,\\\n    \\ Any], clicfg: Dict[str,\\\\\\n    \\\\ Any], known: Iterable[str]) -> Dict[str, Any]:\\\\\\\n    \\\\n    ks = set(known)\\\\\\\\n    out:\\\\\\n    \\\\ Dict[str, Any] = {k: defaults.get(k)\\\n    \\ for k in ks}\\\\\\\\n    for src in (filecfg,\\\\\\n    \\\\ clicfg):\\\\\\\\n        for\\\n    \\ k, v in src.items():\\\\\\\\n            if k in ks and v is\\\\\\n    \\\\ not None:\\\\\\\n    \\\\n                out[k] = v\\\\\\\\n    return out\\\\\\\\n\\\\\\\\ndef load_config(*,\\\\\\\n    \\n    \\\\ dotfile: str = \\\\\\\\\\\\\\\".repo-contextor.toml\\\\\\\\\\\\\\\", defaults: Dict[str,\\\n    \\ Any] | None\\\\\\n    \\\\ = None, cli_cfg: Dict[str, Any] | None = None, known_keys:\\\n    \\ Iterable[str] = ())\\\\\\n    \\\\ -> Dict[str, Any]:\\\\\\\\n    defaults = defaults\\\n    \\ or {}\\\\\\\\n    cli_cfg = cli_cfg or\\\\\\n    \\\\ {}\\\\\\\\n    known = tuple(known_keys)\\\\\\\n    \\\\n    filecfg = _filter_known(_load_toml(dotfile),\\\\\\n    \\\\ known)\\\\\\\\n    return\\\n    \\ _merge(defaults, filecfg, cli_cfg, known)\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"\\\\\\n    src/rcpack/discover.py\\\\\\\n    \\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"File discovery module for repository analysis.\\\\\\\n    \\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing\\\n    \\ import List\\\\\\\\nimport fnmatch\\\\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\\ndef discover_files(\\\\\\\\\\\n    n    inputs: List[Path],\\\\\\\\n    root: Path,\\\\\\\\n    include_patterns:\\\\\\n   \\\n    \\ \\\\ List[str],\\\\\\\\n    exclude_patterns: List[str],\\\\\\\\n) -> List[Path]:\\\\\\\\\\\n    n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"Discover relevant files.\\\\\\\\n\\\\\\\\n    - inputs:\\\n    \\ list of files/dirs to scan\\\\\\\\\\\\\\n    n    - root: common project root; patterns\\\n    \\ are matched against POSIX paths relative\\\\\\n    \\\\ to root\\\\\\\\n    - include_patterns:\\\n    \\ glob patterns to include (if empty, use sensible\\\\\\n    \\\\ defaults)\\\\\\\\n  \\\n    \\  - exclude_patterns: glob patterns to exclude\\\\\\\\n    Returns a\\\\\\n    \\\\ list\\\n    \\ of absolute Paths to files.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    default_include_exts\\\\\\\n    \\n    \\\\ = {\\\\\\\\n        '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp',\\\n    \\ '.c', '.h',\\\\\\\\\\\\\\n    n        '.cs', '.php', '.rb', '.go', '.rs', '.swift',\\\n    \\ '.kt', '.scala',\\\\\\\\n   \\\\\\n    \\\\     '.html', '.css', '.scss', '.sass', '.less',\\\n    \\ '.vue', '.svelte',\\\\\\\\n      \\\\\\n    \\\\  '.md', '.txt', '.rst', '.yaml', '.yml',\\\n    \\ '.json', '.toml', '.ini',\\\\\\\\n      \\\\\\n    \\\\  '.cfg', '.conf', '.xml', '.sql',\\\n    \\ '.sh', '.bash', '.zsh', '.fish',\\\\\\\\n    }\\\\\\\\\\\\\\n    n\\\\\\\\n    always_include_names\\\n    \\ = {\\\\\\\\n        'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING',\\\\\\n    \\\\\\\n    \\ 'Makefile',\\\\\\\\n        'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\\\\\\\n    \\\\\\\\\\n    n        'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore',\\\n    \\ '.gitattributes'\\\\\\\\\\\\\\n    n    }\\\\\\\\n\\\\\\\\n    skip_dir_names = {\\\\\\\\n    \\\n    \\    '.git', '.svn', '.hg', '__pycache__',\\\\\\n    \\\\ '.pytest_cache',\\\\\\\\n   \\\n    \\     'node_modules', '.venv', 'venv', 'env', '.env',\\\\\\\\\\\\\\n    n        'build',\\\n    \\ 'dist', 'target', 'out', '.next', '.nuxt',\\\\\\\\n        '.idea',\\\\\\n    \\\\ '.vscode',\\\n    \\ '.vs', 'coverage', '.coverage'\\\\\\\\n    }\\\\\\\\n\\\\\\\\n    def matches_any(patterns:\\\\\\\n    \\n    \\\\ List[str], rel_posix: str) -> bool:\\\\\\\\n        return any(fnmatch.fnmatch(rel_posix,\\\\\\\n    \\n    \\\\ pat) for pat in patterns)\\\\\\\\n\\\\\\\\n    def should_take(file_path: Path)\\\n    \\ -> bool:\\\\\\\\\\\\\\n    n        rel_posix = file_path.relative_to(root).as_posix()\\\\\\\n    \\\\n        if exclude_patterns\\\\\\n    \\\\ and matches_any(exclude_patterns, rel_posix):\\\\\\\n    \\\\n            return False\\\\\\\\n\\\\\\n    \\\\        if include_patterns:\\\\\\\\n  \\\n    \\          return matches_any(include_patterns,\\\\\\n    \\\\ rel_posix)\\\\\\\\n    \\\n    \\    # default include logic\\\\\\\\n        return file_path.name\\\\\\n    \\\\ in always_include_names\\\n    \\ or file_path.suffix.lower() in default_include_exts\\\\\\\\\\\\\\n    n\\\\\\\\n    discovered:\\\n    \\ list[Path] = []\\\\\\\\n    seen = set()\\\\\\\\n\\\\\\\\n    for item in inputs:\\\\\\\\\\\\\\n\\\n    \\    n        p = item.resolve()\\\\\\\\n        if p.is_file():\\\\\\\\n            #\\\n    \\ Skip if\\\\\\n    \\\\ excluded or in skipped directory\\\\\\\\n            if any(part\\\n    \\ in skip_dir_names\\\\\\n    \\\\ for part in p.parts):\\\\\\\\n                continue\\\\\\\n    \\\\n            if should_take(p):\\\\\\\\\\\\\\n    n                key = p.as_posix()\\\\\\\n    \\\\n                if key not in seen:\\\\\\\\n \\\\\\n    \\\\                   seen.add(key)\\\\\\\n    \\\\n                    discovered.append(p)\\\\\\\\\\\\\\n    n        elif p.is_dir():\\\\\\\n    \\\\n            for child in p.rglob('*'):\\\\\\\\n        \\\\\\n    \\\\        if not\\\n    \\ child.is_file():\\\\\\\\n                    continue\\\\\\\\n           \\\\\\n    \\\\\\\n    \\     if any(part in skip_dir_names for part in child.parts):\\\\\\\\n           \\\n    \\  \\\\\\n    \\\\       continue\\\\\\\\n                if should_take(child):\\\\\\\\n \\\n    \\                \\\\\\n    \\\\   key = child.resolve().as_posix()\\\\\\\\n          \\\n    \\          if key not in seen:\\\\\\\\\\\\\\n    n                        seen.add(key)\\\\\\\n    \\\\n                        discovered.append(child.resolve())\\\\\\\\\\\\\\n    n\\\\\\\\\\\n    n    return sorted(discovered)\\\\\\\",\\\\n    \\\\\\\"src/rcpack/gitinfo.py\\\\\\\": \\\\\\\"\\\n    from __future__\\\\\\n    \\\\ import annotations\\\\\\\\n\\\\\\\\nimport subprocess\\\\\\\\nfrom\\\n    \\ pathlib import Path\\\\\\\\nfrom\\\\\\n    \\\\ typing import Dict, Any\\\\\\\\n\\\\\\\\n\\\\\\\\\\\n    ndef _git(cmd: list[str], cwd: Path) -> str:\\\\\\\\\\\\\\n    n    # Validate git commands\\\n    \\ to prevent injection\\\\\\\\n    allowed_commands = {\\\\\\\\\\\\\\n    n        \\\\\\\\\\\\\\\n    \\\"rev-parse\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"show\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"log\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"status\\\\\\\n    \\\\\\\\\\\", \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\n    \\\\\\\", \\\\\\\\\\\\\\\"config\\\\\\\\\\\\\\\"\\\\\\\\n    }\\\\\\\\n\\\n    \\    if not cmd or cmd[0] not in allowed_commands:\\\\\\\\\\\\\\n    n        raise ValueError(f\\\\\\\n    \\\\\\\\\\\"Git command not allowed: {cmd[0] if cmd else 'empty'}\\\\\\\\\\\\\\n    \\\\\\\")\\\\\\\n    \\\\n    \\\\\\\\n    out = subprocess.check_output([\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\", *cmd], cwd=str(cwd),\\\\\\\n    \\n    \\\\ timeout=30)\\\\\\\\n    return out.decode(\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", errors=\\\\\\\n    \\\\\\\\\\\"replace\\\\\\\\\\\\\\\").strip()\\\\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\\ndef is_git_repo(path: Path)\\\n    \\ -> bool:\\\\\\\\n    try:\\\\\\\\n        flag = _git([\\\\\\\\\\\\\\n    \\\\\\\"rev-parse\\\\\\\\\\\n    \\\\\\\", \\\\\\\\\\\\\\\"--is-inside-work-tree\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\\n        return flag\\\\\\\n    \\n    \\\\ == \\\\\\\\\\\\\\\"true\\\\\\\\\\\\\\\"\\\\\\\\n    except Exception:\\\\\\\\n        return\\\n    \\ False\\\\\\\\n\\\\\\\\n\\\\\\\\ndef get_git_info(path:\\\\\\n    \\\\ Path) -> Dict[str, Any]:\\\\\\\n    \\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Return info for the current\\\\\\n    \\\\\\\n    \\ HEAD of a repo rooted at `path`.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\n    \\\\n        commit\\\\\\n    \\\\ = _git([\\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"HEAD\\\\\\\\\\\n    \\\\\\\"], cwd=path)\\\\\\\\n        branch = _git([\\\\\\\\\\\\\\n    \\\\\\\"rev-parse\\\\\\\\\\\\\\\"\\\n    , \\\\\\\\\\\\\\\"--abbrev-ref\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"HEAD\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\\n        author\\\\\\\n    \\n    \\\\ = _git([\\\\\\\\\\\\\\\"show\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"-s\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--format=%an\\\n    \\ <%ae>\\\\\\\\\\\\\\\"], cwd=path)\\\\\\\\n\\\\\\n    \\\\        date = _git([\\\\\\\\\\\\\\\"show\\\\\\\\\\\n    \\\\\\\", \\\\\\\\\\\\\\\"-s\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--date=local\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"--format=%ad\\\\\\\n    \\\\\\\\\\n    \\\\\\\"], cwd=path)\\\\\\\\n        return {\\\\\\\\n            \\\\\\\\\\\\\\\"is_repo\\\\\\\n    \\\\\\\\\\\": True,\\\\\\\\n    \\\\\\n    \\\\        \\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\": commit,\\\\\\\\n \\\n    \\           \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\": branch,\\\\\\\\n    \\\\\\n    \\\\        \\\\\\\\\\\\\\\"\\\n    author\\\\\\\\\\\\\\\": author,\\\\\\\\n            \\\\\\\\\\\\\\\"date\\\\\\\\\\\\\\\": date,\\\\\\\\n     \\\n    \\   \\\\\\n    \\\\    \\\\\\\\\\\\\\\"note\\\\\\\\\\\\\\\": None,\\\\\\\\n        }\\\\\\\\n    except Exception:\\\\\\\n    \\\\n        # treat\\\\\\n    \\\\ as not a repo if anything fails\\\\\\\\n        return\\\n    \\ {\\\\\\\\n            \\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\\\\n    \\\\\\\": False,\\\\\\\\n            \\\\\\\n    \\\\\\\\\\\"commit\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\": None,\\\\\\\\\\\\\\\n    \\n    n            \\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"date\\\\\\\n    \\\\\\\\\\\": None,\\\\\\\\n      \\\\\\n    \\\\      \\\\\\\\\\\\\\\"note\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Not a git\\\n    \\ repository\\\\\\\\\\\\\\\",\\\\\\\\n        }\\\\\\\\n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/io_utils.py\\\\\\\n    \\\"\\\\\\n    : \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"I/O utilities for file operations.\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom pathlib\\\\\\n    \\\\ import Path\\\\\\\\nfrom typing\\\n    \\ import Tuple\\\\\\\\n\\\\\\\\n\\\\\\\\ndef write_output(output_path:\\\\\\n    \\\\ str, content:\\\n    \\ str) -> None:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Write content to output file.\\\\\\\n    \\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    output_file = Path(output_path)\\\\\\\\n  \\\n    \\  \\\\\\\\n    # Create parent\\\\\\n    \\\\ directories if they don't exist\\\\\\\\n   \\\n    \\ output_file.parent.mkdir(parents=True,\\\\\\n    \\\\ exist_ok=True)\\\\\\\\n    \\\\\\\\\\\n    n    # Write content\\\\\\\\n    with open(output_file, 'w',\\\\\\n    \\\\ encoding='utf-8')\\\n    \\ as f:\\\\\\\\n        f.write(content)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef is_binary_file(path:\\\\\\n\\\n    \\    \\\\ Path, sniff_bytes: int = 2048) -> bool:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    \\\"Heuristically determine\\\\\\n    \\\\ if a file is binary by scanning for NUL bytes.\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n   \\\\\\n    \\\\     with open(path, 'rb')\\\n    \\ as fb:\\\\\\\\n            chunk = fb.read(sniff_bytes)\\\\\\\\\\\\\\n    n        if b\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\\x00\\\\\\\\\\\\\\\" in chunk:\\\\\\\\n            return True\\\\\\\\n        #\\\n    \\ If\\\\\\n    \\\\ the chunk has a lot of non-text bytes, consider it binary\\\\\\\\n\\\n    \\        text_byte_count\\\\\\n    \\\\ = sum(32 <= b <= 126 or b in (9, 10, 13) for\\\n    \\ b in chunk)\\\\\\\\n        return (len(chunk)\\\\\\n    \\\\ - text_byte_count) > max(1,\\\n    \\ len(chunk) // 3)\\\\\\\\n    except Exception:\\\\\\\\n    \\\\\\n    \\\\    # If we cannot\\\n    \\ read, treat as binary to avoid further processing\\\\\\\\n     \\\\\\n    \\\\   return\\\n    \\ True\\\\\\\\n\\\\\\\\n\\\\\\\\ndef read_text_safely(path: Path, max_bytes: int = 16_384)\\\\\\\n    \\n    \\\\ -> Tuple[str, str, bool]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Read a text\\\n    \\ file safely with size\\\\\\n    \\\\ limit and encoding fallbacks.\\\\\\\\n\\\\\\\\n    Returns\\\n    \\ (content, encoding_used, truncated).\\\\\\\\\\\\\\n    n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\n    \\\\\\\\n    truncated = False\\\\\\\\n    raw: bytes\\\\\\\\n    with open(path,\\\\\\n    \\\\\\\n    \\ 'rb') as fb:\\\\\\\\n        raw = fb.read(max_bytes + 1)\\\\\\\\n    if len(raw) >\\\n    \\ max_bytes:\\\\\\\\\\\\\\n    n        truncated = True\\\\\\\\n        raw = raw[:max_bytes]\\\\\\\n    \\\\n\\\\\\\\n    for enc in\\\\\\n    \\\\ (\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"utf-16\\\\\\\\\\\\\\\"\\\n    , \\\\\\\\\\\\\\\"utf-16-le\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"utf-16-be\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"latin-1\\\\\\\\\\\\\\n\\\n    \\    \\\\\\\"):\\\\\\\\n        try:\\\\\\\\n            text = raw.decode(enc)\\\\\\\\n     \\\n    \\       return\\\\\\n    \\\\ text, enc, truncated\\\\\\\\n        except Exception:\\\\\\\\\\\n    n            continue\\\\\\\\n \\\\\\n    \\\\   # Fallback: replace errors with utf-8\\\\\\\n    \\\\n    text = raw.decode(\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\"\\\\\\n    , errors=\\\\\\\\\\\\\\\"replace\\\\\\\n    \\\\\\\\\\\")\\\\\\\\n    return text, \\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\", truncated\\\\\\\",\\\\n   \\\\\\n \\\n    \\   \\\\ \\\\\\\"src/rcpack/packager.py\\\\\\\": \\\\\\\"from __future__ import annotations\\\\\\\n    \\\\n\\\\\\\\nimport\\\\\\n    \\\\ sys\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import\\\n    \\ Iterable, Tuple\\\\\\\\n\\\\\\\\nfrom\\\\\\n    \\\\ rcpack.discover import discover_files\\\\\\\n    \\\\nfrom rcpack.gitinfo import get_git_info,\\\\\\n    \\\\ is_git_repo\\\\\\\\nfrom rcpack.io_utils\\\n    \\ import read_text_safely, is_binary_file\\\\\\\\\\\\\\n    nfrom rcpack.renderer import\\\n    \\ markdown as md_renderer\\\\\\\\nfrom rcpack.renderer.jsonyaml\\\\\\n    \\\\ import render_json,\\\n    \\ render_yaml\\\\\\\\nfrom rcpack.treeview import render_tree\\\\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\\\\\n    ndef _find_root(inputs: list[str]) -> Path:\\\\\\\\n    paths = [Path(p) for p\\\\\\n\\\n    \\    \\\\ in inputs]\\\\\\\\n    if len(paths) == 1 and Path(paths[0]).is_dir():\\\\\\\\\\\n    n        return\\\\\\n    \\\\ paths[0].resolve()\\\\\\\\n    parents = [p if p.is_dir()\\\n    \\ else p.parent for p in paths]\\\\\\\\\\\\\\n    n    root = Path(*Path.commonpath([str(p.resolve())\\\n    \\ for p in parents]).split(\\\\\\\\\\\\\\n    \\\\\\\"/\\\\\\\\\\\\\\\"))\\\\\\\\n    return root.resolve()\\\\\\\n    \\\\n\\\\\\\\n\\\\\\\\ndef build_package(\\\\\\\\n    inputs:\\\\\\n    \\\\ list[str],\\\\\\\\n    include_patterns:\\\n    \\ list[str] | None,\\\\\\\\n    exclude_patterns:\\\\\\n    \\\\ list[str] | None,\\\\\\\\\\\n    n    max_file_bytes: int,\\\\\\\\n    fmt: str = \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\n    \\\\\\\"\\\n    ,\\\\\\\\n) -> Tuple[str, dict]:\\\\\\\\n    root = _find_root(inputs)\\\\\\\\n    root_abs\\\n    \\ =\\\\\\n    \\\\ root.resolve()\\\\\\\\n\\\\\\\\n    repo_info = (\\\\\\\\n        get_git_info(root_abs)\\\n    \\ if is_git_repo(root_abs)\\\\\\n    \\\\ else {\\\\\\\\n            \\\\\\\\\\\\\\\"is_repo\\\\\\\\\\\n    \\\\\\\": False,\\\\\\\\n            \\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\": None,\\\\\\\\\\\\\\n    n      \\\n    \\      \\\\\\\\\\\\\\\"branch\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\": None,\\\\\\\n    \\\\n    \\\\\\n    \\\\        \\\\\\\\\\\\\\\"date\\\\\\\\\\\\\\\": None,\\\\\\\\n            \\\\\\\\\\\\\\\"\\\n    note\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Not a git repository\\\\\\\\\\\\\\n    \\\\\\\",\\\\\\\\n        }\\\\\\\\\\\n    n    )\\\\\\\\n\\\\\\\\n    files = discover_files(\\\\\\\\n        inputs=[Path(p)\\\\\\n  \\\n    \\  \\\\ for p in inputs],\\\\\\\\n        root=root_abs,\\\\\\\\n        include_patterns=include_patterns\\\\\\\n    \\n    \\\\ or [],\\\\\\\\n        exclude_patterns=exclude_patterns or [],\\\\\\\\n    )\\\\\\\n    \\\\n    rel_files\\\\\\n    \\\\ = [f.relative_to(root_abs) for f in files]\\\\\\\\n\\\\\\\\\\\n    n    project_tree = render_tree([p.as_posix()\\\\\\n    \\\\ for p in rel_files])\\\\\\\n    \\\\n\\\\\\\\n    file_sections: list[dict] = []\\\\\\\\n    total_lines\\\\\\n    \\\\ = 0\\\\\\\n    \\\\n    total_chars = 0\\\\\\\\n\\\\\\\\n    for f in files:\\\\\\\\n        rel = f.relative_to(root_abs).as_posix()\\\\\\\n    \\\\\\\\\\n    n        try:\\\\\\\\n            if is_binary_file(f):\\\\\\\\n           \\\n    \\     content =\\\\\\n    \\\\ f\\\\\\\\\\\\\\\"[binary file skipped: {f.name}, {f.stat().st_size}\\\n    \\ bytes]\\\\\\\\\\\\\\\"\\\\\\\\n      \\\\\\n    \\\\          file_sections.append({\\\\\\\\n   \\\n    \\                 \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": rel,\\\\\\\\n\\\\\\n    \\\\                  \\\n    \\  \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": _language_from_ext(f.suffix),\\\\\\\\n      \\\\\\n    \\\\\\\n    \\              \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": content,\\\\\\\\n                    \\\\\\\\\\\\\\\n    \\\"is_truncated\\\\\\\\\\\\\\n    \\\\\\\": False,\\\\\\\\n                })\\\\\\\\n           \\\n    \\     total_chars += len(content)\\\\\\\\\\\\\\n    n                continue\\\\\\\\n\\\\\\\\\\\n    n            content, used_encoding, truncated =\\\\\\n    \\\\ read_text_safely(f,\\\n    \\ max_bytes=max_file_bytes)\\\\\\\\n            total_lines += content.count(\\\\\\\\\\\\\\\n    \\n    \\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\") + (1 if content and not content.endswith(\\\\\\\\\\\\\\\"\\\n    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\") else 0)\\\\\\\\\\\\\\n    n            total_chars += len(content)\\\\\\\n    \\\\n\\\\\\\\n            if truncated:\\\\\\\\n   \\\\\\n    \\\\             note = f\\\\\\\\\\\\\\\n    \\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n[... TRUNCATED to first {max_file_bytes} bytes\\\\\\n    \\\\ ...]\\\\\\\n    \\\\\\\\\\\"\\\\\\\\n                content = content + note\\\\\\\\n                total_chars\\\\\\\n    \\n    \\\\ += len(note)\\\\\\\\n\\\\\\\\n            file_sections.append({\\\\\\\\n       \\\n    \\         \\\\\\\\\\\\\\\"\\\\\\n    path\\\\\\\\\\\\\\\": rel,\\\\\\\\n                \\\\\\\\\\\\\\\"language\\\\\\\n    \\\\\\\\\\\": _language_from_ext(f.suffix),\\\\\\\\\\\\\\n    n                \\\\\\\\\\\\\\\"content\\\\\\\n    \\\\\\\\\\\": content,\\\\\\\\n                \\\\\\\\\\\\\\\"is_truncated\\\\\\\\\\\\\\n    \\\\\\\": truncated,\\\\\\\n    \\\\n            })\\\\\\\\n        except Exception as exc:\\\\\\\\n        \\\\\\n    \\\\\\\n    \\    print(f\\\\\\\\\\\\\\\"[rcpack] error reading {rel}: {exc}\\\\\\\\\\\\\\\", file=sys.stderr)\\\\\\\n    \\\\n \\\\\\n    \\\\           continue\\\\\\\\n\\\\\\\\n    # render in chosen format\\\\\\\\n\\\n    \\    if fmt == \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\n    \\\\\\\":\\\\\\\\n        out_text = md_renderer.render_markdown(\\\\\\\n    \\\\n            root=str(root_abs),\\\\\\\\\\\\\\n    n            repo_info=repo_info,\\\\\\\n    \\\\n            tree_text=project_tree,\\\\\\\\n   \\\\\\n    \\\\         files=file_sections,\\\\\\\n    \\\\n            total_files=len(file_sections),\\\\\\\\\\\\\\n    n            total_lines=total_lines,\\\\\\\n    \\\\n        )\\\\\\\\n    elif fmt == \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\n    \\\\\\\":\\\\\\\\n        out_text\\\n    \\ = render_json(\\\\\\\\n            root=str(root_abs),\\\\\\\\n   \\\\\\n    \\\\       \\\n    \\  repo_info=repo_info,\\\\\\\\n            tree_text=project_tree,\\\\\\\\n      \\\\\\n\\\n    \\    \\\\      files=file_sections,\\\\\\\\n            total_files=len(file_sections),\\\\\\\n    \\\\n \\\\\\n    \\\\           total_lines=total_lines,\\\\\\\\n        )\\\\\\\\n    elif fmt\\\n    \\ == \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\"\\\\\\n    :\\\\\\\\n        out_text = render_yaml(\\\\\\\\n  \\\n    \\          root=str(root_abs),\\\\\\\\n     \\\\\\n    \\\\       repo_info=repo_info,\\\\\\\n    \\\\n            tree_text=project_tree,\\\\\\\\n        \\\\\\n    \\\\    files=file_sections,\\\\\\\n    \\\\n            total_files=len(file_sections),\\\\\\\\n   \\\\\\n    \\\\         total_lines=total_lines,\\\\\\\n    \\\\n        )\\\\\\\\n    else:\\\\\\\\n        raise ValueError(f\\\\\\\\\\\\\\n    \\\\\\\"Unsupported\\\n    \\ format: {fmt}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    stats = {\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\": len(file_sections),\\\\\\\n    \\n    \\\\ \\\\\\\\\\\\\\\"lines\\\\\\\\\\\\\\\": total_lines, \\\\\\\\\\\\\\\"chars\\\\\\\\\\\\\\\": total_chars}\\\\\\\n    \\\\n    return out_text,\\\\\\n    \\\\ stats\\\\\\\\n\\\\\\\\n\\\\\\\\ndef _language_from_ext(ext:\\\n    \\ str) -> str:\\\\\\\\n    ext = ext.lower().lstrip(\\\\\\\\\\\\\\n    \\\\\\\".\\\\\\\\\\\\\\\")\\\\\\\\\\\n    n    mapping = {\\\\\\\\n        \\\\\\\\\\\\\\\"py\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\n    \\\"js\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\n    \\\\\\\"javascript\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"ts\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\n    typescript\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\n    json\\\\\\\\\\\n    \\\\\\\", \\\\\\\\\\\\\\\"md\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"yml\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\n    \\\"yaml\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\"\\\\\\n    : \\\\\\\\\\\\\\\"yaml\\\\\\\\\\\\\\\",\\\\\\\\n     \\\n    \\   \\\\\\\\\\\\\\\"toml\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"toml\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"sh\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"bash\\\\\\\n    \\\\\\\\\\\"\\\\\\n    , \\\\\\\\\\\\\\\"c\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"c\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"cpp\\\\\\\\\\\\\\\": \\\\\\\\\\\n    \\\\\\\"cpp\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"java\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\n    java\\\\\\\\\\\\\\\"\\\n    , \\\\\\\\\\\\\\\"go\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"go\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"rs\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"rust\\\\\\\\\\\n    \\\\\\\",\\\\\\\\n    }\\\\\\\\n    return\\\\\\n    \\\\ mapping.get(ext, \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\\\\n    n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/renderer/jsonyaml.py\\\\\\\": \\\\\\\"\\\\\\n    from __future__\\\n    \\ import annotations\\\\\\\\nimport json\\\\\\\\n\\\\\\\\ntry:\\\\\\\\n    import yaml\\\\\\\\\\\\\\n\\\n    \\    nexcept ImportError:\\\\\\\\n    yaml = None\\\\\\\\n\\\\\\\\n\\\\\\\\ndef render_json(root,\\\n    \\ repo_info,\\\\\\n    \\\\ tree_text, files, total_files, total_lines,recent_files=None,\\\n    \\ file_sizes=None)\\\\\\n    \\\\ -> str:\\\\\\\\n    data = {\\\\\\\\n        \\\\\\\\\\\\\\\"root\\\\\\\n    \\\\\\\\\\\": root,\\\\\\\\n        \\\\\\\\\\\\\\\"repo_info\\\\\\\\\\\\\\n    \\\\\\\": repo_info,\\\\\\\\n \\\n    \\       \\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\": tree_text,\\\\\\\\n        \\\\\\\\\\\\\\\"recent_changes\\\\\\\n    \\\\\\\\\\n    \\\\\\\": recent_files or [],\\\\\\\\n        \\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\": files,\\\\\\\n    \\\\n        \\\\\\\\\\\\\\\"file_sizes\\\\\\\\\\\\\\n    \\\\\\\": file_sizes or {},\\\\\\\\n        \\\\\\\n    \\\\\\\\\\\"summary\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\": total_files,\\\\\\n    \\\\ \\\\\\\n    \\\\\\\\\\\"total_lines\\\\\\\\\\\\\\\": total_lines},\\\\\\\\n        \\\\\\\\n    }\\\\\\\\n    return\\\n    \\ json.dumps(data,\\\\\\n    \\\\ indent=2, ensure_ascii=False)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef render_yaml(root,\\\n    \\ repo_info, tree_text,\\\\\\n    \\\\ files, total_files, total_lines,recent_files=None,\\\n    \\ file_sizes=None) -> str:\\\\\\\\\\\\\\n    n    if yaml is None:\\\\\\\\n        raise\\\n    \\ RuntimeError(\\\\\\\\\\\\\\\"PyYAML not installed; run\\\\\\n    \\\\ `pip install pyyaml`\\\\\\\n    \\\\\\\\\\\")\\\\\\\\n    data = {\\\\\\\\n        \\\\\\\\\\\\\\\"root\\\\\\\\\\\\\\\": root,\\\\\\\\n  \\\\\\n  \\\n    \\  \\\\      \\\\\\\\\\\\\\\"repo_info\\\\\\\\\\\\\\\": repo_info,\\\\\\\\n        \\\\\\\\\\\\\\\"structure\\\\\\\n    \\\\\\\\\\\": tree_text,\\\\\\\\\\\\\\n    n        \\\\\\\\\\\\\\\"recent_changes\\\\\\\\\\\\\\\": recent_files\\\n    \\ or [],\\\\\\\\n        \\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\":\\\\\\n    \\\\ files,\\\\\\\\n        \\\\\\\\\\\\\\\n    \\\"file_sizes\\\\\\\\\\\\\\\": file_sizes or {},\\\\\\\\n        \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\n  \\\n    \\  \\\\\\\": {\\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\": total_files, \\\\\\\\\\\\\\\"total_lines\\\\\\\\\\\\\\\"\\\n    : total_lines},\\\\\\\\n \\\\\\n    \\\\       \\\\\\\\n    }\\\\\\\\n    return yaml.safe_dump(data,\\\n    \\ sort_keys=False, allow_unicode=True)\\\\\\\\\\\\\\n    n\\\\\\\",\\\\n    \\\\\\\"src/rcpack/renderer/markdown.py\\\\\\\n    \\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Markdown renderer\\\\\\n    \\\\ for repository context.\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom typing import Dict, Any\\\\\\\\n\\\\\\\\n\\\\\\\\\\\\\\n\\\n    \\    ndef render_markdown(root: str, repo_info: Dict[str, Any], tree_text: str,\\\n    \\ \\\\\\\\\\\\\\n    n                   files: Dict[str, str], total_files: int, total_lines:\\\n    \\ int,\\\\\\n    \\\\ recent_files=None, file_sizes=None) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\"Render repository\\\\\\n    \\\\ context as markdown.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\n    \\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    lines = []\\\\\\\\n    \\\\\\\\n    # Header\\\\\\\\\\\\\\n    n  \\\n    \\  lines.append(f\\\\\\\\\\\\\\\"# Repository Context: {root}\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\n    \\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # Repository info\\\\\\\\n    if repo_info.get(\\\\\\\n    \\\\\\\\\\\"is_repo\\\\\\\\\\\\\\\"\\\\\\n    ):\\\\\\\\n        lines.append(\\\\\\\\\\\\\\\"## Git Repository\\\n    \\ Information\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\n    \\\\\\\"- **Branch**:\\\n    \\ {repo_info.get('branch', 'N/A')}\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\n\\\n    \\    \\\\\\\"- **Commit**: {repo_info.get('commit', 'N/A')}\\\\\\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\n    \\\\\\\\\\n    \\\\\\\"- **Author**: {repo_info.get('author', 'N/A')}\\\\\\\\\\\\\\\")\\\\\\\\n   \\\n    \\     lines.append(f\\\\\\\\\\\\\\n    \\\\\\\"- **Date**: {repo_info.get('date', 'N/A')}\\\\\\\n    \\\\\\\\\\\")\\\\\\\\n    else:\\\\\\\\n        lines.append(\\\\\\\\\\\\\\n    \\\\\\\"## Repository Information\\\\\\\n    \\\\\\\\\\\")\\\\\\\\n        lines.append(f\\\\\\\\\\\\\\\"- **Note**: {repo_info.get('note',\\\\\\\n    \\n    \\\\ 'Not a git repository')}\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\n    \\\")\\\\\\\\n    \\\\\\\\n    # Summary\\\\\\\\\\\\\\n    n    lines.append(\\\\\\\\\\\\\\\"## Summary\\\\\\\n    \\\\\\\\\\\")\\\\\\\\n    lines.append(f\\\\\\\\\\\\\\\"- **Total Files**:\\\\\\n    \\\\ {total_files}\\\\\\\n    \\\\\\\\\\\")\\\\\\\\n    lines.append(f\\\\\\\\\\\\\\\"- **Total Lines**: {total_lines}\\\\\\\\\\\\\\n\\\n    \\    \\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # Directory\\\n    \\ structure\\\\\\\\n    lines.append(\\\\\\\\\\\\\\n    \\\\\\\"## Directory Structure\\\\\\\\\\\\\\\"\\\n    )\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"```\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(tree_text)\\\\\\\\\\\n    \\\\\\n    n    lines.append(\\\\\\\\\\\\\\\"```\\\\\\\\\\\\\\\")\\\\\\\\n    lines.append(\\\\\\\\\\\\\\\"\\\\\\\n    \\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # will produce\\\\\\n    \\\\ recent files \\\\\\\\n    # Recent files\\\n    \\ (fixed)\\\\\\\\n    if recent_files:\\\\\\\\n       \\\\\\n    \\\\ lines.append(\\\\\\\\\\\\\\\"\\\n    ## Recent Changes\\\\\\\\\\\\\\\")\\\\\\\\n        for file, age in recent_files.items():\\\\\\\n    \\\\\\\\\\n    n            lines.append(f\\\\\\\\\\\\\\\"- {file} (modified {age})\\\\\\\\\\\\\\\"\\\n    )\\\\\\\\n        lines.append(\\\\\\\\\\\\\\n    \\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # File contents\\\\\\\n    \\\\n    lines.append(\\\\\\\\\\\\\\\"## File Contents\\\\\\\\\\\\\\n    \\\\\\\")\\\\\\\\n    lines.append(\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    for file_path, content in sorted(files.items()):\\\\\\\n    \\\\\\\\\\n    n        if file_sizes and file_path in file_sizes:\\\\\\\\n           \\\n    \\ size_bytes =\\\\\\n    \\\\ file_sizes[file_path]\\\\\\\\n            lines.append(f\\\\\\\n    \\\\\\\\\\\"### {file_path} ({size_bytes}\\\\\\n    \\\\ bytes)\\\\\\\\\\\\\\\")\\\\\\\\n        else:\\\\\\\n    \\\\n            lines.append(f\\\\\\\\\\\\\\\"### {file_path}\\\\\\\\\\\\\\n    \\\\\\\")\\\\\\\\n   \\\n    \\     lines.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Detect language\\\n    \\ for\\\\\\n    \\\\ syntax highlighting\\\\\\\\n        ext = file_path.split('.')[-1].lower()\\\n    \\ if '.'\\\\\\n    \\\\ in file_path else ''\\\\\\\\n        lang_map = {\\\\\\\\n        \\\n    \\    'py': 'python', 'js':\\\\\\n    \\\\ 'javascript', 'ts': 'typescript',\\\\\\\\n  \\\n    \\          'java': 'java', 'cpp': 'cpp',\\\\\\n    \\\\ 'c': 'c', 'h': 'c',\\\\\\\\n  \\\n    \\          'cs': 'csharp', 'php': 'php', 'rb': 'ruby',\\\\\\\\\\\\\\n    n          \\\n    \\  'go': 'go', 'rs': 'rust', 'swift': 'swift',\\\\\\\\n            'html':\\\\\\n   \\\n    \\ \\\\ 'html', 'css': 'css', 'scss': 'scss',\\\\\\\\n            'json': 'json', 'yaml':\\\\\\\n    \\n    \\\\ 'yaml', 'yml': 'yaml',\\\\\\\\n            'xml': 'xml', 'sql': 'sql', 'sh':\\\n    \\ 'bash',\\\\\\\\\\\\\\n    n            'md': 'markdown', 'dockerfile': 'dockerfile'\\\\\\\n    \\\\n        }\\\\\\\\n     \\\\\\n    \\\\   \\\\\\\\n        language = lang_map.get(ext, '')\\\\\\\n    \\\\n        lines.append(f\\\\\\\\\\\\\\\"```{language}\\\\\\\\\\\\\\n    \\\\\\\")\\\\\\\\n        lines.append(content)\\\\\\\n    \\\\n        lines.append(\\\\\\\\\\\\\\\"```\\\\\\\\\\\\\\\")\\\\\\\\n   \\\\\\n    \\\\     lines.append(\\\\\\\n    \\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\".join(lines)\\\\\\\n    \\\\n\\\\\\\"\\\\\\n    ,\\\\n    \\\\\\\"src/rcpack/treeview.py\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\n    \\\\\\\"Tree view generation for repository\\\\\\n    \\\\ structure.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\n    \\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import Dict,\\\\\\n    \\\\\\\n    \\ List\\\\\\\\n\\\\\\\\n\\\\\\\\ndef create_tree_view(repo_path: Path, files_data: Dict[str,\\\n    \\ str])\\\\\\n    \\\\ -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create a tree view of\\\n    \\ the repository structure.\\\\\\\\\\\\\\\"\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    paths = list(files_data.keys())\\\\\\\n    \\\\n    return render_tree(paths)\\\\\\\\\\\\\\n    n\\\\\\\\n\\\\\\\\ndef render_tree(paths:\\\n    \\ List[str]) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Render a tree\\\\\\n    \\\\ view\\\n    \\ from a list of relative POSIX paths.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    tree_structure:\\\\\\\n    \\n    \\\\ dict = {}\\\\\\\\n\\\\\\\\n    for p in paths:\\\\\\\\n        parts = Path(p).parts\\\\\\\n    \\\\n      \\\\\\n    \\\\  current = tree_structure\\\\\\\\n        for part in parts[:-1]:\\\\\\\n    \\\\n            if\\\\\\n    \\\\ part not in current:\\\\\\\\n                current[part]\\\n    \\ = {}\\\\\\\\n            current\\\\\\n    \\\\ = current[part]\\\\\\\\n        if parts:\\\\\\\n    \\\\n            current[parts[-1]] = None\\\\\\\\\\\\\\n    n\\\\\\\\n    def _render(structure:\\\n    \\ dict, prefix: str = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\") -> str:\\\\\\\\n      \\\\\\n    \\\\  lines =\\\n    \\ []\\\\\\\\n        items = sorted(structure.items(), key=lambda x: (x[1]\\\\\\n   \\\n    \\ \\\\ is None, x[0]))\\\\\\\\n        for i, (name, subtree) in enumerate(items):\\\\\\\n    \\\\n   \\\\\\n    \\\\         is_last = i == len(items) - 1\\\\\\\\n            lines.append(f\\\\\\\n    \\\\\\\\\\\"{prefix}{'└──\\\\\\n    \\\\ ' if is_last else '├── '}{name}\\\\\\\\\\\\\\\")\\\\\\\\n  \\\n    \\          if subtree is not None:\\\\\\\\\\\\\\n    n                extension = (\\\\\\\n    \\\\\\\\\\\"    \\\\\\\\\\\\\\\" if is_last else \\\\\\\\\\\\\\\"│   \\\\\\\\\\\\\\\")\\\\\\\\n  \\\\\\n    \\\\    \\\n    \\          lines.append(_render(subtree, prefix + extension))\\\\\\\\n        return\\\\\\\n    \\n    \\\\ \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\".join(filter(None, lines))\\\\\\\\n\\\\\\\\n    if not\\\n    \\ tree_structure:\\\\\\\\n \\\\\\n    \\\\       return \\\\\\\\\\\\\\\"No files found\\\\\\\\\\\\\\\"\\\\\\\n    \\\\n    return _render(tree_structure)\\\\\\\"\\\\n\\\\\\n    \\\\  },\\\\n  \\\\\\\"file_sizes\\\\\\\n    \\\": {\\\\n    \\\\\\\"LICENSE\\\\\\\": \\\\\\\"1064\\\\\\\",\\\\n    \\\\\\\"README.md\\\\\\\": \\\\\\\"\\\\\\n \\\n    \\   11164\\\\\\\",\\\\n    \\\\\\\"pyproject.toml\\\\\\\": \\\\\\\"361\\\\\\\",\\\\n    \\\\\\\"src/rcpack/__init__.py\\\\\\\n    \\\": \\\\\\\"\\\\\\n    198\\\\\\\",\\\\n    \\\\\\\"src/rcpack/__main__.py\\\\\\\": \\\\\\\"197\\\\\\\",\\\\\\\n    n    \\\\\\\"src/rcpack/cli.py\\\\\\\": \\\\\\\"\\\\\\n    7087\\\\\\\",\\\\n    \\\\\\\"src/rcpack/config_loader.py\\\\\\\n    \\\": \\\\\\\"2099\\\\\\\",\\\\n    \\\\\\\"src/rcpack/discover.py\\\\\\\"\\\\\\n    : \\\\\\\"3067\\\\\\\",\\\\\\\n    n    \\\\\\\"src/rcpack/gitinfo.py\\\\\\\": \\\\\\\"1653\\\\\\\",\\\\n    \\\\\\\"src/rcpack/io_utils.py\\\\\\\n    \\\"\\\\\\n    : \\\\\\\"1817\\\\\\\",\\\\n    \\\\\\\"src/rcpack/packager.py\\\\\\\": \\\\\\\"4430\\\\\\\",\\\\\\\n    n    \\\\\\\"src/rcpack/renderer/jsonyaml.py\\\\\\\"\\\\\\n    : \\\\\\\"1176\\\\\\\",\\\\n    \\\\\\\"\\\n    src/rcpack/renderer/markdown.py\\\\\\\": \\\\\\\"2829\\\\\\\",\\\\n    \\\\\\\"src/rcpack/treeview.py\\\\\\\n    \\\"\\\\\\n    : \\\\\\\"1371\\\\\\\"\\\\n  },\\\\n  \\\\\\\"summary\\\\\\\": {\\\\n    \\\\\\\"total_files\\\\\\\n    \\\": 14,\\\\n    \\\\\\\"total_lines\\\\\\\"\\\\\\n    : 1180\\\\n  }\\\\n}\\\"\\nfile_sizes:\\n  LICENSE:\\\n    \\ '1064'\\n  README.md: '11164'\\n  pyproject.toml: '361'\\n  src/rcpack/__init__.py:\\\n    \\ '198'\\n  src/rcpack/__main__.py: '197'\\n  src/rcpack/cli.py: '7087'\\n  src/rcpack/config_loader.py:\\\n    \\ '2099'\\n  src/rcpack/discover.py: '3067'\\n  src/rcpack/gitinfo.py: '1653'\\n\\\n    \\  src/rcpack/io_utils.py: '1817'\\n  src/rcpack/packager.py: '4430'\\n  src/rcpack/renderer/jsonyaml.py:\\\n    \\ '1176'\\n  src/rcpack/renderer/markdown.py: '2829'\\n  src/rcpack/treeview.py:\\\n    \\ '1371'\\n  test-output.json: '42249'\\nsummary:\\n  total_files: 15\\n  total_lines:\\\n    \\ 1229\\n\"\nfile_sizes:\n  LICENSE: '1064'\n  README.md: '11164'\n  pyproject.toml: '361'\n  src/rcpack/__init__.py: '198'\n  src/rcpack/__main__.py: '197'\n  src/rcpack/cli.py: '7087'\n  src/rcpack/config_loader.py: '2099'\n  src/rcpack/discover.py: '3067'\n  src/rcpack/gitinfo.py: '1653'\n  src/rcpack/io_utils.py: '1817'\n  src/rcpack/packager.py: '4121'\n  src/rcpack/renderer/jsonyaml.py: '1154'\n  src/rcpack/renderer/markdown.py: '2318'\n  src/rcpack/treeview.py: '1371'\n  src/rcpack/utils.py: '3500'\n  test-iteration2.json: '194424'\n  test-output.json: '42249'\n  test-yaml.yaml: '93888'\nsummary:\n  total_files: 18\n  total_lines: 2511\n",
    "test-output.json": "{\n  \"root\": \"/Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\",\n  \"repo_info\": {\n    \"is_repo\": true,\n    \"commit\": \"682153b169db66d3a72e9cabdd1f3448a3b2986d\",\n    \"branch\": \"refactoring\",\n    \"author\": \"Abhinav <abhinavbhardwaj2002@gmail.com>\",\n    \"date\": \"Fri Oct 3 18:45:48 2025\",\n    \"note\": null\n  },\n  \"structure\": \"├── src\\n│   └── rcpack\\n│       ├── renderer\\n│       │   ├── jsonyaml.py\\n│       │   └── markdown.py\\n│       ├── __init__.py\\n│       ├── __main__.py\\n│       ├── cli.py\\n│       ├── config_loader.py\\n│       ├── discover.py\\n│       ├── gitinfo.py\\n│       ├── io_utils.py\\n│       ├── packager.py\\n│       └── treeview.py\\n├── LICENSE\\n├── README.md\\n└── pyproject.toml\",\n  \"recent_changes\": [],\n  \"files\": {\n    \"LICENSE\": \"MIT License\\n\\nCopyright (c) 2025 Abhinav\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \\\"Software\\\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \\\"AS IS\\\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n\",\n    \"README.md\": \"# Repo-Contextor\\n\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\n\\nA powerful Repository Context Packager CLI tool that analyzes local git repositories and creates comprehensive text files containing repository content optimized for sharing with Large Language Models (LLMs).\\n\\n## Overview\\n\\nWhen developers want to get help from ChatGPT, Claude, or other LLMs about their code, they often struggle with how to share their codebase effectively. Common problems include:\\n\\n- **Lost Context**: Copy-pasting individual files loses important project structure and relationships\\n- **Missing Dependencies**: LLMs can't see how files connect or what libraries are used\\n- **Incomplete Picture**: Hard to convey the overall architecture and organization\\n- **Manual Work**: Time-consuming to gather and format relevant code\\n\\n**Repo-Contextor** solves this by automatically collecting and formatting repository content into a single, well-structured text file that provides rich context to LLMs, enabling them to give much better assistance with your code.\\n\\n## Features\\n\\n- **Git Integration**: Extracts commit SHA, branch, author, and date information\\n- **Project Structure**: Generates a clear directory tree visualization\\n- **File Content Packaging**: Includes file contents with syntax highlighting\\n- **Smart File Discovery**: Recursively scans directories with intelligent filtering\\n- **Binary File Detection**: Automatically skips binary files\\n- **Error Handling**: Gracefully handles permission errors and provides helpful messages\\n- **Multiple Output Formats**: Supports Markdown, JSON, and YAML formats\\n- **Flexible Output**: Write to stdout or save to a file\\n- **Recent Changes Filter**: Give the files which are updated in last 7days with the time when it was recently modified.\\n\\n## Installation\\n\\n### Prerequisites\\n\\n- Python 3.9 or higher\\n- Git (for git repository analysis)\\n\\n### For End Users\\n\\n```bash\\n# Clone and install\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\ncd Repo-Contextor\\npip install -e .\\n```\\n\\n### For Contributors & Local Development\\n\\n```bash\\n# Clone the repository\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\ncd Repo-Contextor\\n\\n# Create virtual environment\\npython -m venv .venv\\nsource .venv/bin/activate  # On Windows: .venv\\\\Scripts\\\\activate\\n\\n# Install in development mode\\npip install -e .\\n```\\n\\n## Usage\\n\\n### Basic Examples\\n\\n```bash\\n# Package current directory to terminal\\nrepo-contextor .\\n\\n# Package a specific directory\\nrepo-contextor /path/to/your/project\\n\\n# Save output to a file\\nrepo-contextor . -o my-project-context.md\\n\\n# Generate JSON format\\nrepo-contextor . -f json -o context.json\\n\\n# Generate YAML format\\nrepo-contextor . -f yaml -o context.yaml\\n\\n# Include only files modified in the last 7 days\\nrepo-contextor . --recent\\n\\n# Combine with output file\\nrepo-contextor . --recent -o recent-changes.md\\n```\\n\\n### Command Line Options\\n\\n| Option | Short | Description | Example |\\n|--------|-------|-------------|---------|\\n| `path` | - | Repository path to analyze (default: current directory) | `repo-contextor /path/to/project` |\\n| `--output` | `-o` | Output file path (default: stdout) | `-o context.md` |\\n| `--format` | `-f` | Output format: text, json, yaml (default: text) | `-f json` |\\n| `--help` | `-h` | Show help message | `-h` |\\n| `--recent`  | `-r`  | Include only files modified in the last 7 days    | `repo-contextor . -r -o recent.md` |\\n\\n### Advanced Examples\\n\\n```bash\\n# Analyze different repository\\nrepo-contextor /path/to/other/project -o other-project.md\\n\\n# Generate JSON for API consumption\\nrepo-contextor . -f json -o api-context.json\\n\\n# Create YAML configuration\\nrepo-contextor . -f yaml -o project-config.yaml\\n\\n# Generate files which are changed recently in 7 days\\nrepo-contextor . -r --output recent-changes.txt\\n\\n```\\n## Configuration via TOML\\n\\nRepo-Contextor supports configuration through a `.repo-contextor.toml` file in the current working directory.  \\nThis file allows you to avoid typing the same CLI arguments every time.\\n\\nExample `.repo-contextor.toml`:\\n\\n```toml\\n# Output file to write results\\noutput = \\\"context.yaml\\\"\\n\\n# Output format: text, json, or yaml\\nformat = \\\"yaml\\\"\\n\\n# Limit to files modified in the last 7 days\\nrecent = true\\n\\n# Repository path to analyze (default = current directory)\\npath = \\\".\\\"\\n```\\n### Rules\\n- If the `.repo-contextor.toml` file is **missing**, the tool falls back to defaults.  \\n- If the file is **present but invalid TOML**, the tool prints a clear error message and exits with status code 1.  \\n- **Unknown keys** in the TOML file are ignored (safe for future extensions).  \\n- **Precedence** of settings is:\\n  1. Command-line arguments (highest priority)  \\n  2. Values from `.repo-contextor.toml`  \\n  3. Built-in defaults (lowest priority)\\n     \\n## Output Format\\n\\nThe tool generates a structured text file with the following sections:\\n\\n### 1. Repository Context Header\\nProject path and identification\\n\\n### 2. Git Repository Information\\n- Current branch\\n- Latest commit SHA\\n- Last commit author\\n- Last commit date\\n\\n### 3. Summary Statistics\\n- Total number of files processed\\n- Total lines of code\\n\\n### 4. Directory Structure\\nClean tree visualization showing project organization\\n\\n### 5. Recent Changes (if `--recent` is used)\\n\\n- Lists files modified in the last 7 days.\\n- Shows relative file paths along with how long ago each file was modified\\n- Helps focus on recently updated parts of the project.\\n- Can be combined with `--output` or `--format` to save or change the output type.\\n\\n\\n### 5. File Contents\\nEach file's content with:\\n- Clear file path headers\\n- Appropriate syntax highlighting language tags\\n- Complete file contents\\n\\n## Example Output\\n\\nWhen you run `repo-contextor .`, the output looks like this:\\n\\n````markdown\\n# Repository Context: /path/to/your/project\\n\\n## Git Repository Information\\n- **Branch**: main\\n- **Commit**: a1b2c3d4e5f6789...\\n- **Author**: John Doe <john@example.com>\\n- **Date**: Fri Sep 12 14:30:15 2025\\n\\n## Summary\\n- **Total Files**: 15\\n- **Total Lines**: 1,247\\n\\n## Directory Structure\\n```\\n├── src/\\n│   ├── main.py\\n│   └── utils.py\\n├── tests/\\n│   └── test_main.py\\n├── README.md\\n└── requirements.txt\\n```\\n## Recent Changes\\n- src/main.py (modified 2 days ago)\\n- src/utils/helpers.py (modified 5 days ago)\\n\\n## File Contents\\n\\n### src/main.py\\n\\n```python\\ndef main():\\n    print(\\\"Hello, World!\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n```\\n\\n### README.md\\n\\n```markdown\\n# My Project\\nThis is a sample project.\\n```\\n\\n## Summary\\n- Total files: 15\\n- Total lines: 1,247\\n````\\n\\n## What Files Are Included\\n\\nThe tool includes most text files but automatically excludes:\\n\\n### Excluded Directories\\n- `.git`, `.svn`, `.hg` (version control)\\n- `__pycache__`, `.pytest_cache` (Python cache)\\n- `node_modules`, `.venv`, `venv` (dependencies/environments)\\n- `.vscode`, `.idea` (IDE directories)\\n- `build`, `dist`, `target` (build directories)\\n\\n### File Handling Rules\\n- **Text files**: All readable text files with common extensions\\n- **Binary files**: Automatically detected and skipped\\n- **Permission errors**: Skipped with graceful handling\\n- **Configuration files**: Includes pyproject.toml, package.json, etc.\\n\\n### Included File Types\\n- Source code: `.py`, `.js`, `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\n- Web files: `.html`, `.css`, `.scss`, `.vue`, `.jsx`, etc.\\n- Documentation: `.md`, `.txt`, `.rst`\\n- Configuration: `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\n- Scripts: `.sh`, `.bash`, `.zsh`\\n\\n## Error Handling\\n\\nThe tool handles errors gracefully:\\n\\n| Error Type | Behavior |\\n|------------|----------|\\n| **Permission errors** | Skipped with warning |\\n| **Binary files** | Automatically detected and skipped |\\n| **Invalid paths** | Clear error messages |\\n| **Non-git repositories** | Works fine, shows \\\"Not a git repository\\\" |\\n| **Unreadable files** | Marked as \\\"[Binary or unreadable file]\\\" |\\n\\n## Development\\n\\n### Project Structure\\n\\n```text\\nRepo-Contextor/\\n├── src/rcpack/              # Main package\\n│   ├── __init__.py         # Package initialization\\n│   ├── cli.py              # Command-line interface\\n│   ├── discover.py         # File discovery logic\\n│   ├── gitinfo.py          # Git repository analysis\\n│   ├── treeview.py         # Directory tree generation\\n│   ├── packager.py         # Main orchestration\\n│   ├── io_utils.py         # File I/O utilities\\n│   └── renderer/           # Output formatters\\n│       ├── markdown.py     # Markdown renderer\\n│       └── jsonyaml.py     # JSON/YAML renderers\\n├── pyproject.toml          # Project configuration\\n├── LICENSE                 # MIT License\\n└── README.md              # This documentation\\n```\\n\\n### Running Tests\\n\\n```bash\\n# Test on current repository\\nrepo-contextor . -o test-output.md\\n\\n# Test different formats\\nrepo-contextor . -f json | head -20\\nrepo-contextor . -f yaml | head -20\\n\\n# Test specific directory\\nrepo-contextor src/ -o src-only.md\\n```\\n\\n### Contributing\\n\\n1. **Fork the repository**\\n2. **Clone your fork:**\\n   ```bash\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\n   cd Repo-Contextor\\n   ```\\n3. **Install for development:**\\n   ```bash\\n   python -m venv .venv\\n   source .venv/bin/activate\\n   pip install -e .\\n   ```\\n4. **Make your changes and test:**\\n   ```bash\\n   repo-contextor . -o test.md\\n   ```\\n5. **Submit a pull request**\\n\\n### Development Workflow\\n\\n```bash\\n# 1. Setup development environment\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\ncd Repo-Contextor\\npython -m venv .venv\\nsource .venv/bin/activate\\npip install -e .\\n\\n# 2. Make changes to the code\\n# Edit files in src/rcpack/\\n\\n# 3. Test your changes\\nrepo-contextor . -o test-output.md\\n\\n# 4. Test different formats\\nrepo-contextor . -f json -o test.json\\nrepo-contextor . -f yaml -o test.yaml\\n\\n# 5. Commit and push changes\\ngit add .\\ngit commit -m \\\"Add new feature\\\"\\ngit push origin feature-branch\\n```\\n\\n## License\\n\\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\\n\\n## Why Repo-Contextor?\\n\\nThe name \\\"Repo-Contextor\\\" combines \\\"Repository\\\" + \\\"Context\\\" + \\\"or\\\", representing the tool's purpose of providing rich context about code repositories in a format that's perfect for LLM interactions.\\n\\n### Use Cases\\n\\n- **AI Assistance**: Get better help from ChatGPT, Claude, or GitHub Copilot\\n- **Code Reviews**: Share complete project context with team members\\n- **Documentation**: Create comprehensive project snapshots\\n- **Onboarding**: Help new team members understand project structure\\n- **Project Analysis**: Understand repository structure and dependencies\\n\\n### Perfect for LLMs\\n\\nThe output format is specifically designed to work well with Large Language Models:\\n- Clear section headers for easy parsing\\n- Syntax highlighting markers for code blocks\\n- Structured metadata (git info, file locations)\\n- Complete project context in a single file\\n- Multiple output formats (Markdown, JSON, YAML)\\n- Optimized for token efficiency\\n\",\n    \"pyproject.toml\": \"[build-system]\\nrequires = [\\\"setuptools>=68\\\", \\\"wheel\\\"]\\nbuild-backend = \\\"setuptools.build_meta\\\"\\n\\n[project]\\nname = \\\"rcpack\\\"\\nversion = \\\"0.1.0\\\"\\ndescription = \\\"Repository Context Packager CLI for LLMs\\\"\\nreadme = \\\"README.md\\\"\\nrequires-python = \\\">=3.9\\\"\\nlicense = { text = \\\"MIT\\\" }\\ndependencies = [\\n    \\\"PyYAML>=6.0\\\"\\n]\\n\\n[project.scripts]\\nrepo-contextor = \\\"rcpack.cli:main\\\"\\n\",\n    \"src/rcpack/__init__.py\": \"\\\"\\\"\\\"Repository Context Packager - CLI tool for creating LLM-optimized repository context.\\\"\\\"\\\"\\n\\n__version__ = \\\"0.1.0\\\"\\n__author__ = \\\"Abhinav\\\"\\n__description__ = \\\"Repository Context Packager CLI for LLMs\\\"\",\n    \"src/rcpack/__main__.py\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"Module entry point to enable `python -m rcpack`.\\n\\nThis simply delegates to the CLI's main() function.\\n\\\"\\\"\\\"\\n\\nfrom .cli import main\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\\n\\n\",\n    \"src/rcpack/cli.py\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"CLI for Repository Context Packager.\\\"\\\"\\\"\\n\\nfrom .config_loader import load_config\\n\\nimport argparse\\nimport sys\\nfrom pathlib import Path\\nfrom .gitinfo import get_git_info\\nfrom .discover import discover_files\\nfrom .treeview import create_tree_view\\nfrom .renderer.markdown import render_markdown\\nfrom .renderer.jsonyaml import render_json, render_yaml\\nfrom .io_utils import write_output\\nfrom datetime import datetime, timedelta\\n\\n\\ndef log_verbose(message: str, verbose: bool) -> None:\\n    \\\"\\\"\\\"Log a message to stderr if verbose mode is enabled.\\\"\\\"\\\"\\n    if verbose:\\n        print(message, file=sys.stderr)\\n\\n\\ndef get_rendered_content(format_type: str, repo_path: str, repo_info: dict, tree_text: str, \\n                        files_data: dict, total_files: int, total_lines: int, \\n                        recent_files_info: dict, file_sizes: dict) -> str:\\n    \\\"\\\"\\\"Get rendered content based on the specified format.\\\"\\\"\\\"\\n    if format_type == \\\"json\\\":\\n        return render_json(\\n            repo_path, repo_info, tree_text, \\n            files_data, total_files, total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n        )\\n    elif format_type == \\\"yaml\\\":\\n        return render_yaml(\\n            repo_path, repo_info, tree_text, \\n            files_data, total_files, total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n        )\\n    else:  # text/markdown\\n        return render_markdown(\\n            repo_path, repo_info, tree_text, \\n            files_data, total_files, total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n        )\\n\\n\\ndef process_file(file_path: Path, repo_path: Path, verbose: bool) -> tuple[str, str, str]:\\n    \\\"\\\"\\\"Process a single file and return its data.\\n    \\n    Returns:\\n        tuple: (relative_path_str, content, file_size)\\n    \\\"\\\"\\\"\\n    relative_path = file_path.relative_to(repo_path)\\n    relative_path_str = str(relative_path)\\n    \\n    log_verbose(f\\\"Reading file: {relative_path}\\\", verbose)\\n    file_size = file_path.stat().st_size\\n    \\n    try:\\n        with open(file_path, 'r', encoding='utf-8') as f:\\n            content = f.read()\\n        return relative_path_str, content, str(file_size)\\n    except (UnicodeDecodeError, PermissionError):\\n        log_verbose(f\\\"Skipping binary/unreadable file: {relative_path}\\\", verbose)\\n        file_size = file_path.stat().st_size if file_path.exists() else 0\\n        content = f\\\"[Binary or unreadable file: {file_path.name}]\\\"\\n        return relative_path_str, content, str(file_size)\\n    except Exception:\\n        log_verbose(f\\\"Error reading file: {relative_path}\\\", verbose)\\n        raise  # Re-raise to handle in calling code\\n\\n\\ndef handle_output(content: str, output_path: str = None) -> None:\\n    \\\"\\\"\\\"Handle output to either file or stdout.\\\"\\\"\\\"\\n    if output_path:\\n        # Write to file\\n        write_output(output_path, content)\\n        print(f\\\"Context package created: {output_path}\\\")\\n    else:\\n        # Output to stdout\\n        print(content)\\n\\n\\ndef main():\\n    parser = argparse.ArgumentParser(\\n        description=\\\"Package repository content for LLM context\\\"\\n    )\\n    parser.add_argument(\\n        \\\"path\\\", \\n        nargs=\\\"?\\\", \\n        default=\\\".\\\", \\n        help=\\\"Repository path (default: current directory)\\\"\\n    )\\n    parser.add_argument(\\n        \\\"-o\\\", \\\"--output\\\", \\n        help=\\\"Output file path (default: stdout)\\\"\\n    )\\n    parser.add_argument(\\n        \\\"-f\\\", \\\"--format\\\", \\n        choices=[\\\"text\\\", \\\"json\\\", \\\"yaml\\\"], \\n        default=\\\"text\\\",\\n        help=\\\"Output format (default: text)\\\"\\n    )\\n\\n    \\\"\\\"\\\" This will read -r from the console and able to search it with this\\\"\\\"\\\"\\n    parser.add_argument(\\n    \\\"-r\\\", \\\"--recent\\\",\\n    action=\\\"store_true\\\",\\n    help=\\\"Include only files modified in the last 7 days\\\"\\n    )\\n    parser.add_argument(\\n        \\\"-v\\\", \\\"--verbose\\\",\\n        action=\\\"store_true\\\",\\n        help=\\\"Print detailed progress information to stderr\\\"\\n    )\\n    \\n    args = parser.parse_args()\\n    \\n    try:\\n        repo_path = Path(args.path).resolve()\\n        if not repo_path.exists():\\n            print(f\\\"Error: Path {repo_path} does not exist\\\", file=sys.stderr)\\n            sys.exit(1)\\n            \\n        # Get repository information\\n        log_verbose(f\\\"Analyzing repository: {repo_path}\\\", args.verbose)\\n        repo_info = get_git_info(repo_path)\\n        \\n        # Discover files\\n        log_verbose(f\\\"Discovering files in: {repo_path}\\\", args.verbose)\\n        discovered_files = discover_files([repo_path], repo_path, [], [])\\n        log_verbose(f\\\"Found {len(discovered_files)} files\\\", args.verbose)\\n        \\n        # will check the file in last 7 days\\n        recent_files_info = {}\\n        if args.recent:\\n            seven_days_ago = datetime.now() - timedelta(days=7)\\n            recent_files = []\\n            for f in discovered_files:\\n                try:\\n                    mtime = datetime.fromtimestamp(f.stat().st_mtime)\\n                    if mtime >= seven_days_ago:\\n                        recent_files.append(f)\\n                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)     \\n                except Exception:\\n                    continue\\n            discovered_files = recent_files\\n        \\n        # Read file contents\\n        files_data = {}\\n        file_sizes = {}\\n        for file_path in discovered_files:\\n            try:\\n                relative_path_str, content, file_size = process_file(file_path, repo_path, args.verbose)\\n                files_data[relative_path_str] = content\\n                file_sizes[relative_path_str] = file_size\\n            except Exception:\\n                continue\\n        \\n        # Create tree view\\n        log_verbose(\\\"Generating directory tree\\\", args.verbose)\\n        tree_text = create_tree_view(repo_path, files_data)\\n        \\n        # Count totals\\n        total_files = len(files_data)\\n        total_lines = sum(len(content.splitlines()) for _, content in files_data.items())\\n        \\n        # Render based on format\\n        log_verbose(f\\\"Rendering output in {args.format} format\\\", args.verbose)\\n        content = get_rendered_content(\\n            args.format, str(repo_path), repo_info, tree_text,\\n            files_data, total_files, total_lines,\\n            recent_files_info if args.recent else {},\\n            file_sizes\\n        )\\n        \\n        handle_output(content, args.output)\\n        \\n    except Exception as e:\\n        print(f\\\"Error: {e}\\\", file=sys.stderr)\\n        sys.exit(1)\\n\\n# this will convert age and give us the difference\\ndef human_readable_age(mtime: datetime) -> str:\\n    delta = datetime.now() - mtime\\n    days = delta.days\\n    seconds = delta.seconds\\n    if days > 0:\\n        return f\\\"{days} day{'s' if days != 1 else ''} ago\\\"\\n    elif seconds >= 3600:\\n        hours = seconds // 3600\\n        return f\\\"{hours} hour{'s' if hours != 1 else ''} ago\\\"\\n    elif seconds >= 60:\\n        minutes = seconds // 60\\n        return f\\\"{minutes} minute{'s' if minutes != 1 else ''} ago\\\"\\n    else:\\n        return \\\"just now\\\"\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\",\n    \"src/rcpack/config_loader.py\": \"# src/rcpack/config_loader.py\\n\\\"\\\"\\\"\\nTOML config loader for Repo-Contextor.\\n\\nRules:\\n- Look for .repo-contextor.toml in the CURRENT directory\\n- If missing: ignore\\n- If present but invalid: print a clear error and exit(1)\\n- Only recognized keys are applied; unknown keys ignored\\n- Precedence: CLI > TOML > DEFAULTS\\n\\\"\\\"\\\"\\nfrom __future__ import annotations\\nimport os, sys\\nfrom typing import Dict, Iterable, Any\\n\\ntry:\\n    import tomllib\\n    _loads = tomllib.loads\\nexcept ModuleNotFoundError:\\n    try:\\n        import tomli\\n        _loads = tomli.loads\\n    except ModuleNotFoundError:\\n        _loads = None\\n\\ndef _need_toml():\\n    if _loads is None:\\n        print(\\\"Error: TOML parser not available. Use Python 3.11+ or `pip install tomli`.\\\", file=sys.stderr)\\n        sys.exit(1)\\n\\ndef _load_toml(dotfile: str) -> Dict[str, Any]:\\n    _need_toml()\\n    if not os.path.exists(dotfile):\\n        return {}\\n    try:\\n        with open(dotfile, \\\"rb\\\") as f:\\n            raw = f.read().decode(\\\"utf-8\\\", errors=\\\"strict\\\")\\n        data = _loads(raw)\\n        return data if isinstance(data, dict) else {}\\n    except Exception as e:\\n        print(f\\\"Error: failed to parse {dotfile} as TOML.\\\\n{e}\\\", file=sys.stderr)\\n        sys.exit(1)\\n\\ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\n    ks = set(known)\\n    return {k: v for k, v in d.items() if k in ks}\\n\\ndef _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\n    ks = set(known)\\n    out: Dict[str, Any] = {k: defaults.get(k) for k in ks}\\n    for src in (filecfg, clicfg):\\n        for k, v in src.items():\\n            if k in ks and v is not None:\\n                out[k] = v\\n    return out\\n\\ndef load_config(*, dotfile: str = \\\".repo-contextor.toml\\\", defaults: Dict[str, Any] | None = None, cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ()) -> Dict[str, Any]:\\n    defaults = defaults or {}\\n    cli_cfg = cli_cfg or {}\\n    known = tuple(known_keys)\\n    filecfg = _filter_known(_load_toml(dotfile), known)\\n    return _merge(defaults, filecfg, cli_cfg, known)\\n\",\n    \"src/rcpack/discover.py\": \"\\\"\\\"\\\"File discovery module for repository analysis.\\\"\\\"\\\"\\n\\nfrom pathlib import Path\\nfrom typing import List\\nimport fnmatch\\n\\n\\ndef discover_files(\\n    inputs: List[Path],\\n    root: Path,\\n    include_patterns: List[str],\\n    exclude_patterns: List[str],\\n) -> List[Path]:\\n    \\\"\\\"\\\"Discover relevant files.\\n\\n    - inputs: list of files/dirs to scan\\n    - root: common project root; patterns are matched against POSIX paths relative to root\\n    - include_patterns: glob patterns to include (if empty, use sensible defaults)\\n    - exclude_patterns: glob patterns to exclude\\n    Returns a list of absolute Paths to files.\\n    \\\"\\\"\\\"\\n\\n    default_include_exts = {\\n        '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\\n        '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\n        '.html', '.css', '.scss', '.sass', '.less', '.vue', '.svelte',\\n        '.md', '.txt', '.rst', '.yaml', '.yml', '.json', '.toml', '.ini',\\n        '.cfg', '.conf', '.xml', '.sql', '.sh', '.bash', '.zsh', '.fish',\\n    }\\n\\n    always_include_names = {\\n        'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING', 'Makefile',\\n        'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\\n        'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\n    }\\n\\n    skip_dir_names = {\\n        '.git', '.svn', '.hg', '__pycache__', '.pytest_cache',\\n        'node_modules', '.venv', 'venv', 'env', '.env',\\n        'build', 'dist', 'target', 'out', '.next', '.nuxt',\\n        '.idea', '.vscode', '.vs', 'coverage', '.coverage'\\n    }\\n\\n    def matches_any(patterns: List[str], rel_posix: str) -> bool:\\n        return any(fnmatch.fnmatch(rel_posix, pat) for pat in patterns)\\n\\n    def should_take(file_path: Path) -> bool:\\n        rel_posix = file_path.relative_to(root).as_posix()\\n        if exclude_patterns and matches_any(exclude_patterns, rel_posix):\\n            return False\\n        if include_patterns:\\n            return matches_any(include_patterns, rel_posix)\\n        # default include logic\\n        return file_path.name in always_include_names or file_path.suffix.lower() in default_include_exts\\n\\n    discovered: list[Path] = []\\n    seen = set()\\n\\n    for item in inputs:\\n        p = item.resolve()\\n        if p.is_file():\\n            # Skip if excluded or in skipped directory\\n            if any(part in skip_dir_names for part in p.parts):\\n                continue\\n            if should_take(p):\\n                key = p.as_posix()\\n                if key not in seen:\\n                    seen.add(key)\\n                    discovered.append(p)\\n        elif p.is_dir():\\n            for child in p.rglob('*'):\\n                if not child.is_file():\\n                    continue\\n                if any(part in skip_dir_names for part in child.parts):\\n                    continue\\n                if should_take(child):\\n                    key = child.resolve().as_posix()\\n                    if key not in seen:\\n                        seen.add(key)\\n                        discovered.append(child.resolve())\\n\\n    return sorted(discovered)\",\n    \"src/rcpack/gitinfo.py\": \"from __future__ import annotations\\n\\nimport subprocess\\nfrom pathlib import Path\\nfrom typing import Dict, Any\\n\\n\\ndef _git(cmd: list[str], cwd: Path) -> str:\\n    # Validate git commands to prevent injection\\n    allowed_commands = {\\n        \\\"rev-parse\\\", \\\"show\\\", \\\"log\\\", \\\"status\\\", \\\"branch\\\", \\\"config\\\"\\n    }\\n    if not cmd or cmd[0] not in allowed_commands:\\n        raise ValueError(f\\\"Git command not allowed: {cmd[0] if cmd else 'empty'}\\\")\\n    \\n    out = subprocess.check_output([\\\"git\\\", *cmd], cwd=str(cwd), timeout=30)\\n    return out.decode(\\\"utf-8\\\", errors=\\\"replace\\\").strip()\\n\\n\\ndef is_git_repo(path: Path) -> bool:\\n    try:\\n        flag = _git([\\\"rev-parse\\\", \\\"--is-inside-work-tree\\\"], cwd=path)\\n        return flag == \\\"true\\\"\\n    except Exception:\\n        return False\\n\\n\\ndef get_git_info(path: Path) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Return info for the current HEAD of a repo rooted at `path`.\\n    \\\"\\\"\\\"\\n    try:\\n        commit = _git([\\\"rev-parse\\\", \\\"HEAD\\\"], cwd=path)\\n        branch = _git([\\\"rev-parse\\\", \\\"--abbrev-ref\\\", \\\"HEAD\\\"], cwd=path)\\n        author = _git([\\\"show\\\", \\\"-s\\\", \\\"--format=%an <%ae>\\\"], cwd=path)\\n        date = _git([\\\"show\\\", \\\"-s\\\", \\\"--date=local\\\", \\\"--format=%ad\\\"], cwd=path)\\n        return {\\n            \\\"is_repo\\\": True,\\n            \\\"commit\\\": commit,\\n            \\\"branch\\\": branch,\\n            \\\"author\\\": author,\\n            \\\"date\\\": date,\\n            \\\"note\\\": None,\\n        }\\n    except Exception:\\n        # treat as not a repo if anything fails\\n        return {\\n            \\\"is_repo\\\": False,\\n            \\\"commit\\\": None,\\n            \\\"branch\\\": None,\\n            \\\"author\\\": None,\\n            \\\"date\\\": None,\\n            \\\"note\\\": \\\"Not a git repository\\\",\\n        }\\n\",\n    \"src/rcpack/io_utils.py\": \"\\\"\\\"\\\"I/O utilities for file operations.\\\"\\\"\\\"\\n\\nfrom pathlib import Path\\nfrom typing import Tuple\\n\\n\\ndef write_output(output_path: str, content: str) -> None:\\n    \\\"\\\"\\\"Write content to output file.\\\"\\\"\\\"\\n    output_file = Path(output_path)\\n    \\n    # Create parent directories if they don't exist\\n    output_file.parent.mkdir(parents=True, exist_ok=True)\\n    \\n    # Write content\\n    with open(output_file, 'w', encoding='utf-8') as f:\\n        f.write(content)\\n\\n\\ndef is_binary_file(path: Path, sniff_bytes: int = 2048) -> bool:\\n    \\\"\\\"\\\"Heuristically determine if a file is binary by scanning for NUL bytes.\\\"\\\"\\\"\\n    try:\\n        with open(path, 'rb') as fb:\\n            chunk = fb.read(sniff_bytes)\\n        if b\\\"\\\\x00\\\" in chunk:\\n            return True\\n        # If the chunk has a lot of non-text bytes, consider it binary\\n        text_byte_count = sum(32 <= b <= 126 or b in (9, 10, 13) for b in chunk)\\n        return (len(chunk) - text_byte_count) > max(1, len(chunk) // 3)\\n    except Exception:\\n        # If we cannot read, treat as binary to avoid further processing\\n        return True\\n\\n\\ndef read_text_safely(path: Path, max_bytes: int = 16_384) -> Tuple[str, str, bool]:\\n    \\\"\\\"\\\"Read a text file safely with size limit and encoding fallbacks.\\n\\n    Returns (content, encoding_used, truncated).\\n    \\\"\\\"\\\"\\n    truncated = False\\n    raw: bytes\\n    with open(path, 'rb') as fb:\\n        raw = fb.read(max_bytes + 1)\\n    if len(raw) > max_bytes:\\n        truncated = True\\n        raw = raw[:max_bytes]\\n\\n    for enc in (\\\"utf-8\\\", \\\"utf-16\\\", \\\"utf-16-le\\\", \\\"utf-16-be\\\", \\\"latin-1\\\"):\\n        try:\\n            text = raw.decode(enc)\\n            return text, enc, truncated\\n        except Exception:\\n            continue\\n    # Fallback: replace errors with utf-8\\n    text = raw.decode(\\\"utf-8\\\", errors=\\\"replace\\\")\\n    return text, \\\"utf-8\\\", truncated\",\n    \"src/rcpack/packager.py\": \"from __future__ import annotations\\n\\nimport sys\\nfrom pathlib import Path\\nfrom typing import Iterable, Tuple\\n\\nfrom rcpack.discover import discover_files\\nfrom rcpack.gitinfo import get_git_info, is_git_repo\\nfrom rcpack.io_utils import read_text_safely, is_binary_file\\nfrom rcpack.renderer import markdown as md_renderer\\nfrom rcpack.renderer.jsonyaml import render_json, render_yaml\\nfrom rcpack.treeview import render_tree\\n\\n\\ndef _find_root(inputs: list[str]) -> Path:\\n    paths = [Path(p) for p in inputs]\\n    if len(paths) == 1 and Path(paths[0]).is_dir():\\n        return paths[0].resolve()\\n    parents = [p if p.is_dir() else p.parent for p in paths]\\n    root = Path(*Path.commonpath([str(p.resolve()) for p in parents]).split(\\\"/\\\"))\\n    return root.resolve()\\n\\n\\ndef build_package(\\n    inputs: list[str],\\n    include_patterns: list[str] | None,\\n    exclude_patterns: list[str] | None,\\n    max_file_bytes: int,\\n    fmt: str = \\\"markdown\\\",\\n) -> Tuple[str, dict]:\\n    root = _find_root(inputs)\\n    root_abs = root.resolve()\\n\\n    repo_info = (\\n        get_git_info(root_abs) if is_git_repo(root_abs) else {\\n            \\\"is_repo\\\": False,\\n            \\\"commit\\\": None,\\n            \\\"branch\\\": None,\\n            \\\"author\\\": None,\\n            \\\"date\\\": None,\\n            \\\"note\\\": \\\"Not a git repository\\\",\\n        }\\n    )\\n\\n    files = discover_files(\\n        inputs=[Path(p) for p in inputs],\\n        root=root_abs,\\n        include_patterns=include_patterns or [],\\n        exclude_patterns=exclude_patterns or [],\\n    )\\n    rel_files = [f.relative_to(root_abs) for f in files]\\n\\n    project_tree = render_tree([p.as_posix() for p in rel_files])\\n\\n    file_sections: list[dict] = []\\n    total_lines = 0\\n    total_chars = 0\\n\\n    for f in files:\\n        rel = f.relative_to(root_abs).as_posix()\\n        try:\\n            if is_binary_file(f):\\n                content = f\\\"[binary file skipped: {f.name}, {f.stat().st_size} bytes]\\\"\\n                file_sections.append({\\n                    \\\"path\\\": rel,\\n                    \\\"language\\\": _language_from_ext(f.suffix),\\n                    \\\"content\\\": content,\\n                    \\\"is_truncated\\\": False,\\n                })\\n                total_chars += len(content)\\n                continue\\n\\n            content, used_encoding, truncated = read_text_safely(f, max_bytes=max_file_bytes)\\n            total_lines += content.count(\\\"\\\\n\\\") + (1 if content and not content.endswith(\\\"\\\\n\\\") else 0)\\n            total_chars += len(content)\\n\\n            if truncated:\\n                note = f\\\"\\\\n\\\\n[... TRUNCATED to first {max_file_bytes} bytes ...]\\\"\\n                content = content + note\\n                total_chars += len(note)\\n\\n            file_sections.append({\\n                \\\"path\\\": rel,\\n                \\\"language\\\": _language_from_ext(f.suffix),\\n                \\\"content\\\": content,\\n                \\\"is_truncated\\\": truncated,\\n            })\\n        except Exception as exc:\\n            print(f\\\"[rcpack] error reading {rel}: {exc}\\\", file=sys.stderr)\\n            continue\\n\\n    # render in chosen format\\n    if fmt == \\\"markdown\\\":\\n        out_text = md_renderer.render_markdown(\\n            root=str(root_abs),\\n            repo_info=repo_info,\\n            tree_text=project_tree,\\n            files=file_sections,\\n            total_files=len(file_sections),\\n            total_lines=total_lines,\\n        )\\n    elif fmt == \\\"json\\\":\\n        out_text = render_json(\\n            root=str(root_abs),\\n            repo_info=repo_info,\\n            tree_text=project_tree,\\n            files=file_sections,\\n            total_files=len(file_sections),\\n            total_lines=total_lines,\\n        )\\n    elif fmt == \\\"yaml\\\":\\n        out_text = render_yaml(\\n            root=str(root_abs),\\n            repo_info=repo_info,\\n            tree_text=project_tree,\\n            files=file_sections,\\n            total_files=len(file_sections),\\n            total_lines=total_lines,\\n        )\\n    else:\\n        raise ValueError(f\\\"Unsupported format: {fmt}\\\")\\n\\n    stats = {\\\"files\\\": len(file_sections), \\\"lines\\\": total_lines, \\\"chars\\\": total_chars}\\n    return out_text, stats\\n\\n\\ndef _language_from_ext(ext: str) -> str:\\n    ext = ext.lower().lstrip(\\\".\\\")\\n    mapping = {\\n        \\\"py\\\": \\\"python\\\", \\\"js\\\": \\\"javascript\\\", \\\"ts\\\": \\\"typescript\\\",\\n        \\\"json\\\": \\\"json\\\", \\\"md\\\": \\\"markdown\\\", \\\"yml\\\": \\\"yaml\\\", \\\"yaml\\\": \\\"yaml\\\",\\n        \\\"toml\\\": \\\"toml\\\", \\\"sh\\\": \\\"bash\\\", \\\"c\\\": \\\"c\\\", \\\"cpp\\\": \\\"cpp\\\",\\n        \\\"java\\\": \\\"java\\\", \\\"go\\\": \\\"go\\\", \\\"rs\\\": \\\"rust\\\",\\n    }\\n    return mapping.get(ext, \\\"\\\")\\n\",\n    \"src/rcpack/renderer/jsonyaml.py\": \"from __future__ import annotations\\nimport json\\n\\ntry:\\n    import yaml\\nexcept ImportError:\\n    yaml = None\\n\\n\\ndef render_json(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\\n    data = {\\n        \\\"root\\\": root,\\n        \\\"repo_info\\\": repo_info,\\n        \\\"structure\\\": tree_text,\\n        \\\"recent_changes\\\": recent_files or [],\\n        \\\"files\\\": files,\\n        \\\"file_sizes\\\": file_sizes or {},\\n        \\\"summary\\\": {\\\"total_files\\\": total_files, \\\"total_lines\\\": total_lines},\\n        \\n    }\\n    return json.dumps(data, indent=2, ensure_ascii=False)\\n\\n\\ndef render_yaml(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\\n    if yaml is None:\\n        raise RuntimeError(\\\"PyYAML not installed; run `pip install pyyaml`\\\")\\n    data = {\\n        \\\"root\\\": root,\\n        \\\"repo_info\\\": repo_info,\\n        \\\"structure\\\": tree_text,\\n        \\\"recent_changes\\\": recent_files or [],\\n        \\\"files\\\": files,\\n        \\\"file_sizes\\\": file_sizes or {},\\n        \\\"summary\\\": {\\\"total_files\\\": total_files, \\\"total_lines\\\": total_lines},\\n        \\n    }\\n    return yaml.safe_dump(data, sort_keys=False, allow_unicode=True)\\n\",\n    \"src/rcpack/renderer/markdown.py\": \"\\\"\\\"\\\"Markdown renderer for repository context.\\\"\\\"\\\"\\n\\nfrom typing import Dict, Any\\n\\n\\ndef render_markdown(root: str, repo_info: Dict[str, Any], tree_text: str, \\n                   files: Dict[str, str], total_files: int, total_lines: int, recent_files=None, file_sizes=None) -> str:\\n    \\\"\\\"\\\"Render repository context as markdown.\\\"\\\"\\\"\\n    \\n    lines = []\\n    \\n    # Header\\n    lines.append(f\\\"# Repository Context: {root}\\\")\\n    lines.append(\\\"\\\")\\n    \\n    # Repository info\\n    if repo_info.get(\\\"is_repo\\\"):\\n        lines.append(\\\"## Git Repository Information\\\")\\n        lines.append(f\\\"- **Branch**: {repo_info.get('branch', 'N/A')}\\\")\\n        lines.append(f\\\"- **Commit**: {repo_info.get('commit', 'N/A')}\\\")\\n        lines.append(f\\\"- **Author**: {repo_info.get('author', 'N/A')}\\\")\\n        lines.append(f\\\"- **Date**: {repo_info.get('date', 'N/A')}\\\")\\n    else:\\n        lines.append(\\\"## Repository Information\\\")\\n        lines.append(f\\\"- **Note**: {repo_info.get('note', 'Not a git repository')}\\\")\\n    lines.append(\\\"\\\")\\n    \\n    # Summary\\n    lines.append(\\\"## Summary\\\")\\n    lines.append(f\\\"- **Total Files**: {total_files}\\\")\\n    lines.append(f\\\"- **Total Lines**: {total_lines}\\\")\\n    lines.append(\\\"\\\")\\n    \\n    # Directory structure\\n    lines.append(\\\"## Directory Structure\\\")\\n    lines.append(\\\"```\\\")\\n    lines.append(tree_text)\\n    lines.append(\\\"```\\\")\\n    lines.append(\\\"\\\")\\n\\n    # will produce recent files \\n    # Recent files (fixed)\\n    if recent_files:\\n        lines.append(\\\"## Recent Changes\\\")\\n        for file, age in recent_files.items():\\n            lines.append(f\\\"- {file} (modified {age})\\\")\\n        lines.append(\\\"\\\")\\n    \\n    # File contents\\n    lines.append(\\\"## File Contents\\\")\\n    lines.append(\\\"\\\")\\n    \\n    for file_path, content in sorted(files.items()):\\n        if file_sizes and file_path in file_sizes:\\n            size_bytes = file_sizes[file_path]\\n            lines.append(f\\\"### {file_path} ({size_bytes} bytes)\\\")\\n        else:\\n            lines.append(f\\\"### {file_path}\\\")\\n        lines.append(\\\"\\\")\\n        \\n        # Detect language for syntax highlighting\\n        ext = file_path.split('.')[-1].lower() if '.' in file_path else ''\\n        lang_map = {\\n            'py': 'python', 'js': 'javascript', 'ts': 'typescript',\\n            'java': 'java', 'cpp': 'cpp', 'c': 'c', 'h': 'c',\\n            'cs': 'csharp', 'php': 'php', 'rb': 'ruby',\\n            'go': 'go', 'rs': 'rust', 'swift': 'swift',\\n            'html': 'html', 'css': 'css', 'scss': 'scss',\\n            'json': 'json', 'yaml': 'yaml', 'yml': 'yaml',\\n            'xml': 'xml', 'sql': 'sql', 'sh': 'bash',\\n            'md': 'markdown', 'dockerfile': 'dockerfile'\\n        }\\n        \\n        language = lang_map.get(ext, '')\\n        lines.append(f\\\"```{language}\\\")\\n        lines.append(content)\\n        lines.append(\\\"```\\\")\\n        lines.append(\\\"\\\")\\n    \\n    return \\\"\\\\n\\\".join(lines)\\n\",\n    \"src/rcpack/treeview.py\": \"\\\"\\\"\\\"Tree view generation for repository structure.\\\"\\\"\\\"\\n\\nfrom pathlib import Path\\nfrom typing import Dict, List\\n\\n\\ndef create_tree_view(repo_path: Path, files_data: Dict[str, str]) -> str:\\n    \\\"\\\"\\\"Create a tree view of the repository structure.\\\"\\\"\\\"\\n    paths = list(files_data.keys())\\n    return render_tree(paths)\\n\\n\\ndef render_tree(paths: List[str]) -> str:\\n    \\\"\\\"\\\"Render a tree view from a list of relative POSIX paths.\\\"\\\"\\\"\\n    tree_structure: dict = {}\\n\\n    for p in paths:\\n        parts = Path(p).parts\\n        current = tree_structure\\n        for part in parts[:-1]:\\n            if part not in current:\\n                current[part] = {}\\n            current = current[part]\\n        if parts:\\n            current[parts[-1]] = None\\n\\n    def _render(structure: dict, prefix: str = \\\"\\\") -> str:\\n        lines = []\\n        items = sorted(structure.items(), key=lambda x: (x[1] is None, x[0]))\\n        for i, (name, subtree) in enumerate(items):\\n            is_last = i == len(items) - 1\\n            lines.append(f\\\"{prefix}{'└── ' if is_last else '├── '}{name}\\\")\\n            if subtree is not None:\\n                extension = (\\\"    \\\" if is_last else \\\"│   \\\")\\n                lines.append(_render(subtree, prefix + extension))\\n        return \\\"\\\\n\\\".join(filter(None, lines))\\n\\n    if not tree_structure:\\n        return \\\"No files found\\\"\\n    return _render(tree_structure)\"\n  },\n  \"file_sizes\": {\n    \"LICENSE\": \"1064\",\n    \"README.md\": \"11164\",\n    \"pyproject.toml\": \"361\",\n    \"src/rcpack/__init__.py\": \"198\",\n    \"src/rcpack/__main__.py\": \"197\",\n    \"src/rcpack/cli.py\": \"7087\",\n    \"src/rcpack/config_loader.py\": \"2099\",\n    \"src/rcpack/discover.py\": \"3067\",\n    \"src/rcpack/gitinfo.py\": \"1653\",\n    \"src/rcpack/io_utils.py\": \"1817\",\n    \"src/rcpack/packager.py\": \"4430\",\n    \"src/rcpack/renderer/jsonyaml.py\": \"1176\",\n    \"src/rcpack/renderer/markdown.py\": \"2829\",\n    \"src/rcpack/treeview.py\": \"1371\"\n  },\n  \"summary\": {\n    \"total_files\": 14,\n    \"total_lines\": 1180\n  }\n}",
    "test-yaml.yaml": "root: /Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\nrepo_info:\n  is_repo: true\n  commit: 682153b169db66d3a72e9cabdd1f3448a3b2986d\n  branch: refactoring\n  author: Abhinav <abhinavbhardwaj2002@gmail.com>\n  date: Fri Oct 3 18:45:48 2025\n  note: null\nstructure: '├── src\n\n  │   └── rcpack\n\n  │       ├── renderer\n\n  │       │   ├── jsonyaml.py\n\n  │       │   └── markdown.py\n\n  │       ├── __init__.py\n\n  │       ├── __main__.py\n\n  │       ├── cli.py\n\n  │       ├── config_loader.py\n\n  │       ├── discover.py\n\n  │       ├── gitinfo.py\n\n  │       ├── io_utils.py\n\n  │       ├── packager.py\n\n  │       └── treeview.py\n\n  ├── LICENSE\n\n  ├── README.md\n\n  ├── pyproject.toml\n\n  └── test-output.json'\nrecent_changes: []\nfiles:\n  LICENSE: 'MIT License\n\n\n    Copyright (c) 2025 Abhinav\n\n\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n\n    of this software and associated documentation files (the \"Software\"), to deal\n\n    in the Software without restriction, including without limitation the rights\n\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n\n    copies of the Software, and to permit persons to whom the Software is\n\n    furnished to do so, subject to the following conditions:\n\n\n    The above copyright notice and this permission notice shall be included in all\n\n    copies or substantial portions of the Software.\n\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n\n    SOFTWARE.\n\n    '\n  README.md: \"# Repo-Contextor\\n\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\n\\\n    [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\n\\\n    \\nA powerful Repository Context Packager CLI tool that analyzes local git repositories\\\n    \\ and creates comprehensive text files containing repository content optimized\\\n    \\ for sharing with Large Language Models (LLMs).\\n\\n## Overview\\n\\nWhen developers\\\n    \\ want to get help from ChatGPT, Claude, or other LLMs about their code, they\\\n    \\ often struggle with how to share their codebase effectively. Common problems\\\n    \\ include:\\n\\n- **Lost Context**: Copy-pasting individual files loses important\\\n    \\ project structure and relationships\\n- **Missing Dependencies**: LLMs can't\\\n    \\ see how files connect or what libraries are used\\n- **Incomplete Picture**:\\\n    \\ Hard to convey the overall architecture and organization\\n- **Manual Work**:\\\n    \\ Time-consuming to gather and format relevant code\\n\\n**Repo-Contextor** solves\\\n    \\ this by automatically collecting and formatting repository content into a single,\\\n    \\ well-structured text file that provides rich context to LLMs, enabling them\\\n    \\ to give much better assistance with your code.\\n\\n## Features\\n\\n- **Git Integration**:\\\n    \\ Extracts commit SHA, branch, author, and date information\\n- **Project Structure**:\\\n    \\ Generates a clear directory tree visualization\\n- **File Content Packaging**:\\\n    \\ Includes file contents with syntax highlighting\\n- **Smart File Discovery**:\\\n    \\ Recursively scans directories with intelligent filtering\\n- **Binary File Detection**:\\\n    \\ Automatically skips binary files\\n- **Error Handling**: Gracefully handles permission\\\n    \\ errors and provides helpful messages\\n- **Multiple Output Formats**: Supports\\\n    \\ Markdown, JSON, and YAML formats\\n- **Flexible Output**: Write to stdout or\\\n    \\ save to a file\\n- **Recent Changes Filter**: Give the files which are updated\\\n    \\ in last 7days with the time when it was recently modified.\\n\\n## Installation\\n\\\n    \\n### Prerequisites\\n\\n- Python 3.9 or higher\\n- Git (for git repository analysis)\\n\\\n    \\n### For End Users\\n\\n```bash\\n# Clone and install\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\n\\\n    cd Repo-Contextor\\npip install -e .\\n```\\n\\n### For Contributors & Local Development\\n\\\n    \\n```bash\\n# Clone the repository\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\n\\\n    cd Repo-Contextor\\n\\n# Create virtual environment\\npython -m venv .venv\\nsource\\\n    \\ .venv/bin/activate  # On Windows: .venv\\\\Scripts\\\\activate\\n\\n# Install in development\\\n    \\ mode\\npip install -e .\\n```\\n\\n## Usage\\n\\n### Basic Examples\\n\\n```bash\\n#\\\n    \\ Package current directory to terminal\\nrepo-contextor .\\n\\n# Package a specific\\\n    \\ directory\\nrepo-contextor /path/to/your/project\\n\\n# Save output to a file\\n\\\n    repo-contextor . -o my-project-context.md\\n\\n# Generate JSON format\\nrepo-contextor\\\n    \\ . -f json -o context.json\\n\\n# Generate YAML format\\nrepo-contextor . -f yaml\\\n    \\ -o context.yaml\\n\\n# Include only files modified in the last 7 days\\nrepo-contextor\\\n    \\ . --recent\\n\\n# Combine with output file\\nrepo-contextor . --recent -o recent-changes.md\\n\\\n    ```\\n\\n### Command Line Options\\n\\n| Option | Short | Description | Example |\\n\\\n    |--------|-------|-------------|---------|\\n| `path` | - | Repository path to\\\n    \\ analyze (default: current directory) | `repo-contextor /path/to/project` |\\n\\\n    | `--output` | `-o` | Output file path (default: stdout) | `-o context.md` |\\n\\\n    | `--format` | `-f` | Output format: text, json, yaml (default: text) | `-f json`\\\n    \\ |\\n| `--help` | `-h` | Show help message | `-h` |\\n| `--recent`  | `-r`  | Include\\\n    \\ only files modified in the last 7 days    | `repo-contextor . -r -o recent.md`\\\n    \\ |\\n\\n### Advanced Examples\\n\\n```bash\\n# Analyze different repository\\nrepo-contextor\\\n    \\ /path/to/other/project -o other-project.md\\n\\n# Generate JSON for API consumption\\n\\\n    repo-contextor . -f json -o api-context.json\\n\\n# Create YAML configuration\\n\\\n    repo-contextor . -f yaml -o project-config.yaml\\n\\n# Generate files which are\\\n    \\ changed recently in 7 days\\nrepo-contextor . -r --output recent-changes.txt\\n\\\n    \\n```\\n## Configuration via TOML\\n\\nRepo-Contextor supports configuration through\\\n    \\ a `.repo-contextor.toml` file in the current working directory.  \\nThis file\\\n    \\ allows you to avoid typing the same CLI arguments every time.\\n\\nExample `.repo-contextor.toml`:\\n\\\n    \\n```toml\\n# Output file to write results\\noutput = \\\"context.yaml\\\"\\n\\n# Output\\\n    \\ format: text, json, or yaml\\nformat = \\\"yaml\\\"\\n\\n# Limit to files modified\\\n    \\ in the last 7 days\\nrecent = true\\n\\n# Repository path to analyze (default =\\\n    \\ current directory)\\npath = \\\".\\\"\\n```\\n### Rules\\n- If the `.repo-contextor.toml`\\\n    \\ file is **missing**, the tool falls back to defaults.  \\n- If the file is **present\\\n    \\ but invalid TOML**, the tool prints a clear error message and exits with status\\\n    \\ code 1.  \\n- **Unknown keys** in the TOML file are ignored (safe for future\\\n    \\ extensions).  \\n- **Precedence** of settings is:\\n  1. Command-line arguments\\\n    \\ (highest priority)  \\n  2. Values from `.repo-contextor.toml`  \\n  3. Built-in\\\n    \\ defaults (lowest priority)\\n     \\n## Output Format\\n\\nThe tool generates a\\\n    \\ structured text file with the following sections:\\n\\n### 1. Repository Context\\\n    \\ Header\\nProject path and identification\\n\\n### 2. Git Repository Information\\n\\\n    - Current branch\\n- Latest commit SHA\\n- Last commit author\\n- Last commit date\\n\\\n    \\n### 3. Summary Statistics\\n- Total number of files processed\\n- Total lines\\\n    \\ of code\\n\\n### 4. Directory Structure\\nClean tree visualization showing project\\\n    \\ organization\\n\\n### 5. Recent Changes (if `--recent` is used)\\n\\n- Lists files\\\n    \\ modified in the last 7 days.\\n- Shows relative file paths along with how long\\\n    \\ ago each file was modified\\n- Helps focus on recently updated parts of the project.\\n\\\n    - Can be combined with `--output` or `--format` to save or change the output type.\\n\\\n    \\n\\n### 5. File Contents\\nEach file's content with:\\n- Clear file path headers\\n\\\n    - Appropriate syntax highlighting language tags\\n- Complete file contents\\n\\n\\\n    ## Example Output\\n\\nWhen you run `repo-contextor .`, the output looks like this:\\n\\\n    \\n````markdown\\n# Repository Context: /path/to/your/project\\n\\n## Git Repository\\\n    \\ Information\\n- **Branch**: main\\n- **Commit**: a1b2c3d4e5f6789...\\n- **Author**:\\\n    \\ John Doe <john@example.com>\\n- **Date**: Fri Sep 12 14:30:15 2025\\n\\n## Summary\\n\\\n    - **Total Files**: 15\\n- **Total Lines**: 1,247\\n\\n## Directory Structure\\n```\\n\\\n    ├── src/\\n│   ├── main.py\\n│   └── utils.py\\n├── tests/\\n│   └── test_main.py\\n\\\n    ├── README.md\\n└── requirements.txt\\n```\\n## Recent Changes\\n- src/main.py (modified\\\n    \\ 2 days ago)\\n- src/utils/helpers.py (modified 5 days ago)\\n\\n## File Contents\\n\\\n    \\n### src/main.py\\n\\n```python\\ndef main():\\n    print(\\\"Hello, World!\\\")\\n\\n\\\n    if __name__ == \\\"__main__\\\":\\n    main()\\n```\\n\\n### README.md\\n\\n```markdown\\n\\\n    # My Project\\nThis is a sample project.\\n```\\n\\n## Summary\\n- Total files: 15\\n\\\n    - Total lines: 1,247\\n````\\n\\n## What Files Are Included\\n\\nThe tool includes\\\n    \\ most text files but automatically excludes:\\n\\n### Excluded Directories\\n- `.git`,\\\n    \\ `.svn`, `.hg` (version control)\\n- `__pycache__`, `.pytest_cache` (Python cache)\\n\\\n    - `node_modules`, `.venv`, `venv` (dependencies/environments)\\n- `.vscode`, `.idea`\\\n    \\ (IDE directories)\\n- `build`, `dist`, `target` (build directories)\\n\\n### File\\\n    \\ Handling Rules\\n- **Text files**: All readable text files with common extensions\\n\\\n    - **Binary files**: Automatically detected and skipped\\n- **Permission errors**:\\\n    \\ Skipped with graceful handling\\n- **Configuration files**: Includes pyproject.toml,\\\n    \\ package.json, etc.\\n\\n### Included File Types\\n- Source code: `.py`, `.js`,\\\n    \\ `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\n- Web files: `.html`, `.css`,\\\n    \\ `.scss`, `.vue`, `.jsx`, etc.\\n- Documentation: `.md`, `.txt`, `.rst`\\n- Configuration:\\\n    \\ `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\n- Scripts: `.sh`, `.bash`, `.zsh`\\n\\\n    \\n## Error Handling\\n\\nThe tool handles errors gracefully:\\n\\n| Error Type | Behavior\\\n    \\ |\\n|------------|----------|\\n| **Permission errors** | Skipped with warning\\\n    \\ |\\n| **Binary files** | Automatically detected and skipped |\\n| **Invalid paths**\\\n    \\ | Clear error messages |\\n| **Non-git repositories** | Works fine, shows \\\"\\\n    Not a git repository\\\" |\\n| **Unreadable files** | Marked as \\\"[Binary or unreadable\\\n    \\ file]\\\" |\\n\\n## Development\\n\\n### Project Structure\\n\\n```text\\nRepo-Contextor/\\n\\\n    ├── src/rcpack/              # Main package\\n│   ├── __init__.py         # Package\\\n    \\ initialization\\n│   ├── cli.py              # Command-line interface\\n│   ├──\\\n    \\ discover.py         # File discovery logic\\n│   ├── gitinfo.py          # Git\\\n    \\ repository analysis\\n│   ├── treeview.py         # Directory tree generation\\n\\\n    │   ├── packager.py         # Main orchestration\\n│   ├── io_utils.py        \\\n    \\ # File I/O utilities\\n│   └── renderer/           # Output formatters\\n│   \\\n    \\    ├── markdown.py     # Markdown renderer\\n│       └── jsonyaml.py     # JSON/YAML\\\n    \\ renderers\\n├── pyproject.toml          # Project configuration\\n├── LICENSE\\\n    \\                 # MIT License\\n└── README.md              # This documentation\\n\\\n    ```\\n\\n### Running Tests\\n\\n```bash\\n# Test on current repository\\nrepo-contextor\\\n    \\ . -o test-output.md\\n\\n# Test different formats\\nrepo-contextor . -f json |\\\n    \\ head -20\\nrepo-contextor . -f yaml | head -20\\n\\n# Test specific directory\\n\\\n    repo-contextor src/ -o src-only.md\\n```\\n\\n### Contributing\\n\\n1. **Fork the repository**\\n\\\n    2. **Clone your fork:**\\n   ```bash\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\n\\\n    \\   cd Repo-Contextor\\n   ```\\n3. **Install for development:**\\n   ```bash\\n \\\n    \\  python -m venv .venv\\n   source .venv/bin/activate\\n   pip install -e .\\n \\\n    \\  ```\\n4. **Make your changes and test:**\\n   ```bash\\n   repo-contextor . -o\\\n    \\ test.md\\n   ```\\n5. **Submit a pull request**\\n\\n### Development Workflow\\n\\n\\\n    ```bash\\n# 1. Setup development environment\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\n\\\n    cd Repo-Contextor\\npython -m venv .venv\\nsource .venv/bin/activate\\npip install\\\n    \\ -e .\\n\\n# 2. Make changes to the code\\n# Edit files in src/rcpack/\\n\\n# 3. Test\\\n    \\ your changes\\nrepo-contextor . -o test-output.md\\n\\n# 4. Test different formats\\n\\\n    repo-contextor . -f json -o test.json\\nrepo-contextor . -f yaml -o test.yaml\\n\\\n    \\n# 5. Commit and push changes\\ngit add .\\ngit commit -m \\\"Add new feature\\\"\\n\\\n    git push origin feature-branch\\n```\\n\\n## License\\n\\nThis project is licensed\\\n    \\ under the MIT License. See the [LICENSE](LICENSE) file for details.\\n\\n## Why\\\n    \\ Repo-Contextor?\\n\\nThe name \\\"Repo-Contextor\\\" combines \\\"Repository\\\" + \\\"\\\n    Context\\\" + \\\"or\\\", representing the tool's purpose of providing rich context\\\n    \\ about code repositories in a format that's perfect for LLM interactions.\\n\\n\\\n    ### Use Cases\\n\\n- **AI Assistance**: Get better help from ChatGPT, Claude, or\\\n    \\ GitHub Copilot\\n- **Code Reviews**: Share complete project context with team\\\n    \\ members\\n- **Documentation**: Create comprehensive project snapshots\\n- **Onboarding**:\\\n    \\ Help new team members understand project structure\\n- **Project Analysis**:\\\n    \\ Understand repository structure and dependencies\\n\\n### Perfect for LLMs\\n\\n\\\n    The output format is specifically designed to work well with Large Language Models:\\n\\\n    - Clear section headers for easy parsing\\n- Syntax highlighting markers for code\\\n    \\ blocks\\n- Structured metadata (git info, file locations)\\n- Complete project\\\n    \\ context in a single file\\n- Multiple output formats (Markdown, JSON, YAML)\\n\\\n    - Optimized for token efficiency\\n\"\n  pyproject.toml: \"[build-system]\\nrequires = [\\\"setuptools>=68\\\", \\\"wheel\\\"]\\nbuild-backend\\\n    \\ = \\\"setuptools.build_meta\\\"\\n\\n[project]\\nname = \\\"rcpack\\\"\\nversion = \\\"0.1.0\\\"\\\n    \\ndescription = \\\"Repository Context Packager CLI for LLMs\\\"\\nreadme = \\\"README.md\\\"\\\n    \\nrequires-python = \\\">=3.9\\\"\\nlicense = { text = \\\"MIT\\\" }\\ndependencies = [\\n\\\n    \\    \\\"PyYAML>=6.0\\\"\\n]\\n\\n[project.scripts]\\nrepo-contextor = \\\"rcpack.cli:main\\\"\\\n    \\n\"\n  src/rcpack/__init__.py: '\"\"\"Repository Context Packager - CLI tool for creating\n    LLM-optimized repository context.\"\"\"\n\n\n    __version__ = \"0.1.0\"\n\n    __author__ = \"Abhinav\"\n\n    __description__ = \"Repository Context Packager CLI for LLMs\"'\n  src/rcpack/__main__.py: \"#!/usr/bin/env python3\\n\\\"\\\"\\\"Module entry point to enable\\\n    \\ `python -m rcpack`.\\n\\nThis simply delegates to the CLI's main() function.\\n\\\n    \\\"\\\"\\\"\\n\\nfrom .cli import main\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\\\n    \\n\\n\"\n  src/rcpack/cli.py: \"#!/usr/bin/env python3\\n\\\"\\\"\\\"CLI for Repository Context Packager.\\\"\\\n    \\\"\\\"\\n\\nfrom .config_loader import load_config\\n\\nimport argparse\\nimport sys\\n\\\n    from pathlib import Path\\nfrom .gitinfo import get_git_info\\nfrom .discover import\\\n    \\ discover_files\\nfrom .treeview import create_tree_view\\nfrom .renderer.markdown\\\n    \\ import render_markdown\\nfrom .renderer.jsonyaml import render_json, render_yaml\\n\\\n    from .io_utils import write_output\\nfrom datetime import datetime, timedelta\\n\\\n    \\n\\ndef log_verbose(message: str, verbose: bool) -> None:\\n    \\\"\\\"\\\"Log a message\\\n    \\ to stderr if verbose mode is enabled.\\\"\\\"\\\"\\n    if verbose:\\n        print(message,\\\n    \\ file=sys.stderr)\\n\\n\\ndef get_rendered_content(format_type: str, repo_path:\\\n    \\ str, repo_info: dict, tree_text: str, \\n                        files_data:\\\n    \\ dict, total_files: int, total_lines: int, \\n                        recent_files_info:\\\n    \\ dict, file_sizes: dict) -> str:\\n    \\\"\\\"\\\"Get rendered content based on the\\\n    \\ specified format.\\\"\\\"\\\"\\n    if format_type == \\\"json\\\":\\n        return render_json(\\n\\\n    \\            repo_path, repo_info, tree_text, \\n            files_data, total_files,\\\n    \\ total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n\\\n    \\        )\\n    elif format_type == \\\"yaml\\\":\\n        return render_yaml(\\n \\\n    \\           repo_path, repo_info, tree_text, \\n            files_data, total_files,\\\n    \\ total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n\\\n    \\        )\\n    else:  # text/markdown\\n        return render_markdown(\\n    \\\n    \\        repo_path, repo_info, tree_text, \\n            files_data, total_files,\\\n    \\ total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n\\\n    \\        )\\n\\n\\ndef process_file(file_path: Path, repo_path: Path, verbose: bool)\\\n    \\ -> tuple[str, str, str]:\\n    \\\"\\\"\\\"Process a single file and return its data.\\n\\\n    \\    \\n    Returns:\\n        tuple: (relative_path_str, content, file_size)\\n\\\n    \\    \\\"\\\"\\\"\\n    relative_path = file_path.relative_to(repo_path)\\n    relative_path_str\\\n    \\ = str(relative_path)\\n    \\n    log_verbose(f\\\"Reading file: {relative_path}\\\"\\\n    , verbose)\\n    file_size = file_path.stat().st_size\\n    \\n    try:\\n       \\\n    \\ with open(file_path, 'r', encoding='utf-8') as f:\\n            content = f.read()\\n\\\n    \\        return relative_path_str, content, str(file_size)\\n    except (UnicodeDecodeError,\\\n    \\ PermissionError):\\n        log_verbose(f\\\"Skipping binary/unreadable file: {relative_path}\\\"\\\n    , verbose)\\n        file_size = file_path.stat().st_size if file_path.exists()\\\n    \\ else 0\\n        content = f\\\"[Binary or unreadable file: {file_path.name}]\\\"\\\n    \\n        return relative_path_str, content, str(file_size)\\n    except Exception:\\n\\\n    \\        log_verbose(f\\\"Error reading file: {relative_path}\\\", verbose)\\n    \\\n    \\    raise  # Re-raise to handle in calling code\\n\\n\\ndef handle_output(content:\\\n    \\ str, output_path: str = None) -> None:\\n    \\\"\\\"\\\"Handle output to either file\\\n    \\ or stdout.\\\"\\\"\\\"\\n    if output_path:\\n        # Write to file\\n        write_output(output_path,\\\n    \\ content)\\n        print(f\\\"Context package created: {output_path}\\\")\\n    else:\\n\\\n    \\        # Output to stdout\\n        print(content)\\n\\n\\ndef main():\\n    parser\\\n    \\ = argparse.ArgumentParser(\\n        description=\\\"Package repository content\\\n    \\ for LLM context\\\"\\n    )\\n    parser.add_argument(\\n        \\\"path\\\", \\n   \\\n    \\     nargs=\\\"?\\\", \\n        default=\\\".\\\", \\n        help=\\\"Repository path (default:\\\n    \\ current directory)\\\"\\n    )\\n    parser.add_argument(\\n        \\\"-o\\\", \\\"--output\\\"\\\n    , \\n        help=\\\"Output file path (default: stdout)\\\"\\n    )\\n    parser.add_argument(\\n\\\n    \\        \\\"-f\\\", \\\"--format\\\", \\n        choices=[\\\"text\\\", \\\"json\\\", \\\"yaml\\\"\\\n    ], \\n        default=\\\"text\\\",\\n        help=\\\"Output format (default: text)\\\"\\\n    \\n    )\\n\\n    \\\"\\\"\\\" This will read -r from the console and able to search it\\\n    \\ with this\\\"\\\"\\\"\\n    parser.add_argument(\\n    \\\"-r\\\", \\\"--recent\\\",\\n    action=\\\"\\\n    store_true\\\",\\n    help=\\\"Include only files modified in the last 7 days\\\"\\n \\\n    \\   )\\n    parser.add_argument(\\n        \\\"-v\\\", \\\"--verbose\\\",\\n        action=\\\"\\\n    store_true\\\",\\n        help=\\\"Print detailed progress information to stderr\\\"\\n\\\n    \\    )\\n    \\n    args = parser.parse_args()\\n    \\n    try:\\n        repo_path\\\n    \\ = Path(args.path).resolve()\\n        if not repo_path.exists():\\n          \\\n    \\  print(f\\\"Error: Path {repo_path} does not exist\\\", file=sys.stderr)\\n     \\\n    \\       sys.exit(1)\\n            \\n        # Get repository information\\n    \\\n    \\    log_verbose(f\\\"Analyzing repository: {repo_path}\\\", args.verbose)\\n     \\\n    \\   repo_info = get_git_info(repo_path)\\n        \\n        # Discover files\\n\\\n    \\        log_verbose(f\\\"Discovering files in: {repo_path}\\\", args.verbose)\\n \\\n    \\       discovered_files = discover_files([repo_path], repo_path, [], [])\\n  \\\n    \\      log_verbose(f\\\"Found {len(discovered_files)} files\\\", args.verbose)\\n \\\n    \\       \\n        # will check the file in last 7 days\\n        recent_files_info\\\n    \\ = {}\\n        if args.recent:\\n            seven_days_ago = datetime.now() -\\\n    \\ timedelta(days=7)\\n            recent_files = []\\n            for f in discovered_files:\\n\\\n    \\                try:\\n                    mtime = datetime.fromtimestamp(f.stat().st_mtime)\\n\\\n    \\                    if mtime >= seven_days_ago:\\n                        recent_files.append(f)\\n\\\n    \\                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)\\\n    \\     \\n                except Exception:\\n                    continue\\n    \\\n    \\        discovered_files = recent_files\\n        \\n        # Read file contents\\n\\\n    \\        files_data = {}\\n        file_sizes = {}\\n        for file_path in discovered_files:\\n\\\n    \\            try:\\n                relative_path_str, content, file_size = process_file(file_path,\\\n    \\ repo_path, args.verbose)\\n                files_data[relative_path_str] = content\\n\\\n    \\                file_sizes[relative_path_str] = file_size\\n            except\\\n    \\ Exception:\\n                continue\\n        \\n        # Create tree view\\n\\\n    \\        log_verbose(\\\"Generating directory tree\\\", args.verbose)\\n        tree_text\\\n    \\ = create_tree_view(repo_path, files_data)\\n        \\n        # Count totals\\n\\\n    \\        total_files = len(files_data)\\n        total_lines = sum(len(content.splitlines())\\\n    \\ for _, content in files_data.items())\\n        \\n        # Render based on format\\n\\\n    \\        log_verbose(f\\\"Rendering output in {args.format} format\\\", args.verbose)\\n\\\n    \\        content = get_rendered_content(\\n            args.format, str(repo_path),\\\n    \\ repo_info, tree_text,\\n            files_data, total_files, total_lines,\\n \\\n    \\           recent_files_info if args.recent else {},\\n            file_sizes\\n\\\n    \\        )\\n        \\n        handle_output(content, args.output)\\n        \\n\\\n    \\    except Exception as e:\\n        print(f\\\"Error: {e}\\\", file=sys.stderr)\\n\\\n    \\        sys.exit(1)\\n\\n# this will convert age and give us the difference\\ndef\\\n    \\ human_readable_age(mtime: datetime) -> str:\\n    delta = datetime.now() - mtime\\n\\\n    \\    days = delta.days\\n    seconds = delta.seconds\\n    if days > 0:\\n      \\\n    \\  return f\\\"{days} day{'s' if days != 1 else ''} ago\\\"\\n    elif seconds >= 3600:\\n\\\n    \\        hours = seconds // 3600\\n        return f\\\"{hours} hour{'s' if hours\\\n    \\ != 1 else ''} ago\\\"\\n    elif seconds >= 60:\\n        minutes = seconds // 60\\n\\\n    \\        return f\\\"{minutes} minute{'s' if minutes != 1 else ''} ago\\\"\\n    else:\\n\\\n    \\        return \\\"just now\\\"\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\"\n  src/rcpack/config_loader.py: \"# src/rcpack/config_loader.py\\n\\\"\\\"\\\"\\nTOML config\\\n    \\ loader for Repo-Contextor.\\n\\nRules:\\n- Look for .repo-contextor.toml in the\\\n    \\ CURRENT directory\\n- If missing: ignore\\n- If present but invalid: print a clear\\\n    \\ error and exit(1)\\n- Only recognized keys are applied; unknown keys ignored\\n\\\n    - Precedence: CLI > TOML > DEFAULTS\\n\\\"\\\"\\\"\\nfrom __future__ import annotations\\n\\\n    import os, sys\\nfrom typing import Dict, Iterable, Any\\n\\ntry:\\n    import tomllib\\n\\\n    \\    _loads = tomllib.loads\\nexcept ModuleNotFoundError:\\n    try:\\n        import\\\n    \\ tomli\\n        _loads = tomli.loads\\n    except ModuleNotFoundError:\\n     \\\n    \\   _loads = None\\n\\ndef _need_toml():\\n    if _loads is None:\\n        print(\\\"\\\n    Error: TOML parser not available. Use Python 3.11+ or `pip install tomli`.\\\",\\\n    \\ file=sys.stderr)\\n        sys.exit(1)\\n\\ndef _load_toml(dotfile: str) -> Dict[str,\\\n    \\ Any]:\\n    _need_toml()\\n    if not os.path.exists(dotfile):\\n        return\\\n    \\ {}\\n    try:\\n        with open(dotfile, \\\"rb\\\") as f:\\n            raw = f.read().decode(\\\"\\\n    utf-8\\\", errors=\\\"strict\\\")\\n        data = _loads(raw)\\n        return data if\\\n    \\ isinstance(data, dict) else {}\\n    except Exception as e:\\n        print(f\\\"\\\n    Error: failed to parse {dotfile} as TOML.\\\\n{e}\\\", file=sys.stderr)\\n        sys.exit(1)\\n\\\n    \\ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\n\\\n    \\    ks = set(known)\\n    return {k: v for k, v in d.items() if k in ks}\\n\\ndef\\\n    \\ _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str,\\\n    \\ Any], known: Iterable[str]) -> Dict[str, Any]:\\n    ks = set(known)\\n    out:\\\n    \\ Dict[str, Any] = {k: defaults.get(k) for k in ks}\\n    for src in (filecfg,\\\n    \\ clicfg):\\n        for k, v in src.items():\\n            if k in ks and v is\\\n    \\ not None:\\n                out[k] = v\\n    return out\\n\\ndef load_config(*,\\\n    \\ dotfile: str = \\\".repo-contextor.toml\\\", defaults: Dict[str, Any] | None = None,\\\n    \\ cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ()) -> Dict[str,\\\n    \\ Any]:\\n    defaults = defaults or {}\\n    cli_cfg = cli_cfg or {}\\n    known\\\n    \\ = tuple(known_keys)\\n    filecfg = _filter_known(_load_toml(dotfile), known)\\n\\\n    \\    return _merge(defaults, filecfg, cli_cfg, known)\\n\"\n  src/rcpack/discover.py: \"\\\"\\\"\\\"File discovery module for repository analysis.\\\"\\\"\\\n    \\\"\\n\\nfrom pathlib import Path\\nfrom typing import List\\nimport fnmatch\\n\\n\\n\\\n    def discover_files(\\n    inputs: List[Path],\\n    root: Path,\\n    include_patterns:\\\n    \\ List[str],\\n    exclude_patterns: List[str],\\n) -> List[Path]:\\n    \\\"\\\"\\\"Discover\\\n    \\ relevant files.\\n\\n    - inputs: list of files/dirs to scan\\n    - root: common\\\n    \\ project root; patterns are matched against POSIX paths relative to root\\n  \\\n    \\  - include_patterns: glob patterns to include (if empty, use sensible defaults)\\n\\\n    \\    - exclude_patterns: glob patterns to exclude\\n    Returns a list of absolute\\\n    \\ Paths to files.\\n    \\\"\\\"\\\"\\n\\n    default_include_exts = {\\n        '.py',\\\n    \\ '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\\n        '.cs', '.php',\\\n    \\ '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\n        '.html', '.css', '.scss',\\\n    \\ '.sass', '.less', '.vue', '.svelte',\\n        '.md', '.txt', '.rst', '.yaml',\\\n    \\ '.yml', '.json', '.toml', '.ini',\\n        '.cfg', '.conf', '.xml', '.sql',\\\n    \\ '.sh', '.bash', '.zsh', '.fish',\\n    }\\n\\n    always_include_names = {\\n  \\\n    \\      'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING', 'Makefile',\\n       \\\n    \\ 'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\\n      \\\n    \\  'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\n\\\n    \\    }\\n\\n    skip_dir_names = {\\n        '.git', '.svn', '.hg', '__pycache__',\\\n    \\ '.pytest_cache',\\n        'node_modules', '.venv', 'venv', 'env', '.env',\\n\\\n    \\        'build', 'dist', 'target', 'out', '.next', '.nuxt',\\n        '.idea',\\\n    \\ '.vscode', '.vs', 'coverage', '.coverage'\\n    }\\n\\n    def matches_any(patterns:\\\n    \\ List[str], rel_posix: str) -> bool:\\n        return any(fnmatch.fnmatch(rel_posix,\\\n    \\ pat) for pat in patterns)\\n\\n    def should_take(file_path: Path) -> bool:\\n\\\n    \\        rel_posix = file_path.relative_to(root).as_posix()\\n        if exclude_patterns\\\n    \\ and matches_any(exclude_patterns, rel_posix):\\n            return False\\n  \\\n    \\      if include_patterns:\\n            return matches_any(include_patterns,\\\n    \\ rel_posix)\\n        # default include logic\\n        return file_path.name in\\\n    \\ always_include_names or file_path.suffix.lower() in default_include_exts\\n\\n\\\n    \\    discovered: list[Path] = []\\n    seen = set()\\n\\n    for item in inputs:\\n\\\n    \\        p = item.resolve()\\n        if p.is_file():\\n            # Skip if excluded\\\n    \\ or in skipped directory\\n            if any(part in skip_dir_names for part\\\n    \\ in p.parts):\\n                continue\\n            if should_take(p):\\n   \\\n    \\             key = p.as_posix()\\n                if key not in seen:\\n      \\\n    \\              seen.add(key)\\n                    discovered.append(p)\\n     \\\n    \\   elif p.is_dir():\\n            for child in p.rglob('*'):\\n               \\\n    \\ if not child.is_file():\\n                    continue\\n                if any(part\\\n    \\ in skip_dir_names for part in child.parts):\\n                    continue\\n\\\n    \\                if should_take(child):\\n                    key = child.resolve().as_posix()\\n\\\n    \\                    if key not in seen:\\n                        seen.add(key)\\n\\\n    \\                        discovered.append(child.resolve())\\n\\n    return sorted(discovered)\"\n  src/rcpack/gitinfo.py: \"from __future__ import annotations\\n\\nimport subprocess\\n\\\n    from pathlib import Path\\nfrom typing import Dict, Any\\n\\n\\ndef _git(cmd: list[str],\\\n    \\ cwd: Path) -> str:\\n    # Validate git commands to prevent injection\\n    allowed_commands\\\n    \\ = {\\n        \\\"rev-parse\\\", \\\"show\\\", \\\"log\\\", \\\"status\\\", \\\"branch\\\", \\\"config\\\"\\\n    \\n    }\\n    if not cmd or cmd[0] not in allowed_commands:\\n        raise ValueError(f\\\"\\\n    Git command not allowed: {cmd[0] if cmd else 'empty'}\\\")\\n    \\n    out = subprocess.check_output([\\\"\\\n    git\\\", *cmd], cwd=str(cwd), timeout=30)\\n    return out.decode(\\\"utf-8\\\", errors=\\\"\\\n    replace\\\").strip()\\n\\n\\ndef is_git_repo(path: Path) -> bool:\\n    try:\\n     \\\n    \\   flag = _git([\\\"rev-parse\\\", \\\"--is-inside-work-tree\\\"], cwd=path)\\n      \\\n    \\  return flag == \\\"true\\\"\\n    except Exception:\\n        return False\\n\\n\\n\\\n    def get_git_info(path: Path) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Return info for\\\n    \\ the current HEAD of a repo rooted at `path`.\\n    \\\"\\\"\\\"\\n    try:\\n       \\\n    \\ commit = _git([\\\"rev-parse\\\", \\\"HEAD\\\"], cwd=path)\\n        branch = _git([\\\"\\\n    rev-parse\\\", \\\"--abbrev-ref\\\", \\\"HEAD\\\"], cwd=path)\\n        author = _git([\\\"\\\n    show\\\", \\\"-s\\\", \\\"--format=%an <%ae>\\\"], cwd=path)\\n        date = _git([\\\"show\\\"\\\n    , \\\"-s\\\", \\\"--date=local\\\", \\\"--format=%ad\\\"], cwd=path)\\n        return {\\n \\\n    \\           \\\"is_repo\\\": True,\\n            \\\"commit\\\": commit,\\n            \\\"\\\n    branch\\\": branch,\\n            \\\"author\\\": author,\\n            \\\"date\\\": date,\\n\\\n    \\            \\\"note\\\": None,\\n        }\\n    except Exception:\\n        # treat\\\n    \\ as not a repo if anything fails\\n        return {\\n            \\\"is_repo\\\":\\\n    \\ False,\\n            \\\"commit\\\": None,\\n            \\\"branch\\\": None,\\n     \\\n    \\       \\\"author\\\": None,\\n            \\\"date\\\": None,\\n            \\\"note\\\":\\\n    \\ \\\"Not a git repository\\\",\\n        }\\n\"\n  src/rcpack/io_utils.py: \"\\\"\\\"\\\"I/O utilities for file operations.\\\"\\\"\\\"\\n\\nfrom\\\n    \\ pathlib import Path\\nfrom typing import Tuple\\n\\n\\ndef write_output(output_path:\\\n    \\ str, content: str) -> None:\\n    \\\"\\\"\\\"Write content to output file.\\\"\\\"\\\"\\n\\\n    \\    output_file = Path(output_path)\\n    \\n    # Create parent directories if\\\n    \\ they don't exist\\n    output_file.parent.mkdir(parents=True, exist_ok=True)\\n\\\n    \\    \\n    # Write content\\n    with open(output_file, 'w', encoding='utf-8')\\\n    \\ as f:\\n        f.write(content)\\n\\n\\ndef is_binary_file(path: Path, sniff_bytes:\\\n    \\ int = 2048) -> bool:\\n    \\\"\\\"\\\"Heuristically determine if a file is binary\\\n    \\ by scanning for NUL bytes.\\\"\\\"\\\"\\n    try:\\n        with open(path, 'rb') as\\\n    \\ fb:\\n            chunk = fb.read(sniff_bytes)\\n        if b\\\"\\\\x00\\\" in chunk:\\n\\\n    \\            return True\\n        # If the chunk has a lot of non-text bytes,\\\n    \\ consider it binary\\n        text_byte_count = sum(32 <= b <= 126 or b in (9,\\\n    \\ 10, 13) for b in chunk)\\n        return (len(chunk) - text_byte_count) > max(1,\\\n    \\ len(chunk) // 3)\\n    except Exception:\\n        # If we cannot read, treat\\\n    \\ as binary to avoid further processing\\n        return True\\n\\n\\ndef read_text_safely(path:\\\n    \\ Path, max_bytes: int = 16_384) -> Tuple[str, str, bool]:\\n    \\\"\\\"\\\"Read a text\\\n    \\ file safely with size limit and encoding fallbacks.\\n\\n    Returns (content,\\\n    \\ encoding_used, truncated).\\n    \\\"\\\"\\\"\\n    truncated = False\\n    raw: bytes\\n\\\n    \\    with open(path, 'rb') as fb:\\n        raw = fb.read(max_bytes + 1)\\n    if\\\n    \\ len(raw) > max_bytes:\\n        truncated = True\\n        raw = raw[:max_bytes]\\n\\\n    \\n    for enc in (\\\"utf-8\\\", \\\"utf-16\\\", \\\"utf-16-le\\\", \\\"utf-16-be\\\", \\\"latin-1\\\"\\\n    ):\\n        try:\\n            text = raw.decode(enc)\\n            return text,\\\n    \\ enc, truncated\\n        except Exception:\\n            continue\\n    # Fallback:\\\n    \\ replace errors with utf-8\\n    text = raw.decode(\\\"utf-8\\\", errors=\\\"replace\\\"\\\n    )\\n    return text, \\\"utf-8\\\", truncated\"\n  src/rcpack/packager.py: \"from __future__ import annotations\\n\\nimport sys\\nfrom\\\n    \\ pathlib import Path\\nfrom typing import Iterable, Tuple\\n\\nfrom rcpack.discover\\\n    \\ import discover_files\\nfrom rcpack.gitinfo import get_git_info, is_git_repo\\n\\\n    from rcpack.io_utils import read_text_safely, is_binary_file\\nfrom rcpack.renderer\\\n    \\ import markdown as md_renderer\\nfrom rcpack.renderer.jsonyaml import render_json,\\\n    \\ render_yaml\\nfrom rcpack.treeview import render_tree\\n\\n\\ndef _find_root(inputs:\\\n    \\ list[str]) -> Path:\\n    paths = [Path(p) for p in inputs]\\n    if len(paths)\\\n    \\ == 1 and Path(paths[0]).is_dir():\\n        return paths[0].resolve()\\n    parents\\\n    \\ = [p if p.is_dir() else p.parent for p in paths]\\n    root = Path(*Path.commonpath([str(p.resolve())\\\n    \\ for p in parents]).split(\\\"/\\\"))\\n    return root.resolve()\\n\\n\\ndef build_package(\\n\\\n    \\    inputs: list[str],\\n    include_patterns: list[str] | None,\\n    exclude_patterns:\\\n    \\ list[str] | None,\\n    max_file_bytes: int,\\n    fmt: str = \\\"markdown\\\",\\n\\\n    ) -> Tuple[str, dict]:\\n    root = _find_root(inputs)\\n    root_abs = root.resolve()\\n\\\n    \\n    repo_info = (\\n        get_git_info(root_abs) if is_git_repo(root_abs) else\\\n    \\ {\\n            \\\"is_repo\\\": False,\\n            \\\"commit\\\": None,\\n        \\\n    \\    \\\"branch\\\": None,\\n            \\\"author\\\": None,\\n            \\\"date\\\": None,\\n\\\n    \\            \\\"note\\\": \\\"Not a git repository\\\",\\n        }\\n    )\\n\\n    files\\\n    \\ = discover_files(\\n        inputs=[Path(p) for p in inputs],\\n        root=root_abs,\\n\\\n    \\        include_patterns=include_patterns or [],\\n        exclude_patterns=exclude_patterns\\\n    \\ or [],\\n    )\\n    rel_files = [f.relative_to(root_abs) for f in files]\\n\\n\\\n    \\    project_tree = render_tree([p.as_posix() for p in rel_files])\\n\\n    file_sections:\\\n    \\ list[dict] = []\\n    total_lines = 0\\n    total_chars = 0\\n\\n    for f in files:\\n\\\n    \\        rel = f.relative_to(root_abs).as_posix()\\n        try:\\n            if\\\n    \\ is_binary_file(f):\\n                content = f\\\"[binary file skipped: {f.name},\\\n    \\ {f.stat().st_size} bytes]\\\"\\n                file_sections.append({\\n      \\\n    \\              \\\"path\\\": rel,\\n                    \\\"language\\\": _language_from_ext(f.suffix),\\n\\\n    \\                    \\\"content\\\": content,\\n                    \\\"is_truncated\\\"\\\n    : False,\\n                })\\n                total_chars += len(content)\\n  \\\n    \\              continue\\n\\n            content, used_encoding, truncated = read_text_safely(f,\\\n    \\ max_bytes=max_file_bytes)\\n            total_lines += content.count(\\\"\\\\n\\\"\\\n    ) + (1 if content and not content.endswith(\\\"\\\\n\\\") else 0)\\n            total_chars\\\n    \\ += len(content)\\n\\n            if truncated:\\n                note = f\\\"\\\\n\\\\\\\n    n[... TRUNCATED to first {max_file_bytes} bytes ...]\\\"\\n                content\\\n    \\ = content + note\\n                total_chars += len(note)\\n\\n            file_sections.append({\\n\\\n    \\                \\\"path\\\": rel,\\n                \\\"language\\\": _language_from_ext(f.suffix),\\n\\\n    \\                \\\"content\\\": content,\\n                \\\"is_truncated\\\": truncated,\\n\\\n    \\            })\\n        except Exception as exc:\\n            print(f\\\"[rcpack]\\\n    \\ error reading {rel}: {exc}\\\", file=sys.stderr)\\n            continue\\n\\n   \\\n    \\ # render in chosen format\\n    if fmt == \\\"markdown\\\":\\n        out_text = md_renderer.render_markdown(\\n\\\n    \\            root=str(root_abs),\\n            repo_info=repo_info,\\n         \\\n    \\   tree_text=project_tree,\\n            files=file_sections,\\n            total_files=len(file_sections),\\n\\\n    \\            total_lines=total_lines,\\n        )\\n    elif fmt == \\\"json\\\":\\n\\\n    \\        out_text = render_json(\\n            root=str(root_abs),\\n          \\\n    \\  repo_info=repo_info,\\n            tree_text=project_tree,\\n            files=file_sections,\\n\\\n    \\            total_files=len(file_sections),\\n            total_lines=total_lines,\\n\\\n    \\        )\\n    elif fmt == \\\"yaml\\\":\\n        out_text = render_yaml(\\n     \\\n    \\       root=str(root_abs),\\n            repo_info=repo_info,\\n            tree_text=project_tree,\\n\\\n    \\            files=file_sections,\\n            total_files=len(file_sections),\\n\\\n    \\            total_lines=total_lines,\\n        )\\n    else:\\n        raise ValueError(f\\\"\\\n    Unsupported format: {fmt}\\\")\\n\\n    stats = {\\\"files\\\": len(file_sections), \\\"\\\n    lines\\\": total_lines, \\\"chars\\\": total_chars}\\n    return out_text, stats\\n\\n\\n\\\n    def _language_from_ext(ext: str) -> str:\\n    ext = ext.lower().lstrip(\\\".\\\")\\n\\\n    \\    mapping = {\\n        \\\"py\\\": \\\"python\\\", \\\"js\\\": \\\"javascript\\\", \\\"ts\\\":\\\n    \\ \\\"typescript\\\",\\n        \\\"json\\\": \\\"json\\\", \\\"md\\\": \\\"markdown\\\", \\\"yml\\\":\\\n    \\ \\\"yaml\\\", \\\"yaml\\\": \\\"yaml\\\",\\n        \\\"toml\\\": \\\"toml\\\", \\\"sh\\\": \\\"bash\\\"\\\n    , \\\"c\\\": \\\"c\\\", \\\"cpp\\\": \\\"cpp\\\",\\n        \\\"java\\\": \\\"java\\\", \\\"go\\\": \\\"go\\\"\\\n    , \\\"rs\\\": \\\"rust\\\",\\n    }\\n    return mapping.get(ext, \\\"\\\")\\n\"\n  src/rcpack/renderer/jsonyaml.py: \"from __future__ import annotations\\nimport json\\n\\\n    \\ntry:\\n    import yaml\\nexcept ImportError:\\n    yaml = None\\n\\n\\ndef render_json(root,\\\n    \\ repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None)\\\n    \\ -> str:\\n    data = {\\n        \\\"root\\\": root,\\n        \\\"repo_info\\\": repo_info,\\n\\\n    \\        \\\"structure\\\": tree_text,\\n        \\\"recent_changes\\\": recent_files or\\\n    \\ [],\\n        \\\"files\\\": files,\\n        \\\"file_sizes\\\": file_sizes or {},\\n\\\n    \\        \\\"summary\\\": {\\\"total_files\\\": total_files, \\\"total_lines\\\": total_lines},\\n\\\n    \\        \\n    }\\n    return json.dumps(data, indent=2, ensure_ascii=False)\\n\\n\\\n    \\ndef render_yaml(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None,\\\n    \\ file_sizes=None) -> str:\\n    if yaml is None:\\n        raise RuntimeError(\\\"\\\n    PyYAML not installed; run `pip install pyyaml`\\\")\\n    data = {\\n        \\\"root\\\"\\\n    : root,\\n        \\\"repo_info\\\": repo_info,\\n        \\\"structure\\\": tree_text,\\n\\\n    \\        \\\"recent_changes\\\": recent_files or [],\\n        \\\"files\\\": files,\\n\\\n    \\        \\\"file_sizes\\\": file_sizes or {},\\n        \\\"summary\\\": {\\\"total_files\\\"\\\n    : total_files, \\\"total_lines\\\": total_lines},\\n        \\n    }\\n    return yaml.safe_dump(data,\\\n    \\ sort_keys=False, allow_unicode=True)\\n\"\n  src/rcpack/renderer/markdown.py: \"\\\"\\\"\\\"Markdown renderer for repository context.\\\"\\\n    \\\"\\\"\\n\\nfrom typing import Dict, Any\\n\\n\\ndef render_markdown(root: str, repo_info:\\\n    \\ Dict[str, Any], tree_text: str, \\n                   files: Dict[str, str],\\\n    \\ total_files: int, total_lines: int, recent_files=None, file_sizes=None) -> str:\\n\\\n    \\    \\\"\\\"\\\"Render repository context as markdown.\\\"\\\"\\\"\\n    \\n    lines = []\\n\\\n    \\    \\n    # Header\\n    lines.append(f\\\"# Repository Context: {root}\\\")\\n   \\\n    \\ lines.append(\\\"\\\")\\n    \\n    # Repository info\\n    if repo_info.get(\\\"is_repo\\\"\\\n    ):\\n        lines.append(\\\"## Git Repository Information\\\")\\n        lines.append(f\\\"\\\n    - **Branch**: {repo_info.get('branch', 'N/A')}\\\")\\n        lines.append(f\\\"- **Commit**:\\\n    \\ {repo_info.get('commit', 'N/A')}\\\")\\n        lines.append(f\\\"- **Author**: {repo_info.get('author',\\\n    \\ 'N/A')}\\\")\\n        lines.append(f\\\"- **Date**: {repo_info.get('date', 'N/A')}\\\"\\\n    )\\n    else:\\n        lines.append(\\\"## Repository Information\\\")\\n        lines.append(f\\\"\\\n    - **Note**: {repo_info.get('note', 'Not a git repository')}\\\")\\n    lines.append(\\\"\\\n    \\\")\\n    \\n    # Summary\\n    lines.append(\\\"## Summary\\\")\\n    lines.append(f\\\"\\\n    - **Total Files**: {total_files}\\\")\\n    lines.append(f\\\"- **Total Lines**: {total_lines}\\\"\\\n    )\\n    lines.append(\\\"\\\")\\n    \\n    # Directory structure\\n    lines.append(\\\"\\\n    ## Directory Structure\\\")\\n    lines.append(\\\"```\\\")\\n    lines.append(tree_text)\\n\\\n    \\    lines.append(\\\"```\\\")\\n    lines.append(\\\"\\\")\\n\\n    # will produce recent\\\n    \\ files \\n    # Recent files (fixed)\\n    if recent_files:\\n        lines.append(\\\"\\\n    ## Recent Changes\\\")\\n        for file, age in recent_files.items():\\n       \\\n    \\     lines.append(f\\\"- {file} (modified {age})\\\")\\n        lines.append(\\\"\\\"\\\n    )\\n    \\n    # File contents\\n    lines.append(\\\"## File Contents\\\")\\n    lines.append(\\\"\\\n    \\\")\\n    \\n    for file_path, content in sorted(files.items()):\\n        if file_sizes\\\n    \\ and file_path in file_sizes:\\n            size_bytes = file_sizes[file_path]\\n\\\n    \\            lines.append(f\\\"### {file_path} ({size_bytes} bytes)\\\")\\n       \\\n    \\ else:\\n            lines.append(f\\\"### {file_path}\\\")\\n        lines.append(\\\"\\\n    \\\")\\n        \\n        # Detect language for syntax highlighting\\n        ext\\\n    \\ = file_path.split('.')[-1].lower() if '.' in file_path else ''\\n        lang_map\\\n    \\ = {\\n            'py': 'python', 'js': 'javascript', 'ts': 'typescript',\\n \\\n    \\           'java': 'java', 'cpp': 'cpp', 'c': 'c', 'h': 'c',\\n            'cs':\\\n    \\ 'csharp', 'php': 'php', 'rb': 'ruby',\\n            'go': 'go', 'rs': 'rust',\\\n    \\ 'swift': 'swift',\\n            'html': 'html', 'css': 'css', 'scss': 'scss',\\n\\\n    \\            'json': 'json', 'yaml': 'yaml', 'yml': 'yaml',\\n            'xml':\\\n    \\ 'xml', 'sql': 'sql', 'sh': 'bash',\\n            'md': 'markdown', 'dockerfile':\\\n    \\ 'dockerfile'\\n        }\\n        \\n        language = lang_map.get(ext, '')\\n\\\n    \\        lines.append(f\\\"```{language}\\\")\\n        lines.append(content)\\n   \\\n    \\     lines.append(\\\"```\\\")\\n        lines.append(\\\"\\\")\\n    \\n    return \\\"\\\\\\\n    n\\\".join(lines)\\n\"\n  src/rcpack/treeview.py: \"\\\"\\\"\\\"Tree view generation for repository structure.\\\"\\\"\\\n    \\\"\\n\\nfrom pathlib import Path\\nfrom typing import Dict, List\\n\\n\\ndef create_tree_view(repo_path:\\\n    \\ Path, files_data: Dict[str, str]) -> str:\\n    \\\"\\\"\\\"Create a tree view of the\\\n    \\ repository structure.\\\"\\\"\\\"\\n    paths = list(files_data.keys())\\n    return\\\n    \\ render_tree(paths)\\n\\n\\ndef render_tree(paths: List[str]) -> str:\\n    \\\"\\\"\\\"\\\n    Render a tree view from a list of relative POSIX paths.\\\"\\\"\\\"\\n    tree_structure:\\\n    \\ dict = {}\\n\\n    for p in paths:\\n        parts = Path(p).parts\\n        current\\\n    \\ = tree_structure\\n        for part in parts[:-1]:\\n            if part not in\\\n    \\ current:\\n                current[part] = {}\\n            current = current[part]\\n\\\n    \\        if parts:\\n            current[parts[-1]] = None\\n\\n    def _render(structure:\\\n    \\ dict, prefix: str = \\\"\\\") -> str:\\n        lines = []\\n        items = sorted(structure.items(),\\\n    \\ key=lambda x: (x[1] is None, x[0]))\\n        for i, (name, subtree) in enumerate(items):\\n\\\n    \\            is_last = i == len(items) - 1\\n            lines.append(f\\\"{prefix}{'└──\\\n    \\ ' if is_last else '├── '}{name}\\\")\\n            if subtree is not None:\\n  \\\n    \\              extension = (\\\"    \\\" if is_last else \\\"│   \\\")\\n             \\\n    \\   lines.append(_render(subtree, prefix + extension))\\n        return \\\"\\\\n\\\"\\\n    .join(filter(None, lines))\\n\\n    if not tree_structure:\\n        return \\\"No\\\n    \\ files found\\\"\\n    return _render(tree_structure)\"\n  test-output.json: \"{\\n  \\\"root\\\": \\\"/Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\\\"\\\n    ,\\n  \\\"repo_info\\\": {\\n    \\\"is_repo\\\": true,\\n    \\\"commit\\\": \\\"682153b169db66d3a72e9cabdd1f3448a3b2986d\\\"\\\n    ,\\n    \\\"branch\\\": \\\"refactoring\\\",\\n    \\\"author\\\": \\\"Abhinav <abhinavbhardwaj2002@gmail.com>\\\"\\\n    ,\\n    \\\"date\\\": \\\"Fri Oct 3 18:45:48 2025\\\",\\n    \\\"note\\\": null\\n  },\\n  \\\"\\\n    structure\\\": \\\"├── src\\\\n│   └── rcpack\\\\n│       ├── renderer\\\\n│       │   ├──\\\n    \\ jsonyaml.py\\\\n│       │   └── markdown.py\\\\n│       ├── __init__.py\\\\n│    \\\n    \\   ├── __main__.py\\\\n│       ├── cli.py\\\\n│       ├── config_loader.py\\\\n│  \\\n    \\     ├── discover.py\\\\n│       ├── gitinfo.py\\\\n│       ├── io_utils.py\\\\n│ \\\n    \\      ├── packager.py\\\\n│       └── treeview.py\\\\n├── LICENSE\\\\n├── README.md\\\\\\\n    n└── pyproject.toml\\\",\\n  \\\"recent_changes\\\": [],\\n  \\\"files\\\": {\\n    \\\"LICENSE\\\"\\\n    : \\\"MIT License\\\\n\\\\nCopyright (c) 2025 Abhinav\\\\n\\\\nPermission is hereby granted,\\\n    \\ free of charge, to any person obtaining a copy\\\\nof this software and associated\\\n    \\ documentation files (the \\\\\\\"Software\\\\\\\"), to deal\\\\nin the Software without\\\n    \\ restriction, including without limitation the rights\\\\nto use, copy, modify,\\\n    \\ merge, publish, distribute, sublicense, and/or sell\\\\ncopies of the Software,\\\n    \\ and to permit persons to whom the Software is\\\\nfurnished to do so, subject\\\n    \\ to the following conditions:\\\\n\\\\nThe above copyright notice and this permission\\\n    \\ notice shall be included in all\\\\ncopies or substantial portions of the Software.\\\\\\\n    n\\\\nTHE SOFTWARE IS PROVIDED \\\\\\\"AS IS\\\\\\\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\\\n    \\ OR\\\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\\\\n    nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\\\\n    nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\nLIABILITY,\\\n    \\ WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\nOUT OF\\\n    \\ OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\nSOFTWARE.\\\\\\\n    n\\\",\\n    \\\"README.md\\\": \\\"# Repo-Contextor\\\\n\\\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\\\\\\n    n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\\\\\\n    n\\\\nA powerful Repository Context Packager CLI tool that analyzes local git repositories\\\n    \\ and creates comprehensive text files containing repository content optimized\\\n    \\ for sharing with Large Language Models (LLMs).\\\\n\\\\n## Overview\\\\n\\\\nWhen developers\\\n    \\ want to get help from ChatGPT, Claude, or other LLMs about their code, they\\\n    \\ often struggle with how to share their codebase effectively. Common problems\\\n    \\ include:\\\\n\\\\n- **Lost Context**: Copy-pasting individual files loses important\\\n    \\ project structure and relationships\\\\n- **Missing Dependencies**: LLMs can't\\\n    \\ see how files connect or what libraries are used\\\\n- **Incomplete Picture**:\\\n    \\ Hard to convey the overall architecture and organization\\\\n- **Manual Work**:\\\n    \\ Time-consuming to gather and format relevant code\\\\n\\\\n**Repo-Contextor** solves\\\n    \\ this by automatically collecting and formatting repository content into a single,\\\n    \\ well-structured text file that provides rich context to LLMs, enabling them\\\n    \\ to give much better assistance with your code.\\\\n\\\\n## Features\\\\n\\\\n- **Git\\\n    \\ Integration**: Extracts commit SHA, branch, author, and date information\\\\n-\\\n    \\ **Project Structure**: Generates a clear directory tree visualization\\\\n- **File\\\n    \\ Content Packaging**: Includes file contents with syntax highlighting\\\\n- **Smart\\\n    \\ File Discovery**: Recursively scans directories with intelligent filtering\\\\\\\n    n- **Binary File Detection**: Automatically skips binary files\\\\n- **Error Handling**:\\\n    \\ Gracefully handles permission errors and provides helpful messages\\\\n- **Multiple\\\n    \\ Output Formats**: Supports Markdown, JSON, and YAML formats\\\\n- **Flexible Output**:\\\n    \\ Write to stdout or save to a file\\\\n- **Recent Changes Filter**: Give the files\\\n    \\ which are updated in last 7days with the time when it was recently modified.\\\\\\\n    n\\\\n## Installation\\\\n\\\\n### Prerequisites\\\\n\\\\n- Python 3.9 or higher\\\\n- Git\\\n    \\ (for git repository analysis)\\\\n\\\\n### For End Users\\\\n\\\\n```bash\\\\n# Clone\\\n    \\ and install\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    ncd Repo-Contextor\\\\npip install -e .\\\\n```\\\\n\\\\n### For Contributors & Local\\\n    \\ Development\\\\n\\\\n```bash\\\\n# Clone the repository\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    ncd Repo-Contextor\\\\n\\\\n# Create virtual environment\\\\npython -m venv .venv\\\\\\\n    nsource .venv/bin/activate  # On Windows: .venv\\\\\\\\Scripts\\\\\\\\activate\\\\n\\\\n#\\\n    \\ Install in development mode\\\\npip install -e .\\\\n```\\\\n\\\\n## Usage\\\\n\\\\n###\\\n    \\ Basic Examples\\\\n\\\\n```bash\\\\n# Package current directory to terminal\\\\nrepo-contextor\\\n    \\ .\\\\n\\\\n# Package a specific directory\\\\nrepo-contextor /path/to/your/project\\\\\\\n    n\\\\n# Save output to a file\\\\nrepo-contextor . -o my-project-context.md\\\\n\\\\n#\\\n    \\ Generate JSON format\\\\nrepo-contextor . -f json -o context.json\\\\n\\\\n# Generate\\\n    \\ YAML format\\\\nrepo-contextor . -f yaml -o context.yaml\\\\n\\\\n# Include only files\\\n    \\ modified in the last 7 days\\\\nrepo-contextor . --recent\\\\n\\\\n# Combine with\\\n    \\ output file\\\\nrepo-contextor . --recent -o recent-changes.md\\\\n```\\\\n\\\\n###\\\n    \\ Command Line Options\\\\n\\\\n| Option | Short | Description | Example |\\\\n|--------|-------|-------------|---------|\\\\\\\n    n| `path` | - | Repository path to analyze (default: current directory) | `repo-contextor\\\n    \\ /path/to/project` |\\\\n| `--output` | `-o` | Output file path (default: stdout)\\\n    \\ | `-o context.md` |\\\\n| `--format` | `-f` | Output format: text, json, yaml\\\n    \\ (default: text) | `-f json` |\\\\n| `--help` | `-h` | Show help message | `-h`\\\n    \\ |\\\\n| `--recent`  | `-r`  | Include only files modified in the last 7 days \\\n    \\   | `repo-contextor . -r -o recent.md` |\\\\n\\\\n### Advanced Examples\\\\n\\\\n```bash\\\\\\\n    n# Analyze different repository\\\\nrepo-contextor /path/to/other/project -o other-project.md\\\\\\\n    n\\\\n# Generate JSON for API consumption\\\\nrepo-contextor . -f json -o api-context.json\\\\\\\n    n\\\\n# Create YAML configuration\\\\nrepo-contextor . -f yaml -o project-config.yaml\\\\\\\n    n\\\\n# Generate files which are changed recently in 7 days\\\\nrepo-contextor . -r\\\n    \\ --output recent-changes.txt\\\\n\\\\n```\\\\n## Configuration via TOML\\\\n\\\\nRepo-Contextor\\\n    \\ supports configuration through a `.repo-contextor.toml` file in the current\\\n    \\ working directory.  \\\\nThis file allows you to avoid typing the same CLI arguments\\\n    \\ every time.\\\\n\\\\nExample `.repo-contextor.toml`:\\\\n\\\\n```toml\\\\n# Output file\\\n    \\ to write results\\\\noutput = \\\\\\\"context.yaml\\\\\\\"\\\\n\\\\n# Output format: text,\\\n    \\ json, or yaml\\\\nformat = \\\\\\\"yaml\\\\\\\"\\\\n\\\\n# Limit to files modified in the\\\n    \\ last 7 days\\\\nrecent = true\\\\n\\\\n# Repository path to analyze (default = current\\\n    \\ directory)\\\\npath = \\\\\\\".\\\\\\\"\\\\n```\\\\n### Rules\\\\n- If the `.repo-contextor.toml`\\\n    \\ file is **missing**, the tool falls back to defaults.  \\\\n- If the file is **present\\\n    \\ but invalid TOML**, the tool prints a clear error message and exits with status\\\n    \\ code 1.  \\\\n- **Unknown keys** in the TOML file are ignored (safe for future\\\n    \\ extensions).  \\\\n- **Precedence** of settings is:\\\\n  1. Command-line arguments\\\n    \\ (highest priority)  \\\\n  2. Values from `.repo-contextor.toml`  \\\\n  3. Built-in\\\n    \\ defaults (lowest priority)\\\\n     \\\\n## Output Format\\\\n\\\\nThe tool generates\\\n    \\ a structured text file with the following sections:\\\\n\\\\n### 1. Repository Context\\\n    \\ Header\\\\nProject path and identification\\\\n\\\\n### 2. Git Repository Information\\\\\\\n    n- Current branch\\\\n- Latest commit SHA\\\\n- Last commit author\\\\n- Last commit\\\n    \\ date\\\\n\\\\n### 3. Summary Statistics\\\\n- Total number of files processed\\\\n-\\\n    \\ Total lines of code\\\\n\\\\n### 4. Directory Structure\\\\nClean tree visualization\\\n    \\ showing project organization\\\\n\\\\n### 5. Recent Changes (if `--recent` is used)\\\\\\\n    n\\\\n- Lists files modified in the last 7 days.\\\\n- Shows relative file paths along\\\n    \\ with how long ago each file was modified\\\\n- Helps focus on recently updated\\\n    \\ parts of the project.\\\\n- Can be combined with `--output` or `--format` to save\\\n    \\ or change the output type.\\\\n\\\\n\\\\n### 5. File Contents\\\\nEach file's content\\\n    \\ with:\\\\n- Clear file path headers\\\\n- Appropriate syntax highlighting language\\\n    \\ tags\\\\n- Complete file contents\\\\n\\\\n## Example Output\\\\n\\\\nWhen you run `repo-contextor\\\n    \\ .`, the output looks like this:\\\\n\\\\n````markdown\\\\n# Repository Context: /path/to/your/project\\\\\\\n    n\\\\n## Git Repository Information\\\\n- **Branch**: main\\\\n- **Commit**: a1b2c3d4e5f6789...\\\\\\\n    n- **Author**: John Doe <john@example.com>\\\\n- **Date**: Fri Sep 12 14:30:15 2025\\\\\\\n    n\\\\n## Summary\\\\n- **Total Files**: 15\\\\n- **Total Lines**: 1,247\\\\n\\\\n## Directory\\\n    \\ Structure\\\\n```\\\\n├── src/\\\\n│   ├── main.py\\\\n│   └── utils.py\\\\n├── tests/\\\\\\\n    n│   └── test_main.py\\\\n├── README.md\\\\n└── requirements.txt\\\\n```\\\\n## Recent\\\n    \\ Changes\\\\n- src/main.py (modified 2 days ago)\\\\n- src/utils/helpers.py (modified\\\n    \\ 5 days ago)\\\\n\\\\n## File Contents\\\\n\\\\n### src/main.py\\\\n\\\\n```python\\\\ndef\\\n    \\ main():\\\\n    print(\\\\\\\"Hello, World!\\\\\\\")\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\n    \\\":\\\\n    main()\\\\n```\\\\n\\\\n### README.md\\\\n\\\\n```markdown\\\\n# My Project\\\\nThis\\\n    \\ is a sample project.\\\\n```\\\\n\\\\n## Summary\\\\n- Total files: 15\\\\n- Total lines:\\\n    \\ 1,247\\\\n````\\\\n\\\\n## What Files Are Included\\\\n\\\\nThe tool includes most text\\\n    \\ files but automatically excludes:\\\\n\\\\n### Excluded Directories\\\\n- `.git`,\\\n    \\ `.svn`, `.hg` (version control)\\\\n- `__pycache__`, `.pytest_cache` (Python cache)\\\\\\\n    n- `node_modules`, `.venv`, `venv` (dependencies/environments)\\\\n- `.vscode`,\\\n    \\ `.idea` (IDE directories)\\\\n- `build`, `dist`, `target` (build directories)\\\\\\\n    n\\\\n### File Handling Rules\\\\n- **Text files**: All readable text files with common\\\n    \\ extensions\\\\n- **Binary files**: Automatically detected and skipped\\\\n- **Permission\\\n    \\ errors**: Skipped with graceful handling\\\\n- **Configuration files**: Includes\\\n    \\ pyproject.toml, package.json, etc.\\\\n\\\\n### Included File Types\\\\n- Source code:\\\n    \\ `.py`, `.js`, `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\\\n- Web files:\\\n    \\ `.html`, `.css`, `.scss`, `.vue`, `.jsx`, etc.\\\\n- Documentation: `.md`, `.txt`,\\\n    \\ `.rst`\\\\n- Configuration: `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\\\n- Scripts:\\\n    \\ `.sh`, `.bash`, `.zsh`\\\\n\\\\n## Error Handling\\\\n\\\\nThe tool handles errors gracefully:\\\\\\\n    n\\\\n| Error Type | Behavior |\\\\n|------------|----------|\\\\n| **Permission errors**\\\n    \\ | Skipped with warning |\\\\n| **Binary files** | Automatically detected and skipped\\\n    \\ |\\\\n| **Invalid paths** | Clear error messages |\\\\n| **Non-git repositories**\\\n    \\ | Works fine, shows \\\\\\\"Not a git repository\\\\\\\" |\\\\n| **Unreadable files**\\\n    \\ | Marked as \\\\\\\"[Binary or unreadable file]\\\\\\\" |\\\\n\\\\n## Development\\\\n\\\\n###\\\n    \\ Project Structure\\\\n\\\\n```text\\\\nRepo-Contextor/\\\\n├── src/rcpack/         \\\n    \\     # Main package\\\\n│   ├── __init__.py         # Package initialization\\\\\\\n    n│   ├── cli.py              # Command-line interface\\\\n│   ├── discover.py  \\\n    \\       # File discovery logic\\\\n│   ├── gitinfo.py          # Git repository\\\n    \\ analysis\\\\n│   ├── treeview.py         # Directory tree generation\\\\n│   ├──\\\n    \\ packager.py         # Main orchestration\\\\n│   ├── io_utils.py         # File\\\n    \\ I/O utilities\\\\n│   └── renderer/           # Output formatters\\\\n│       ├──\\\n    \\ markdown.py     # Markdown renderer\\\\n│       └── jsonyaml.py     # JSON/YAML\\\n    \\ renderers\\\\n├── pyproject.toml          # Project configuration\\\\n├── LICENSE\\\n    \\                 # MIT License\\\\n└── README.md              # This documentation\\\\\\\n    n```\\\\n\\\\n### Running Tests\\\\n\\\\n```bash\\\\n# Test on current repository\\\\nrepo-contextor\\\n    \\ . -o test-output.md\\\\n\\\\n# Test different formats\\\\nrepo-contextor . -f json\\\n    \\ | head -20\\\\nrepo-contextor . -f yaml | head -20\\\\n\\\\n# Test specific directory\\\\\\\n    nrepo-contextor src/ -o src-only.md\\\\n```\\\\n\\\\n### Contributing\\\\n\\\\n1. **Fork\\\n    \\ the repository**\\\\n2. **Clone your fork:**\\\\n   ```bash\\\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    n   cd Repo-Contextor\\\\n   ```\\\\n3. **Install for development:**\\\\n   ```bash\\\\\\\n    n   python -m venv .venv\\\\n   source .venv/bin/activate\\\\n   pip install -e .\\\\\\\n    n   ```\\\\n4. **Make your changes and test:**\\\\n   ```bash\\\\n   repo-contextor\\\n    \\ . -o test.md\\\\n   ```\\\\n5. **Submit a pull request**\\\\n\\\\n### Development Workflow\\\\\\\n    n\\\\n```bash\\\\n# 1. Setup development environment\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    ncd Repo-Contextor\\\\npython -m venv .venv\\\\nsource .venv/bin/activate\\\\npip install\\\n    \\ -e .\\\\n\\\\n# 2. Make changes to the code\\\\n# Edit files in src/rcpack/\\\\n\\\\n#\\\n    \\ 3. Test your changes\\\\nrepo-contextor . -o test-output.md\\\\n\\\\n# 4. Test different\\\n    \\ formats\\\\nrepo-contextor . -f json -o test.json\\\\nrepo-contextor . -f yaml -o\\\n    \\ test.yaml\\\\n\\\\n# 5. Commit and push changes\\\\ngit add .\\\\ngit commit -m \\\\\\\"\\\n    Add new feature\\\\\\\"\\\\ngit push origin feature-branch\\\\n```\\\\n\\\\n## License\\\\n\\\\\\\n    nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file\\\n    \\ for details.\\\\n\\\\n## Why Repo-Contextor?\\\\n\\\\nThe name \\\\\\\"Repo-Contextor\\\\\\\"\\\n    \\ combines \\\\\\\"Repository\\\\\\\" + \\\\\\\"Context\\\\\\\" + \\\\\\\"or\\\\\\\", representing the\\\n    \\ tool's purpose of providing rich context about code repositories in a format\\\n    \\ that's perfect for LLM interactions.\\\\n\\\\n### Use Cases\\\\n\\\\n- **AI Assistance**:\\\n    \\ Get better help from ChatGPT, Claude, or GitHub Copilot\\\\n- **Code Reviews**:\\\n    \\ Share complete project context with team members\\\\n- **Documentation**: Create\\\n    \\ comprehensive project snapshots\\\\n- **Onboarding**: Help new team members understand\\\n    \\ project structure\\\\n- **Project Analysis**: Understand repository structure\\\n    \\ and dependencies\\\\n\\\\n### Perfect for LLMs\\\\n\\\\nThe output format is specifically\\\n    \\ designed to work well with Large Language Models:\\\\n- Clear section headers\\\n    \\ for easy parsing\\\\n- Syntax highlighting markers for code blocks\\\\n- Structured\\\n    \\ metadata (git info, file locations)\\\\n- Complete project context in a single\\\n    \\ file\\\\n- Multiple output formats (Markdown, JSON, YAML)\\\\n- Optimized for token\\\n    \\ efficiency\\\\n\\\",\\n    \\\"pyproject.toml\\\": \\\"[build-system]\\\\nrequires = [\\\\\\\"\\\n    setuptools>=68\\\\\\\", \\\\\\\"wheel\\\\\\\"]\\\\nbuild-backend = \\\\\\\"setuptools.build_meta\\\\\\\n    \\\"\\\\n\\\\n[project]\\\\nname = \\\\\\\"rcpack\\\\\\\"\\\\nversion = \\\\\\\"0.1.0\\\\\\\"\\\\ndescription\\\n    \\ = \\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\"\\\\nreadme = \\\\\\\"README.md\\\\\\\n    \\\"\\\\nrequires-python = \\\\\\\">=3.9\\\\\\\"\\\\nlicense = { text = \\\\\\\"MIT\\\\\\\" }\\\\ndependencies\\\n    \\ = [\\\\n    \\\\\\\"PyYAML>=6.0\\\\\\\"\\\\n]\\\\n\\\\n[project.scripts]\\\\nrepo-contextor =\\\n    \\ \\\\\\\"rcpack.cli:main\\\\\\\"\\\\n\\\",\\n    \\\"src/rcpack/__init__.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\n    Repository Context Packager - CLI tool for creating LLM-optimized repository context.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n\\\\n__version__ = \\\\\\\"0.1.0\\\\\\\"\\\\n__author__ = \\\\\\\"Abhinav\\\\\\\"\\\\n__description__\\\n    \\ = \\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\"\\\",\\n    \\\"src/rcpack/__main__.py\\\"\\\n    : \\\"#!/usr/bin/env python3\\\\n\\\\\\\"\\\\\\\"\\\\\\\"Module entry point to enable `python\\\n    \\ -m rcpack`.\\\\n\\\\nThis simply delegates to the CLI's main() function.\\\\n\\\\\\\"\\\\\\\n    \\\"\\\\\\\"\\\\n\\\\nfrom .cli import main\\\\n\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\n    \\    main()\\\\n\\\\n\\\\n\\\",\\n    \\\"src/rcpack/cli.py\\\": \\\"#!/usr/bin/env python3\\\\\\\n    n\\\\\\\"\\\\\\\"\\\\\\\"CLI for Repository Context Packager.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom .config_loader\\\n    \\ import load_config\\\\n\\\\nimport argparse\\\\nimport sys\\\\nfrom pathlib import Path\\\\\\\n    nfrom .gitinfo import get_git_info\\\\nfrom .discover import discover_files\\\\nfrom\\\n    \\ .treeview import create_tree_view\\\\nfrom .renderer.markdown import render_markdown\\\\\\\n    nfrom .renderer.jsonyaml import render_json, render_yaml\\\\nfrom .io_utils import\\\n    \\ write_output\\\\nfrom datetime import datetime, timedelta\\\\n\\\\n\\\\ndef log_verbose(message:\\\n    \\ str, verbose: bool) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Log a message to stderr if verbose\\\n    \\ mode is enabled.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if verbose:\\\\n        print(message, file=sys.stderr)\\\\\\\n    n\\\\n\\\\ndef get_rendered_content(format_type: str, repo_path: str, repo_info: dict,\\\n    \\ tree_text: str, \\\\n                        files_data: dict, total_files: int,\\\n    \\ total_lines: int, \\\\n                        recent_files_info: dict, file_sizes:\\\n    \\ dict) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Get rendered content based on the specified\\\n    \\ format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if format_type == \\\\\\\"json\\\\\\\":\\\\n        return render_json(\\\\\\\n    n            repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\n    \\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\\\\n    n        )\\\\n    elif format_type == \\\\\\\"yaml\\\\\\\":\\\\n        return render_yaml(\\\\\\\n    n            repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\n    \\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\\\\n    n        )\\\\n    else:  # text/markdown\\\\n        return render_markdown(\\\\n \\\n    \\           repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\n    \\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\\\\n    n        )\\\\n\\\\n\\\\ndef process_file(file_path: Path, repo_path: Path, verbose:\\\n    \\ bool) -> tuple[str, str, str]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Process a single file and return\\\n    \\ its data.\\\\n    \\\\n    Returns:\\\\n        tuple: (relative_path_str, content,\\\n    \\ file_size)\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    relative_path = file_path.relative_to(repo_path)\\\\\\\n    n    relative_path_str = str(relative_path)\\\\n    \\\\n    log_verbose(f\\\\\\\"Reading\\\n    \\ file: {relative_path}\\\\\\\", verbose)\\\\n    file_size = file_path.stat().st_size\\\\\\\n    n    \\\\n    try:\\\\n        with open(file_path, 'r', encoding='utf-8') as f:\\\\\\\n    n            content = f.read()\\\\n        return relative_path_str, content, str(file_size)\\\\\\\n    n    except (UnicodeDecodeError, PermissionError):\\\\n        log_verbose(f\\\\\\\"\\\n    Skipping binary/unreadable file: {relative_path}\\\\\\\", verbose)\\\\n        file_size\\\n    \\ = file_path.stat().st_size if file_path.exists() else 0\\\\n        content =\\\n    \\ f\\\\\\\"[Binary or unreadable file: {file_path.name}]\\\\\\\"\\\\n        return relative_path_str,\\\n    \\ content, str(file_size)\\\\n    except Exception:\\\\n        log_verbose(f\\\\\\\"\\\n    Error reading file: {relative_path}\\\\\\\", verbose)\\\\n        raise  # Re-raise\\\n    \\ to handle in calling code\\\\n\\\\n\\\\ndef handle_output(content: str, output_path:\\\n    \\ str = None) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Handle output to either file or stdout.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n    if output_path:\\\\n        # Write to file\\\\n        write_output(output_path,\\\n    \\ content)\\\\n        print(f\\\\\\\"Context package created: {output_path}\\\\\\\")\\\\\\\n    n    else:\\\\n        # Output to stdout\\\\n        print(content)\\\\n\\\\n\\\\ndef main():\\\\\\\n    n    parser = argparse.ArgumentParser(\\\\n        description=\\\\\\\"Package repository\\\n    \\ content for LLM context\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"\\\n    path\\\\\\\", \\\\n        nargs=\\\\\\\"?\\\\\\\", \\\\n        default=\\\\\\\".\\\\\\\", \\\\n      \\\n    \\  help=\\\\\\\"Repository path (default: current directory)\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\\\\n    n        \\\\\\\"-o\\\\\\\", \\\\\\\"--output\\\\\\\", \\\\n        help=\\\\\\\"Output file path (default:\\\n    \\ stdout)\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"-f\\\\\\\", \\\\\\\"--format\\\\\\\n    \\\", \\\\n        choices=[\\\\\\\"text\\\\\\\", \\\\\\\"json\\\\\\\", \\\\\\\"yaml\\\\\\\"], \\\\n       \\\n    \\ default=\\\\\\\"text\\\\\\\",\\\\n        help=\\\\\\\"Output format (default: text)\\\\\\\"\\\\\\\n    n    )\\\\n\\\\n    \\\\\\\"\\\\\\\"\\\\\\\" This will read -r from the console and able to search\\\n    \\ it with this\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    parser.add_argument(\\\\n    \\\\\\\"-r\\\\\\\", \\\\\\\"--recent\\\\\\\n    \\\",\\\\n    action=\\\\\\\"store_true\\\\\\\",\\\\n    help=\\\\\\\"Include only files modified\\\n    \\ in the last 7 days\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"-v\\\\\\\n    \\\", \\\\\\\"--verbose\\\\\\\",\\\\n        action=\\\\\\\"store_true\\\\\\\",\\\\n        help=\\\\\\\"\\\n    Print detailed progress information to stderr\\\\\\\"\\\\n    )\\\\n    \\\\n    args =\\\n    \\ parser.parse_args()\\\\n    \\\\n    try:\\\\n        repo_path = Path(args.path).resolve()\\\\\\\n    n        if not repo_path.exists():\\\\n            print(f\\\\\\\"Error: Path {repo_path}\\\n    \\ does not exist\\\\\\\", file=sys.stderr)\\\\n            sys.exit(1)\\\\n          \\\n    \\  \\\\n        # Get repository information\\\\n        log_verbose(f\\\\\\\"Analyzing\\\n    \\ repository: {repo_path}\\\\\\\", args.verbose)\\\\n        repo_info = get_git_info(repo_path)\\\\\\\n    n        \\\\n        # Discover files\\\\n        log_verbose(f\\\\\\\"Discovering files\\\n    \\ in: {repo_path}\\\\\\\", args.verbose)\\\\n        discovered_files = discover_files([repo_path],\\\n    \\ repo_path, [], [])\\\\n        log_verbose(f\\\\\\\"Found {len(discovered_files)}\\\n    \\ files\\\\\\\", args.verbose)\\\\n        \\\\n        # will check the file in last\\\n    \\ 7 days\\\\n        recent_files_info = {}\\\\n        if args.recent:\\\\n       \\\n    \\     seven_days_ago = datetime.now() - timedelta(days=7)\\\\n            recent_files\\\n    \\ = []\\\\n            for f in discovered_files:\\\\n                try:\\\\n    \\\n    \\                mtime = datetime.fromtimestamp(f.stat().st_mtime)\\\\n        \\\n    \\            if mtime >= seven_days_ago:\\\\n                        recent_files.append(f)\\\\\\\n    n                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)\\\n    \\     \\\\n                except Exception:\\\\n                    continue\\\\n \\\n    \\           discovered_files = recent_files\\\\n        \\\\n        # Read file contents\\\\\\\n    n        files_data = {}\\\\n        file_sizes = {}\\\\n        for file_path in\\\n    \\ discovered_files:\\\\n            try:\\\\n                relative_path_str, content,\\\n    \\ file_size = process_file(file_path, repo_path, args.verbose)\\\\n            \\\n    \\    files_data[relative_path_str] = content\\\\n                file_sizes[relative_path_str]\\\n    \\ = file_size\\\\n            except Exception:\\\\n                continue\\\\n  \\\n    \\      \\\\n        # Create tree view\\\\n        log_verbose(\\\\\\\"Generating directory\\\n    \\ tree\\\\\\\", args.verbose)\\\\n        tree_text = create_tree_view(repo_path, files_data)\\\\\\\n    n        \\\\n        # Count totals\\\\n        total_files = len(files_data)\\\\n\\\n    \\        total_lines = sum(len(content.splitlines()) for _, content in files_data.items())\\\\\\\n    n        \\\\n        # Render based on format\\\\n        log_verbose(f\\\\\\\"Rendering\\\n    \\ output in {args.format} format\\\\\\\", args.verbose)\\\\n        content = get_rendered_content(\\\\\\\n    n            args.format, str(repo_path), repo_info, tree_text,\\\\n           \\\n    \\ files_data, total_files, total_lines,\\\\n            recent_files_info if args.recent\\\n    \\ else {},\\\\n            file_sizes\\\\n        )\\\\n        \\\\n        handle_output(content,\\\n    \\ args.output)\\\\n        \\\\n    except Exception as e:\\\\n        print(f\\\\\\\"Error:\\\n    \\ {e}\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\n# this will convert age\\\n    \\ and give us the difference\\\\ndef human_readable_age(mtime: datetime) -> str:\\\\\\\n    n    delta = datetime.now() - mtime\\\\n    days = delta.days\\\\n    seconds = delta.seconds\\\\\\\n    n    if days > 0:\\\\n        return f\\\\\\\"{days} day{'s' if days != 1 else ''} ago\\\\\\\n    \\\"\\\\n    elif seconds >= 3600:\\\\n        hours = seconds // 3600\\\\n        return\\\n    \\ f\\\\\\\"{hours} hour{'s' if hours != 1 else ''} ago\\\\\\\"\\\\n    elif seconds >= 60:\\\\\\\n    n        minutes = seconds // 60\\\\n        return f\\\\\\\"{minutes} minute{'s' if\\\n    \\ minutes != 1 else ''} ago\\\\\\\"\\\\n    else:\\\\n        return \\\\\\\"just now\\\\\\\"\\\\\\\n    n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\\n\\\",\\n    \\\"src/rcpack/config_loader.py\\\"\\\n    : \\\"# src/rcpack/config_loader.py\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nTOML config loader for Repo-Contextor.\\\\\\\n    n\\\\nRules:\\\\n- Look for .repo-contextor.toml in the CURRENT directory\\\\n- If missing:\\\n    \\ ignore\\\\n- If present but invalid: print a clear error and exit(1)\\\\n- Only\\\n    \\ recognized keys are applied; unknown keys ignored\\\\n- Precedence: CLI > TOML\\\n    \\ > DEFAULTS\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nfrom __future__ import annotations\\\\nimport os,\\\n    \\ sys\\\\nfrom typing import Dict, Iterable, Any\\\\n\\\\ntry:\\\\n    import tomllib\\\\\\\n    n    _loads = tomllib.loads\\\\nexcept ModuleNotFoundError:\\\\n    try:\\\\n      \\\n    \\  import tomli\\\\n        _loads = tomli.loads\\\\n    except ModuleNotFoundError:\\\\\\\n    n        _loads = None\\\\n\\\\ndef _need_toml():\\\\n    if _loads is None:\\\\n    \\\n    \\    print(\\\\\\\"Error: TOML parser not available. Use Python 3.11+ or `pip install\\\n    \\ tomli`.\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\ndef _load_toml(dotfile:\\\n    \\ str) -> Dict[str, Any]:\\\\n    _need_toml()\\\\n    if not os.path.exists(dotfile):\\\\\\\n    n        return {}\\\\n    try:\\\\n        with open(dotfile, \\\\\\\"rb\\\\\\\") as f:\\\\\\\n    n            raw = f.read().decode(\\\\\\\"utf-8\\\\\\\", errors=\\\\\\\"strict\\\\\\\")\\\\n  \\\n    \\      data = _loads(raw)\\\\n        return data if isinstance(data, dict) else\\\n    \\ {}\\\\n    except Exception as e:\\\\n        print(f\\\\\\\"Error: failed to parse\\\n    \\ {dotfile} as TOML.\\\\\\\\n{e}\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\\\\n    ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\\\\\\n    n    ks = set(known)\\\\n    return {k: v for k, v in d.items() if k in ks}\\\\n\\\\\\\n    ndef _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str,\\\n    \\ Any], known: Iterable[str]) -> Dict[str, Any]:\\\\n    ks = set(known)\\\\n    out:\\\n    \\ Dict[str, Any] = {k: defaults.get(k) for k in ks}\\\\n    for src in (filecfg,\\\n    \\ clicfg):\\\\n        for k, v in src.items():\\\\n            if k in ks and v is\\\n    \\ not None:\\\\n                out[k] = v\\\\n    return out\\\\n\\\\ndef load_config(*,\\\n    \\ dotfile: str = \\\\\\\".repo-contextor.toml\\\\\\\", defaults: Dict[str, Any] | None\\\n    \\ = None, cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ())\\\n    \\ -> Dict[str, Any]:\\\\n    defaults = defaults or {}\\\\n    cli_cfg = cli_cfg or\\\n    \\ {}\\\\n    known = tuple(known_keys)\\\\n    filecfg = _filter_known(_load_toml(dotfile),\\\n    \\ known)\\\\n    return _merge(defaults, filecfg, cli_cfg, known)\\\\n\\\",\\n    \\\"\\\n    src/rcpack/discover.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"File discovery module for repository analysis.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom pathlib import Path\\\\nfrom typing import List\\\\nimport fnmatch\\\\\\\n    n\\\\n\\\\ndef discover_files(\\\\n    inputs: List[Path],\\\\n    root: Path,\\\\n    include_patterns:\\\n    \\ List[str],\\\\n    exclude_patterns: List[str],\\\\n) -> List[Path]:\\\\n    \\\\\\\"\\\\\\\n    \\\"\\\\\\\"Discover relevant files.\\\\n\\\\n    - inputs: list of files/dirs to scan\\\\\\\n    n    - root: common project root; patterns are matched against POSIX paths relative\\\n    \\ to root\\\\n    - include_patterns: glob patterns to include (if empty, use sensible\\\n    \\ defaults)\\\\n    - exclude_patterns: glob patterns to exclude\\\\n    Returns a\\\n    \\ list of absolute Paths to files.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    default_include_exts\\\n    \\ = {\\\\n        '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\\\\\\\n    n        '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\\\n   \\\n    \\     '.html', '.css', '.scss', '.sass', '.less', '.vue', '.svelte',\\\\n      \\\n    \\  '.md', '.txt', '.rst', '.yaml', '.yml', '.json', '.toml', '.ini',\\\\n      \\\n    \\  '.cfg', '.conf', '.xml', '.sql', '.sh', '.bash', '.zsh', '.fish',\\\\n    }\\\\\\\n    n\\\\n    always_include_names = {\\\\n        'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING',\\\n    \\ 'Makefile',\\\\n        'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\\\\\\\n    n        'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\\\\\\n    n    }\\\\n\\\\n    skip_dir_names = {\\\\n        '.git', '.svn', '.hg', '__pycache__',\\\n    \\ '.pytest_cache',\\\\n        'node_modules', '.venv', 'venv', 'env', '.env',\\\\\\\n    n        'build', 'dist', 'target', 'out', '.next', '.nuxt',\\\\n        '.idea',\\\n    \\ '.vscode', '.vs', 'coverage', '.coverage'\\\\n    }\\\\n\\\\n    def matches_any(patterns:\\\n    \\ List[str], rel_posix: str) -> bool:\\\\n        return any(fnmatch.fnmatch(rel_posix,\\\n    \\ pat) for pat in patterns)\\\\n\\\\n    def should_take(file_path: Path) -> bool:\\\\\\\n    n        rel_posix = file_path.relative_to(root).as_posix()\\\\n        if exclude_patterns\\\n    \\ and matches_any(exclude_patterns, rel_posix):\\\\n            return False\\\\n\\\n    \\        if include_patterns:\\\\n            return matches_any(include_patterns,\\\n    \\ rel_posix)\\\\n        # default include logic\\\\n        return file_path.name\\\n    \\ in always_include_names or file_path.suffix.lower() in default_include_exts\\\\\\\n    n\\\\n    discovered: list[Path] = []\\\\n    seen = set()\\\\n\\\\n    for item in inputs:\\\\\\\n    n        p = item.resolve()\\\\n        if p.is_file():\\\\n            # Skip if\\\n    \\ excluded or in skipped directory\\\\n            if any(part in skip_dir_names\\\n    \\ for part in p.parts):\\\\n                continue\\\\n            if should_take(p):\\\\\\\n    n                key = p.as_posix()\\\\n                if key not in seen:\\\\n \\\n    \\                   seen.add(key)\\\\n                    discovered.append(p)\\\\\\\n    n        elif p.is_dir():\\\\n            for child in p.rglob('*'):\\\\n        \\\n    \\        if not child.is_file():\\\\n                    continue\\\\n           \\\n    \\     if any(part in skip_dir_names for part in child.parts):\\\\n             \\\n    \\       continue\\\\n                if should_take(child):\\\\n                 \\\n    \\   key = child.resolve().as_posix()\\\\n                    if key not in seen:\\\\\\\n    n                        seen.add(key)\\\\n                        discovered.append(child.resolve())\\\\\\\n    n\\\\n    return sorted(discovered)\\\",\\n    \\\"src/rcpack/gitinfo.py\\\": \\\"from __future__\\\n    \\ import annotations\\\\n\\\\nimport subprocess\\\\nfrom pathlib import Path\\\\nfrom\\\n    \\ typing import Dict, Any\\\\n\\\\n\\\\ndef _git(cmd: list[str], cwd: Path) -> str:\\\\\\\n    n    # Validate git commands to prevent injection\\\\n    allowed_commands = {\\\\\\\n    n        \\\\\\\"rev-parse\\\\\\\", \\\\\\\"show\\\\\\\", \\\\\\\"log\\\\\\\", \\\\\\\"status\\\\\\\", \\\\\\\"branch\\\\\\\n    \\\", \\\\\\\"config\\\\\\\"\\\\n    }\\\\n    if not cmd or cmd[0] not in allowed_commands:\\\\\\\n    n        raise ValueError(f\\\\\\\"Git command not allowed: {cmd[0] if cmd else 'empty'}\\\\\\\n    \\\")\\\\n    \\\\n    out = subprocess.check_output([\\\\\\\"git\\\\\\\", *cmd], cwd=str(cwd),\\\n    \\ timeout=30)\\\\n    return out.decode(\\\\\\\"utf-8\\\\\\\", errors=\\\\\\\"replace\\\\\\\").strip()\\\\\\\n    n\\\\n\\\\ndef is_git_repo(path: Path) -> bool:\\\\n    try:\\\\n        flag = _git([\\\\\\\n    \\\"rev-parse\\\\\\\", \\\\\\\"--is-inside-work-tree\\\\\\\"], cwd=path)\\\\n        return flag\\\n    \\ == \\\\\\\"true\\\\\\\"\\\\n    except Exception:\\\\n        return False\\\\n\\\\n\\\\ndef get_git_info(path:\\\n    \\ Path) -> Dict[str, Any]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Return info for the current\\\n    \\ HEAD of a repo rooted at `path`.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        commit\\\n    \\ = _git([\\\\\\\"rev-parse\\\\\\\", \\\\\\\"HEAD\\\\\\\"], cwd=path)\\\\n        branch = _git([\\\\\\\n    \\\"rev-parse\\\\\\\", \\\\\\\"--abbrev-ref\\\\\\\", \\\\\\\"HEAD\\\\\\\"], cwd=path)\\\\n        author\\\n    \\ = _git([\\\\\\\"show\\\\\\\", \\\\\\\"-s\\\\\\\", \\\\\\\"--format=%an <%ae>\\\\\\\"], cwd=path)\\\\n\\\n    \\        date = _git([\\\\\\\"show\\\\\\\", \\\\\\\"-s\\\\\\\", \\\\\\\"--date=local\\\\\\\", \\\\\\\"--format=%ad\\\\\\\n    \\\"], cwd=path)\\\\n        return {\\\\n            \\\\\\\"is_repo\\\\\\\": True,\\\\n    \\\n    \\        \\\\\\\"commit\\\\\\\": commit,\\\\n            \\\\\\\"branch\\\\\\\": branch,\\\\n    \\\n    \\        \\\\\\\"author\\\\\\\": author,\\\\n            \\\\\\\"date\\\\\\\": date,\\\\n        \\\n    \\    \\\\\\\"note\\\\\\\": None,\\\\n        }\\\\n    except Exception:\\\\n        # treat\\\n    \\ as not a repo if anything fails\\\\n        return {\\\\n            \\\\\\\"is_repo\\\\\\\n    \\\": False,\\\\n            \\\\\\\"commit\\\\\\\": None,\\\\n            \\\\\\\"branch\\\\\\\": None,\\\\\\\n    n            \\\\\\\"author\\\\\\\": None,\\\\n            \\\\\\\"date\\\\\\\": None,\\\\n      \\\n    \\      \\\\\\\"note\\\\\\\": \\\\\\\"Not a git repository\\\\\\\",\\\\n        }\\\\n\\\",\\n    \\\"src/rcpack/io_utils.py\\\"\\\n    : \\\"\\\\\\\"\\\\\\\"\\\\\\\"I/O utilities for file operations.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom pathlib\\\n    \\ import Path\\\\nfrom typing import Tuple\\\\n\\\\n\\\\ndef write_output(output_path:\\\n    \\ str, content: str) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Write content to output file.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n    output_file = Path(output_path)\\\\n    \\\\n    # Create parent\\\n    \\ directories if they don't exist\\\\n    output_file.parent.mkdir(parents=True,\\\n    \\ exist_ok=True)\\\\n    \\\\n    # Write content\\\\n    with open(output_file, 'w',\\\n    \\ encoding='utf-8') as f:\\\\n        f.write(content)\\\\n\\\\n\\\\ndef is_binary_file(path:\\\n    \\ Path, sniff_bytes: int = 2048) -> bool:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Heuristically determine\\\n    \\ if a file is binary by scanning for NUL bytes.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n   \\\n    \\     with open(path, 'rb') as fb:\\\\n            chunk = fb.read(sniff_bytes)\\\\\\\n    n        if b\\\\\\\"\\\\\\\\x00\\\\\\\" in chunk:\\\\n            return True\\\\n        # If\\\n    \\ the chunk has a lot of non-text bytes, consider it binary\\\\n        text_byte_count\\\n    \\ = sum(32 <= b <= 126 or b in (9, 10, 13) for b in chunk)\\\\n        return (len(chunk)\\\n    \\ - text_byte_count) > max(1, len(chunk) // 3)\\\\n    except Exception:\\\\n    \\\n    \\    # If we cannot read, treat as binary to avoid further processing\\\\n     \\\n    \\   return True\\\\n\\\\n\\\\ndef read_text_safely(path: Path, max_bytes: int = 16_384)\\\n    \\ -> Tuple[str, str, bool]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Read a text file safely with size\\\n    \\ limit and encoding fallbacks.\\\\n\\\\n    Returns (content, encoding_used, truncated).\\\\\\\n    n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    truncated = False\\\\n    raw: bytes\\\\n    with open(path,\\\n    \\ 'rb') as fb:\\\\n        raw = fb.read(max_bytes + 1)\\\\n    if len(raw) > max_bytes:\\\\\\\n    n        truncated = True\\\\n        raw = raw[:max_bytes]\\\\n\\\\n    for enc in\\\n    \\ (\\\\\\\"utf-8\\\\\\\", \\\\\\\"utf-16\\\\\\\", \\\\\\\"utf-16-le\\\\\\\", \\\\\\\"utf-16-be\\\\\\\", \\\\\\\"latin-1\\\\\\\n    \\\"):\\\\n        try:\\\\n            text = raw.decode(enc)\\\\n            return\\\n    \\ text, enc, truncated\\\\n        except Exception:\\\\n            continue\\\\n \\\n    \\   # Fallback: replace errors with utf-8\\\\n    text = raw.decode(\\\\\\\"utf-8\\\\\\\"\\\n    , errors=\\\\\\\"replace\\\\\\\")\\\\n    return text, \\\\\\\"utf-8\\\\\\\", truncated\\\",\\n   \\\n    \\ \\\"src/rcpack/packager.py\\\": \\\"from __future__ import annotations\\\\n\\\\nimport\\\n    \\ sys\\\\nfrom pathlib import Path\\\\nfrom typing import Iterable, Tuple\\\\n\\\\nfrom\\\n    \\ rcpack.discover import discover_files\\\\nfrom rcpack.gitinfo import get_git_info,\\\n    \\ is_git_repo\\\\nfrom rcpack.io_utils import read_text_safely, is_binary_file\\\\\\\n    nfrom rcpack.renderer import markdown as md_renderer\\\\nfrom rcpack.renderer.jsonyaml\\\n    \\ import render_json, render_yaml\\\\nfrom rcpack.treeview import render_tree\\\\\\\n    n\\\\n\\\\ndef _find_root(inputs: list[str]) -> Path:\\\\n    paths = [Path(p) for p\\\n    \\ in inputs]\\\\n    if len(paths) == 1 and Path(paths[0]).is_dir():\\\\n        return\\\n    \\ paths[0].resolve()\\\\n    parents = [p if p.is_dir() else p.parent for p in paths]\\\\\\\n    n    root = Path(*Path.commonpath([str(p.resolve()) for p in parents]).split(\\\\\\\n    \\\"/\\\\\\\"))\\\\n    return root.resolve()\\\\n\\\\n\\\\ndef build_package(\\\\n    inputs:\\\n    \\ list[str],\\\\n    include_patterns: list[str] | None,\\\\n    exclude_patterns:\\\n    \\ list[str] | None,\\\\n    max_file_bytes: int,\\\\n    fmt: str = \\\\\\\"markdown\\\\\\\n    \\\",\\\\n) -> Tuple[str, dict]:\\\\n    root = _find_root(inputs)\\\\n    root_abs =\\\n    \\ root.resolve()\\\\n\\\\n    repo_info = (\\\\n        get_git_info(root_abs) if is_git_repo(root_abs)\\\n    \\ else {\\\\n            \\\\\\\"is_repo\\\\\\\": False,\\\\n            \\\\\\\"commit\\\\\\\": None,\\\\\\\n    n            \\\\\\\"branch\\\\\\\": None,\\\\n            \\\\\\\"author\\\\\\\": None,\\\\n    \\\n    \\        \\\\\\\"date\\\\\\\": None,\\\\n            \\\\\\\"note\\\\\\\": \\\\\\\"Not a git repository\\\\\\\n    \\\",\\\\n        }\\\\n    )\\\\n\\\\n    files = discover_files(\\\\n        inputs=[Path(p)\\\n    \\ for p in inputs],\\\\n        root=root_abs,\\\\n        include_patterns=include_patterns\\\n    \\ or [],\\\\n        exclude_patterns=exclude_patterns or [],\\\\n    )\\\\n    rel_files\\\n    \\ = [f.relative_to(root_abs) for f in files]\\\\n\\\\n    project_tree = render_tree([p.as_posix()\\\n    \\ for p in rel_files])\\\\n\\\\n    file_sections: list[dict] = []\\\\n    total_lines\\\n    \\ = 0\\\\n    total_chars = 0\\\\n\\\\n    for f in files:\\\\n        rel = f.relative_to(root_abs).as_posix()\\\\\\\n    n        try:\\\\n            if is_binary_file(f):\\\\n                content =\\\n    \\ f\\\\\\\"[binary file skipped: {f.name}, {f.stat().st_size} bytes]\\\\\\\"\\\\n      \\\n    \\          file_sections.append({\\\\n                    \\\\\\\"path\\\\\\\": rel,\\\\n\\\n    \\                    \\\\\\\"language\\\\\\\": _language_from_ext(f.suffix),\\\\n      \\\n    \\              \\\\\\\"content\\\\\\\": content,\\\\n                    \\\\\\\"is_truncated\\\\\\\n    \\\": False,\\\\n                })\\\\n                total_chars += len(content)\\\\\\\n    n                continue\\\\n\\\\n            content, used_encoding, truncated =\\\n    \\ read_text_safely(f, max_bytes=max_file_bytes)\\\\n            total_lines += content.count(\\\\\\\n    \\\"\\\\\\\\n\\\\\\\") + (1 if content and not content.endswith(\\\\\\\"\\\\\\\\n\\\\\\\") else 0)\\\\\\\n    n            total_chars += len(content)\\\\n\\\\n            if truncated:\\\\n   \\\n    \\             note = f\\\\\\\"\\\\\\\\n\\\\\\\\n[... TRUNCATED to first {max_file_bytes} bytes\\\n    \\ ...]\\\\\\\"\\\\n                content = content + note\\\\n                total_chars\\\n    \\ += len(note)\\\\n\\\\n            file_sections.append({\\\\n                \\\\\\\"\\\n    path\\\\\\\": rel,\\\\n                \\\\\\\"language\\\\\\\": _language_from_ext(f.suffix),\\\\\\\n    n                \\\\\\\"content\\\\\\\": content,\\\\n                \\\\\\\"is_truncated\\\\\\\n    \\\": truncated,\\\\n            })\\\\n        except Exception as exc:\\\\n        \\\n    \\    print(f\\\\\\\"[rcpack] error reading {rel}: {exc}\\\\\\\", file=sys.stderr)\\\\n \\\n    \\           continue\\\\n\\\\n    # render in chosen format\\\\n    if fmt == \\\\\\\"markdown\\\\\\\n    \\\":\\\\n        out_text = md_renderer.render_markdown(\\\\n            root=str(root_abs),\\\\\\\n    n            repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n   \\\n    \\         files=file_sections,\\\\n            total_files=len(file_sections),\\\\\\\n    n            total_lines=total_lines,\\\\n        )\\\\n    elif fmt == \\\\\\\"json\\\\\\\n    \\\":\\\\n        out_text = render_json(\\\\n            root=str(root_abs),\\\\n   \\\n    \\         repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n      \\\n    \\      files=file_sections,\\\\n            total_files=len(file_sections),\\\\n \\\n    \\           total_lines=total_lines,\\\\n        )\\\\n    elif fmt == \\\\\\\"yaml\\\\\\\"\\\n    :\\\\n        out_text = render_yaml(\\\\n            root=str(root_abs),\\\\n     \\\n    \\       repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n        \\\n    \\    files=file_sections,\\\\n            total_files=len(file_sections),\\\\n   \\\n    \\         total_lines=total_lines,\\\\n        )\\\\n    else:\\\\n        raise ValueError(f\\\\\\\n    \\\"Unsupported format: {fmt}\\\\\\\")\\\\n\\\\n    stats = {\\\\\\\"files\\\\\\\": len(file_sections),\\\n    \\ \\\\\\\"lines\\\\\\\": total_lines, \\\\\\\"chars\\\\\\\": total_chars}\\\\n    return out_text,\\\n    \\ stats\\\\n\\\\n\\\\ndef _language_from_ext(ext: str) -> str:\\\\n    ext = ext.lower().lstrip(\\\\\\\n    \\\".\\\\\\\")\\\\n    mapping = {\\\\n        \\\\\\\"py\\\\\\\": \\\\\\\"python\\\\\\\", \\\\\\\"js\\\\\\\": \\\\\\\n    \\\"javascript\\\\\\\", \\\\\\\"ts\\\\\\\": \\\\\\\"typescript\\\\\\\",\\\\n        \\\\\\\"json\\\\\\\": \\\\\\\"\\\n    json\\\\\\\", \\\\\\\"md\\\\\\\": \\\\\\\"markdown\\\\\\\", \\\\\\\"yml\\\\\\\": \\\\\\\"yaml\\\\\\\", \\\\\\\"yaml\\\\\\\"\\\n    : \\\\\\\"yaml\\\\\\\",\\\\n        \\\\\\\"toml\\\\\\\": \\\\\\\"toml\\\\\\\", \\\\\\\"sh\\\\\\\": \\\\\\\"bash\\\\\\\"\\\n    , \\\\\\\"c\\\\\\\": \\\\\\\"c\\\\\\\", \\\\\\\"cpp\\\\\\\": \\\\\\\"cpp\\\\\\\",\\\\n        \\\\\\\"java\\\\\\\": \\\\\\\"\\\n    java\\\\\\\", \\\\\\\"go\\\\\\\": \\\\\\\"go\\\\\\\", \\\\\\\"rs\\\\\\\": \\\\\\\"rust\\\\\\\",\\\\n    }\\\\n    return\\\n    \\ mapping.get(ext, \\\\\\\"\\\\\\\")\\\\n\\\",\\n    \\\"src/rcpack/renderer/jsonyaml.py\\\": \\\"\\\n    from __future__ import annotations\\\\nimport json\\\\n\\\\ntry:\\\\n    import yaml\\\\\\\n    nexcept ImportError:\\\\n    yaml = None\\\\n\\\\n\\\\ndef render_json(root, repo_info,\\\n    \\ tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None)\\\n    \\ -> str:\\\\n    data = {\\\\n        \\\\\\\"root\\\\\\\": root,\\\\n        \\\\\\\"repo_info\\\\\\\n    \\\": repo_info,\\\\n        \\\\\\\"structure\\\\\\\": tree_text,\\\\n        \\\\\\\"recent_changes\\\\\\\n    \\\": recent_files or [],\\\\n        \\\\\\\"files\\\\\\\": files,\\\\n        \\\\\\\"file_sizes\\\\\\\n    \\\": file_sizes or {},\\\\n        \\\\\\\"summary\\\\\\\": {\\\\\\\"total_files\\\\\\\": total_files,\\\n    \\ \\\\\\\"total_lines\\\\\\\": total_lines},\\\\n        \\\\n    }\\\\n    return json.dumps(data,\\\n    \\ indent=2, ensure_ascii=False)\\\\n\\\\n\\\\ndef render_yaml(root, repo_info, tree_text,\\\n    \\ files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\\\\\\\n    n    if yaml is None:\\\\n        raise RuntimeError(\\\\\\\"PyYAML not installed; run\\\n    \\ `pip install pyyaml`\\\\\\\")\\\\n    data = {\\\\n        \\\\\\\"root\\\\\\\": root,\\\\n  \\\n    \\      \\\\\\\"repo_info\\\\\\\": repo_info,\\\\n        \\\\\\\"structure\\\\\\\": tree_text,\\\\\\\n    n        \\\\\\\"recent_changes\\\\\\\": recent_files or [],\\\\n        \\\\\\\"files\\\\\\\":\\\n    \\ files,\\\\n        \\\\\\\"file_sizes\\\\\\\": file_sizes or {},\\\\n        \\\\\\\"summary\\\\\\\n    \\\": {\\\\\\\"total_files\\\\\\\": total_files, \\\\\\\"total_lines\\\\\\\": total_lines},\\\\n \\\n    \\       \\\\n    }\\\\n    return yaml.safe_dump(data, sort_keys=False, allow_unicode=True)\\\\\\\n    n\\\",\\n    \\\"src/rcpack/renderer/markdown.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Markdown renderer\\\n    \\ for repository context.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom typing import Dict, Any\\\\n\\\\n\\\\\\\n    ndef render_markdown(root: str, repo_info: Dict[str, Any], tree_text: str, \\\\\\\n    n                   files: Dict[str, str], total_files: int, total_lines: int,\\\n    \\ recent_files=None, file_sizes=None) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Render repository\\\n    \\ context as markdown.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    lines = []\\\\n    \\\\n    # Header\\\\\\\n    n    lines.append(f\\\\\\\"# Repository Context: {root}\\\\\\\")\\\\n    lines.append(\\\\\\\n    \\\"\\\\\\\")\\\\n    \\\\n    # Repository info\\\\n    if repo_info.get(\\\\\\\"is_repo\\\\\\\"\\\n    ):\\\\n        lines.append(\\\\\\\"## Git Repository Information\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Branch**: {repo_info.get('branch', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Commit**: {repo_info.get('commit', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Author**: {repo_info.get('author', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Date**: {repo_info.get('date', 'N/A')}\\\\\\\")\\\\n    else:\\\\n        lines.append(\\\\\\\n    \\\"## Repository Information\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Note**: {repo_info.get('note',\\\n    \\ 'Not a git repository')}\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Summary\\\\\\\n    n    lines.append(\\\\\\\"## Summary\\\\\\\")\\\\n    lines.append(f\\\\\\\"- **Total Files**:\\\n    \\ {total_files}\\\\\\\")\\\\n    lines.append(f\\\\\\\"- **Total Lines**: {total_lines}\\\\\\\n    \\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Directory structure\\\\n    lines.append(\\\\\\\n    \\\"## Directory Structure\\\\\\\")\\\\n    lines.append(\\\\\\\"```\\\\\\\")\\\\n    lines.append(tree_text)\\\\\\\n    n    lines.append(\\\\\\\"```\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n\\\\n    # will produce\\\n    \\ recent files \\\\n    # Recent files (fixed)\\\\n    if recent_files:\\\\n       \\\n    \\ lines.append(\\\\\\\"## Recent Changes\\\\\\\")\\\\n        for file, age in recent_files.items():\\\\\\\n    n            lines.append(f\\\\\\\"- {file} (modified {age})\\\\\\\")\\\\n        lines.append(\\\\\\\n    \\\"\\\\\\\")\\\\n    \\\\n    # File contents\\\\n    lines.append(\\\\\\\"## File Contents\\\\\\\n    \\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    for file_path, content in sorted(files.items()):\\\\\\\n    n        if file_sizes and file_path in file_sizes:\\\\n            size_bytes =\\\n    \\ file_sizes[file_path]\\\\n            lines.append(f\\\\\\\"### {file_path} ({size_bytes}\\\n    \\ bytes)\\\\\\\")\\\\n        else:\\\\n            lines.append(f\\\\\\\"### {file_path}\\\\\\\n    \\\")\\\\n        lines.append(\\\\\\\"\\\\\\\")\\\\n        \\\\n        # Detect language for\\\n    \\ syntax highlighting\\\\n        ext = file_path.split('.')[-1].lower() if '.'\\\n    \\ in file_path else ''\\\\n        lang_map = {\\\\n            'py': 'python', 'js':\\\n    \\ 'javascript', 'ts': 'typescript',\\\\n            'java': 'java', 'cpp': 'cpp',\\\n    \\ 'c': 'c', 'h': 'c',\\\\n            'cs': 'csharp', 'php': 'php', 'rb': 'ruby',\\\\\\\n    n            'go': 'go', 'rs': 'rust', 'swift': 'swift',\\\\n            'html':\\\n    \\ 'html', 'css': 'css', 'scss': 'scss',\\\\n            'json': 'json', 'yaml':\\\n    \\ 'yaml', 'yml': 'yaml',\\\\n            'xml': 'xml', 'sql': 'sql', 'sh': 'bash',\\\\\\\n    n            'md': 'markdown', 'dockerfile': 'dockerfile'\\\\n        }\\\\n     \\\n    \\   \\\\n        language = lang_map.get(ext, '')\\\\n        lines.append(f\\\\\\\"```{language}\\\\\\\n    \\\")\\\\n        lines.append(content)\\\\n        lines.append(\\\\\\\"```\\\\\\\")\\\\n   \\\n    \\     lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    return \\\\\\\"\\\\\\\\n\\\\\\\".join(lines)\\\\n\\\"\\\n    ,\\n    \\\"src/rcpack/treeview.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Tree view generation for repository\\\n    \\ structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom pathlib import Path\\\\nfrom typing import Dict,\\\n    \\ List\\\\n\\\\n\\\\ndef create_tree_view(repo_path: Path, files_data: Dict[str, str])\\\n    \\ -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create a tree view of the repository structure.\\\\\\\"\\\n    \\\\\\\"\\\\\\\"\\\\n    paths = list(files_data.keys())\\\\n    return render_tree(paths)\\\\\\\n    n\\\\n\\\\ndef render_tree(paths: List[str]) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Render a tree\\\n    \\ view from a list of relative POSIX paths.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    tree_structure:\\\n    \\ dict = {}\\\\n\\\\n    for p in paths:\\\\n        parts = Path(p).parts\\\\n      \\\n    \\  current = tree_structure\\\\n        for part in parts[:-1]:\\\\n            if\\\n    \\ part not in current:\\\\n                current[part] = {}\\\\n            current\\\n    \\ = current[part]\\\\n        if parts:\\\\n            current[parts[-1]] = None\\\\\\\n    n\\\\n    def _render(structure: dict, prefix: str = \\\\\\\"\\\\\\\") -> str:\\\\n      \\\n    \\  lines = []\\\\n        items = sorted(structure.items(), key=lambda x: (x[1]\\\n    \\ is None, x[0]))\\\\n        for i, (name, subtree) in enumerate(items):\\\\n   \\\n    \\         is_last = i == len(items) - 1\\\\n            lines.append(f\\\\\\\"{prefix}{'└──\\\n    \\ ' if is_last else '├── '}{name}\\\\\\\")\\\\n            if subtree is not None:\\\\\\\n    n                extension = (\\\\\\\"    \\\\\\\" if is_last else \\\\\\\"│   \\\\\\\")\\\\n  \\\n    \\              lines.append(_render(subtree, prefix + extension))\\\\n        return\\\n    \\ \\\\\\\"\\\\\\\\n\\\\\\\".join(filter(None, lines))\\\\n\\\\n    if not tree_structure:\\\\n \\\n    \\       return \\\\\\\"No files found\\\\\\\"\\\\n    return _render(tree_structure)\\\"\\n\\\n    \\  },\\n  \\\"file_sizes\\\": {\\n    \\\"LICENSE\\\": \\\"1064\\\",\\n    \\\"README.md\\\": \\\"\\\n    11164\\\",\\n    \\\"pyproject.toml\\\": \\\"361\\\",\\n    \\\"src/rcpack/__init__.py\\\": \\\"\\\n    198\\\",\\n    \\\"src/rcpack/__main__.py\\\": \\\"197\\\",\\n    \\\"src/rcpack/cli.py\\\": \\\"\\\n    7087\\\",\\n    \\\"src/rcpack/config_loader.py\\\": \\\"2099\\\",\\n    \\\"src/rcpack/discover.py\\\"\\\n    : \\\"3067\\\",\\n    \\\"src/rcpack/gitinfo.py\\\": \\\"1653\\\",\\n    \\\"src/rcpack/io_utils.py\\\"\\\n    : \\\"1817\\\",\\n    \\\"src/rcpack/packager.py\\\": \\\"4430\\\",\\n    \\\"src/rcpack/renderer/jsonyaml.py\\\"\\\n    : \\\"1176\\\",\\n    \\\"src/rcpack/renderer/markdown.py\\\": \\\"2829\\\",\\n    \\\"src/rcpack/treeview.py\\\"\\\n    : \\\"1371\\\"\\n  },\\n  \\\"summary\\\": {\\n    \\\"total_files\\\": 14,\\n    \\\"total_lines\\\"\\\n    : 1180\\n  }\\n}\"\nfile_sizes:\n  LICENSE: '1064'\n  README.md: '11164'\n  pyproject.toml: '361'\n  src/rcpack/__init__.py: '198'\n  src/rcpack/__main__.py: '197'\n  src/rcpack/cli.py: '7087'\n  src/rcpack/config_loader.py: '2099'\n  src/rcpack/discover.py: '3067'\n  src/rcpack/gitinfo.py: '1653'\n  src/rcpack/io_utils.py: '1817'\n  src/rcpack/packager.py: '4430'\n  src/rcpack/renderer/jsonyaml.py: '1176'\n  src/rcpack/renderer/markdown.py: '2829'\n  src/rcpack/treeview.py: '1371'\n  test-output.json: '42249'\nsummary:\n  total_files: 15\n  total_lines: 1229\n"
  },
  "file_sizes": {
    "LICENSE": "1064",
    "README.md": "11164",
    "pyproject.toml": "361",
    "src/rcpack/__init__.py": "198",
    "src/rcpack/__main__.py": "197",
    "src/rcpack/cli.py": "7087",
    "src/rcpack/config_loader.py": "2099",
    "src/rcpack/discover.py": "2244",
    "src/rcpack/gitinfo.py": "1653",
    "src/rcpack/io_utils.py": "1817",
    "src/rcpack/packager.py": "4121",
    "src/rcpack/renderer/jsonyaml.py": "1154",
    "src/rcpack/renderer/markdown.py": "2318",
    "src/rcpack/treeview.py": "1371",
    "src/rcpack/utils.py": "4445",
    "test-iteration2.json": "194424",
    "test-iteration2.yaml": "449619",
    "test-output.json": "42249",
    "test-yaml.yaml": "93888"
  },
  "summary": {
    "total_files": 19,
    "total_lines": 7721
  }
}
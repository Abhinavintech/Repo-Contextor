{
  "root": "/Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor",
  "repo_info": {
    "is_repo": true,
    "commit": "57f0f88ec3d11a89d5ca08ee4fb5b9b561c1b8aa",
    "branch": "refactoring",
    "author": "Abhinav <abhinavbhardwaj2002@gmail.com>",
    "date": "Fri Oct 10 19:19:52 2025",
    "note": null
  },
  "structure": "├── src\n│   └── rcpack\n│       ├── renderer\n│       │   ├── jsonyaml.py\n│       │   └── markdown.py\n│       ├── __init__.py\n│       ├── __main__.py\n│       ├── cli.py\n│       ├── config_loader.py\n│       ├── discover.py\n│       ├── gitinfo.py\n│       ├── io_utils.py\n│       ├── packager.py\n│       ├── treeview.py\n│       └── utils.py\n├── LICENSE\n├── README.md\n├── pyproject.toml\n├── test-output.json\n└── test-yaml.yaml",
  "recent_changes": {},
  "files": {
    "LICENSE": "MIT License\n\nCopyright (c) 2025 Abhinav\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
    "README.md": "# Repo-Contextor\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nA powerful Repository Context Packager CLI tool that analyzes local git repositories and creates comprehensive text files containing repository content optimized for sharing with Large Language Models (LLMs).\n\n## Overview\n\nWhen developers want to get help from ChatGPT, Claude, or other LLMs about their code, they often struggle with how to share their codebase effectively. Common problems include:\n\n- **Lost Context**: Copy-pasting individual files loses important project structure and relationships\n- **Missing Dependencies**: LLMs can't see how files connect or what libraries are used\n- **Incomplete Picture**: Hard to convey the overall architecture and organization\n- **Manual Work**: Time-consuming to gather and format relevant code\n\n**Repo-Contextor** solves this by automatically collecting and formatting repository content into a single, well-structured text file that provides rich context to LLMs, enabling them to give much better assistance with your code.\n\n## Features\n\n- **Git Integration**: Extracts commit SHA, branch, author, and date information\n- **Project Structure**: Generates a clear directory tree visualization\n- **File Content Packaging**: Includes file contents with syntax highlighting\n- **Smart File Discovery**: Recursively scans directories with intelligent filtering\n- **Binary File Detection**: Automatically skips binary files\n- **Error Handling**: Gracefully handles permission errors and provides helpful messages\n- **Multiple Output Formats**: Supports Markdown, JSON, and YAML formats\n- **Flexible Output**: Write to stdout or save to a file\n- **Recent Changes Filter**: Give the files which are updated in last 7days with the time when it was recently modified.\n\n## Installation\n\n### Prerequisites\n\n- Python 3.9 or higher\n- Git (for git repository analysis)\n\n### For End Users\n\n```bash\n# Clone and install\ngit clone https://github.com/yourusername/Repo-Contextor.git\ncd Repo-Contextor\npip install -e .\n```\n\n### For Contributors & Local Development\n\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/Repo-Contextor.git\ncd Repo-Contextor\n\n# Create virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install in development mode\npip install -e .\n```\n\n## Usage\n\n### Basic Examples\n\n```bash\n# Package current directory to terminal\nrepo-contextor .\n\n# Package a specific directory\nrepo-contextor /path/to/your/project\n\n# Save output to a file\nrepo-contextor . -o my-project-context.md\n\n# Generate JSON format\nrepo-contextor . -f json -o context.json\n\n# Generate YAML format\nrepo-contextor . -f yaml -o context.yaml\n\n# Include only files modified in the last 7 days\nrepo-contextor . --recent\n\n# Combine with output file\nrepo-contextor . --recent -o recent-changes.md\n```\n\n### Command Line Options\n\n| Option | Short | Description | Example |\n|--------|-------|-------------|---------|\n| `path` | - | Repository path to analyze (default: current directory) | `repo-contextor /path/to/project` |\n| `--output` | `-o` | Output file path (default: stdout) | `-o context.md` |\n| `--format` | `-f` | Output format: text, json, yaml (default: text) | `-f json` |\n| `--help` | `-h` | Show help message | `-h` |\n| `--recent`  | `-r`  | Include only files modified in the last 7 days    | `repo-contextor . -r -o recent.md` |\n\n### Advanced Examples\n\n```bash\n# Analyze different repository\nrepo-contextor /path/to/other/project -o other-project.md\n\n# Generate JSON for API consumption\nrepo-contextor . -f json -o api-context.json\n\n# Create YAML configuration\nrepo-contextor . -f yaml -o project-config.yaml\n\n# Generate files which are changed recently in 7 days\nrepo-contextor . -r --output recent-changes.txt\n\n```\n## Configuration via TOML\n\nRepo-Contextor supports configuration through a `.repo-contextor.toml` file in the current working directory.  \nThis file allows you to avoid typing the same CLI arguments every time.\n\nExample `.repo-contextor.toml`:\n\n```toml\n# Output file to write results\noutput = \"context.yaml\"\n\n# Output format: text, json, or yaml\nformat = \"yaml\"\n\n# Limit to files modified in the last 7 days\nrecent = true\n\n# Repository path to analyze (default = current directory)\npath = \".\"\n```\n### Rules\n- If the `.repo-contextor.toml` file is **missing**, the tool falls back to defaults.  \n- If the file is **present but invalid TOML**, the tool prints a clear error message and exits with status code 1.  \n- **Unknown keys** in the TOML file are ignored (safe for future extensions).  \n- **Precedence** of settings is:\n  1. Command-line arguments (highest priority)  \n  2. Values from `.repo-contextor.toml`  \n  3. Built-in defaults (lowest priority)\n     \n## Output Format\n\nThe tool generates a structured text file with the following sections:\n\n### 1. Repository Context Header\nProject path and identification\n\n### 2. Git Repository Information\n- Current branch\n- Latest commit SHA\n- Last commit author\n- Last commit date\n\n### 3. Summary Statistics\n- Total number of files processed\n- Total lines of code\n\n### 4. Directory Structure\nClean tree visualization showing project organization\n\n### 5. Recent Changes (if `--recent` is used)\n\n- Lists files modified in the last 7 days.\n- Shows relative file paths along with how long ago each file was modified\n- Helps focus on recently updated parts of the project.\n- Can be combined with `--output` or `--format` to save or change the output type.\n\n\n### 5. File Contents\nEach file's content with:\n- Clear file path headers\n- Appropriate syntax highlighting language tags\n- Complete file contents\n\n## Example Output\n\nWhen you run `repo-contextor .`, the output looks like this:\n\n````markdown\n# Repository Context: /path/to/your/project\n\n## Git Repository Information\n- **Branch**: main\n- **Commit**: a1b2c3d4e5f6789...\n- **Author**: John Doe <john@example.com>\n- **Date**: Fri Sep 12 14:30:15 2025\n\n## Summary\n- **Total Files**: 15\n- **Total Lines**: 1,247\n\n## Directory Structure\n```\n├── src/\n│   ├── main.py\n│   └── utils.py\n├── tests/\n│   └── test_main.py\n├── README.md\n└── requirements.txt\n```\n## Recent Changes\n- src/main.py (modified 2 days ago)\n- src/utils/helpers.py (modified 5 days ago)\n\n## File Contents\n\n### src/main.py\n\n```python\ndef main():\n    print(\"Hello, World!\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### README.md\n\n```markdown\n# My Project\nThis is a sample project.\n```\n\n## Summary\n- Total files: 15\n- Total lines: 1,247\n````\n\n## What Files Are Included\n\nThe tool includes most text files but automatically excludes:\n\n### Excluded Directories\n- `.git`, `.svn`, `.hg` (version control)\n- `__pycache__`, `.pytest_cache` (Python cache)\n- `node_modules`, `.venv`, `venv` (dependencies/environments)\n- `.vscode`, `.idea` (IDE directories)\n- `build`, `dist`, `target` (build directories)\n\n### File Handling Rules\n- **Text files**: All readable text files with common extensions\n- **Binary files**: Automatically detected and skipped\n- **Permission errors**: Skipped with graceful handling\n- **Configuration files**: Includes pyproject.toml, package.json, etc.\n\n### Included File Types\n- Source code: `.py`, `.js`, `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\n- Web files: `.html`, `.css`, `.scss`, `.vue`, `.jsx`, etc.\n- Documentation: `.md`, `.txt`, `.rst`\n- Configuration: `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\n- Scripts: `.sh`, `.bash`, `.zsh`\n\n## Error Handling\n\nThe tool handles errors gracefully:\n\n| Error Type | Behavior |\n|------------|----------|\n| **Permission errors** | Skipped with warning |\n| **Binary files** | Automatically detected and skipped |\n| **Invalid paths** | Clear error messages |\n| **Non-git repositories** | Works fine, shows \"Not a git repository\" |\n| **Unreadable files** | Marked as \"[Binary or unreadable file]\" |\n\n## Development\n\n### Project Structure\n\n```text\nRepo-Contextor/\n├── src/rcpack/              # Main package\n│   ├── __init__.py         # Package initialization\n│   ├── cli.py              # Command-line interface\n│   ├── discover.py         # File discovery logic\n│   ├── gitinfo.py          # Git repository analysis\n│   ├── treeview.py         # Directory tree generation\n│   ├── packager.py         # Main orchestration\n│   ├── io_utils.py         # File I/O utilities\n│   └── renderer/           # Output formatters\n│       ├── markdown.py     # Markdown renderer\n│       └── jsonyaml.py     # JSON/YAML renderers\n├── pyproject.toml          # Project configuration\n├── LICENSE                 # MIT License\n└── README.md              # This documentation\n```\n\n### Running Tests\n\n```bash\n# Test on current repository\nrepo-contextor . -o test-output.md\n\n# Test different formats\nrepo-contextor . -f json | head -20\nrepo-contextor . -f yaml | head -20\n\n# Test specific directory\nrepo-contextor src/ -o src-only.md\n```\n\n### Contributing\n\n1. **Fork the repository**\n2. **Clone your fork:**\n   ```bash\n   git clone https://github.com/yourusername/Repo-Contextor.git\n   cd Repo-Contextor\n   ```\n3. **Install for development:**\n   ```bash\n   python -m venv .venv\n   source .venv/bin/activate\n   pip install -e .\n   ```\n4. **Make your changes and test:**\n   ```bash\n   repo-contextor . -o test.md\n   ```\n5. **Submit a pull request**\n\n### Development Workflow\n\n```bash\n# 1. Setup development environment\ngit clone https://github.com/yourusername/Repo-Contextor.git\ncd Repo-Contextor\npython -m venv .venv\nsource .venv/bin/activate\npip install -e .\n\n# 2. Make changes to the code\n# Edit files in src/rcpack/\n\n# 3. Test your changes\nrepo-contextor . -o test-output.md\n\n# 4. Test different formats\nrepo-contextor . -f json -o test.json\nrepo-contextor . -f yaml -o test.yaml\n\n# 5. Commit and push changes\ngit add .\ngit commit -m \"Add new feature\"\ngit push origin feature-branch\n```\n\n## License\n\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\n\n## Why Repo-Contextor?\n\nThe name \"Repo-Contextor\" combines \"Repository\" + \"Context\" + \"or\", representing the tool's purpose of providing rich context about code repositories in a format that's perfect for LLM interactions.\n\n### Use Cases\n\n- **AI Assistance**: Get better help from ChatGPT, Claude, or GitHub Copilot\n- **Code Reviews**: Share complete project context with team members\n- **Documentation**: Create comprehensive project snapshots\n- **Onboarding**: Help new team members understand project structure\n- **Project Analysis**: Understand repository structure and dependencies\n\n### Perfect for LLMs\n\nThe output format is specifically designed to work well with Large Language Models:\n- Clear section headers for easy parsing\n- Syntax highlighting markers for code blocks\n- Structured metadata (git info, file locations)\n- Complete project context in a single file\n- Multiple output formats (Markdown, JSON, YAML)\n- Optimized for token efficiency\n",
    "pyproject.toml": "[build-system]\nrequires = [\"setuptools>=68\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"rcpack\"\nversion = \"0.1.0\"\ndescription = \"Repository Context Packager CLI for LLMs\"\nreadme = \"README.md\"\nrequires-python = \">=3.9\"\nlicense = { text = \"MIT\" }\ndependencies = [\n    \"PyYAML>=6.0\"\n]\n\n[project.scripts]\nrepo-contextor = \"rcpack.cli:main\"\n",
    "src/rcpack/__init__.py": "\"\"\"Repository Context Packager - CLI tool for creating LLM-optimized repository context.\"\"\"\n\n__version__ = \"0.1.0\"\n__author__ = \"Abhinav\"\n__description__ = \"Repository Context Packager CLI for LLMs\"",
    "src/rcpack/__main__.py": "#!/usr/bin/env python3\n\"\"\"Module entry point to enable `python -m rcpack`.\n\nThis simply delegates to the CLI's main() function.\n\"\"\"\n\nfrom .cli import main\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n",
    "src/rcpack/cli.py": "#!/usr/bin/env python3\n\"\"\"CLI for Repository Context Packager.\"\"\"\n\nfrom .config_loader import load_config\n\nimport argparse\nimport sys\nfrom pathlib import Path\nfrom .gitinfo import get_git_info\nfrom .discover import discover_files\nfrom .treeview import create_tree_view\nfrom .renderer.markdown import render_markdown\nfrom .renderer.jsonyaml import render_json, render_yaml\nfrom .io_utils import write_output\nfrom datetime import datetime, timedelta\n\n\ndef log_verbose(message: str, verbose: bool) -> None:\n    \"\"\"Log a message to stderr if verbose mode is enabled.\"\"\"\n    if verbose:\n        print(message, file=sys.stderr)\n\n\ndef get_rendered_content(format_type: str, repo_path: str, repo_info: dict, tree_text: str, \n                        files_data: dict, total_files: int, total_lines: int, \n                        recent_files_info: dict, file_sizes: dict) -> str:\n    \"\"\"Get rendered content based on the specified format.\"\"\"\n    if format_type == \"json\":\n        return render_json(\n            repo_path, repo_info, tree_text, \n            files_data, total_files, total_lines,\n            recent_files=recent_files_info,\n            file_sizes=file_sizes\n        )\n    elif format_type == \"yaml\":\n        return render_yaml(\n            repo_path, repo_info, tree_text, \n            files_data, total_files, total_lines,\n            recent_files=recent_files_info,\n            file_sizes=file_sizes\n        )\n    else:  # text/markdown\n        return render_markdown(\n            repo_path, repo_info, tree_text, \n            files_data, total_files, total_lines,\n            recent_files=recent_files_info,\n            file_sizes=file_sizes\n        )\n\n\ndef process_file(file_path: Path, repo_path: Path, verbose: bool) -> tuple[str, str, str]:\n    \"\"\"Process a single file and return its data.\n    \n    Returns:\n        tuple: (relative_path_str, content, file_size)\n    \"\"\"\n    relative_path = file_path.relative_to(repo_path)\n    relative_path_str = str(relative_path)\n    \n    log_verbose(f\"Reading file: {relative_path}\", verbose)\n    file_size = file_path.stat().st_size\n    \n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n        return relative_path_str, content, str(file_size)\n    except (UnicodeDecodeError, PermissionError):\n        log_verbose(f\"Skipping binary/unreadable file: {relative_path}\", verbose)\n        file_size = file_path.stat().st_size if file_path.exists() else 0\n        content = f\"[Binary or unreadable file: {file_path.name}]\"\n        return relative_path_str, content, str(file_size)\n    except Exception:\n        log_verbose(f\"Error reading file: {relative_path}\", verbose)\n        raise  # Re-raise to handle in calling code\n\n\ndef handle_output(content: str, output_path: str = None) -> None:\n    \"\"\"Handle output to either file or stdout.\"\"\"\n    if output_path:\n        # Write to file\n        write_output(output_path, content)\n        print(f\"Context package created: {output_path}\")\n    else:\n        # Output to stdout\n        print(content)\n\n\ndef main():\n    parser = argparse.ArgumentParser(\n        description=\"Package repository content for LLM context\"\n    )\n    parser.add_argument(\n        \"path\", \n        nargs=\"?\", \n        default=\".\", \n        help=\"Repository path (default: current directory)\"\n    )\n    parser.add_argument(\n        \"-o\", \"--output\", \n        help=\"Output file path (default: stdout)\"\n    )\n    parser.add_argument(\n        \"-f\", \"--format\", \n        choices=[\"text\", \"json\", \"yaml\"], \n        default=\"text\",\n        help=\"Output format (default: text)\"\n    )\n\n    \"\"\" This will read -r from the console and able to search it with this\"\"\"\n    parser.add_argument(\n    \"-r\", \"--recent\",\n    action=\"store_true\",\n    help=\"Include only files modified in the last 7 days\"\n    )\n    parser.add_argument(\n        \"-v\", \"--verbose\",\n        action=\"store_true\",\n        help=\"Print detailed progress information to stderr\"\n    )\n    \n    args = parser.parse_args()\n    \n    try:\n        repo_path = Path(args.path).resolve()\n        if not repo_path.exists():\n            print(f\"Error: Path {repo_path} does not exist\", file=sys.stderr)\n            sys.exit(1)\n            \n        # Get repository information\n        log_verbose(f\"Analyzing repository: {repo_path}\", args.verbose)\n        repo_info = get_git_info(repo_path)\n        \n        # Discover files\n        log_verbose(f\"Discovering files in: {repo_path}\", args.verbose)\n        discovered_files = discover_files([repo_path], repo_path, [], [])\n        log_verbose(f\"Found {len(discovered_files)} files\", args.verbose)\n        \n        # will check the file in last 7 days\n        recent_files_info = {}\n        if args.recent:\n            seven_days_ago = datetime.now() - timedelta(days=7)\n            recent_files = []\n            for f in discovered_files:\n                try:\n                    mtime = datetime.fromtimestamp(f.stat().st_mtime)\n                    if mtime >= seven_days_ago:\n                        recent_files.append(f)\n                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)     \n                except Exception:\n                    continue\n            discovered_files = recent_files\n        \n        # Read file contents\n        files_data = {}\n        file_sizes = {}\n        for file_path in discovered_files:\n            try:\n                relative_path_str, content, file_size = process_file(file_path, repo_path, args.verbose)\n                files_data[relative_path_str] = content\n                file_sizes[relative_path_str] = file_size\n            except Exception:\n                continue\n        \n        # Create tree view\n        log_verbose(\"Generating directory tree\", args.verbose)\n        tree_text = create_tree_view(repo_path, files_data)\n        \n        # Count totals\n        total_files = len(files_data)\n        total_lines = sum(len(content.splitlines()) for _, content in files_data.items())\n        \n        # Render based on format\n        log_verbose(f\"Rendering output in {args.format} format\", args.verbose)\n        content = get_rendered_content(\n            args.format, str(repo_path), repo_info, tree_text,\n            files_data, total_files, total_lines,\n            recent_files_info if args.recent else {},\n            file_sizes\n        )\n        \n        handle_output(content, args.output)\n        \n    except Exception as e:\n        print(f\"Error: {e}\", file=sys.stderr)\n        sys.exit(1)\n\n# this will convert age and give us the difference\ndef human_readable_age(mtime: datetime) -> str:\n    delta = datetime.now() - mtime\n    days = delta.days\n    seconds = delta.seconds\n    if days > 0:\n        return f\"{days} day{'s' if days != 1 else ''} ago\"\n    elif seconds >= 3600:\n        hours = seconds // 3600\n        return f\"{hours} hour{'s' if hours != 1 else ''} ago\"\n    elif seconds >= 60:\n        minutes = seconds // 60\n        return f\"{minutes} minute{'s' if minutes != 1 else ''} ago\"\n    else:\n        return \"just now\"\n\nif __name__ == \"__main__\":\n    main()\n",
    "src/rcpack/config_loader.py": "# src/rcpack/config_loader.py\n\"\"\"\nTOML config loader for Repo-Contextor.\n\nRules:\n- Look for .repo-contextor.toml in the CURRENT directory\n- If missing: ignore\n- If present but invalid: print a clear error and exit(1)\n- Only recognized keys are applied; unknown keys ignored\n- Precedence: CLI > TOML > DEFAULTS\n\"\"\"\nfrom __future__ import annotations\nimport os, sys\nfrom typing import Dict, Iterable, Any\n\ntry:\n    import tomllib\n    _loads = tomllib.loads\nexcept ModuleNotFoundError:\n    try:\n        import tomli\n        _loads = tomli.loads\n    except ModuleNotFoundError:\n        _loads = None\n\ndef _need_toml():\n    if _loads is None:\n        print(\"Error: TOML parser not available. Use Python 3.11+ or `pip install tomli`.\", file=sys.stderr)\n        sys.exit(1)\n\ndef _load_toml(dotfile: str) -> Dict[str, Any]:\n    _need_toml()\n    if not os.path.exists(dotfile):\n        return {}\n    try:\n        with open(dotfile, \"rb\") as f:\n            raw = f.read().decode(\"utf-8\", errors=\"strict\")\n        data = _loads(raw)\n        return data if isinstance(data, dict) else {}\n    except Exception as e:\n        print(f\"Error: failed to parse {dotfile} as TOML.\\n{e}\", file=sys.stderr)\n        sys.exit(1)\n\ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\n    ks = set(known)\n    return {k: v for k, v in d.items() if k in ks}\n\ndef _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\n    ks = set(known)\n    out: Dict[str, Any] = {k: defaults.get(k) for k in ks}\n    for src in (filecfg, clicfg):\n        for k, v in src.items():\n            if k in ks and v is not None:\n                out[k] = v\n    return out\n\ndef load_config(*, dotfile: str = \".repo-contextor.toml\", defaults: Dict[str, Any] | None = None, cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ()) -> Dict[str, Any]:\n    defaults = defaults or {}\n    cli_cfg = cli_cfg or {}\n    known = tuple(known_keys)\n    filecfg = _filter_known(_load_toml(dotfile), known)\n    return _merge(defaults, filecfg, cli_cfg, known)\n",
    "src/rcpack/discover.py": "\"\"\"File discovery module for repository analysis.\"\"\"\n\nfrom pathlib import Path\nfrom typing import List\nimport fnmatch\n\n\ndef discover_files(\n    inputs: List[Path],\n    root: Path,\n    include_patterns: List[str],\n    exclude_patterns: List[str],\n) -> List[Path]:\n    \"\"\"Discover relevant files.\n\n    - inputs: list of files/dirs to scan\n    - root: common project root; patterns are matched against POSIX paths relative to root\n    - include_patterns: glob patterns to include (if empty, use sensible defaults)\n    - exclude_patterns: glob patterns to exclude\n    Returns a list of absolute Paths to files.\n    \"\"\"\n\n    default_include_exts = {\n        '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\n        '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\n        '.html', '.css', '.scss', '.sass', '.less', '.vue', '.svelte',\n        '.md', '.txt', '.rst', '.yaml', '.yml', '.json', '.toml', '.ini',\n        '.cfg', '.conf', '.xml', '.sql', '.sh', '.bash', '.zsh', '.fish',\n    }\n\n    always_include_names = {\n        'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING', 'Makefile',\n        'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\n        'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\n    }\n\n    skip_dir_names = {\n        '.git', '.svn', '.hg', '__pycache__', '.pytest_cache',\n        'node_modules', '.venv', 'venv', 'env', '.env',\n        'build', 'dist', 'target', 'out', '.next', '.nuxt',\n        '.idea', '.vscode', '.vs', 'coverage', '.coverage'\n    }\n\n    def matches_any(patterns: List[str], rel_posix: str) -> bool:\n        return any(fnmatch.fnmatch(rel_posix, pat) for pat in patterns)\n\n    def should_take(file_path: Path) -> bool:\n        rel_posix = file_path.relative_to(root).as_posix()\n        if exclude_patterns and matches_any(exclude_patterns, rel_posix):\n            return False\n        if include_patterns:\n            return matches_any(include_patterns, rel_posix)\n        # default include logic\n        return file_path.name in always_include_names or file_path.suffix.lower() in default_include_exts\n\n    discovered: list[Path] = []\n    seen = set()\n\n    for item in inputs:\n        p = item.resolve()\n        if p.is_file():\n            # Skip if excluded or in skipped directory\n            if any(part in skip_dir_names for part in p.parts):\n                continue\n            if should_take(p):\n                key = p.as_posix()\n                if key not in seen:\n                    seen.add(key)\n                    discovered.append(p)\n        elif p.is_dir():\n            for child in p.rglob('*'):\n                if not child.is_file():\n                    continue\n                if any(part in skip_dir_names for part in child.parts):\n                    continue\n                if should_take(child):\n                    key = child.resolve().as_posix()\n                    if key not in seen:\n                        seen.add(key)\n                        discovered.append(child.resolve())\n\n    return sorted(discovered)",
    "src/rcpack/gitinfo.py": "from __future__ import annotations\n\nimport subprocess\nfrom pathlib import Path\nfrom typing import Dict, Any\n\n\ndef _git(cmd: list[str], cwd: Path) -> str:\n    # Validate git commands to prevent injection\n    allowed_commands = {\n        \"rev-parse\", \"show\", \"log\", \"status\", \"branch\", \"config\"\n    }\n    if not cmd or cmd[0] not in allowed_commands:\n        raise ValueError(f\"Git command not allowed: {cmd[0] if cmd else 'empty'}\")\n    \n    out = subprocess.check_output([\"git\", *cmd], cwd=str(cwd), timeout=30)\n    return out.decode(\"utf-8\", errors=\"replace\").strip()\n\n\ndef is_git_repo(path: Path) -> bool:\n    try:\n        flag = _git([\"rev-parse\", \"--is-inside-work-tree\"], cwd=path)\n        return flag == \"true\"\n    except Exception:\n        return False\n\n\ndef get_git_info(path: Path) -> Dict[str, Any]:\n    \"\"\"\n    Return info for the current HEAD of a repo rooted at `path`.\n    \"\"\"\n    try:\n        commit = _git([\"rev-parse\", \"HEAD\"], cwd=path)\n        branch = _git([\"rev-parse\", \"--abbrev-ref\", \"HEAD\"], cwd=path)\n        author = _git([\"show\", \"-s\", \"--format=%an <%ae>\"], cwd=path)\n        date = _git([\"show\", \"-s\", \"--date=local\", \"--format=%ad\"], cwd=path)\n        return {\n            \"is_repo\": True,\n            \"commit\": commit,\n            \"branch\": branch,\n            \"author\": author,\n            \"date\": date,\n            \"note\": None,\n        }\n    except Exception:\n        # treat as not a repo if anything fails\n        return {\n            \"is_repo\": False,\n            \"commit\": None,\n            \"branch\": None,\n            \"author\": None,\n            \"date\": None,\n            \"note\": \"Not a git repository\",\n        }\n",
    "src/rcpack/io_utils.py": "\"\"\"I/O utilities for file operations.\"\"\"\n\nfrom pathlib import Path\nfrom typing import Tuple\n\n\ndef write_output(output_path: str, content: str) -> None:\n    \"\"\"Write content to output file.\"\"\"\n    output_file = Path(output_path)\n    \n    # Create parent directories if they don't exist\n    output_file.parent.mkdir(parents=True, exist_ok=True)\n    \n    # Write content\n    with open(output_file, 'w', encoding='utf-8') as f:\n        f.write(content)\n\n\ndef is_binary_file(path: Path, sniff_bytes: int = 2048) -> bool:\n    \"\"\"Heuristically determine if a file is binary by scanning for NUL bytes.\"\"\"\n    try:\n        with open(path, 'rb') as fb:\n            chunk = fb.read(sniff_bytes)\n        if b\"\\x00\" in chunk:\n            return True\n        # If the chunk has a lot of non-text bytes, consider it binary\n        text_byte_count = sum(32 <= b <= 126 or b in (9, 10, 13) for b in chunk)\n        return (len(chunk) - text_byte_count) > max(1, len(chunk) // 3)\n    except Exception:\n        # If we cannot read, treat as binary to avoid further processing\n        return True\n\n\ndef read_text_safely(path: Path, max_bytes: int = 16_384) -> Tuple[str, str, bool]:\n    \"\"\"Read a text file safely with size limit and encoding fallbacks.\n\n    Returns (content, encoding_used, truncated).\n    \"\"\"\n    truncated = False\n    raw: bytes\n    with open(path, 'rb') as fb:\n        raw = fb.read(max_bytes + 1)\n    if len(raw) > max_bytes:\n        truncated = True\n        raw = raw[:max_bytes]\n\n    for enc in (\"utf-8\", \"utf-16\", \"utf-16-le\", \"utf-16-be\", \"latin-1\"):\n        try:\n            text = raw.decode(enc)\n            return text, enc, truncated\n        except Exception:\n            continue\n    # Fallback: replace errors with utf-8\n    text = raw.decode(\"utf-8\", errors=\"replace\")\n    return text, \"utf-8\", truncated",
    "src/rcpack/packager.py": "from __future__ import annotations\n\nimport sys\nfrom pathlib import Path\nfrom typing import Iterable, Tuple\n\nfrom rcpack.discover import discover_files\nfrom rcpack.gitinfo import get_git_info, is_git_repo\nfrom rcpack.io_utils import read_text_safely, is_binary_file\nfrom rcpack.renderer import markdown as md_renderer\nfrom rcpack.renderer.jsonyaml import render_json, render_yaml\nfrom rcpack.treeview import render_tree\nfrom rcpack.utils import get_language_from_extension\n\n\ndef _find_root(inputs: list[str]) -> Path:\n    paths = [Path(p) for p in inputs]\n    if len(paths) == 1 and Path(paths[0]).is_dir():\n        return paths[0].resolve()\n    parents = [p if p.is_dir() else p.parent for p in paths]\n    root = Path(*Path.commonpath([str(p.resolve()) for p in parents]).split(\"/\"))\n    return root.resolve()\n\n\ndef build_package(\n    inputs: list[str],\n    include_patterns: list[str] | None,\n    exclude_patterns: list[str] | None,\n    max_file_bytes: int,\n    fmt: str = \"markdown\",\n) -> Tuple[str, dict]:\n    root = _find_root(inputs)\n    root_abs = root.resolve()\n\n    repo_info = (\n        get_git_info(root_abs) if is_git_repo(root_abs) else {\n            \"is_repo\": False,\n            \"commit\": None,\n            \"branch\": None,\n            \"author\": None,\n            \"date\": None,\n            \"note\": \"Not a git repository\",\n        }\n    )\n\n    files = discover_files(\n        inputs=[Path(p) for p in inputs],\n        root=root_abs,\n        include_patterns=include_patterns or [],\n        exclude_patterns=exclude_patterns or [],\n    )\n    rel_files = [f.relative_to(root_abs) for f in files]\n\n    project_tree = render_tree([p.as_posix() for p in rel_files])\n\n    file_sections: list[dict] = []\n    total_lines = 0\n    total_chars = 0\n\n    for f in files:\n        rel = f.relative_to(root_abs).as_posix()\n        try:\n            if is_binary_file(f):\n                content = f\"[binary file skipped: {f.name}, {f.stat().st_size} bytes]\"\n                file_sections.append({\n                    \"path\": rel,\n                    \"language\": get_language_from_extension(f.suffix),\n                    \"content\": content,\n                    \"is_truncated\": False,\n                })\n                total_chars += len(content)\n                continue\n\n            content, used_encoding, truncated = read_text_safely(f, max_bytes=max_file_bytes)\n            total_lines += content.count(\"\\n\") + (1 if content and not content.endswith(\"\\n\") else 0)\n            total_chars += len(content)\n\n            if truncated:\n                note = f\"\\n\\n[... TRUNCATED to first {max_file_bytes} bytes ...]\"\n                content = content + note\n                total_chars += len(note)\n\n            file_sections.append({\n                \"path\": rel,\n                \"language\": get_language_from_extension(f.suffix),\n                \"content\": content,\n                \"is_truncated\": truncated,\n            })\n        except Exception as exc:\n            print(f\"[rcpack] error reading {rel}: {exc}\", file=sys.stderr)\n            continue\n\n    # render in chosen format\n    if fmt == \"markdown\":\n        out_text = md_renderer.render_markdown(\n            root=str(root_abs),\n            repo_info=repo_info,\n            tree_text=project_tree,\n            files=file_sections,\n            total_files=len(file_sections),\n            total_lines=total_lines,\n        )\n    elif fmt == \"json\":\n        out_text = render_json(\n            root=str(root_abs),\n            repo_info=repo_info,\n            tree_text=project_tree,\n            files=file_sections,\n            total_files=len(file_sections),\n            total_lines=total_lines,\n        )\n    elif fmt == \"yaml\":\n        out_text = render_yaml(\n            root=str(root_abs),\n            repo_info=repo_info,\n            tree_text=project_tree,\n            files=file_sections,\n            total_files=len(file_sections),\n            total_lines=total_lines,\n        )\n    else:\n        raise ValueError(f\"Unsupported format: {fmt}\")\n\n    stats = {\"files\": len(file_sections), \"lines\": total_lines, \"chars\": total_chars}\n    return out_text, stats\n",
    "src/rcpack/renderer/jsonyaml.py": "from __future__ import annotations\nimport json\nfrom ..utils import build_repository_data\n\ntry:\n    import yaml\nexcept ImportError:\n    yaml = None\n\n\ndef render_json(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\n    data = build_repository_data(\n        root=root,\n        repo_info=repo_info,\n        tree_text=tree_text,\n        files=files,\n        total_files=total_files,\n        total_lines=total_lines,\n        recent_files=recent_files,\n        file_sizes=file_sizes\n    )\n    return json.dumps(data, indent=2, ensure_ascii=False)\n\n\ndef render_yaml(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\n    if yaml is None:\n        raise RuntimeError(\"PyYAML not installed; run `pip install pyyaml`\")\n    data = build_repository_data(\n        root=root,\n        repo_info=repo_info,\n        tree_text=tree_text,\n        files=files,\n        total_files=total_files,\n        total_lines=total_lines,\n        recent_files=recent_files,\n        file_sizes=file_sizes\n    )\n    return yaml.safe_dump(data, sort_keys=False, allow_unicode=True)\n",
    "src/rcpack/renderer/markdown.py": "\"\"\"Markdown renderer for repository context.\"\"\"\n\nfrom typing import Dict, Any\nfrom ..utils import get_language_from_extension\n\n\ndef render_markdown(root: str, repo_info: Dict[str, Any], tree_text: str, \n                   files: Dict[str, str], total_files: int, total_lines: int, recent_files=None, file_sizes=None) -> str:\n    \"\"\"Render repository context as markdown.\"\"\"\n    \n    lines = []\n    \n    # Header\n    lines.append(f\"# Repository Context: {root}\")\n    lines.append(\"\")\n    \n    # Repository info\n    if repo_info.get(\"is_repo\"):\n        lines.append(\"## Git Repository Information\")\n        lines.append(f\"- **Branch**: {repo_info.get('branch', 'N/A')}\")\n        lines.append(f\"- **Commit**: {repo_info.get('commit', 'N/A')}\")\n        lines.append(f\"- **Author**: {repo_info.get('author', 'N/A')}\")\n        lines.append(f\"- **Date**: {repo_info.get('date', 'N/A')}\")\n    else:\n        lines.append(\"## Repository Information\")\n        lines.append(f\"- **Note**: {repo_info.get('note', 'Not a git repository')}\")\n    lines.append(\"\")\n    \n    # Summary\n    lines.append(\"## Summary\")\n    lines.append(f\"- **Total Files**: {total_files}\")\n    lines.append(f\"- **Total Lines**: {total_lines}\")\n    lines.append(\"\")\n    \n    # Directory structure\n    lines.append(\"## Directory Structure\")\n    lines.append(\"```\")\n    lines.append(tree_text)\n    lines.append(\"```\")\n    lines.append(\"\")\n\n    # will produce recent files \n    # Recent files (fixed)\n    if recent_files:\n        lines.append(\"## Recent Changes\")\n        for file, age in recent_files.items():\n            lines.append(f\"- {file} (modified {age})\")\n        lines.append(\"\")\n    \n    # File contents\n    lines.append(\"## File Contents\")\n    lines.append(\"\")\n    \n    for file_path, content in sorted(files.items()):\n        if file_sizes and file_path in file_sizes:\n            size_bytes = file_sizes[file_path]\n            lines.append(f\"### {file_path} ({size_bytes} bytes)\")\n        else:\n            lines.append(f\"### {file_path}\")\n        lines.append(\"\")\n        \n        # Detect language for syntax highlighting\n        language = get_language_from_extension(file_path)\n        \n        lines.append(f\"```{language}\")\n        lines.append(content)\n        lines.append(\"```\")\n        lines.append(\"\")\n    \n    return \"\\n\".join(lines)\n",
    "src/rcpack/treeview.py": "\"\"\"Tree view generation for repository structure.\"\"\"\n\nfrom pathlib import Path\nfrom typing import Dict, List\n\n\ndef create_tree_view(repo_path: Path, files_data: Dict[str, str]) -> str:\n    \"\"\"Create a tree view of the repository structure.\"\"\"\n    paths = list(files_data.keys())\n    return render_tree(paths)\n\n\ndef render_tree(paths: List[str]) -> str:\n    \"\"\"Render a tree view from a list of relative POSIX paths.\"\"\"\n    tree_structure: dict = {}\n\n    for p in paths:\n        parts = Path(p).parts\n        current = tree_structure\n        for part in parts[:-1]:\n            if part not in current:\n                current[part] = {}\n            current = current[part]\n        if parts:\n            current[parts[-1]] = None\n\n    def _render(structure: dict, prefix: str = \"\") -> str:\n        lines = []\n        items = sorted(structure.items(), key=lambda x: (x[1] is None, x[0]))\n        for i, (name, subtree) in enumerate(items):\n            is_last = i == len(items) - 1\n            lines.append(f\"{prefix}{'└── ' if is_last else '├── '}{name}\")\n            if subtree is not None:\n                extension = (\"    \" if is_last else \"│   \")\n                lines.append(_render(subtree, prefix + extension))\n        return \"\\n\".join(filter(None, lines))\n\n    if not tree_structure:\n        return \"No files found\"\n    return _render(tree_structure)",
    "src/rcpack/utils.py": "\"\"\"Utility functions shared across the rcpack package.\"\"\"\n\nfrom typing import Dict, Any, Optional\n\n\ndef get_language_from_extension(file_path_or_ext: str) -> str:\n    \"\"\"Get the language identifier for syntax highlighting from a file path or extension.\n    \n    Args:\n        file_path_or_ext: Either a file path (e.g., 'src/main.py') or extension (e.g., '.py' or 'py')\n    \n    Returns:\n        Language identifier for syntax highlighting (e.g., 'python', 'javascript')\n    \"\"\"\n    # Extract extension from file path if needed\n    if '.' in file_path_or_ext and not file_path_or_ext.startswith('.'):\n        # It's a file path, extract the extension\n        ext = file_path_or_ext.split('.')[-1].lower()\n    else:\n        # It's already an extension, clean it up\n        ext = file_path_or_ext.lower().lstrip(\".\")\n    \n    # Comprehensive language mapping combining both existing mappings\n    language_map = {\n        'py': 'python', 'js': 'javascript', 'ts': 'typescript',\n        'jsx': 'javascript', 'tsx': 'typescript',\n        'java': 'java', 'cpp': 'cpp', 'c': 'c', 'h': 'c',\n        'cs': 'csharp', 'php': 'php', 'rb': 'ruby',\n        'go': 'go', 'rs': 'rust', 'swift': 'swift', 'kt': 'kotlin',\n        'html': 'html', 'css': 'css', 'scss': 'scss', 'sass': 'sass',\n        'json': 'json', 'yaml': 'yaml', 'yml': 'yaml',\n        'toml': 'toml', 'xml': 'xml', 'sql': 'sql', 'sh': 'bash',\n        'bash': 'bash', 'zsh': 'bash', 'fish': 'fish',\n        'md': 'markdown', 'txt': 'text',\n        'dockerfile': 'dockerfile', 'makefile': 'makefile'\n    }\n    \n    return language_map.get(ext, '')\n\n\ndef build_repository_data(\n    root: str,\n    repo_info: Dict[str, Any],\n    tree_text: str,\n    files: Dict[str, str],\n    total_files: int,\n    total_lines: int,\n    recent_files: Optional[Dict[str, str]] = None,\n    file_sizes: Optional[Dict[str, str]] = None\n) -> Dict[str, Any]:\n    \"\"\"Build the standard repository data structure used by all renderers.\n    \n    Args:\n        root: Repository root path\n        repo_info: Git repository information\n        tree_text: Directory tree text representation\n        files: Dictionary of file paths to content\n        total_files: Total number of files\n        total_lines: Total number of lines\n        recent_files: Optional dict of recently modified files\n        file_sizes: Optional dict of file sizes\n        \n    Returns:\n        Standardized data dictionary for rendering\n    \"\"\"\n    return {\n        \"root\": root,\n        \"repo_info\": repo_info,\n        \"structure\": tree_text,\n        \"recent_changes\": recent_files or {},\n        \"files\": files,\n        \"file_sizes\": file_sizes or {},\n        \"summary\": {\"total_files\": total_files, \"total_lines\": total_lines},\n    }\n\n\ndef calculate_total_lines(content_dict: Dict[str, str]) -> int:\n    \"\"\"Calculate the total number of lines from a dictionary of file contents.\n    \n    Args:\n        content_dict: Dictionary mapping file paths to their content\n        \n    Returns:\n        Total number of lines across all files\n    \"\"\"\n    return sum(len(content.splitlines()) for content in content_dict.values())\n\n\ndef calculate_total_characters(content_dict: Dict[str, str]) -> int:\n    \"\"\"Calculate the total number of characters from a dictionary of file contents.\n    \n    Args:\n        content_dict: Dictionary mapping file paths to their content\n        \n    Returns:\n        Total number of characters across all files\n    \"\"\"\n    return sum(len(content) for content in content_dict.values())",
    "test-output.json": "{\n  \"root\": \"/Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\",\n  \"repo_info\": {\n    \"is_repo\": true,\n    \"commit\": \"682153b169db66d3a72e9cabdd1f3448a3b2986d\",\n    \"branch\": \"refactoring\",\n    \"author\": \"Abhinav <abhinavbhardwaj2002@gmail.com>\",\n    \"date\": \"Fri Oct 3 18:45:48 2025\",\n    \"note\": null\n  },\n  \"structure\": \"├── src\\n│   └── rcpack\\n│       ├── renderer\\n│       │   ├── jsonyaml.py\\n│       │   └── markdown.py\\n│       ├── __init__.py\\n│       ├── __main__.py\\n│       ├── cli.py\\n│       ├── config_loader.py\\n│       ├── discover.py\\n│       ├── gitinfo.py\\n│       ├── io_utils.py\\n│       ├── packager.py\\n│       └── treeview.py\\n├── LICENSE\\n├── README.md\\n└── pyproject.toml\",\n  \"recent_changes\": [],\n  \"files\": {\n    \"LICENSE\": \"MIT License\\n\\nCopyright (c) 2025 Abhinav\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \\\"Software\\\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \\\"AS IS\\\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n\",\n    \"README.md\": \"# Repo-Contextor\\n\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\n\\nA powerful Repository Context Packager CLI tool that analyzes local git repositories and creates comprehensive text files containing repository content optimized for sharing with Large Language Models (LLMs).\\n\\n## Overview\\n\\nWhen developers want to get help from ChatGPT, Claude, or other LLMs about their code, they often struggle with how to share their codebase effectively. Common problems include:\\n\\n- **Lost Context**: Copy-pasting individual files loses important project structure and relationships\\n- **Missing Dependencies**: LLMs can't see how files connect or what libraries are used\\n- **Incomplete Picture**: Hard to convey the overall architecture and organization\\n- **Manual Work**: Time-consuming to gather and format relevant code\\n\\n**Repo-Contextor** solves this by automatically collecting and formatting repository content into a single, well-structured text file that provides rich context to LLMs, enabling them to give much better assistance with your code.\\n\\n## Features\\n\\n- **Git Integration**: Extracts commit SHA, branch, author, and date information\\n- **Project Structure**: Generates a clear directory tree visualization\\n- **File Content Packaging**: Includes file contents with syntax highlighting\\n- **Smart File Discovery**: Recursively scans directories with intelligent filtering\\n- **Binary File Detection**: Automatically skips binary files\\n- **Error Handling**: Gracefully handles permission errors and provides helpful messages\\n- **Multiple Output Formats**: Supports Markdown, JSON, and YAML formats\\n- **Flexible Output**: Write to stdout or save to a file\\n- **Recent Changes Filter**: Give the files which are updated in last 7days with the time when it was recently modified.\\n\\n## Installation\\n\\n### Prerequisites\\n\\n- Python 3.9 or higher\\n- Git (for git repository analysis)\\n\\n### For End Users\\n\\n```bash\\n# Clone and install\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\ncd Repo-Contextor\\npip install -e .\\n```\\n\\n### For Contributors & Local Development\\n\\n```bash\\n# Clone the repository\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\ncd Repo-Contextor\\n\\n# Create virtual environment\\npython -m venv .venv\\nsource .venv/bin/activate  # On Windows: .venv\\\\Scripts\\\\activate\\n\\n# Install in development mode\\npip install -e .\\n```\\n\\n## Usage\\n\\n### Basic Examples\\n\\n```bash\\n# Package current directory to terminal\\nrepo-contextor .\\n\\n# Package a specific directory\\nrepo-contextor /path/to/your/project\\n\\n# Save output to a file\\nrepo-contextor . -o my-project-context.md\\n\\n# Generate JSON format\\nrepo-contextor . -f json -o context.json\\n\\n# Generate YAML format\\nrepo-contextor . -f yaml -o context.yaml\\n\\n# Include only files modified in the last 7 days\\nrepo-contextor . --recent\\n\\n# Combine with output file\\nrepo-contextor . --recent -o recent-changes.md\\n```\\n\\n### Command Line Options\\n\\n| Option | Short | Description | Example |\\n|--------|-------|-------------|---------|\\n| `path` | - | Repository path to analyze (default: current directory) | `repo-contextor /path/to/project` |\\n| `--output` | `-o` | Output file path (default: stdout) | `-o context.md` |\\n| `--format` | `-f` | Output format: text, json, yaml (default: text) | `-f json` |\\n| `--help` | `-h` | Show help message | `-h` |\\n| `--recent`  | `-r`  | Include only files modified in the last 7 days    | `repo-contextor . -r -o recent.md` |\\n\\n### Advanced Examples\\n\\n```bash\\n# Analyze different repository\\nrepo-contextor /path/to/other/project -o other-project.md\\n\\n# Generate JSON for API consumption\\nrepo-contextor . -f json -o api-context.json\\n\\n# Create YAML configuration\\nrepo-contextor . -f yaml -o project-config.yaml\\n\\n# Generate files which are changed recently in 7 days\\nrepo-contextor . -r --output recent-changes.txt\\n\\n```\\n## Configuration via TOML\\n\\nRepo-Contextor supports configuration through a `.repo-contextor.toml` file in the current working directory.  \\nThis file allows you to avoid typing the same CLI arguments every time.\\n\\nExample `.repo-contextor.toml`:\\n\\n```toml\\n# Output file to write results\\noutput = \\\"context.yaml\\\"\\n\\n# Output format: text, json, or yaml\\nformat = \\\"yaml\\\"\\n\\n# Limit to files modified in the last 7 days\\nrecent = true\\n\\n# Repository path to analyze (default = current directory)\\npath = \\\".\\\"\\n```\\n### Rules\\n- If the `.repo-contextor.toml` file is **missing**, the tool falls back to defaults.  \\n- If the file is **present but invalid TOML**, the tool prints a clear error message and exits with status code 1.  \\n- **Unknown keys** in the TOML file are ignored (safe for future extensions).  \\n- **Precedence** of settings is:\\n  1. Command-line arguments (highest priority)  \\n  2. Values from `.repo-contextor.toml`  \\n  3. Built-in defaults (lowest priority)\\n     \\n## Output Format\\n\\nThe tool generates a structured text file with the following sections:\\n\\n### 1. Repository Context Header\\nProject path and identification\\n\\n### 2. Git Repository Information\\n- Current branch\\n- Latest commit SHA\\n- Last commit author\\n- Last commit date\\n\\n### 3. Summary Statistics\\n- Total number of files processed\\n- Total lines of code\\n\\n### 4. Directory Structure\\nClean tree visualization showing project organization\\n\\n### 5. Recent Changes (if `--recent` is used)\\n\\n- Lists files modified in the last 7 days.\\n- Shows relative file paths along with how long ago each file was modified\\n- Helps focus on recently updated parts of the project.\\n- Can be combined with `--output` or `--format` to save or change the output type.\\n\\n\\n### 5. File Contents\\nEach file's content with:\\n- Clear file path headers\\n- Appropriate syntax highlighting language tags\\n- Complete file contents\\n\\n## Example Output\\n\\nWhen you run `repo-contextor .`, the output looks like this:\\n\\n````markdown\\n# Repository Context: /path/to/your/project\\n\\n## Git Repository Information\\n- **Branch**: main\\n- **Commit**: a1b2c3d4e5f6789...\\n- **Author**: John Doe <john@example.com>\\n- **Date**: Fri Sep 12 14:30:15 2025\\n\\n## Summary\\n- **Total Files**: 15\\n- **Total Lines**: 1,247\\n\\n## Directory Structure\\n```\\n├── src/\\n│   ├── main.py\\n│   └── utils.py\\n├── tests/\\n│   └── test_main.py\\n├── README.md\\n└── requirements.txt\\n```\\n## Recent Changes\\n- src/main.py (modified 2 days ago)\\n- src/utils/helpers.py (modified 5 days ago)\\n\\n## File Contents\\n\\n### src/main.py\\n\\n```python\\ndef main():\\n    print(\\\"Hello, World!\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n```\\n\\n### README.md\\n\\n```markdown\\n# My Project\\nThis is a sample project.\\n```\\n\\n## Summary\\n- Total files: 15\\n- Total lines: 1,247\\n````\\n\\n## What Files Are Included\\n\\nThe tool includes most text files but automatically excludes:\\n\\n### Excluded Directories\\n- `.git`, `.svn`, `.hg` (version control)\\n- `__pycache__`, `.pytest_cache` (Python cache)\\n- `node_modules`, `.venv`, `venv` (dependencies/environments)\\n- `.vscode`, `.idea` (IDE directories)\\n- `build`, `dist`, `target` (build directories)\\n\\n### File Handling Rules\\n- **Text files**: All readable text files with common extensions\\n- **Binary files**: Automatically detected and skipped\\n- **Permission errors**: Skipped with graceful handling\\n- **Configuration files**: Includes pyproject.toml, package.json, etc.\\n\\n### Included File Types\\n- Source code: `.py`, `.js`, `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\n- Web files: `.html`, `.css`, `.scss`, `.vue`, `.jsx`, etc.\\n- Documentation: `.md`, `.txt`, `.rst`\\n- Configuration: `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\n- Scripts: `.sh`, `.bash`, `.zsh`\\n\\n## Error Handling\\n\\nThe tool handles errors gracefully:\\n\\n| Error Type | Behavior |\\n|------------|----------|\\n| **Permission errors** | Skipped with warning |\\n| **Binary files** | Automatically detected and skipped |\\n| **Invalid paths** | Clear error messages |\\n| **Non-git repositories** | Works fine, shows \\\"Not a git repository\\\" |\\n| **Unreadable files** | Marked as \\\"[Binary or unreadable file]\\\" |\\n\\n## Development\\n\\n### Project Structure\\n\\n```text\\nRepo-Contextor/\\n├── src/rcpack/              # Main package\\n│   ├── __init__.py         # Package initialization\\n│   ├── cli.py              # Command-line interface\\n│   ├── discover.py         # File discovery logic\\n│   ├── gitinfo.py          # Git repository analysis\\n│   ├── treeview.py         # Directory tree generation\\n│   ├── packager.py         # Main orchestration\\n│   ├── io_utils.py         # File I/O utilities\\n│   └── renderer/           # Output formatters\\n│       ├── markdown.py     # Markdown renderer\\n│       └── jsonyaml.py     # JSON/YAML renderers\\n├── pyproject.toml          # Project configuration\\n├── LICENSE                 # MIT License\\n└── README.md              # This documentation\\n```\\n\\n### Running Tests\\n\\n```bash\\n# Test on current repository\\nrepo-contextor . -o test-output.md\\n\\n# Test different formats\\nrepo-contextor . -f json | head -20\\nrepo-contextor . -f yaml | head -20\\n\\n# Test specific directory\\nrepo-contextor src/ -o src-only.md\\n```\\n\\n### Contributing\\n\\n1. **Fork the repository**\\n2. **Clone your fork:**\\n   ```bash\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\n   cd Repo-Contextor\\n   ```\\n3. **Install for development:**\\n   ```bash\\n   python -m venv .venv\\n   source .venv/bin/activate\\n   pip install -e .\\n   ```\\n4. **Make your changes and test:**\\n   ```bash\\n   repo-contextor . -o test.md\\n   ```\\n5. **Submit a pull request**\\n\\n### Development Workflow\\n\\n```bash\\n# 1. Setup development environment\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\ncd Repo-Contextor\\npython -m venv .venv\\nsource .venv/bin/activate\\npip install -e .\\n\\n# 2. Make changes to the code\\n# Edit files in src/rcpack/\\n\\n# 3. Test your changes\\nrepo-contextor . -o test-output.md\\n\\n# 4. Test different formats\\nrepo-contextor . -f json -o test.json\\nrepo-contextor . -f yaml -o test.yaml\\n\\n# 5. Commit and push changes\\ngit add .\\ngit commit -m \\\"Add new feature\\\"\\ngit push origin feature-branch\\n```\\n\\n## License\\n\\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\\n\\n## Why Repo-Contextor?\\n\\nThe name \\\"Repo-Contextor\\\" combines \\\"Repository\\\" + \\\"Context\\\" + \\\"or\\\", representing the tool's purpose of providing rich context about code repositories in a format that's perfect for LLM interactions.\\n\\n### Use Cases\\n\\n- **AI Assistance**: Get better help from ChatGPT, Claude, or GitHub Copilot\\n- **Code Reviews**: Share complete project context with team members\\n- **Documentation**: Create comprehensive project snapshots\\n- **Onboarding**: Help new team members understand project structure\\n- **Project Analysis**: Understand repository structure and dependencies\\n\\n### Perfect for LLMs\\n\\nThe output format is specifically designed to work well with Large Language Models:\\n- Clear section headers for easy parsing\\n- Syntax highlighting markers for code blocks\\n- Structured metadata (git info, file locations)\\n- Complete project context in a single file\\n- Multiple output formats (Markdown, JSON, YAML)\\n- Optimized for token efficiency\\n\",\n    \"pyproject.toml\": \"[build-system]\\nrequires = [\\\"setuptools>=68\\\", \\\"wheel\\\"]\\nbuild-backend = \\\"setuptools.build_meta\\\"\\n\\n[project]\\nname = \\\"rcpack\\\"\\nversion = \\\"0.1.0\\\"\\ndescription = \\\"Repository Context Packager CLI for LLMs\\\"\\nreadme = \\\"README.md\\\"\\nrequires-python = \\\">=3.9\\\"\\nlicense = { text = \\\"MIT\\\" }\\ndependencies = [\\n    \\\"PyYAML>=6.0\\\"\\n]\\n\\n[project.scripts]\\nrepo-contextor = \\\"rcpack.cli:main\\\"\\n\",\n    \"src/rcpack/__init__.py\": \"\\\"\\\"\\\"Repository Context Packager - CLI tool for creating LLM-optimized repository context.\\\"\\\"\\\"\\n\\n__version__ = \\\"0.1.0\\\"\\n__author__ = \\\"Abhinav\\\"\\n__description__ = \\\"Repository Context Packager CLI for LLMs\\\"\",\n    \"src/rcpack/__main__.py\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"Module entry point to enable `python -m rcpack`.\\n\\nThis simply delegates to the CLI's main() function.\\n\\\"\\\"\\\"\\n\\nfrom .cli import main\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\\n\\n\",\n    \"src/rcpack/cli.py\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"CLI for Repository Context Packager.\\\"\\\"\\\"\\n\\nfrom .config_loader import load_config\\n\\nimport argparse\\nimport sys\\nfrom pathlib import Path\\nfrom .gitinfo import get_git_info\\nfrom .discover import discover_files\\nfrom .treeview import create_tree_view\\nfrom .renderer.markdown import render_markdown\\nfrom .renderer.jsonyaml import render_json, render_yaml\\nfrom .io_utils import write_output\\nfrom datetime import datetime, timedelta\\n\\n\\ndef log_verbose(message: str, verbose: bool) -> None:\\n    \\\"\\\"\\\"Log a message to stderr if verbose mode is enabled.\\\"\\\"\\\"\\n    if verbose:\\n        print(message, file=sys.stderr)\\n\\n\\ndef get_rendered_content(format_type: str, repo_path: str, repo_info: dict, tree_text: str, \\n                        files_data: dict, total_files: int, total_lines: int, \\n                        recent_files_info: dict, file_sizes: dict) -> str:\\n    \\\"\\\"\\\"Get rendered content based on the specified format.\\\"\\\"\\\"\\n    if format_type == \\\"json\\\":\\n        return render_json(\\n            repo_path, repo_info, tree_text, \\n            files_data, total_files, total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n        )\\n    elif format_type == \\\"yaml\\\":\\n        return render_yaml(\\n            repo_path, repo_info, tree_text, \\n            files_data, total_files, total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n        )\\n    else:  # text/markdown\\n        return render_markdown(\\n            repo_path, repo_info, tree_text, \\n            files_data, total_files, total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n        )\\n\\n\\ndef process_file(file_path: Path, repo_path: Path, verbose: bool) -> tuple[str, str, str]:\\n    \\\"\\\"\\\"Process a single file and return its data.\\n    \\n    Returns:\\n        tuple: (relative_path_str, content, file_size)\\n    \\\"\\\"\\\"\\n    relative_path = file_path.relative_to(repo_path)\\n    relative_path_str = str(relative_path)\\n    \\n    log_verbose(f\\\"Reading file: {relative_path}\\\", verbose)\\n    file_size = file_path.stat().st_size\\n    \\n    try:\\n        with open(file_path, 'r', encoding='utf-8') as f:\\n            content = f.read()\\n        return relative_path_str, content, str(file_size)\\n    except (UnicodeDecodeError, PermissionError):\\n        log_verbose(f\\\"Skipping binary/unreadable file: {relative_path}\\\", verbose)\\n        file_size = file_path.stat().st_size if file_path.exists() else 0\\n        content = f\\\"[Binary or unreadable file: {file_path.name}]\\\"\\n        return relative_path_str, content, str(file_size)\\n    except Exception:\\n        log_verbose(f\\\"Error reading file: {relative_path}\\\", verbose)\\n        raise  # Re-raise to handle in calling code\\n\\n\\ndef handle_output(content: str, output_path: str = None) -> None:\\n    \\\"\\\"\\\"Handle output to either file or stdout.\\\"\\\"\\\"\\n    if output_path:\\n        # Write to file\\n        write_output(output_path, content)\\n        print(f\\\"Context package created: {output_path}\\\")\\n    else:\\n        # Output to stdout\\n        print(content)\\n\\n\\ndef main():\\n    parser = argparse.ArgumentParser(\\n        description=\\\"Package repository content for LLM context\\\"\\n    )\\n    parser.add_argument(\\n        \\\"path\\\", \\n        nargs=\\\"?\\\", \\n        default=\\\".\\\", \\n        help=\\\"Repository path (default: current directory)\\\"\\n    )\\n    parser.add_argument(\\n        \\\"-o\\\", \\\"--output\\\", \\n        help=\\\"Output file path (default: stdout)\\\"\\n    )\\n    parser.add_argument(\\n        \\\"-f\\\", \\\"--format\\\", \\n        choices=[\\\"text\\\", \\\"json\\\", \\\"yaml\\\"], \\n        default=\\\"text\\\",\\n        help=\\\"Output format (default: text)\\\"\\n    )\\n\\n    \\\"\\\"\\\" This will read -r from the console and able to search it with this\\\"\\\"\\\"\\n    parser.add_argument(\\n    \\\"-r\\\", \\\"--recent\\\",\\n    action=\\\"store_true\\\",\\n    help=\\\"Include only files modified in the last 7 days\\\"\\n    )\\n    parser.add_argument(\\n        \\\"-v\\\", \\\"--verbose\\\",\\n        action=\\\"store_true\\\",\\n        help=\\\"Print detailed progress information to stderr\\\"\\n    )\\n    \\n    args = parser.parse_args()\\n    \\n    try:\\n        repo_path = Path(args.path).resolve()\\n        if not repo_path.exists():\\n            print(f\\\"Error: Path {repo_path} does not exist\\\", file=sys.stderr)\\n            sys.exit(1)\\n            \\n        # Get repository information\\n        log_verbose(f\\\"Analyzing repository: {repo_path}\\\", args.verbose)\\n        repo_info = get_git_info(repo_path)\\n        \\n        # Discover files\\n        log_verbose(f\\\"Discovering files in: {repo_path}\\\", args.verbose)\\n        discovered_files = discover_files([repo_path], repo_path, [], [])\\n        log_verbose(f\\\"Found {len(discovered_files)} files\\\", args.verbose)\\n        \\n        # will check the file in last 7 days\\n        recent_files_info = {}\\n        if args.recent:\\n            seven_days_ago = datetime.now() - timedelta(days=7)\\n            recent_files = []\\n            for f in discovered_files:\\n                try:\\n                    mtime = datetime.fromtimestamp(f.stat().st_mtime)\\n                    if mtime >= seven_days_ago:\\n                        recent_files.append(f)\\n                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)     \\n                except Exception:\\n                    continue\\n            discovered_files = recent_files\\n        \\n        # Read file contents\\n        files_data = {}\\n        file_sizes = {}\\n        for file_path in discovered_files:\\n            try:\\n                relative_path_str, content, file_size = process_file(file_path, repo_path, args.verbose)\\n                files_data[relative_path_str] = content\\n                file_sizes[relative_path_str] = file_size\\n            except Exception:\\n                continue\\n        \\n        # Create tree view\\n        log_verbose(\\\"Generating directory tree\\\", args.verbose)\\n        tree_text = create_tree_view(repo_path, files_data)\\n        \\n        # Count totals\\n        total_files = len(files_data)\\n        total_lines = sum(len(content.splitlines()) for _, content in files_data.items())\\n        \\n        # Render based on format\\n        log_verbose(f\\\"Rendering output in {args.format} format\\\", args.verbose)\\n        content = get_rendered_content(\\n            args.format, str(repo_path), repo_info, tree_text,\\n            files_data, total_files, total_lines,\\n            recent_files_info if args.recent else {},\\n            file_sizes\\n        )\\n        \\n        handle_output(content, args.output)\\n        \\n    except Exception as e:\\n        print(f\\\"Error: {e}\\\", file=sys.stderr)\\n        sys.exit(1)\\n\\n# this will convert age and give us the difference\\ndef human_readable_age(mtime: datetime) -> str:\\n    delta = datetime.now() - mtime\\n    days = delta.days\\n    seconds = delta.seconds\\n    if days > 0:\\n        return f\\\"{days} day{'s' if days != 1 else ''} ago\\\"\\n    elif seconds >= 3600:\\n        hours = seconds // 3600\\n        return f\\\"{hours} hour{'s' if hours != 1 else ''} ago\\\"\\n    elif seconds >= 60:\\n        minutes = seconds // 60\\n        return f\\\"{minutes} minute{'s' if minutes != 1 else ''} ago\\\"\\n    else:\\n        return \\\"just now\\\"\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\",\n    \"src/rcpack/config_loader.py\": \"# src/rcpack/config_loader.py\\n\\\"\\\"\\\"\\nTOML config loader for Repo-Contextor.\\n\\nRules:\\n- Look for .repo-contextor.toml in the CURRENT directory\\n- If missing: ignore\\n- If present but invalid: print a clear error and exit(1)\\n- Only recognized keys are applied; unknown keys ignored\\n- Precedence: CLI > TOML > DEFAULTS\\n\\\"\\\"\\\"\\nfrom __future__ import annotations\\nimport os, sys\\nfrom typing import Dict, Iterable, Any\\n\\ntry:\\n    import tomllib\\n    _loads = tomllib.loads\\nexcept ModuleNotFoundError:\\n    try:\\n        import tomli\\n        _loads = tomli.loads\\n    except ModuleNotFoundError:\\n        _loads = None\\n\\ndef _need_toml():\\n    if _loads is None:\\n        print(\\\"Error: TOML parser not available. Use Python 3.11+ or `pip install tomli`.\\\", file=sys.stderr)\\n        sys.exit(1)\\n\\ndef _load_toml(dotfile: str) -> Dict[str, Any]:\\n    _need_toml()\\n    if not os.path.exists(dotfile):\\n        return {}\\n    try:\\n        with open(dotfile, \\\"rb\\\") as f:\\n            raw = f.read().decode(\\\"utf-8\\\", errors=\\\"strict\\\")\\n        data = _loads(raw)\\n        return data if isinstance(data, dict) else {}\\n    except Exception as e:\\n        print(f\\\"Error: failed to parse {dotfile} as TOML.\\\\n{e}\\\", file=sys.stderr)\\n        sys.exit(1)\\n\\ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\n    ks = set(known)\\n    return {k: v for k, v in d.items() if k in ks}\\n\\ndef _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\n    ks = set(known)\\n    out: Dict[str, Any] = {k: defaults.get(k) for k in ks}\\n    for src in (filecfg, clicfg):\\n        for k, v in src.items():\\n            if k in ks and v is not None:\\n                out[k] = v\\n    return out\\n\\ndef load_config(*, dotfile: str = \\\".repo-contextor.toml\\\", defaults: Dict[str, Any] | None = None, cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ()) -> Dict[str, Any]:\\n    defaults = defaults or {}\\n    cli_cfg = cli_cfg or {}\\n    known = tuple(known_keys)\\n    filecfg = _filter_known(_load_toml(dotfile), known)\\n    return _merge(defaults, filecfg, cli_cfg, known)\\n\",\n    \"src/rcpack/discover.py\": \"\\\"\\\"\\\"File discovery module for repository analysis.\\\"\\\"\\\"\\n\\nfrom pathlib import Path\\nfrom typing import List\\nimport fnmatch\\n\\n\\ndef discover_files(\\n    inputs: List[Path],\\n    root: Path,\\n    include_patterns: List[str],\\n    exclude_patterns: List[str],\\n) -> List[Path]:\\n    \\\"\\\"\\\"Discover relevant files.\\n\\n    - inputs: list of files/dirs to scan\\n    - root: common project root; patterns are matched against POSIX paths relative to root\\n    - include_patterns: glob patterns to include (if empty, use sensible defaults)\\n    - exclude_patterns: glob patterns to exclude\\n    Returns a list of absolute Paths to files.\\n    \\\"\\\"\\\"\\n\\n    default_include_exts = {\\n        '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\\n        '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\n        '.html', '.css', '.scss', '.sass', '.less', '.vue', '.svelte',\\n        '.md', '.txt', '.rst', '.yaml', '.yml', '.json', '.toml', '.ini',\\n        '.cfg', '.conf', '.xml', '.sql', '.sh', '.bash', '.zsh', '.fish',\\n    }\\n\\n    always_include_names = {\\n        'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING', 'Makefile',\\n        'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\\n        'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\n    }\\n\\n    skip_dir_names = {\\n        '.git', '.svn', '.hg', '__pycache__', '.pytest_cache',\\n        'node_modules', '.venv', 'venv', 'env', '.env',\\n        'build', 'dist', 'target', 'out', '.next', '.nuxt',\\n        '.idea', '.vscode', '.vs', 'coverage', '.coverage'\\n    }\\n\\n    def matches_any(patterns: List[str], rel_posix: str) -> bool:\\n        return any(fnmatch.fnmatch(rel_posix, pat) for pat in patterns)\\n\\n    def should_take(file_path: Path) -> bool:\\n        rel_posix = file_path.relative_to(root).as_posix()\\n        if exclude_patterns and matches_any(exclude_patterns, rel_posix):\\n            return False\\n        if include_patterns:\\n            return matches_any(include_patterns, rel_posix)\\n        # default include logic\\n        return file_path.name in always_include_names or file_path.suffix.lower() in default_include_exts\\n\\n    discovered: list[Path] = []\\n    seen = set()\\n\\n    for item in inputs:\\n        p = item.resolve()\\n        if p.is_file():\\n            # Skip if excluded or in skipped directory\\n            if any(part in skip_dir_names for part in p.parts):\\n                continue\\n            if should_take(p):\\n                key = p.as_posix()\\n                if key not in seen:\\n                    seen.add(key)\\n                    discovered.append(p)\\n        elif p.is_dir():\\n            for child in p.rglob('*'):\\n                if not child.is_file():\\n                    continue\\n                if any(part in skip_dir_names for part in child.parts):\\n                    continue\\n                if should_take(child):\\n                    key = child.resolve().as_posix()\\n                    if key not in seen:\\n                        seen.add(key)\\n                        discovered.append(child.resolve())\\n\\n    return sorted(discovered)\",\n    \"src/rcpack/gitinfo.py\": \"from __future__ import annotations\\n\\nimport subprocess\\nfrom pathlib import Path\\nfrom typing import Dict, Any\\n\\n\\ndef _git(cmd: list[str], cwd: Path) -> str:\\n    # Validate git commands to prevent injection\\n    allowed_commands = {\\n        \\\"rev-parse\\\", \\\"show\\\", \\\"log\\\", \\\"status\\\", \\\"branch\\\", \\\"config\\\"\\n    }\\n    if not cmd or cmd[0] not in allowed_commands:\\n        raise ValueError(f\\\"Git command not allowed: {cmd[0] if cmd else 'empty'}\\\")\\n    \\n    out = subprocess.check_output([\\\"git\\\", *cmd], cwd=str(cwd), timeout=30)\\n    return out.decode(\\\"utf-8\\\", errors=\\\"replace\\\").strip()\\n\\n\\ndef is_git_repo(path: Path) -> bool:\\n    try:\\n        flag = _git([\\\"rev-parse\\\", \\\"--is-inside-work-tree\\\"], cwd=path)\\n        return flag == \\\"true\\\"\\n    except Exception:\\n        return False\\n\\n\\ndef get_git_info(path: Path) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Return info for the current HEAD of a repo rooted at `path`.\\n    \\\"\\\"\\\"\\n    try:\\n        commit = _git([\\\"rev-parse\\\", \\\"HEAD\\\"], cwd=path)\\n        branch = _git([\\\"rev-parse\\\", \\\"--abbrev-ref\\\", \\\"HEAD\\\"], cwd=path)\\n        author = _git([\\\"show\\\", \\\"-s\\\", \\\"--format=%an <%ae>\\\"], cwd=path)\\n        date = _git([\\\"show\\\", \\\"-s\\\", \\\"--date=local\\\", \\\"--format=%ad\\\"], cwd=path)\\n        return {\\n            \\\"is_repo\\\": True,\\n            \\\"commit\\\": commit,\\n            \\\"branch\\\": branch,\\n            \\\"author\\\": author,\\n            \\\"date\\\": date,\\n            \\\"note\\\": None,\\n        }\\n    except Exception:\\n        # treat as not a repo if anything fails\\n        return {\\n            \\\"is_repo\\\": False,\\n            \\\"commit\\\": None,\\n            \\\"branch\\\": None,\\n            \\\"author\\\": None,\\n            \\\"date\\\": None,\\n            \\\"note\\\": \\\"Not a git repository\\\",\\n        }\\n\",\n    \"src/rcpack/io_utils.py\": \"\\\"\\\"\\\"I/O utilities for file operations.\\\"\\\"\\\"\\n\\nfrom pathlib import Path\\nfrom typing import Tuple\\n\\n\\ndef write_output(output_path: str, content: str) -> None:\\n    \\\"\\\"\\\"Write content to output file.\\\"\\\"\\\"\\n    output_file = Path(output_path)\\n    \\n    # Create parent directories if they don't exist\\n    output_file.parent.mkdir(parents=True, exist_ok=True)\\n    \\n    # Write content\\n    with open(output_file, 'w', encoding='utf-8') as f:\\n        f.write(content)\\n\\n\\ndef is_binary_file(path: Path, sniff_bytes: int = 2048) -> bool:\\n    \\\"\\\"\\\"Heuristically determine if a file is binary by scanning for NUL bytes.\\\"\\\"\\\"\\n    try:\\n        with open(path, 'rb') as fb:\\n            chunk = fb.read(sniff_bytes)\\n        if b\\\"\\\\x00\\\" in chunk:\\n            return True\\n        # If the chunk has a lot of non-text bytes, consider it binary\\n        text_byte_count = sum(32 <= b <= 126 or b in (9, 10, 13) for b in chunk)\\n        return (len(chunk) - text_byte_count) > max(1, len(chunk) // 3)\\n    except Exception:\\n        # If we cannot read, treat as binary to avoid further processing\\n        return True\\n\\n\\ndef read_text_safely(path: Path, max_bytes: int = 16_384) -> Tuple[str, str, bool]:\\n    \\\"\\\"\\\"Read a text file safely with size limit and encoding fallbacks.\\n\\n    Returns (content, encoding_used, truncated).\\n    \\\"\\\"\\\"\\n    truncated = False\\n    raw: bytes\\n    with open(path, 'rb') as fb:\\n        raw = fb.read(max_bytes + 1)\\n    if len(raw) > max_bytes:\\n        truncated = True\\n        raw = raw[:max_bytes]\\n\\n    for enc in (\\\"utf-8\\\", \\\"utf-16\\\", \\\"utf-16-le\\\", \\\"utf-16-be\\\", \\\"latin-1\\\"):\\n        try:\\n            text = raw.decode(enc)\\n            return text, enc, truncated\\n        except Exception:\\n            continue\\n    # Fallback: replace errors with utf-8\\n    text = raw.decode(\\\"utf-8\\\", errors=\\\"replace\\\")\\n    return text, \\\"utf-8\\\", truncated\",\n    \"src/rcpack/packager.py\": \"from __future__ import annotations\\n\\nimport sys\\nfrom pathlib import Path\\nfrom typing import Iterable, Tuple\\n\\nfrom rcpack.discover import discover_files\\nfrom rcpack.gitinfo import get_git_info, is_git_repo\\nfrom rcpack.io_utils import read_text_safely, is_binary_file\\nfrom rcpack.renderer import markdown as md_renderer\\nfrom rcpack.renderer.jsonyaml import render_json, render_yaml\\nfrom rcpack.treeview import render_tree\\n\\n\\ndef _find_root(inputs: list[str]) -> Path:\\n    paths = [Path(p) for p in inputs]\\n    if len(paths) == 1 and Path(paths[0]).is_dir():\\n        return paths[0].resolve()\\n    parents = [p if p.is_dir() else p.parent for p in paths]\\n    root = Path(*Path.commonpath([str(p.resolve()) for p in parents]).split(\\\"/\\\"))\\n    return root.resolve()\\n\\n\\ndef build_package(\\n    inputs: list[str],\\n    include_patterns: list[str] | None,\\n    exclude_patterns: list[str] | None,\\n    max_file_bytes: int,\\n    fmt: str = \\\"markdown\\\",\\n) -> Tuple[str, dict]:\\n    root = _find_root(inputs)\\n    root_abs = root.resolve()\\n\\n    repo_info = (\\n        get_git_info(root_abs) if is_git_repo(root_abs) else {\\n            \\\"is_repo\\\": False,\\n            \\\"commit\\\": None,\\n            \\\"branch\\\": None,\\n            \\\"author\\\": None,\\n            \\\"date\\\": None,\\n            \\\"note\\\": \\\"Not a git repository\\\",\\n        }\\n    )\\n\\n    files = discover_files(\\n        inputs=[Path(p) for p in inputs],\\n        root=root_abs,\\n        include_patterns=include_patterns or [],\\n        exclude_patterns=exclude_patterns or [],\\n    )\\n    rel_files = [f.relative_to(root_abs) for f in files]\\n\\n    project_tree = render_tree([p.as_posix() for p in rel_files])\\n\\n    file_sections: list[dict] = []\\n    total_lines = 0\\n    total_chars = 0\\n\\n    for f in files:\\n        rel = f.relative_to(root_abs).as_posix()\\n        try:\\n            if is_binary_file(f):\\n                content = f\\\"[binary file skipped: {f.name}, {f.stat().st_size} bytes]\\\"\\n                file_sections.append({\\n                    \\\"path\\\": rel,\\n                    \\\"language\\\": _language_from_ext(f.suffix),\\n                    \\\"content\\\": content,\\n                    \\\"is_truncated\\\": False,\\n                })\\n                total_chars += len(content)\\n                continue\\n\\n            content, used_encoding, truncated = read_text_safely(f, max_bytes=max_file_bytes)\\n            total_lines += content.count(\\\"\\\\n\\\") + (1 if content and not content.endswith(\\\"\\\\n\\\") else 0)\\n            total_chars += len(content)\\n\\n            if truncated:\\n                note = f\\\"\\\\n\\\\n[... TRUNCATED to first {max_file_bytes} bytes ...]\\\"\\n                content = content + note\\n                total_chars += len(note)\\n\\n            file_sections.append({\\n                \\\"path\\\": rel,\\n                \\\"language\\\": _language_from_ext(f.suffix),\\n                \\\"content\\\": content,\\n                \\\"is_truncated\\\": truncated,\\n            })\\n        except Exception as exc:\\n            print(f\\\"[rcpack] error reading {rel}: {exc}\\\", file=sys.stderr)\\n            continue\\n\\n    # render in chosen format\\n    if fmt == \\\"markdown\\\":\\n        out_text = md_renderer.render_markdown(\\n            root=str(root_abs),\\n            repo_info=repo_info,\\n            tree_text=project_tree,\\n            files=file_sections,\\n            total_files=len(file_sections),\\n            total_lines=total_lines,\\n        )\\n    elif fmt == \\\"json\\\":\\n        out_text = render_json(\\n            root=str(root_abs),\\n            repo_info=repo_info,\\n            tree_text=project_tree,\\n            files=file_sections,\\n            total_files=len(file_sections),\\n            total_lines=total_lines,\\n        )\\n    elif fmt == \\\"yaml\\\":\\n        out_text = render_yaml(\\n            root=str(root_abs),\\n            repo_info=repo_info,\\n            tree_text=project_tree,\\n            files=file_sections,\\n            total_files=len(file_sections),\\n            total_lines=total_lines,\\n        )\\n    else:\\n        raise ValueError(f\\\"Unsupported format: {fmt}\\\")\\n\\n    stats = {\\\"files\\\": len(file_sections), \\\"lines\\\": total_lines, \\\"chars\\\": total_chars}\\n    return out_text, stats\\n\\n\\ndef _language_from_ext(ext: str) -> str:\\n    ext = ext.lower().lstrip(\\\".\\\")\\n    mapping = {\\n        \\\"py\\\": \\\"python\\\", \\\"js\\\": \\\"javascript\\\", \\\"ts\\\": \\\"typescript\\\",\\n        \\\"json\\\": \\\"json\\\", \\\"md\\\": \\\"markdown\\\", \\\"yml\\\": \\\"yaml\\\", \\\"yaml\\\": \\\"yaml\\\",\\n        \\\"toml\\\": \\\"toml\\\", \\\"sh\\\": \\\"bash\\\", \\\"c\\\": \\\"c\\\", \\\"cpp\\\": \\\"cpp\\\",\\n        \\\"java\\\": \\\"java\\\", \\\"go\\\": \\\"go\\\", \\\"rs\\\": \\\"rust\\\",\\n    }\\n    return mapping.get(ext, \\\"\\\")\\n\",\n    \"src/rcpack/renderer/jsonyaml.py\": \"from __future__ import annotations\\nimport json\\n\\ntry:\\n    import yaml\\nexcept ImportError:\\n    yaml = None\\n\\n\\ndef render_json(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\\n    data = {\\n        \\\"root\\\": root,\\n        \\\"repo_info\\\": repo_info,\\n        \\\"structure\\\": tree_text,\\n        \\\"recent_changes\\\": recent_files or [],\\n        \\\"files\\\": files,\\n        \\\"file_sizes\\\": file_sizes or {},\\n        \\\"summary\\\": {\\\"total_files\\\": total_files, \\\"total_lines\\\": total_lines},\\n        \\n    }\\n    return json.dumps(data, indent=2, ensure_ascii=False)\\n\\n\\ndef render_yaml(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\\n    if yaml is None:\\n        raise RuntimeError(\\\"PyYAML not installed; run `pip install pyyaml`\\\")\\n    data = {\\n        \\\"root\\\": root,\\n        \\\"repo_info\\\": repo_info,\\n        \\\"structure\\\": tree_text,\\n        \\\"recent_changes\\\": recent_files or [],\\n        \\\"files\\\": files,\\n        \\\"file_sizes\\\": file_sizes or {},\\n        \\\"summary\\\": {\\\"total_files\\\": total_files, \\\"total_lines\\\": total_lines},\\n        \\n    }\\n    return yaml.safe_dump(data, sort_keys=False, allow_unicode=True)\\n\",\n    \"src/rcpack/renderer/markdown.py\": \"\\\"\\\"\\\"Markdown renderer for repository context.\\\"\\\"\\\"\\n\\nfrom typing import Dict, Any\\n\\n\\ndef render_markdown(root: str, repo_info: Dict[str, Any], tree_text: str, \\n                   files: Dict[str, str], total_files: int, total_lines: int, recent_files=None, file_sizes=None) -> str:\\n    \\\"\\\"\\\"Render repository context as markdown.\\\"\\\"\\\"\\n    \\n    lines = []\\n    \\n    # Header\\n    lines.append(f\\\"# Repository Context: {root}\\\")\\n    lines.append(\\\"\\\")\\n    \\n    # Repository info\\n    if repo_info.get(\\\"is_repo\\\"):\\n        lines.append(\\\"## Git Repository Information\\\")\\n        lines.append(f\\\"- **Branch**: {repo_info.get('branch', 'N/A')}\\\")\\n        lines.append(f\\\"- **Commit**: {repo_info.get('commit', 'N/A')}\\\")\\n        lines.append(f\\\"- **Author**: {repo_info.get('author', 'N/A')}\\\")\\n        lines.append(f\\\"- **Date**: {repo_info.get('date', 'N/A')}\\\")\\n    else:\\n        lines.append(\\\"## Repository Information\\\")\\n        lines.append(f\\\"- **Note**: {repo_info.get('note', 'Not a git repository')}\\\")\\n    lines.append(\\\"\\\")\\n    \\n    # Summary\\n    lines.append(\\\"## Summary\\\")\\n    lines.append(f\\\"- **Total Files**: {total_files}\\\")\\n    lines.append(f\\\"- **Total Lines**: {total_lines}\\\")\\n    lines.append(\\\"\\\")\\n    \\n    # Directory structure\\n    lines.append(\\\"## Directory Structure\\\")\\n    lines.append(\\\"```\\\")\\n    lines.append(tree_text)\\n    lines.append(\\\"```\\\")\\n    lines.append(\\\"\\\")\\n\\n    # will produce recent files \\n    # Recent files (fixed)\\n    if recent_files:\\n        lines.append(\\\"## Recent Changes\\\")\\n        for file, age in recent_files.items():\\n            lines.append(f\\\"- {file} (modified {age})\\\")\\n        lines.append(\\\"\\\")\\n    \\n    # File contents\\n    lines.append(\\\"## File Contents\\\")\\n    lines.append(\\\"\\\")\\n    \\n    for file_path, content in sorted(files.items()):\\n        if file_sizes and file_path in file_sizes:\\n            size_bytes = file_sizes[file_path]\\n            lines.append(f\\\"### {file_path} ({size_bytes} bytes)\\\")\\n        else:\\n            lines.append(f\\\"### {file_path}\\\")\\n        lines.append(\\\"\\\")\\n        \\n        # Detect language for syntax highlighting\\n        ext = file_path.split('.')[-1].lower() if '.' in file_path else ''\\n        lang_map = {\\n            'py': 'python', 'js': 'javascript', 'ts': 'typescript',\\n            'java': 'java', 'cpp': 'cpp', 'c': 'c', 'h': 'c',\\n            'cs': 'csharp', 'php': 'php', 'rb': 'ruby',\\n            'go': 'go', 'rs': 'rust', 'swift': 'swift',\\n            'html': 'html', 'css': 'css', 'scss': 'scss',\\n            'json': 'json', 'yaml': 'yaml', 'yml': 'yaml',\\n            'xml': 'xml', 'sql': 'sql', 'sh': 'bash',\\n            'md': 'markdown', 'dockerfile': 'dockerfile'\\n        }\\n        \\n        language = lang_map.get(ext, '')\\n        lines.append(f\\\"```{language}\\\")\\n        lines.append(content)\\n        lines.append(\\\"```\\\")\\n        lines.append(\\\"\\\")\\n    \\n    return \\\"\\\\n\\\".join(lines)\\n\",\n    \"src/rcpack/treeview.py\": \"\\\"\\\"\\\"Tree view generation for repository structure.\\\"\\\"\\\"\\n\\nfrom pathlib import Path\\nfrom typing import Dict, List\\n\\n\\ndef create_tree_view(repo_path: Path, files_data: Dict[str, str]) -> str:\\n    \\\"\\\"\\\"Create a tree view of the repository structure.\\\"\\\"\\\"\\n    paths = list(files_data.keys())\\n    return render_tree(paths)\\n\\n\\ndef render_tree(paths: List[str]) -> str:\\n    \\\"\\\"\\\"Render a tree view from a list of relative POSIX paths.\\\"\\\"\\\"\\n    tree_structure: dict = {}\\n\\n    for p in paths:\\n        parts = Path(p).parts\\n        current = tree_structure\\n        for part in parts[:-1]:\\n            if part not in current:\\n                current[part] = {}\\n            current = current[part]\\n        if parts:\\n            current[parts[-1]] = None\\n\\n    def _render(structure: dict, prefix: str = \\\"\\\") -> str:\\n        lines = []\\n        items = sorted(structure.items(), key=lambda x: (x[1] is None, x[0]))\\n        for i, (name, subtree) in enumerate(items):\\n            is_last = i == len(items) - 1\\n            lines.append(f\\\"{prefix}{'└── ' if is_last else '├── '}{name}\\\")\\n            if subtree is not None:\\n                extension = (\\\"    \\\" if is_last else \\\"│   \\\")\\n                lines.append(_render(subtree, prefix + extension))\\n        return \\\"\\\\n\\\".join(filter(None, lines))\\n\\n    if not tree_structure:\\n        return \\\"No files found\\\"\\n    return _render(tree_structure)\"\n  },\n  \"file_sizes\": {\n    \"LICENSE\": \"1064\",\n    \"README.md\": \"11164\",\n    \"pyproject.toml\": \"361\",\n    \"src/rcpack/__init__.py\": \"198\",\n    \"src/rcpack/__main__.py\": \"197\",\n    \"src/rcpack/cli.py\": \"7087\",\n    \"src/rcpack/config_loader.py\": \"2099\",\n    \"src/rcpack/discover.py\": \"3067\",\n    \"src/rcpack/gitinfo.py\": \"1653\",\n    \"src/rcpack/io_utils.py\": \"1817\",\n    \"src/rcpack/packager.py\": \"4430\",\n    \"src/rcpack/renderer/jsonyaml.py\": \"1176\",\n    \"src/rcpack/renderer/markdown.py\": \"2829\",\n    \"src/rcpack/treeview.py\": \"1371\"\n  },\n  \"summary\": {\n    \"total_files\": 14,\n    \"total_lines\": 1180\n  }\n}",
    "test-yaml.yaml": "root: /Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\nrepo_info:\n  is_repo: true\n  commit: 682153b169db66d3a72e9cabdd1f3448a3b2986d\n  branch: refactoring\n  author: Abhinav <abhinavbhardwaj2002@gmail.com>\n  date: Fri Oct 3 18:45:48 2025\n  note: null\nstructure: '├── src\n\n  │   └── rcpack\n\n  │       ├── renderer\n\n  │       │   ├── jsonyaml.py\n\n  │       │   └── markdown.py\n\n  │       ├── __init__.py\n\n  │       ├── __main__.py\n\n  │       ├── cli.py\n\n  │       ├── config_loader.py\n\n  │       ├── discover.py\n\n  │       ├── gitinfo.py\n\n  │       ├── io_utils.py\n\n  │       ├── packager.py\n\n  │       └── treeview.py\n\n  ├── LICENSE\n\n  ├── README.md\n\n  ├── pyproject.toml\n\n  └── test-output.json'\nrecent_changes: []\nfiles:\n  LICENSE: 'MIT License\n\n\n    Copyright (c) 2025 Abhinav\n\n\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n\n    of this software and associated documentation files (the \"Software\"), to deal\n\n    in the Software without restriction, including without limitation the rights\n\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n\n    copies of the Software, and to permit persons to whom the Software is\n\n    furnished to do so, subject to the following conditions:\n\n\n    The above copyright notice and this permission notice shall be included in all\n\n    copies or substantial portions of the Software.\n\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n\n    SOFTWARE.\n\n    '\n  README.md: \"# Repo-Contextor\\n\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\n\\\n    [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\n\\\n    \\nA powerful Repository Context Packager CLI tool that analyzes local git repositories\\\n    \\ and creates comprehensive text files containing repository content optimized\\\n    \\ for sharing with Large Language Models (LLMs).\\n\\n## Overview\\n\\nWhen developers\\\n    \\ want to get help from ChatGPT, Claude, or other LLMs about their code, they\\\n    \\ often struggle with how to share their codebase effectively. Common problems\\\n    \\ include:\\n\\n- **Lost Context**: Copy-pasting individual files loses important\\\n    \\ project structure and relationships\\n- **Missing Dependencies**: LLMs can't\\\n    \\ see how files connect or what libraries are used\\n- **Incomplete Picture**:\\\n    \\ Hard to convey the overall architecture and organization\\n- **Manual Work**:\\\n    \\ Time-consuming to gather and format relevant code\\n\\n**Repo-Contextor** solves\\\n    \\ this by automatically collecting and formatting repository content into a single,\\\n    \\ well-structured text file that provides rich context to LLMs, enabling them\\\n    \\ to give much better assistance with your code.\\n\\n## Features\\n\\n- **Git Integration**:\\\n    \\ Extracts commit SHA, branch, author, and date information\\n- **Project Structure**:\\\n    \\ Generates a clear directory tree visualization\\n- **File Content Packaging**:\\\n    \\ Includes file contents with syntax highlighting\\n- **Smart File Discovery**:\\\n    \\ Recursively scans directories with intelligent filtering\\n- **Binary File Detection**:\\\n    \\ Automatically skips binary files\\n- **Error Handling**: Gracefully handles permission\\\n    \\ errors and provides helpful messages\\n- **Multiple Output Formats**: Supports\\\n    \\ Markdown, JSON, and YAML formats\\n- **Flexible Output**: Write to stdout or\\\n    \\ save to a file\\n- **Recent Changes Filter**: Give the files which are updated\\\n    \\ in last 7days with the time when it was recently modified.\\n\\n## Installation\\n\\\n    \\n### Prerequisites\\n\\n- Python 3.9 or higher\\n- Git (for git repository analysis)\\n\\\n    \\n### For End Users\\n\\n```bash\\n# Clone and install\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\n\\\n    cd Repo-Contextor\\npip install -e .\\n```\\n\\n### For Contributors & Local Development\\n\\\n    \\n```bash\\n# Clone the repository\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\n\\\n    cd Repo-Contextor\\n\\n# Create virtual environment\\npython -m venv .venv\\nsource\\\n    \\ .venv/bin/activate  # On Windows: .venv\\\\Scripts\\\\activate\\n\\n# Install in development\\\n    \\ mode\\npip install -e .\\n```\\n\\n## Usage\\n\\n### Basic Examples\\n\\n```bash\\n#\\\n    \\ Package current directory to terminal\\nrepo-contextor .\\n\\n# Package a specific\\\n    \\ directory\\nrepo-contextor /path/to/your/project\\n\\n# Save output to a file\\n\\\n    repo-contextor . -o my-project-context.md\\n\\n# Generate JSON format\\nrepo-contextor\\\n    \\ . -f json -o context.json\\n\\n# Generate YAML format\\nrepo-contextor . -f yaml\\\n    \\ -o context.yaml\\n\\n# Include only files modified in the last 7 days\\nrepo-contextor\\\n    \\ . --recent\\n\\n# Combine with output file\\nrepo-contextor . --recent -o recent-changes.md\\n\\\n    ```\\n\\n### Command Line Options\\n\\n| Option | Short | Description | Example |\\n\\\n    |--------|-------|-------------|---------|\\n| `path` | - | Repository path to\\\n    \\ analyze (default: current directory) | `repo-contextor /path/to/project` |\\n\\\n    | `--output` | `-o` | Output file path (default: stdout) | `-o context.md` |\\n\\\n    | `--format` | `-f` | Output format: text, json, yaml (default: text) | `-f json`\\\n    \\ |\\n| `--help` | `-h` | Show help message | `-h` |\\n| `--recent`  | `-r`  | Include\\\n    \\ only files modified in the last 7 days    | `repo-contextor . -r -o recent.md`\\\n    \\ |\\n\\n### Advanced Examples\\n\\n```bash\\n# Analyze different repository\\nrepo-contextor\\\n    \\ /path/to/other/project -o other-project.md\\n\\n# Generate JSON for API consumption\\n\\\n    repo-contextor . -f json -o api-context.json\\n\\n# Create YAML configuration\\n\\\n    repo-contextor . -f yaml -o project-config.yaml\\n\\n# Generate files which are\\\n    \\ changed recently in 7 days\\nrepo-contextor . -r --output recent-changes.txt\\n\\\n    \\n```\\n## Configuration via TOML\\n\\nRepo-Contextor supports configuration through\\\n    \\ a `.repo-contextor.toml` file in the current working directory.  \\nThis file\\\n    \\ allows you to avoid typing the same CLI arguments every time.\\n\\nExample `.repo-contextor.toml`:\\n\\\n    \\n```toml\\n# Output file to write results\\noutput = \\\"context.yaml\\\"\\n\\n# Output\\\n    \\ format: text, json, or yaml\\nformat = \\\"yaml\\\"\\n\\n# Limit to files modified\\\n    \\ in the last 7 days\\nrecent = true\\n\\n# Repository path to analyze (default =\\\n    \\ current directory)\\npath = \\\".\\\"\\n```\\n### Rules\\n- If the `.repo-contextor.toml`\\\n    \\ file is **missing**, the tool falls back to defaults.  \\n- If the file is **present\\\n    \\ but invalid TOML**, the tool prints a clear error message and exits with status\\\n    \\ code 1.  \\n- **Unknown keys** in the TOML file are ignored (safe for future\\\n    \\ extensions).  \\n- **Precedence** of settings is:\\n  1. Command-line arguments\\\n    \\ (highest priority)  \\n  2. Values from `.repo-contextor.toml`  \\n  3. Built-in\\\n    \\ defaults (lowest priority)\\n     \\n## Output Format\\n\\nThe tool generates a\\\n    \\ structured text file with the following sections:\\n\\n### 1. Repository Context\\\n    \\ Header\\nProject path and identification\\n\\n### 2. Git Repository Information\\n\\\n    - Current branch\\n- Latest commit SHA\\n- Last commit author\\n- Last commit date\\n\\\n    \\n### 3. Summary Statistics\\n- Total number of files processed\\n- Total lines\\\n    \\ of code\\n\\n### 4. Directory Structure\\nClean tree visualization showing project\\\n    \\ organization\\n\\n### 5. Recent Changes (if `--recent` is used)\\n\\n- Lists files\\\n    \\ modified in the last 7 days.\\n- Shows relative file paths along with how long\\\n    \\ ago each file was modified\\n- Helps focus on recently updated parts of the project.\\n\\\n    - Can be combined with `--output` or `--format` to save or change the output type.\\n\\\n    \\n\\n### 5. File Contents\\nEach file's content with:\\n- Clear file path headers\\n\\\n    - Appropriate syntax highlighting language tags\\n- Complete file contents\\n\\n\\\n    ## Example Output\\n\\nWhen you run `repo-contextor .`, the output looks like this:\\n\\\n    \\n````markdown\\n# Repository Context: /path/to/your/project\\n\\n## Git Repository\\\n    \\ Information\\n- **Branch**: main\\n- **Commit**: a1b2c3d4e5f6789...\\n- **Author**:\\\n    \\ John Doe <john@example.com>\\n- **Date**: Fri Sep 12 14:30:15 2025\\n\\n## Summary\\n\\\n    - **Total Files**: 15\\n- **Total Lines**: 1,247\\n\\n## Directory Structure\\n```\\n\\\n    ├── src/\\n│   ├── main.py\\n│   └── utils.py\\n├── tests/\\n│   └── test_main.py\\n\\\n    ├── README.md\\n└── requirements.txt\\n```\\n## Recent Changes\\n- src/main.py (modified\\\n    \\ 2 days ago)\\n- src/utils/helpers.py (modified 5 days ago)\\n\\n## File Contents\\n\\\n    \\n### src/main.py\\n\\n```python\\ndef main():\\n    print(\\\"Hello, World!\\\")\\n\\n\\\n    if __name__ == \\\"__main__\\\":\\n    main()\\n```\\n\\n### README.md\\n\\n```markdown\\n\\\n    # My Project\\nThis is a sample project.\\n```\\n\\n## Summary\\n- Total files: 15\\n\\\n    - Total lines: 1,247\\n````\\n\\n## What Files Are Included\\n\\nThe tool includes\\\n    \\ most text files but automatically excludes:\\n\\n### Excluded Directories\\n- `.git`,\\\n    \\ `.svn`, `.hg` (version control)\\n- `__pycache__`, `.pytest_cache` (Python cache)\\n\\\n    - `node_modules`, `.venv`, `venv` (dependencies/environments)\\n- `.vscode`, `.idea`\\\n    \\ (IDE directories)\\n- `build`, `dist`, `target` (build directories)\\n\\n### File\\\n    \\ Handling Rules\\n- **Text files**: All readable text files with common extensions\\n\\\n    - **Binary files**: Automatically detected and skipped\\n- **Permission errors**:\\\n    \\ Skipped with graceful handling\\n- **Configuration files**: Includes pyproject.toml,\\\n    \\ package.json, etc.\\n\\n### Included File Types\\n- Source code: `.py`, `.js`,\\\n    \\ `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\n- Web files: `.html`, `.css`,\\\n    \\ `.scss`, `.vue`, `.jsx`, etc.\\n- Documentation: `.md`, `.txt`, `.rst`\\n- Configuration:\\\n    \\ `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\n- Scripts: `.sh`, `.bash`, `.zsh`\\n\\\n    \\n## Error Handling\\n\\nThe tool handles errors gracefully:\\n\\n| Error Type | Behavior\\\n    \\ |\\n|------------|----------|\\n| **Permission errors** | Skipped with warning\\\n    \\ |\\n| **Binary files** | Automatically detected and skipped |\\n| **Invalid paths**\\\n    \\ | Clear error messages |\\n| **Non-git repositories** | Works fine, shows \\\"\\\n    Not a git repository\\\" |\\n| **Unreadable files** | Marked as \\\"[Binary or unreadable\\\n    \\ file]\\\" |\\n\\n## Development\\n\\n### Project Structure\\n\\n```text\\nRepo-Contextor/\\n\\\n    ├── src/rcpack/              # Main package\\n│   ├── __init__.py         # Package\\\n    \\ initialization\\n│   ├── cli.py              # Command-line interface\\n│   ├──\\\n    \\ discover.py         # File discovery logic\\n│   ├── gitinfo.py          # Git\\\n    \\ repository analysis\\n│   ├── treeview.py         # Directory tree generation\\n\\\n    │   ├── packager.py         # Main orchestration\\n│   ├── io_utils.py        \\\n    \\ # File I/O utilities\\n│   └── renderer/           # Output formatters\\n│   \\\n    \\    ├── markdown.py     # Markdown renderer\\n│       └── jsonyaml.py     # JSON/YAML\\\n    \\ renderers\\n├── pyproject.toml          # Project configuration\\n├── LICENSE\\\n    \\                 # MIT License\\n└── README.md              # This documentation\\n\\\n    ```\\n\\n### Running Tests\\n\\n```bash\\n# Test on current repository\\nrepo-contextor\\\n    \\ . -o test-output.md\\n\\n# Test different formats\\nrepo-contextor . -f json |\\\n    \\ head -20\\nrepo-contextor . -f yaml | head -20\\n\\n# Test specific directory\\n\\\n    repo-contextor src/ -o src-only.md\\n```\\n\\n### Contributing\\n\\n1. **Fork the repository**\\n\\\n    2. **Clone your fork:**\\n   ```bash\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\n\\\n    \\   cd Repo-Contextor\\n   ```\\n3. **Install for development:**\\n   ```bash\\n \\\n    \\  python -m venv .venv\\n   source .venv/bin/activate\\n   pip install -e .\\n \\\n    \\  ```\\n4. **Make your changes and test:**\\n   ```bash\\n   repo-contextor . -o\\\n    \\ test.md\\n   ```\\n5. **Submit a pull request**\\n\\n### Development Workflow\\n\\n\\\n    ```bash\\n# 1. Setup development environment\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\n\\\n    cd Repo-Contextor\\npython -m venv .venv\\nsource .venv/bin/activate\\npip install\\\n    \\ -e .\\n\\n# 2. Make changes to the code\\n# Edit files in src/rcpack/\\n\\n# 3. Test\\\n    \\ your changes\\nrepo-contextor . -o test-output.md\\n\\n# 4. Test different formats\\n\\\n    repo-contextor . -f json -o test.json\\nrepo-contextor . -f yaml -o test.yaml\\n\\\n    \\n# 5. Commit and push changes\\ngit add .\\ngit commit -m \\\"Add new feature\\\"\\n\\\n    git push origin feature-branch\\n```\\n\\n## License\\n\\nThis project is licensed\\\n    \\ under the MIT License. See the [LICENSE](LICENSE) file for details.\\n\\n## Why\\\n    \\ Repo-Contextor?\\n\\nThe name \\\"Repo-Contextor\\\" combines \\\"Repository\\\" + \\\"\\\n    Context\\\" + \\\"or\\\", representing the tool's purpose of providing rich context\\\n    \\ about code repositories in a format that's perfect for LLM interactions.\\n\\n\\\n    ### Use Cases\\n\\n- **AI Assistance**: Get better help from ChatGPT, Claude, or\\\n    \\ GitHub Copilot\\n- **Code Reviews**: Share complete project context with team\\\n    \\ members\\n- **Documentation**: Create comprehensive project snapshots\\n- **Onboarding**:\\\n    \\ Help new team members understand project structure\\n- **Project Analysis**:\\\n    \\ Understand repository structure and dependencies\\n\\n### Perfect for LLMs\\n\\n\\\n    The output format is specifically designed to work well with Large Language Models:\\n\\\n    - Clear section headers for easy parsing\\n- Syntax highlighting markers for code\\\n    \\ blocks\\n- Structured metadata (git info, file locations)\\n- Complete project\\\n    \\ context in a single file\\n- Multiple output formats (Markdown, JSON, YAML)\\n\\\n    - Optimized for token efficiency\\n\"\n  pyproject.toml: \"[build-system]\\nrequires = [\\\"setuptools>=68\\\", \\\"wheel\\\"]\\nbuild-backend\\\n    \\ = \\\"setuptools.build_meta\\\"\\n\\n[project]\\nname = \\\"rcpack\\\"\\nversion = \\\"0.1.0\\\"\\\n    \\ndescription = \\\"Repository Context Packager CLI for LLMs\\\"\\nreadme = \\\"README.md\\\"\\\n    \\nrequires-python = \\\">=3.9\\\"\\nlicense = { text = \\\"MIT\\\" }\\ndependencies = [\\n\\\n    \\    \\\"PyYAML>=6.0\\\"\\n]\\n\\n[project.scripts]\\nrepo-contextor = \\\"rcpack.cli:main\\\"\\\n    \\n\"\n  src/rcpack/__init__.py: '\"\"\"Repository Context Packager - CLI tool for creating\n    LLM-optimized repository context.\"\"\"\n\n\n    __version__ = \"0.1.0\"\n\n    __author__ = \"Abhinav\"\n\n    __description__ = \"Repository Context Packager CLI for LLMs\"'\n  src/rcpack/__main__.py: \"#!/usr/bin/env python3\\n\\\"\\\"\\\"Module entry point to enable\\\n    \\ `python -m rcpack`.\\n\\nThis simply delegates to the CLI's main() function.\\n\\\n    \\\"\\\"\\\"\\n\\nfrom .cli import main\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\\\n    \\n\\n\"\n  src/rcpack/cli.py: \"#!/usr/bin/env python3\\n\\\"\\\"\\\"CLI for Repository Context Packager.\\\"\\\n    \\\"\\\"\\n\\nfrom .config_loader import load_config\\n\\nimport argparse\\nimport sys\\n\\\n    from pathlib import Path\\nfrom .gitinfo import get_git_info\\nfrom .discover import\\\n    \\ discover_files\\nfrom .treeview import create_tree_view\\nfrom .renderer.markdown\\\n    \\ import render_markdown\\nfrom .renderer.jsonyaml import render_json, render_yaml\\n\\\n    from .io_utils import write_output\\nfrom datetime import datetime, timedelta\\n\\\n    \\n\\ndef log_verbose(message: str, verbose: bool) -> None:\\n    \\\"\\\"\\\"Log a message\\\n    \\ to stderr if verbose mode is enabled.\\\"\\\"\\\"\\n    if verbose:\\n        print(message,\\\n    \\ file=sys.stderr)\\n\\n\\ndef get_rendered_content(format_type: str, repo_path:\\\n    \\ str, repo_info: dict, tree_text: str, \\n                        files_data:\\\n    \\ dict, total_files: int, total_lines: int, \\n                        recent_files_info:\\\n    \\ dict, file_sizes: dict) -> str:\\n    \\\"\\\"\\\"Get rendered content based on the\\\n    \\ specified format.\\\"\\\"\\\"\\n    if format_type == \\\"json\\\":\\n        return render_json(\\n\\\n    \\            repo_path, repo_info, tree_text, \\n            files_data, total_files,\\\n    \\ total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n\\\n    \\        )\\n    elif format_type == \\\"yaml\\\":\\n        return render_yaml(\\n \\\n    \\           repo_path, repo_info, tree_text, \\n            files_data, total_files,\\\n    \\ total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n\\\n    \\        )\\n    else:  # text/markdown\\n        return render_markdown(\\n    \\\n    \\        repo_path, repo_info, tree_text, \\n            files_data, total_files,\\\n    \\ total_lines,\\n            recent_files=recent_files_info,\\n            file_sizes=file_sizes\\n\\\n    \\        )\\n\\n\\ndef process_file(file_path: Path, repo_path: Path, verbose: bool)\\\n    \\ -> tuple[str, str, str]:\\n    \\\"\\\"\\\"Process a single file and return its data.\\n\\\n    \\    \\n    Returns:\\n        tuple: (relative_path_str, content, file_size)\\n\\\n    \\    \\\"\\\"\\\"\\n    relative_path = file_path.relative_to(repo_path)\\n    relative_path_str\\\n    \\ = str(relative_path)\\n    \\n    log_verbose(f\\\"Reading file: {relative_path}\\\"\\\n    , verbose)\\n    file_size = file_path.stat().st_size\\n    \\n    try:\\n       \\\n    \\ with open(file_path, 'r', encoding='utf-8') as f:\\n            content = f.read()\\n\\\n    \\        return relative_path_str, content, str(file_size)\\n    except (UnicodeDecodeError,\\\n    \\ PermissionError):\\n        log_verbose(f\\\"Skipping binary/unreadable file: {relative_path}\\\"\\\n    , verbose)\\n        file_size = file_path.stat().st_size if file_path.exists()\\\n    \\ else 0\\n        content = f\\\"[Binary or unreadable file: {file_path.name}]\\\"\\\n    \\n        return relative_path_str, content, str(file_size)\\n    except Exception:\\n\\\n    \\        log_verbose(f\\\"Error reading file: {relative_path}\\\", verbose)\\n    \\\n    \\    raise  # Re-raise to handle in calling code\\n\\n\\ndef handle_output(content:\\\n    \\ str, output_path: str = None) -> None:\\n    \\\"\\\"\\\"Handle output to either file\\\n    \\ or stdout.\\\"\\\"\\\"\\n    if output_path:\\n        # Write to file\\n        write_output(output_path,\\\n    \\ content)\\n        print(f\\\"Context package created: {output_path}\\\")\\n    else:\\n\\\n    \\        # Output to stdout\\n        print(content)\\n\\n\\ndef main():\\n    parser\\\n    \\ = argparse.ArgumentParser(\\n        description=\\\"Package repository content\\\n    \\ for LLM context\\\"\\n    )\\n    parser.add_argument(\\n        \\\"path\\\", \\n   \\\n    \\     nargs=\\\"?\\\", \\n        default=\\\".\\\", \\n        help=\\\"Repository path (default:\\\n    \\ current directory)\\\"\\n    )\\n    parser.add_argument(\\n        \\\"-o\\\", \\\"--output\\\"\\\n    , \\n        help=\\\"Output file path (default: stdout)\\\"\\n    )\\n    parser.add_argument(\\n\\\n    \\        \\\"-f\\\", \\\"--format\\\", \\n        choices=[\\\"text\\\", \\\"json\\\", \\\"yaml\\\"\\\n    ], \\n        default=\\\"text\\\",\\n        help=\\\"Output format (default: text)\\\"\\\n    \\n    )\\n\\n    \\\"\\\"\\\" This will read -r from the console and able to search it\\\n    \\ with this\\\"\\\"\\\"\\n    parser.add_argument(\\n    \\\"-r\\\", \\\"--recent\\\",\\n    action=\\\"\\\n    store_true\\\",\\n    help=\\\"Include only files modified in the last 7 days\\\"\\n \\\n    \\   )\\n    parser.add_argument(\\n        \\\"-v\\\", \\\"--verbose\\\",\\n        action=\\\"\\\n    store_true\\\",\\n        help=\\\"Print detailed progress information to stderr\\\"\\n\\\n    \\    )\\n    \\n    args = parser.parse_args()\\n    \\n    try:\\n        repo_path\\\n    \\ = Path(args.path).resolve()\\n        if not repo_path.exists():\\n          \\\n    \\  print(f\\\"Error: Path {repo_path} does not exist\\\", file=sys.stderr)\\n     \\\n    \\       sys.exit(1)\\n            \\n        # Get repository information\\n    \\\n    \\    log_verbose(f\\\"Analyzing repository: {repo_path}\\\", args.verbose)\\n     \\\n    \\   repo_info = get_git_info(repo_path)\\n        \\n        # Discover files\\n\\\n    \\        log_verbose(f\\\"Discovering files in: {repo_path}\\\", args.verbose)\\n \\\n    \\       discovered_files = discover_files([repo_path], repo_path, [], [])\\n  \\\n    \\      log_verbose(f\\\"Found {len(discovered_files)} files\\\", args.verbose)\\n \\\n    \\       \\n        # will check the file in last 7 days\\n        recent_files_info\\\n    \\ = {}\\n        if args.recent:\\n            seven_days_ago = datetime.now() -\\\n    \\ timedelta(days=7)\\n            recent_files = []\\n            for f in discovered_files:\\n\\\n    \\                try:\\n                    mtime = datetime.fromtimestamp(f.stat().st_mtime)\\n\\\n    \\                    if mtime >= seven_days_ago:\\n                        recent_files.append(f)\\n\\\n    \\                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)\\\n    \\     \\n                except Exception:\\n                    continue\\n    \\\n    \\        discovered_files = recent_files\\n        \\n        # Read file contents\\n\\\n    \\        files_data = {}\\n        file_sizes = {}\\n        for file_path in discovered_files:\\n\\\n    \\            try:\\n                relative_path_str, content, file_size = process_file(file_path,\\\n    \\ repo_path, args.verbose)\\n                files_data[relative_path_str] = content\\n\\\n    \\                file_sizes[relative_path_str] = file_size\\n            except\\\n    \\ Exception:\\n                continue\\n        \\n        # Create tree view\\n\\\n    \\        log_verbose(\\\"Generating directory tree\\\", args.verbose)\\n        tree_text\\\n    \\ = create_tree_view(repo_path, files_data)\\n        \\n        # Count totals\\n\\\n    \\        total_files = len(files_data)\\n        total_lines = sum(len(content.splitlines())\\\n    \\ for _, content in files_data.items())\\n        \\n        # Render based on format\\n\\\n    \\        log_verbose(f\\\"Rendering output in {args.format} format\\\", args.verbose)\\n\\\n    \\        content = get_rendered_content(\\n            args.format, str(repo_path),\\\n    \\ repo_info, tree_text,\\n            files_data, total_files, total_lines,\\n \\\n    \\           recent_files_info if args.recent else {},\\n            file_sizes\\n\\\n    \\        )\\n        \\n        handle_output(content, args.output)\\n        \\n\\\n    \\    except Exception as e:\\n        print(f\\\"Error: {e}\\\", file=sys.stderr)\\n\\\n    \\        sys.exit(1)\\n\\n# this will convert age and give us the difference\\ndef\\\n    \\ human_readable_age(mtime: datetime) -> str:\\n    delta = datetime.now() - mtime\\n\\\n    \\    days = delta.days\\n    seconds = delta.seconds\\n    if days > 0:\\n      \\\n    \\  return f\\\"{days} day{'s' if days != 1 else ''} ago\\\"\\n    elif seconds >= 3600:\\n\\\n    \\        hours = seconds // 3600\\n        return f\\\"{hours} hour{'s' if hours\\\n    \\ != 1 else ''} ago\\\"\\n    elif seconds >= 60:\\n        minutes = seconds // 60\\n\\\n    \\        return f\\\"{minutes} minute{'s' if minutes != 1 else ''} ago\\\"\\n    else:\\n\\\n    \\        return \\\"just now\\\"\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\"\n  src/rcpack/config_loader.py: \"# src/rcpack/config_loader.py\\n\\\"\\\"\\\"\\nTOML config\\\n    \\ loader for Repo-Contextor.\\n\\nRules:\\n- Look for .repo-contextor.toml in the\\\n    \\ CURRENT directory\\n- If missing: ignore\\n- If present but invalid: print a clear\\\n    \\ error and exit(1)\\n- Only recognized keys are applied; unknown keys ignored\\n\\\n    - Precedence: CLI > TOML > DEFAULTS\\n\\\"\\\"\\\"\\nfrom __future__ import annotations\\n\\\n    import os, sys\\nfrom typing import Dict, Iterable, Any\\n\\ntry:\\n    import tomllib\\n\\\n    \\    _loads = tomllib.loads\\nexcept ModuleNotFoundError:\\n    try:\\n        import\\\n    \\ tomli\\n        _loads = tomli.loads\\n    except ModuleNotFoundError:\\n     \\\n    \\   _loads = None\\n\\ndef _need_toml():\\n    if _loads is None:\\n        print(\\\"\\\n    Error: TOML parser not available. Use Python 3.11+ or `pip install tomli`.\\\",\\\n    \\ file=sys.stderr)\\n        sys.exit(1)\\n\\ndef _load_toml(dotfile: str) -> Dict[str,\\\n    \\ Any]:\\n    _need_toml()\\n    if not os.path.exists(dotfile):\\n        return\\\n    \\ {}\\n    try:\\n        with open(dotfile, \\\"rb\\\") as f:\\n            raw = f.read().decode(\\\"\\\n    utf-8\\\", errors=\\\"strict\\\")\\n        data = _loads(raw)\\n        return data if\\\n    \\ isinstance(data, dict) else {}\\n    except Exception as e:\\n        print(f\\\"\\\n    Error: failed to parse {dotfile} as TOML.\\\\n{e}\\\", file=sys.stderr)\\n        sys.exit(1)\\n\\\n    \\ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\n\\\n    \\    ks = set(known)\\n    return {k: v for k, v in d.items() if k in ks}\\n\\ndef\\\n    \\ _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str,\\\n    \\ Any], known: Iterable[str]) -> Dict[str, Any]:\\n    ks = set(known)\\n    out:\\\n    \\ Dict[str, Any] = {k: defaults.get(k) for k in ks}\\n    for src in (filecfg,\\\n    \\ clicfg):\\n        for k, v in src.items():\\n            if k in ks and v is\\\n    \\ not None:\\n                out[k] = v\\n    return out\\n\\ndef load_config(*,\\\n    \\ dotfile: str = \\\".repo-contextor.toml\\\", defaults: Dict[str, Any] | None = None,\\\n    \\ cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ()) -> Dict[str,\\\n    \\ Any]:\\n    defaults = defaults or {}\\n    cli_cfg = cli_cfg or {}\\n    known\\\n    \\ = tuple(known_keys)\\n    filecfg = _filter_known(_load_toml(dotfile), known)\\n\\\n    \\    return _merge(defaults, filecfg, cli_cfg, known)\\n\"\n  src/rcpack/discover.py: \"\\\"\\\"\\\"File discovery module for repository analysis.\\\"\\\"\\\n    \\\"\\n\\nfrom pathlib import Path\\nfrom typing import List\\nimport fnmatch\\n\\n\\n\\\n    def discover_files(\\n    inputs: List[Path],\\n    root: Path,\\n    include_patterns:\\\n    \\ List[str],\\n    exclude_patterns: List[str],\\n) -> List[Path]:\\n    \\\"\\\"\\\"Discover\\\n    \\ relevant files.\\n\\n    - inputs: list of files/dirs to scan\\n    - root: common\\\n    \\ project root; patterns are matched against POSIX paths relative to root\\n  \\\n    \\  - include_patterns: glob patterns to include (if empty, use sensible defaults)\\n\\\n    \\    - exclude_patterns: glob patterns to exclude\\n    Returns a list of absolute\\\n    \\ Paths to files.\\n    \\\"\\\"\\\"\\n\\n    default_include_exts = {\\n        '.py',\\\n    \\ '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\\n        '.cs', '.php',\\\n    \\ '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\n        '.html', '.css', '.scss',\\\n    \\ '.sass', '.less', '.vue', '.svelte',\\n        '.md', '.txt', '.rst', '.yaml',\\\n    \\ '.yml', '.json', '.toml', '.ini',\\n        '.cfg', '.conf', '.xml', '.sql',\\\n    \\ '.sh', '.bash', '.zsh', '.fish',\\n    }\\n\\n    always_include_names = {\\n  \\\n    \\      'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING', 'Makefile',\\n       \\\n    \\ 'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\\n      \\\n    \\  'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\n\\\n    \\    }\\n\\n    skip_dir_names = {\\n        '.git', '.svn', '.hg', '__pycache__',\\\n    \\ '.pytest_cache',\\n        'node_modules', '.venv', 'venv', 'env', '.env',\\n\\\n    \\        'build', 'dist', 'target', 'out', '.next', '.nuxt',\\n        '.idea',\\\n    \\ '.vscode', '.vs', 'coverage', '.coverage'\\n    }\\n\\n    def matches_any(patterns:\\\n    \\ List[str], rel_posix: str) -> bool:\\n        return any(fnmatch.fnmatch(rel_posix,\\\n    \\ pat) for pat in patterns)\\n\\n    def should_take(file_path: Path) -> bool:\\n\\\n    \\        rel_posix = file_path.relative_to(root).as_posix()\\n        if exclude_patterns\\\n    \\ and matches_any(exclude_patterns, rel_posix):\\n            return False\\n  \\\n    \\      if include_patterns:\\n            return matches_any(include_patterns,\\\n    \\ rel_posix)\\n        # default include logic\\n        return file_path.name in\\\n    \\ always_include_names or file_path.suffix.lower() in default_include_exts\\n\\n\\\n    \\    discovered: list[Path] = []\\n    seen = set()\\n\\n    for item in inputs:\\n\\\n    \\        p = item.resolve()\\n        if p.is_file():\\n            # Skip if excluded\\\n    \\ or in skipped directory\\n            if any(part in skip_dir_names for part\\\n    \\ in p.parts):\\n                continue\\n            if should_take(p):\\n   \\\n    \\             key = p.as_posix()\\n                if key not in seen:\\n      \\\n    \\              seen.add(key)\\n                    discovered.append(p)\\n     \\\n    \\   elif p.is_dir():\\n            for child in p.rglob('*'):\\n               \\\n    \\ if not child.is_file():\\n                    continue\\n                if any(part\\\n    \\ in skip_dir_names for part in child.parts):\\n                    continue\\n\\\n    \\                if should_take(child):\\n                    key = child.resolve().as_posix()\\n\\\n    \\                    if key not in seen:\\n                        seen.add(key)\\n\\\n    \\                        discovered.append(child.resolve())\\n\\n    return sorted(discovered)\"\n  src/rcpack/gitinfo.py: \"from __future__ import annotations\\n\\nimport subprocess\\n\\\n    from pathlib import Path\\nfrom typing import Dict, Any\\n\\n\\ndef _git(cmd: list[str],\\\n    \\ cwd: Path) -> str:\\n    # Validate git commands to prevent injection\\n    allowed_commands\\\n    \\ = {\\n        \\\"rev-parse\\\", \\\"show\\\", \\\"log\\\", \\\"status\\\", \\\"branch\\\", \\\"config\\\"\\\n    \\n    }\\n    if not cmd or cmd[0] not in allowed_commands:\\n        raise ValueError(f\\\"\\\n    Git command not allowed: {cmd[0] if cmd else 'empty'}\\\")\\n    \\n    out = subprocess.check_output([\\\"\\\n    git\\\", *cmd], cwd=str(cwd), timeout=30)\\n    return out.decode(\\\"utf-8\\\", errors=\\\"\\\n    replace\\\").strip()\\n\\n\\ndef is_git_repo(path: Path) -> bool:\\n    try:\\n     \\\n    \\   flag = _git([\\\"rev-parse\\\", \\\"--is-inside-work-tree\\\"], cwd=path)\\n      \\\n    \\  return flag == \\\"true\\\"\\n    except Exception:\\n        return False\\n\\n\\n\\\n    def get_git_info(path: Path) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Return info for\\\n    \\ the current HEAD of a repo rooted at `path`.\\n    \\\"\\\"\\\"\\n    try:\\n       \\\n    \\ commit = _git([\\\"rev-parse\\\", \\\"HEAD\\\"], cwd=path)\\n        branch = _git([\\\"\\\n    rev-parse\\\", \\\"--abbrev-ref\\\", \\\"HEAD\\\"], cwd=path)\\n        author = _git([\\\"\\\n    show\\\", \\\"-s\\\", \\\"--format=%an <%ae>\\\"], cwd=path)\\n        date = _git([\\\"show\\\"\\\n    , \\\"-s\\\", \\\"--date=local\\\", \\\"--format=%ad\\\"], cwd=path)\\n        return {\\n \\\n    \\           \\\"is_repo\\\": True,\\n            \\\"commit\\\": commit,\\n            \\\"\\\n    branch\\\": branch,\\n            \\\"author\\\": author,\\n            \\\"date\\\": date,\\n\\\n    \\            \\\"note\\\": None,\\n        }\\n    except Exception:\\n        # treat\\\n    \\ as not a repo if anything fails\\n        return {\\n            \\\"is_repo\\\":\\\n    \\ False,\\n            \\\"commit\\\": None,\\n            \\\"branch\\\": None,\\n     \\\n    \\       \\\"author\\\": None,\\n            \\\"date\\\": None,\\n            \\\"note\\\":\\\n    \\ \\\"Not a git repository\\\",\\n        }\\n\"\n  src/rcpack/io_utils.py: \"\\\"\\\"\\\"I/O utilities for file operations.\\\"\\\"\\\"\\n\\nfrom\\\n    \\ pathlib import Path\\nfrom typing import Tuple\\n\\n\\ndef write_output(output_path:\\\n    \\ str, content: str) -> None:\\n    \\\"\\\"\\\"Write content to output file.\\\"\\\"\\\"\\n\\\n    \\    output_file = Path(output_path)\\n    \\n    # Create parent directories if\\\n    \\ they don't exist\\n    output_file.parent.mkdir(parents=True, exist_ok=True)\\n\\\n    \\    \\n    # Write content\\n    with open(output_file, 'w', encoding='utf-8')\\\n    \\ as f:\\n        f.write(content)\\n\\n\\ndef is_binary_file(path: Path, sniff_bytes:\\\n    \\ int = 2048) -> bool:\\n    \\\"\\\"\\\"Heuristically determine if a file is binary\\\n    \\ by scanning for NUL bytes.\\\"\\\"\\\"\\n    try:\\n        with open(path, 'rb') as\\\n    \\ fb:\\n            chunk = fb.read(sniff_bytes)\\n        if b\\\"\\\\x00\\\" in chunk:\\n\\\n    \\            return True\\n        # If the chunk has a lot of non-text bytes,\\\n    \\ consider it binary\\n        text_byte_count = sum(32 <= b <= 126 or b in (9,\\\n    \\ 10, 13) for b in chunk)\\n        return (len(chunk) - text_byte_count) > max(1,\\\n    \\ len(chunk) // 3)\\n    except Exception:\\n        # If we cannot read, treat\\\n    \\ as binary to avoid further processing\\n        return True\\n\\n\\ndef read_text_safely(path:\\\n    \\ Path, max_bytes: int = 16_384) -> Tuple[str, str, bool]:\\n    \\\"\\\"\\\"Read a text\\\n    \\ file safely with size limit and encoding fallbacks.\\n\\n    Returns (content,\\\n    \\ encoding_used, truncated).\\n    \\\"\\\"\\\"\\n    truncated = False\\n    raw: bytes\\n\\\n    \\    with open(path, 'rb') as fb:\\n        raw = fb.read(max_bytes + 1)\\n    if\\\n    \\ len(raw) > max_bytes:\\n        truncated = True\\n        raw = raw[:max_bytes]\\n\\\n    \\n    for enc in (\\\"utf-8\\\", \\\"utf-16\\\", \\\"utf-16-le\\\", \\\"utf-16-be\\\", \\\"latin-1\\\"\\\n    ):\\n        try:\\n            text = raw.decode(enc)\\n            return text,\\\n    \\ enc, truncated\\n        except Exception:\\n            continue\\n    # Fallback:\\\n    \\ replace errors with utf-8\\n    text = raw.decode(\\\"utf-8\\\", errors=\\\"replace\\\"\\\n    )\\n    return text, \\\"utf-8\\\", truncated\"\n  src/rcpack/packager.py: \"from __future__ import annotations\\n\\nimport sys\\nfrom\\\n    \\ pathlib import Path\\nfrom typing import Iterable, Tuple\\n\\nfrom rcpack.discover\\\n    \\ import discover_files\\nfrom rcpack.gitinfo import get_git_info, is_git_repo\\n\\\n    from rcpack.io_utils import read_text_safely, is_binary_file\\nfrom rcpack.renderer\\\n    \\ import markdown as md_renderer\\nfrom rcpack.renderer.jsonyaml import render_json,\\\n    \\ render_yaml\\nfrom rcpack.treeview import render_tree\\n\\n\\ndef _find_root(inputs:\\\n    \\ list[str]) -> Path:\\n    paths = [Path(p) for p in inputs]\\n    if len(paths)\\\n    \\ == 1 and Path(paths[0]).is_dir():\\n        return paths[0].resolve()\\n    parents\\\n    \\ = [p if p.is_dir() else p.parent for p in paths]\\n    root = Path(*Path.commonpath([str(p.resolve())\\\n    \\ for p in parents]).split(\\\"/\\\"))\\n    return root.resolve()\\n\\n\\ndef build_package(\\n\\\n    \\    inputs: list[str],\\n    include_patterns: list[str] | None,\\n    exclude_patterns:\\\n    \\ list[str] | None,\\n    max_file_bytes: int,\\n    fmt: str = \\\"markdown\\\",\\n\\\n    ) -> Tuple[str, dict]:\\n    root = _find_root(inputs)\\n    root_abs = root.resolve()\\n\\\n    \\n    repo_info = (\\n        get_git_info(root_abs) if is_git_repo(root_abs) else\\\n    \\ {\\n            \\\"is_repo\\\": False,\\n            \\\"commit\\\": None,\\n        \\\n    \\    \\\"branch\\\": None,\\n            \\\"author\\\": None,\\n            \\\"date\\\": None,\\n\\\n    \\            \\\"note\\\": \\\"Not a git repository\\\",\\n        }\\n    )\\n\\n    files\\\n    \\ = discover_files(\\n        inputs=[Path(p) for p in inputs],\\n        root=root_abs,\\n\\\n    \\        include_patterns=include_patterns or [],\\n        exclude_patterns=exclude_patterns\\\n    \\ or [],\\n    )\\n    rel_files = [f.relative_to(root_abs) for f in files]\\n\\n\\\n    \\    project_tree = render_tree([p.as_posix() for p in rel_files])\\n\\n    file_sections:\\\n    \\ list[dict] = []\\n    total_lines = 0\\n    total_chars = 0\\n\\n    for f in files:\\n\\\n    \\        rel = f.relative_to(root_abs).as_posix()\\n        try:\\n            if\\\n    \\ is_binary_file(f):\\n                content = f\\\"[binary file skipped: {f.name},\\\n    \\ {f.stat().st_size} bytes]\\\"\\n                file_sections.append({\\n      \\\n    \\              \\\"path\\\": rel,\\n                    \\\"language\\\": _language_from_ext(f.suffix),\\n\\\n    \\                    \\\"content\\\": content,\\n                    \\\"is_truncated\\\"\\\n    : False,\\n                })\\n                total_chars += len(content)\\n  \\\n    \\              continue\\n\\n            content, used_encoding, truncated = read_text_safely(f,\\\n    \\ max_bytes=max_file_bytes)\\n            total_lines += content.count(\\\"\\\\n\\\"\\\n    ) + (1 if content and not content.endswith(\\\"\\\\n\\\") else 0)\\n            total_chars\\\n    \\ += len(content)\\n\\n            if truncated:\\n                note = f\\\"\\\\n\\\\\\\n    n[... TRUNCATED to first {max_file_bytes} bytes ...]\\\"\\n                content\\\n    \\ = content + note\\n                total_chars += len(note)\\n\\n            file_sections.append({\\n\\\n    \\                \\\"path\\\": rel,\\n                \\\"language\\\": _language_from_ext(f.suffix),\\n\\\n    \\                \\\"content\\\": content,\\n                \\\"is_truncated\\\": truncated,\\n\\\n    \\            })\\n        except Exception as exc:\\n            print(f\\\"[rcpack]\\\n    \\ error reading {rel}: {exc}\\\", file=sys.stderr)\\n            continue\\n\\n   \\\n    \\ # render in chosen format\\n    if fmt == \\\"markdown\\\":\\n        out_text = md_renderer.render_markdown(\\n\\\n    \\            root=str(root_abs),\\n            repo_info=repo_info,\\n         \\\n    \\   tree_text=project_tree,\\n            files=file_sections,\\n            total_files=len(file_sections),\\n\\\n    \\            total_lines=total_lines,\\n        )\\n    elif fmt == \\\"json\\\":\\n\\\n    \\        out_text = render_json(\\n            root=str(root_abs),\\n          \\\n    \\  repo_info=repo_info,\\n            tree_text=project_tree,\\n            files=file_sections,\\n\\\n    \\            total_files=len(file_sections),\\n            total_lines=total_lines,\\n\\\n    \\        )\\n    elif fmt == \\\"yaml\\\":\\n        out_text = render_yaml(\\n     \\\n    \\       root=str(root_abs),\\n            repo_info=repo_info,\\n            tree_text=project_tree,\\n\\\n    \\            files=file_sections,\\n            total_files=len(file_sections),\\n\\\n    \\            total_lines=total_lines,\\n        )\\n    else:\\n        raise ValueError(f\\\"\\\n    Unsupported format: {fmt}\\\")\\n\\n    stats = {\\\"files\\\": len(file_sections), \\\"\\\n    lines\\\": total_lines, \\\"chars\\\": total_chars}\\n    return out_text, stats\\n\\n\\n\\\n    def _language_from_ext(ext: str) -> str:\\n    ext = ext.lower().lstrip(\\\".\\\")\\n\\\n    \\    mapping = {\\n        \\\"py\\\": \\\"python\\\", \\\"js\\\": \\\"javascript\\\", \\\"ts\\\":\\\n    \\ \\\"typescript\\\",\\n        \\\"json\\\": \\\"json\\\", \\\"md\\\": \\\"markdown\\\", \\\"yml\\\":\\\n    \\ \\\"yaml\\\", \\\"yaml\\\": \\\"yaml\\\",\\n        \\\"toml\\\": \\\"toml\\\", \\\"sh\\\": \\\"bash\\\"\\\n    , \\\"c\\\": \\\"c\\\", \\\"cpp\\\": \\\"cpp\\\",\\n        \\\"java\\\": \\\"java\\\", \\\"go\\\": \\\"go\\\"\\\n    , \\\"rs\\\": \\\"rust\\\",\\n    }\\n    return mapping.get(ext, \\\"\\\")\\n\"\n  src/rcpack/renderer/jsonyaml.py: \"from __future__ import annotations\\nimport json\\n\\\n    \\ntry:\\n    import yaml\\nexcept ImportError:\\n    yaml = None\\n\\n\\ndef render_json(root,\\\n    \\ repo_info, tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None)\\\n    \\ -> str:\\n    data = {\\n        \\\"root\\\": root,\\n        \\\"repo_info\\\": repo_info,\\n\\\n    \\        \\\"structure\\\": tree_text,\\n        \\\"recent_changes\\\": recent_files or\\\n    \\ [],\\n        \\\"files\\\": files,\\n        \\\"file_sizes\\\": file_sizes or {},\\n\\\n    \\        \\\"summary\\\": {\\\"total_files\\\": total_files, \\\"total_lines\\\": total_lines},\\n\\\n    \\        \\n    }\\n    return json.dumps(data, indent=2, ensure_ascii=False)\\n\\n\\\n    \\ndef render_yaml(root, repo_info, tree_text, files, total_files, total_lines,recent_files=None,\\\n    \\ file_sizes=None) -> str:\\n    if yaml is None:\\n        raise RuntimeError(\\\"\\\n    PyYAML not installed; run `pip install pyyaml`\\\")\\n    data = {\\n        \\\"root\\\"\\\n    : root,\\n        \\\"repo_info\\\": repo_info,\\n        \\\"structure\\\": tree_text,\\n\\\n    \\        \\\"recent_changes\\\": recent_files or [],\\n        \\\"files\\\": files,\\n\\\n    \\        \\\"file_sizes\\\": file_sizes or {},\\n        \\\"summary\\\": {\\\"total_files\\\"\\\n    : total_files, \\\"total_lines\\\": total_lines},\\n        \\n    }\\n    return yaml.safe_dump(data,\\\n    \\ sort_keys=False, allow_unicode=True)\\n\"\n  src/rcpack/renderer/markdown.py: \"\\\"\\\"\\\"Markdown renderer for repository context.\\\"\\\n    \\\"\\\"\\n\\nfrom typing import Dict, Any\\n\\n\\ndef render_markdown(root: str, repo_info:\\\n    \\ Dict[str, Any], tree_text: str, \\n                   files: Dict[str, str],\\\n    \\ total_files: int, total_lines: int, recent_files=None, file_sizes=None) -> str:\\n\\\n    \\    \\\"\\\"\\\"Render repository context as markdown.\\\"\\\"\\\"\\n    \\n    lines = []\\n\\\n    \\    \\n    # Header\\n    lines.append(f\\\"# Repository Context: {root}\\\")\\n   \\\n    \\ lines.append(\\\"\\\")\\n    \\n    # Repository info\\n    if repo_info.get(\\\"is_repo\\\"\\\n    ):\\n        lines.append(\\\"## Git Repository Information\\\")\\n        lines.append(f\\\"\\\n    - **Branch**: {repo_info.get('branch', 'N/A')}\\\")\\n        lines.append(f\\\"- **Commit**:\\\n    \\ {repo_info.get('commit', 'N/A')}\\\")\\n        lines.append(f\\\"- **Author**: {repo_info.get('author',\\\n    \\ 'N/A')}\\\")\\n        lines.append(f\\\"- **Date**: {repo_info.get('date', 'N/A')}\\\"\\\n    )\\n    else:\\n        lines.append(\\\"## Repository Information\\\")\\n        lines.append(f\\\"\\\n    - **Note**: {repo_info.get('note', 'Not a git repository')}\\\")\\n    lines.append(\\\"\\\n    \\\")\\n    \\n    # Summary\\n    lines.append(\\\"## Summary\\\")\\n    lines.append(f\\\"\\\n    - **Total Files**: {total_files}\\\")\\n    lines.append(f\\\"- **Total Lines**: {total_lines}\\\"\\\n    )\\n    lines.append(\\\"\\\")\\n    \\n    # Directory structure\\n    lines.append(\\\"\\\n    ## Directory Structure\\\")\\n    lines.append(\\\"```\\\")\\n    lines.append(tree_text)\\n\\\n    \\    lines.append(\\\"```\\\")\\n    lines.append(\\\"\\\")\\n\\n    # will produce recent\\\n    \\ files \\n    # Recent files (fixed)\\n    if recent_files:\\n        lines.append(\\\"\\\n    ## Recent Changes\\\")\\n        for file, age in recent_files.items():\\n       \\\n    \\     lines.append(f\\\"- {file} (modified {age})\\\")\\n        lines.append(\\\"\\\"\\\n    )\\n    \\n    # File contents\\n    lines.append(\\\"## File Contents\\\")\\n    lines.append(\\\"\\\n    \\\")\\n    \\n    for file_path, content in sorted(files.items()):\\n        if file_sizes\\\n    \\ and file_path in file_sizes:\\n            size_bytes = file_sizes[file_path]\\n\\\n    \\            lines.append(f\\\"### {file_path} ({size_bytes} bytes)\\\")\\n       \\\n    \\ else:\\n            lines.append(f\\\"### {file_path}\\\")\\n        lines.append(\\\"\\\n    \\\")\\n        \\n        # Detect language for syntax highlighting\\n        ext\\\n    \\ = file_path.split('.')[-1].lower() if '.' in file_path else ''\\n        lang_map\\\n    \\ = {\\n            'py': 'python', 'js': 'javascript', 'ts': 'typescript',\\n \\\n    \\           'java': 'java', 'cpp': 'cpp', 'c': 'c', 'h': 'c',\\n            'cs':\\\n    \\ 'csharp', 'php': 'php', 'rb': 'ruby',\\n            'go': 'go', 'rs': 'rust',\\\n    \\ 'swift': 'swift',\\n            'html': 'html', 'css': 'css', 'scss': 'scss',\\n\\\n    \\            'json': 'json', 'yaml': 'yaml', 'yml': 'yaml',\\n            'xml':\\\n    \\ 'xml', 'sql': 'sql', 'sh': 'bash',\\n            'md': 'markdown', 'dockerfile':\\\n    \\ 'dockerfile'\\n        }\\n        \\n        language = lang_map.get(ext, '')\\n\\\n    \\        lines.append(f\\\"```{language}\\\")\\n        lines.append(content)\\n   \\\n    \\     lines.append(\\\"```\\\")\\n        lines.append(\\\"\\\")\\n    \\n    return \\\"\\\\\\\n    n\\\".join(lines)\\n\"\n  src/rcpack/treeview.py: \"\\\"\\\"\\\"Tree view generation for repository structure.\\\"\\\"\\\n    \\\"\\n\\nfrom pathlib import Path\\nfrom typing import Dict, List\\n\\n\\ndef create_tree_view(repo_path:\\\n    \\ Path, files_data: Dict[str, str]) -> str:\\n    \\\"\\\"\\\"Create a tree view of the\\\n    \\ repository structure.\\\"\\\"\\\"\\n    paths = list(files_data.keys())\\n    return\\\n    \\ render_tree(paths)\\n\\n\\ndef render_tree(paths: List[str]) -> str:\\n    \\\"\\\"\\\"\\\n    Render a tree view from a list of relative POSIX paths.\\\"\\\"\\\"\\n    tree_structure:\\\n    \\ dict = {}\\n\\n    for p in paths:\\n        parts = Path(p).parts\\n        current\\\n    \\ = tree_structure\\n        for part in parts[:-1]:\\n            if part not in\\\n    \\ current:\\n                current[part] = {}\\n            current = current[part]\\n\\\n    \\        if parts:\\n            current[parts[-1]] = None\\n\\n    def _render(structure:\\\n    \\ dict, prefix: str = \\\"\\\") -> str:\\n        lines = []\\n        items = sorted(structure.items(),\\\n    \\ key=lambda x: (x[1] is None, x[0]))\\n        for i, (name, subtree) in enumerate(items):\\n\\\n    \\            is_last = i == len(items) - 1\\n            lines.append(f\\\"{prefix}{'└──\\\n    \\ ' if is_last else '├── '}{name}\\\")\\n            if subtree is not None:\\n  \\\n    \\              extension = (\\\"    \\\" if is_last else \\\"│   \\\")\\n             \\\n    \\   lines.append(_render(subtree, prefix + extension))\\n        return \\\"\\\\n\\\"\\\n    .join(filter(None, lines))\\n\\n    if not tree_structure:\\n        return \\\"No\\\n    \\ files found\\\"\\n    return _render(tree_structure)\"\n  test-output.json: \"{\\n  \\\"root\\\": \\\"/Users/abhinavbhardwaj/Desktop/Semester 5/OSD600/Repo-Contextor\\\"\\\n    ,\\n  \\\"repo_info\\\": {\\n    \\\"is_repo\\\": true,\\n    \\\"commit\\\": \\\"682153b169db66d3a72e9cabdd1f3448a3b2986d\\\"\\\n    ,\\n    \\\"branch\\\": \\\"refactoring\\\",\\n    \\\"author\\\": \\\"Abhinav <abhinavbhardwaj2002@gmail.com>\\\"\\\n    ,\\n    \\\"date\\\": \\\"Fri Oct 3 18:45:48 2025\\\",\\n    \\\"note\\\": null\\n  },\\n  \\\"\\\n    structure\\\": \\\"├── src\\\\n│   └── rcpack\\\\n│       ├── renderer\\\\n│       │   ├──\\\n    \\ jsonyaml.py\\\\n│       │   └── markdown.py\\\\n│       ├── __init__.py\\\\n│    \\\n    \\   ├── __main__.py\\\\n│       ├── cli.py\\\\n│       ├── config_loader.py\\\\n│  \\\n    \\     ├── discover.py\\\\n│       ├── gitinfo.py\\\\n│       ├── io_utils.py\\\\n│ \\\n    \\      ├── packager.py\\\\n│       └── treeview.py\\\\n├── LICENSE\\\\n├── README.md\\\\\\\n    n└── pyproject.toml\\\",\\n  \\\"recent_changes\\\": [],\\n  \\\"files\\\": {\\n    \\\"LICENSE\\\"\\\n    : \\\"MIT License\\\\n\\\\nCopyright (c) 2025 Abhinav\\\\n\\\\nPermission is hereby granted,\\\n    \\ free of charge, to any person obtaining a copy\\\\nof this software and associated\\\n    \\ documentation files (the \\\\\\\"Software\\\\\\\"), to deal\\\\nin the Software without\\\n    \\ restriction, including without limitation the rights\\\\nto use, copy, modify,\\\n    \\ merge, publish, distribute, sublicense, and/or sell\\\\ncopies of the Software,\\\n    \\ and to permit persons to whom the Software is\\\\nfurnished to do so, subject\\\n    \\ to the following conditions:\\\\n\\\\nThe above copyright notice and this permission\\\n    \\ notice shall be included in all\\\\ncopies or substantial portions of the Software.\\\\\\\n    n\\\\nTHE SOFTWARE IS PROVIDED \\\\\\\"AS IS\\\\\\\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\\\n    \\ OR\\\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\\\\n    nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\\\\n    nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\nLIABILITY,\\\n    \\ WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\nOUT OF\\\n    \\ OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\nSOFTWARE.\\\\\\\n    n\\\",\\n    \\\"README.md\\\": \\\"# Repo-Contextor\\\\n\\\\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\\\\\\\n    n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\\\\\\n    n\\\\nA powerful Repository Context Packager CLI tool that analyzes local git repositories\\\n    \\ and creates comprehensive text files containing repository content optimized\\\n    \\ for sharing with Large Language Models (LLMs).\\\\n\\\\n## Overview\\\\n\\\\nWhen developers\\\n    \\ want to get help from ChatGPT, Claude, or other LLMs about their code, they\\\n    \\ often struggle with how to share their codebase effectively. Common problems\\\n    \\ include:\\\\n\\\\n- **Lost Context**: Copy-pasting individual files loses important\\\n    \\ project structure and relationships\\\\n- **Missing Dependencies**: LLMs can't\\\n    \\ see how files connect or what libraries are used\\\\n- **Incomplete Picture**:\\\n    \\ Hard to convey the overall architecture and organization\\\\n- **Manual Work**:\\\n    \\ Time-consuming to gather and format relevant code\\\\n\\\\n**Repo-Contextor** solves\\\n    \\ this by automatically collecting and formatting repository content into a single,\\\n    \\ well-structured text file that provides rich context to LLMs, enabling them\\\n    \\ to give much better assistance with your code.\\\\n\\\\n## Features\\\\n\\\\n- **Git\\\n    \\ Integration**: Extracts commit SHA, branch, author, and date information\\\\n-\\\n    \\ **Project Structure**: Generates a clear directory tree visualization\\\\n- **File\\\n    \\ Content Packaging**: Includes file contents with syntax highlighting\\\\n- **Smart\\\n    \\ File Discovery**: Recursively scans directories with intelligent filtering\\\\\\\n    n- **Binary File Detection**: Automatically skips binary files\\\\n- **Error Handling**:\\\n    \\ Gracefully handles permission errors and provides helpful messages\\\\n- **Multiple\\\n    \\ Output Formats**: Supports Markdown, JSON, and YAML formats\\\\n- **Flexible Output**:\\\n    \\ Write to stdout or save to a file\\\\n- **Recent Changes Filter**: Give the files\\\n    \\ which are updated in last 7days with the time when it was recently modified.\\\\\\\n    n\\\\n## Installation\\\\n\\\\n### Prerequisites\\\\n\\\\n- Python 3.9 or higher\\\\n- Git\\\n    \\ (for git repository analysis)\\\\n\\\\n### For End Users\\\\n\\\\n```bash\\\\n# Clone\\\n    \\ and install\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    ncd Repo-Contextor\\\\npip install -e .\\\\n```\\\\n\\\\n### For Contributors & Local\\\n    \\ Development\\\\n\\\\n```bash\\\\n# Clone the repository\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    ncd Repo-Contextor\\\\n\\\\n# Create virtual environment\\\\npython -m venv .venv\\\\\\\n    nsource .venv/bin/activate  # On Windows: .venv\\\\\\\\Scripts\\\\\\\\activate\\\\n\\\\n#\\\n    \\ Install in development mode\\\\npip install -e .\\\\n```\\\\n\\\\n## Usage\\\\n\\\\n###\\\n    \\ Basic Examples\\\\n\\\\n```bash\\\\n# Package current directory to terminal\\\\nrepo-contextor\\\n    \\ .\\\\n\\\\n# Package a specific directory\\\\nrepo-contextor /path/to/your/project\\\\\\\n    n\\\\n# Save output to a file\\\\nrepo-contextor . -o my-project-context.md\\\\n\\\\n#\\\n    \\ Generate JSON format\\\\nrepo-contextor . -f json -o context.json\\\\n\\\\n# Generate\\\n    \\ YAML format\\\\nrepo-contextor . -f yaml -o context.yaml\\\\n\\\\n# Include only files\\\n    \\ modified in the last 7 days\\\\nrepo-contextor . --recent\\\\n\\\\n# Combine with\\\n    \\ output file\\\\nrepo-contextor . --recent -o recent-changes.md\\\\n```\\\\n\\\\n###\\\n    \\ Command Line Options\\\\n\\\\n| Option | Short | Description | Example |\\\\n|--------|-------|-------------|---------|\\\\\\\n    n| `path` | - | Repository path to analyze (default: current directory) | `repo-contextor\\\n    \\ /path/to/project` |\\\\n| `--output` | `-o` | Output file path (default: stdout)\\\n    \\ | `-o context.md` |\\\\n| `--format` | `-f` | Output format: text, json, yaml\\\n    \\ (default: text) | `-f json` |\\\\n| `--help` | `-h` | Show help message | `-h`\\\n    \\ |\\\\n| `--recent`  | `-r`  | Include only files modified in the last 7 days \\\n    \\   | `repo-contextor . -r -o recent.md` |\\\\n\\\\n### Advanced Examples\\\\n\\\\n```bash\\\\\\\n    n# Analyze different repository\\\\nrepo-contextor /path/to/other/project -o other-project.md\\\\\\\n    n\\\\n# Generate JSON for API consumption\\\\nrepo-contextor . -f json -o api-context.json\\\\\\\n    n\\\\n# Create YAML configuration\\\\nrepo-contextor . -f yaml -o project-config.yaml\\\\\\\n    n\\\\n# Generate files which are changed recently in 7 days\\\\nrepo-contextor . -r\\\n    \\ --output recent-changes.txt\\\\n\\\\n```\\\\n## Configuration via TOML\\\\n\\\\nRepo-Contextor\\\n    \\ supports configuration through a `.repo-contextor.toml` file in the current\\\n    \\ working directory.  \\\\nThis file allows you to avoid typing the same CLI arguments\\\n    \\ every time.\\\\n\\\\nExample `.repo-contextor.toml`:\\\\n\\\\n```toml\\\\n# Output file\\\n    \\ to write results\\\\noutput = \\\\\\\"context.yaml\\\\\\\"\\\\n\\\\n# Output format: text,\\\n    \\ json, or yaml\\\\nformat = \\\\\\\"yaml\\\\\\\"\\\\n\\\\n# Limit to files modified in the\\\n    \\ last 7 days\\\\nrecent = true\\\\n\\\\n# Repository path to analyze (default = current\\\n    \\ directory)\\\\npath = \\\\\\\".\\\\\\\"\\\\n```\\\\n### Rules\\\\n- If the `.repo-contextor.toml`\\\n    \\ file is **missing**, the tool falls back to defaults.  \\\\n- If the file is **present\\\n    \\ but invalid TOML**, the tool prints a clear error message and exits with status\\\n    \\ code 1.  \\\\n- **Unknown keys** in the TOML file are ignored (safe for future\\\n    \\ extensions).  \\\\n- **Precedence** of settings is:\\\\n  1. Command-line arguments\\\n    \\ (highest priority)  \\\\n  2. Values from `.repo-contextor.toml`  \\\\n  3. Built-in\\\n    \\ defaults (lowest priority)\\\\n     \\\\n## Output Format\\\\n\\\\nThe tool generates\\\n    \\ a structured text file with the following sections:\\\\n\\\\n### 1. Repository Context\\\n    \\ Header\\\\nProject path and identification\\\\n\\\\n### 2. Git Repository Information\\\\\\\n    n- Current branch\\\\n- Latest commit SHA\\\\n- Last commit author\\\\n- Last commit\\\n    \\ date\\\\n\\\\n### 3. Summary Statistics\\\\n- Total number of files processed\\\\n-\\\n    \\ Total lines of code\\\\n\\\\n### 4. Directory Structure\\\\nClean tree visualization\\\n    \\ showing project organization\\\\n\\\\n### 5. Recent Changes (if `--recent` is used)\\\\\\\n    n\\\\n- Lists files modified in the last 7 days.\\\\n- Shows relative file paths along\\\n    \\ with how long ago each file was modified\\\\n- Helps focus on recently updated\\\n    \\ parts of the project.\\\\n- Can be combined with `--output` or `--format` to save\\\n    \\ or change the output type.\\\\n\\\\n\\\\n### 5. File Contents\\\\nEach file's content\\\n    \\ with:\\\\n- Clear file path headers\\\\n- Appropriate syntax highlighting language\\\n    \\ tags\\\\n- Complete file contents\\\\n\\\\n## Example Output\\\\n\\\\nWhen you run `repo-contextor\\\n    \\ .`, the output looks like this:\\\\n\\\\n````markdown\\\\n# Repository Context: /path/to/your/project\\\\\\\n    n\\\\n## Git Repository Information\\\\n- **Branch**: main\\\\n- **Commit**: a1b2c3d4e5f6789...\\\\\\\n    n- **Author**: John Doe <john@example.com>\\\\n- **Date**: Fri Sep 12 14:30:15 2025\\\\\\\n    n\\\\n## Summary\\\\n- **Total Files**: 15\\\\n- **Total Lines**: 1,247\\\\n\\\\n## Directory\\\n    \\ Structure\\\\n```\\\\n├── src/\\\\n│   ├── main.py\\\\n│   └── utils.py\\\\n├── tests/\\\\\\\n    n│   └── test_main.py\\\\n├── README.md\\\\n└── requirements.txt\\\\n```\\\\n## Recent\\\n    \\ Changes\\\\n- src/main.py (modified 2 days ago)\\\\n- src/utils/helpers.py (modified\\\n    \\ 5 days ago)\\\\n\\\\n## File Contents\\\\n\\\\n### src/main.py\\\\n\\\\n```python\\\\ndef\\\n    \\ main():\\\\n    print(\\\\\\\"Hello, World!\\\\\\\")\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\n    \\\":\\\\n    main()\\\\n```\\\\n\\\\n### README.md\\\\n\\\\n```markdown\\\\n# My Project\\\\nThis\\\n    \\ is a sample project.\\\\n```\\\\n\\\\n## Summary\\\\n- Total files: 15\\\\n- Total lines:\\\n    \\ 1,247\\\\n````\\\\n\\\\n## What Files Are Included\\\\n\\\\nThe tool includes most text\\\n    \\ files but automatically excludes:\\\\n\\\\n### Excluded Directories\\\\n- `.git`,\\\n    \\ `.svn`, `.hg` (version control)\\\\n- `__pycache__`, `.pytest_cache` (Python cache)\\\\\\\n    n- `node_modules`, `.venv`, `venv` (dependencies/environments)\\\\n- `.vscode`,\\\n    \\ `.idea` (IDE directories)\\\\n- `build`, `dist`, `target` (build directories)\\\\\\\n    n\\\\n### File Handling Rules\\\\n- **Text files**: All readable text files with common\\\n    \\ extensions\\\\n- **Binary files**: Automatically detected and skipped\\\\n- **Permission\\\n    \\ errors**: Skipped with graceful handling\\\\n- **Configuration files**: Includes\\\n    \\ pyproject.toml, package.json, etc.\\\\n\\\\n### Included File Types\\\\n- Source code:\\\n    \\ `.py`, `.js`, `.ts`, `.java`, `.cpp`, `.c`, `.go`, `.rs`, etc.\\\\n- Web files:\\\n    \\ `.html`, `.css`, `.scss`, `.vue`, `.jsx`, etc.\\\\n- Documentation: `.md`, `.txt`,\\\n    \\ `.rst`\\\\n- Configuration: `.json`, `.yaml`, `.toml`, `.ini`, `.cfg`\\\\n- Scripts:\\\n    \\ `.sh`, `.bash`, `.zsh`\\\\n\\\\n## Error Handling\\\\n\\\\nThe tool handles errors gracefully:\\\\\\\n    n\\\\n| Error Type | Behavior |\\\\n|------------|----------|\\\\n| **Permission errors**\\\n    \\ | Skipped with warning |\\\\n| **Binary files** | Automatically detected and skipped\\\n    \\ |\\\\n| **Invalid paths** | Clear error messages |\\\\n| **Non-git repositories**\\\n    \\ | Works fine, shows \\\\\\\"Not a git repository\\\\\\\" |\\\\n| **Unreadable files**\\\n    \\ | Marked as \\\\\\\"[Binary or unreadable file]\\\\\\\" |\\\\n\\\\n## Development\\\\n\\\\n###\\\n    \\ Project Structure\\\\n\\\\n```text\\\\nRepo-Contextor/\\\\n├── src/rcpack/         \\\n    \\     # Main package\\\\n│   ├── __init__.py         # Package initialization\\\\\\\n    n│   ├── cli.py              # Command-line interface\\\\n│   ├── discover.py  \\\n    \\       # File discovery logic\\\\n│   ├── gitinfo.py          # Git repository\\\n    \\ analysis\\\\n│   ├── treeview.py         # Directory tree generation\\\\n│   ├──\\\n    \\ packager.py         # Main orchestration\\\\n│   ├── io_utils.py         # File\\\n    \\ I/O utilities\\\\n│   └── renderer/           # Output formatters\\\\n│       ├──\\\n    \\ markdown.py     # Markdown renderer\\\\n│       └── jsonyaml.py     # JSON/YAML\\\n    \\ renderers\\\\n├── pyproject.toml          # Project configuration\\\\n├── LICENSE\\\n    \\                 # MIT License\\\\n└── README.md              # This documentation\\\\\\\n    n```\\\\n\\\\n### Running Tests\\\\n\\\\n```bash\\\\n# Test on current repository\\\\nrepo-contextor\\\n    \\ . -o test-output.md\\\\n\\\\n# Test different formats\\\\nrepo-contextor . -f json\\\n    \\ | head -20\\\\nrepo-contextor . -f yaml | head -20\\\\n\\\\n# Test specific directory\\\\\\\n    nrepo-contextor src/ -o src-only.md\\\\n```\\\\n\\\\n### Contributing\\\\n\\\\n1. **Fork\\\n    \\ the repository**\\\\n2. **Clone your fork:**\\\\n   ```bash\\\\n   git clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    n   cd Repo-Contextor\\\\n   ```\\\\n3. **Install for development:**\\\\n   ```bash\\\\\\\n    n   python -m venv .venv\\\\n   source .venv/bin/activate\\\\n   pip install -e .\\\\\\\n    n   ```\\\\n4. **Make your changes and test:**\\\\n   ```bash\\\\n   repo-contextor\\\n    \\ . -o test.md\\\\n   ```\\\\n5. **Submit a pull request**\\\\n\\\\n### Development Workflow\\\\\\\n    n\\\\n```bash\\\\n# 1. Setup development environment\\\\ngit clone https://github.com/yourusername/Repo-Contextor.git\\\\\\\n    ncd Repo-Contextor\\\\npython -m venv .venv\\\\nsource .venv/bin/activate\\\\npip install\\\n    \\ -e .\\\\n\\\\n# 2. Make changes to the code\\\\n# Edit files in src/rcpack/\\\\n\\\\n#\\\n    \\ 3. Test your changes\\\\nrepo-contextor . -o test-output.md\\\\n\\\\n# 4. Test different\\\n    \\ formats\\\\nrepo-contextor . -f json -o test.json\\\\nrepo-contextor . -f yaml -o\\\n    \\ test.yaml\\\\n\\\\n# 5. Commit and push changes\\\\ngit add .\\\\ngit commit -m \\\\\\\"\\\n    Add new feature\\\\\\\"\\\\ngit push origin feature-branch\\\\n```\\\\n\\\\n## License\\\\n\\\\\\\n    nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file\\\n    \\ for details.\\\\n\\\\n## Why Repo-Contextor?\\\\n\\\\nThe name \\\\\\\"Repo-Contextor\\\\\\\"\\\n    \\ combines \\\\\\\"Repository\\\\\\\" + \\\\\\\"Context\\\\\\\" + \\\\\\\"or\\\\\\\", representing the\\\n    \\ tool's purpose of providing rich context about code repositories in a format\\\n    \\ that's perfect for LLM interactions.\\\\n\\\\n### Use Cases\\\\n\\\\n- **AI Assistance**:\\\n    \\ Get better help from ChatGPT, Claude, or GitHub Copilot\\\\n- **Code Reviews**:\\\n    \\ Share complete project context with team members\\\\n- **Documentation**: Create\\\n    \\ comprehensive project snapshots\\\\n- **Onboarding**: Help new team members understand\\\n    \\ project structure\\\\n- **Project Analysis**: Understand repository structure\\\n    \\ and dependencies\\\\n\\\\n### Perfect for LLMs\\\\n\\\\nThe output format is specifically\\\n    \\ designed to work well with Large Language Models:\\\\n- Clear section headers\\\n    \\ for easy parsing\\\\n- Syntax highlighting markers for code blocks\\\\n- Structured\\\n    \\ metadata (git info, file locations)\\\\n- Complete project context in a single\\\n    \\ file\\\\n- Multiple output formats (Markdown, JSON, YAML)\\\\n- Optimized for token\\\n    \\ efficiency\\\\n\\\",\\n    \\\"pyproject.toml\\\": \\\"[build-system]\\\\nrequires = [\\\\\\\"\\\n    setuptools>=68\\\\\\\", \\\\\\\"wheel\\\\\\\"]\\\\nbuild-backend = \\\\\\\"setuptools.build_meta\\\\\\\n    \\\"\\\\n\\\\n[project]\\\\nname = \\\\\\\"rcpack\\\\\\\"\\\\nversion = \\\\\\\"0.1.0\\\\\\\"\\\\ndescription\\\n    \\ = \\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\"\\\\nreadme = \\\\\\\"README.md\\\\\\\n    \\\"\\\\nrequires-python = \\\\\\\">=3.9\\\\\\\"\\\\nlicense = { text = \\\\\\\"MIT\\\\\\\" }\\\\ndependencies\\\n    \\ = [\\\\n    \\\\\\\"PyYAML>=6.0\\\\\\\"\\\\n]\\\\n\\\\n[project.scripts]\\\\nrepo-contextor =\\\n    \\ \\\\\\\"rcpack.cli:main\\\\\\\"\\\\n\\\",\\n    \\\"src/rcpack/__init__.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\n    Repository Context Packager - CLI tool for creating LLM-optimized repository context.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n\\\\n__version__ = \\\\\\\"0.1.0\\\\\\\"\\\\n__author__ = \\\\\\\"Abhinav\\\\\\\"\\\\n__description__\\\n    \\ = \\\\\\\"Repository Context Packager CLI for LLMs\\\\\\\"\\\",\\n    \\\"src/rcpack/__main__.py\\\"\\\n    : \\\"#!/usr/bin/env python3\\\\n\\\\\\\"\\\\\\\"\\\\\\\"Module entry point to enable `python\\\n    \\ -m rcpack`.\\\\n\\\\nThis simply delegates to the CLI's main() function.\\\\n\\\\\\\"\\\\\\\n    \\\"\\\\\\\"\\\\n\\\\nfrom .cli import main\\\\n\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\n    \\    main()\\\\n\\\\n\\\\n\\\",\\n    \\\"src/rcpack/cli.py\\\": \\\"#!/usr/bin/env python3\\\\\\\n    n\\\\\\\"\\\\\\\"\\\\\\\"CLI for Repository Context Packager.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom .config_loader\\\n    \\ import load_config\\\\n\\\\nimport argparse\\\\nimport sys\\\\nfrom pathlib import Path\\\\\\\n    nfrom .gitinfo import get_git_info\\\\nfrom .discover import discover_files\\\\nfrom\\\n    \\ .treeview import create_tree_view\\\\nfrom .renderer.markdown import render_markdown\\\\\\\n    nfrom .renderer.jsonyaml import render_json, render_yaml\\\\nfrom .io_utils import\\\n    \\ write_output\\\\nfrom datetime import datetime, timedelta\\\\n\\\\n\\\\ndef log_verbose(message:\\\n    \\ str, verbose: bool) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Log a message to stderr if verbose\\\n    \\ mode is enabled.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if verbose:\\\\n        print(message, file=sys.stderr)\\\\\\\n    n\\\\n\\\\ndef get_rendered_content(format_type: str, repo_path: str, repo_info: dict,\\\n    \\ tree_text: str, \\\\n                        files_data: dict, total_files: int,\\\n    \\ total_lines: int, \\\\n                        recent_files_info: dict, file_sizes:\\\n    \\ dict) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Get rendered content based on the specified\\\n    \\ format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if format_type == \\\\\\\"json\\\\\\\":\\\\n        return render_json(\\\\\\\n    n            repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\n    \\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\\\\n    n        )\\\\n    elif format_type == \\\\\\\"yaml\\\\\\\":\\\\n        return render_yaml(\\\\\\\n    n            repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\n    \\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\\\\n    n        )\\\\n    else:  # text/markdown\\\\n        return render_markdown(\\\\n \\\n    \\           repo_path, repo_info, tree_text, \\\\n            files_data, total_files,\\\n    \\ total_lines,\\\\n            recent_files=recent_files_info,\\\\n            file_sizes=file_sizes\\\\\\\n    n        )\\\\n\\\\n\\\\ndef process_file(file_path: Path, repo_path: Path, verbose:\\\n    \\ bool) -> tuple[str, str, str]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Process a single file and return\\\n    \\ its data.\\\\n    \\\\n    Returns:\\\\n        tuple: (relative_path_str, content,\\\n    \\ file_size)\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    relative_path = file_path.relative_to(repo_path)\\\\\\\n    n    relative_path_str = str(relative_path)\\\\n    \\\\n    log_verbose(f\\\\\\\"Reading\\\n    \\ file: {relative_path}\\\\\\\", verbose)\\\\n    file_size = file_path.stat().st_size\\\\\\\n    n    \\\\n    try:\\\\n        with open(file_path, 'r', encoding='utf-8') as f:\\\\\\\n    n            content = f.read()\\\\n        return relative_path_str, content, str(file_size)\\\\\\\n    n    except (UnicodeDecodeError, PermissionError):\\\\n        log_verbose(f\\\\\\\"\\\n    Skipping binary/unreadable file: {relative_path}\\\\\\\", verbose)\\\\n        file_size\\\n    \\ = file_path.stat().st_size if file_path.exists() else 0\\\\n        content =\\\n    \\ f\\\\\\\"[Binary or unreadable file: {file_path.name}]\\\\\\\"\\\\n        return relative_path_str,\\\n    \\ content, str(file_size)\\\\n    except Exception:\\\\n        log_verbose(f\\\\\\\"\\\n    Error reading file: {relative_path}\\\\\\\", verbose)\\\\n        raise  # Re-raise\\\n    \\ to handle in calling code\\\\n\\\\n\\\\ndef handle_output(content: str, output_path:\\\n    \\ str = None) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Handle output to either file or stdout.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n    if output_path:\\\\n        # Write to file\\\\n        write_output(output_path,\\\n    \\ content)\\\\n        print(f\\\\\\\"Context package created: {output_path}\\\\\\\")\\\\\\\n    n    else:\\\\n        # Output to stdout\\\\n        print(content)\\\\n\\\\n\\\\ndef main():\\\\\\\n    n    parser = argparse.ArgumentParser(\\\\n        description=\\\\\\\"Package repository\\\n    \\ content for LLM context\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"\\\n    path\\\\\\\", \\\\n        nargs=\\\\\\\"?\\\\\\\", \\\\n        default=\\\\\\\".\\\\\\\", \\\\n      \\\n    \\  help=\\\\\\\"Repository path (default: current directory)\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\\\\n    n        \\\\\\\"-o\\\\\\\", \\\\\\\"--output\\\\\\\", \\\\n        help=\\\\\\\"Output file path (default:\\\n    \\ stdout)\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"-f\\\\\\\", \\\\\\\"--format\\\\\\\n    \\\", \\\\n        choices=[\\\\\\\"text\\\\\\\", \\\\\\\"json\\\\\\\", \\\\\\\"yaml\\\\\\\"], \\\\n       \\\n    \\ default=\\\\\\\"text\\\\\\\",\\\\n        help=\\\\\\\"Output format (default: text)\\\\\\\"\\\\\\\n    n    )\\\\n\\\\n    \\\\\\\"\\\\\\\"\\\\\\\" This will read -r from the console and able to search\\\n    \\ it with this\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    parser.add_argument(\\\\n    \\\\\\\"-r\\\\\\\", \\\\\\\"--recent\\\\\\\n    \\\",\\\\n    action=\\\\\\\"store_true\\\\\\\",\\\\n    help=\\\\\\\"Include only files modified\\\n    \\ in the last 7 days\\\\\\\"\\\\n    )\\\\n    parser.add_argument(\\\\n        \\\\\\\"-v\\\\\\\n    \\\", \\\\\\\"--verbose\\\\\\\",\\\\n        action=\\\\\\\"store_true\\\\\\\",\\\\n        help=\\\\\\\"\\\n    Print detailed progress information to stderr\\\\\\\"\\\\n    )\\\\n    \\\\n    args =\\\n    \\ parser.parse_args()\\\\n    \\\\n    try:\\\\n        repo_path = Path(args.path).resolve()\\\\\\\n    n        if not repo_path.exists():\\\\n            print(f\\\\\\\"Error: Path {repo_path}\\\n    \\ does not exist\\\\\\\", file=sys.stderr)\\\\n            sys.exit(1)\\\\n          \\\n    \\  \\\\n        # Get repository information\\\\n        log_verbose(f\\\\\\\"Analyzing\\\n    \\ repository: {repo_path}\\\\\\\", args.verbose)\\\\n        repo_info = get_git_info(repo_path)\\\\\\\n    n        \\\\n        # Discover files\\\\n        log_verbose(f\\\\\\\"Discovering files\\\n    \\ in: {repo_path}\\\\\\\", args.verbose)\\\\n        discovered_files = discover_files([repo_path],\\\n    \\ repo_path, [], [])\\\\n        log_verbose(f\\\\\\\"Found {len(discovered_files)}\\\n    \\ files\\\\\\\", args.verbose)\\\\n        \\\\n        # will check the file in last\\\n    \\ 7 days\\\\n        recent_files_info = {}\\\\n        if args.recent:\\\\n       \\\n    \\     seven_days_ago = datetime.now() - timedelta(days=7)\\\\n            recent_files\\\n    \\ = []\\\\n            for f in discovered_files:\\\\n                try:\\\\n    \\\n    \\                mtime = datetime.fromtimestamp(f.stat().st_mtime)\\\\n        \\\n    \\            if mtime >= seven_days_ago:\\\\n                        recent_files.append(f)\\\\\\\n    n                        recent_files_info[str(f.relative_to(repo_path))] = human_readable_age(mtime)\\\n    \\     \\\\n                except Exception:\\\\n                    continue\\\\n \\\n    \\           discovered_files = recent_files\\\\n        \\\\n        # Read file contents\\\\\\\n    n        files_data = {}\\\\n        file_sizes = {}\\\\n        for file_path in\\\n    \\ discovered_files:\\\\n            try:\\\\n                relative_path_str, content,\\\n    \\ file_size = process_file(file_path, repo_path, args.verbose)\\\\n            \\\n    \\    files_data[relative_path_str] = content\\\\n                file_sizes[relative_path_str]\\\n    \\ = file_size\\\\n            except Exception:\\\\n                continue\\\\n  \\\n    \\      \\\\n        # Create tree view\\\\n        log_verbose(\\\\\\\"Generating directory\\\n    \\ tree\\\\\\\", args.verbose)\\\\n        tree_text = create_tree_view(repo_path, files_data)\\\\\\\n    n        \\\\n        # Count totals\\\\n        total_files = len(files_data)\\\\n\\\n    \\        total_lines = sum(len(content.splitlines()) for _, content in files_data.items())\\\\\\\n    n        \\\\n        # Render based on format\\\\n        log_verbose(f\\\\\\\"Rendering\\\n    \\ output in {args.format} format\\\\\\\", args.verbose)\\\\n        content = get_rendered_content(\\\\\\\n    n            args.format, str(repo_path), repo_info, tree_text,\\\\n           \\\n    \\ files_data, total_files, total_lines,\\\\n            recent_files_info if args.recent\\\n    \\ else {},\\\\n            file_sizes\\\\n        )\\\\n        \\\\n        handle_output(content,\\\n    \\ args.output)\\\\n        \\\\n    except Exception as e:\\\\n        print(f\\\\\\\"Error:\\\n    \\ {e}\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\n# this will convert age\\\n    \\ and give us the difference\\\\ndef human_readable_age(mtime: datetime) -> str:\\\\\\\n    n    delta = datetime.now() - mtime\\\\n    days = delta.days\\\\n    seconds = delta.seconds\\\\\\\n    n    if days > 0:\\\\n        return f\\\\\\\"{days} day{'s' if days != 1 else ''} ago\\\\\\\n    \\\"\\\\n    elif seconds >= 3600:\\\\n        hours = seconds // 3600\\\\n        return\\\n    \\ f\\\\\\\"{hours} hour{'s' if hours != 1 else ''} ago\\\\\\\"\\\\n    elif seconds >= 60:\\\\\\\n    n        minutes = seconds // 60\\\\n        return f\\\\\\\"{minutes} minute{'s' if\\\n    \\ minutes != 1 else ''} ago\\\\\\\"\\\\n    else:\\\\n        return \\\\\\\"just now\\\\\\\"\\\\\\\n    n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\\n\\\",\\n    \\\"src/rcpack/config_loader.py\\\"\\\n    : \\\"# src/rcpack/config_loader.py\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nTOML config loader for Repo-Contextor.\\\\\\\n    n\\\\nRules:\\\\n- Look for .repo-contextor.toml in the CURRENT directory\\\\n- If missing:\\\n    \\ ignore\\\\n- If present but invalid: print a clear error and exit(1)\\\\n- Only\\\n    \\ recognized keys are applied; unknown keys ignored\\\\n- Precedence: CLI > TOML\\\n    \\ > DEFAULTS\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nfrom __future__ import annotations\\\\nimport os,\\\n    \\ sys\\\\nfrom typing import Dict, Iterable, Any\\\\n\\\\ntry:\\\\n    import tomllib\\\\\\\n    n    _loads = tomllib.loads\\\\nexcept ModuleNotFoundError:\\\\n    try:\\\\n      \\\n    \\  import tomli\\\\n        _loads = tomli.loads\\\\n    except ModuleNotFoundError:\\\\\\\n    n        _loads = None\\\\n\\\\ndef _need_toml():\\\\n    if _loads is None:\\\\n    \\\n    \\    print(\\\\\\\"Error: TOML parser not available. Use Python 3.11+ or `pip install\\\n    \\ tomli`.\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\ndef _load_toml(dotfile:\\\n    \\ str) -> Dict[str, Any]:\\\\n    _need_toml()\\\\n    if not os.path.exists(dotfile):\\\\\\\n    n        return {}\\\\n    try:\\\\n        with open(dotfile, \\\\\\\"rb\\\\\\\") as f:\\\\\\\n    n            raw = f.read().decode(\\\\\\\"utf-8\\\\\\\", errors=\\\\\\\"strict\\\\\\\")\\\\n  \\\n    \\      data = _loads(raw)\\\\n        return data if isinstance(data, dict) else\\\n    \\ {}\\\\n    except Exception as e:\\\\n        print(f\\\\\\\"Error: failed to parse\\\n    \\ {dotfile} as TOML.\\\\\\\\n{e}\\\\\\\", file=sys.stderr)\\\\n        sys.exit(1)\\\\n\\\\\\\n    ndef _filter_known(d: Dict[str, Any], known: Iterable[str]) -> Dict[str, Any]:\\\\\\\n    n    ks = set(known)\\\\n    return {k: v for k, v in d.items() if k in ks}\\\\n\\\\\\\n    ndef _merge(defaults: Dict[str, Any], filecfg: Dict[str, Any], clicfg: Dict[str,\\\n    \\ Any], known: Iterable[str]) -> Dict[str, Any]:\\\\n    ks = set(known)\\\\n    out:\\\n    \\ Dict[str, Any] = {k: defaults.get(k) for k in ks}\\\\n    for src in (filecfg,\\\n    \\ clicfg):\\\\n        for k, v in src.items():\\\\n            if k in ks and v is\\\n    \\ not None:\\\\n                out[k] = v\\\\n    return out\\\\n\\\\ndef load_config(*,\\\n    \\ dotfile: str = \\\\\\\".repo-contextor.toml\\\\\\\", defaults: Dict[str, Any] | None\\\n    \\ = None, cli_cfg: Dict[str, Any] | None = None, known_keys: Iterable[str] = ())\\\n    \\ -> Dict[str, Any]:\\\\n    defaults = defaults or {}\\\\n    cli_cfg = cli_cfg or\\\n    \\ {}\\\\n    known = tuple(known_keys)\\\\n    filecfg = _filter_known(_load_toml(dotfile),\\\n    \\ known)\\\\n    return _merge(defaults, filecfg, cli_cfg, known)\\\\n\\\",\\n    \\\"\\\n    src/rcpack/discover.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"File discovery module for repository analysis.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom pathlib import Path\\\\nfrom typing import List\\\\nimport fnmatch\\\\\\\n    n\\\\n\\\\ndef discover_files(\\\\n    inputs: List[Path],\\\\n    root: Path,\\\\n    include_patterns:\\\n    \\ List[str],\\\\n    exclude_patterns: List[str],\\\\n) -> List[Path]:\\\\n    \\\\\\\"\\\\\\\n    \\\"\\\\\\\"Discover relevant files.\\\\n\\\\n    - inputs: list of files/dirs to scan\\\\\\\n    n    - root: common project root; patterns are matched against POSIX paths relative\\\n    \\ to root\\\\n    - include_patterns: glob patterns to include (if empty, use sensible\\\n    \\ defaults)\\\\n    - exclude_patterns: glob patterns to exclude\\\\n    Returns a\\\n    \\ list of absolute Paths to files.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    default_include_exts\\\n    \\ = {\\\\n        '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',\\\\\\\n    n        '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\\\\n   \\\n    \\     '.html', '.css', '.scss', '.sass', '.less', '.vue', '.svelte',\\\\n      \\\n    \\  '.md', '.txt', '.rst', '.yaml', '.yml', '.json', '.toml', '.ini',\\\\n      \\\n    \\  '.cfg', '.conf', '.xml', '.sql', '.sh', '.bash', '.zsh', '.fish',\\\\n    }\\\\\\\n    n\\\\n    always_include_names = {\\\\n        'README', 'LICENSE', 'CHANGELOG', 'CONTRIBUTING',\\\n    \\ 'Makefile',\\\\n        'requirements.txt', 'package.json', 'Cargo.toml', 'pyproject.toml',\\\\\\\n    n        'setup.py', 'setup.cfg', 'pom.xml', 'build.gradle', '.gitignore', '.gitattributes'\\\\\\\n    n    }\\\\n\\\\n    skip_dir_names = {\\\\n        '.git', '.svn', '.hg', '__pycache__',\\\n    \\ '.pytest_cache',\\\\n        'node_modules', '.venv', 'venv', 'env', '.env',\\\\\\\n    n        'build', 'dist', 'target', 'out', '.next', '.nuxt',\\\\n        '.idea',\\\n    \\ '.vscode', '.vs', 'coverage', '.coverage'\\\\n    }\\\\n\\\\n    def matches_any(patterns:\\\n    \\ List[str], rel_posix: str) -> bool:\\\\n        return any(fnmatch.fnmatch(rel_posix,\\\n    \\ pat) for pat in patterns)\\\\n\\\\n    def should_take(file_path: Path) -> bool:\\\\\\\n    n        rel_posix = file_path.relative_to(root).as_posix()\\\\n        if exclude_patterns\\\n    \\ and matches_any(exclude_patterns, rel_posix):\\\\n            return False\\\\n\\\n    \\        if include_patterns:\\\\n            return matches_any(include_patterns,\\\n    \\ rel_posix)\\\\n        # default include logic\\\\n        return file_path.name\\\n    \\ in always_include_names or file_path.suffix.lower() in default_include_exts\\\\\\\n    n\\\\n    discovered: list[Path] = []\\\\n    seen = set()\\\\n\\\\n    for item in inputs:\\\\\\\n    n        p = item.resolve()\\\\n        if p.is_file():\\\\n            # Skip if\\\n    \\ excluded or in skipped directory\\\\n            if any(part in skip_dir_names\\\n    \\ for part in p.parts):\\\\n                continue\\\\n            if should_take(p):\\\\\\\n    n                key = p.as_posix()\\\\n                if key not in seen:\\\\n \\\n    \\                   seen.add(key)\\\\n                    discovered.append(p)\\\\\\\n    n        elif p.is_dir():\\\\n            for child in p.rglob('*'):\\\\n        \\\n    \\        if not child.is_file():\\\\n                    continue\\\\n           \\\n    \\     if any(part in skip_dir_names for part in child.parts):\\\\n             \\\n    \\       continue\\\\n                if should_take(child):\\\\n                 \\\n    \\   key = child.resolve().as_posix()\\\\n                    if key not in seen:\\\\\\\n    n                        seen.add(key)\\\\n                        discovered.append(child.resolve())\\\\\\\n    n\\\\n    return sorted(discovered)\\\",\\n    \\\"src/rcpack/gitinfo.py\\\": \\\"from __future__\\\n    \\ import annotations\\\\n\\\\nimport subprocess\\\\nfrom pathlib import Path\\\\nfrom\\\n    \\ typing import Dict, Any\\\\n\\\\n\\\\ndef _git(cmd: list[str], cwd: Path) -> str:\\\\\\\n    n    # Validate git commands to prevent injection\\\\n    allowed_commands = {\\\\\\\n    n        \\\\\\\"rev-parse\\\\\\\", \\\\\\\"show\\\\\\\", \\\\\\\"log\\\\\\\", \\\\\\\"status\\\\\\\", \\\\\\\"branch\\\\\\\n    \\\", \\\\\\\"config\\\\\\\"\\\\n    }\\\\n    if not cmd or cmd[0] not in allowed_commands:\\\\\\\n    n        raise ValueError(f\\\\\\\"Git command not allowed: {cmd[0] if cmd else 'empty'}\\\\\\\n    \\\")\\\\n    \\\\n    out = subprocess.check_output([\\\\\\\"git\\\\\\\", *cmd], cwd=str(cwd),\\\n    \\ timeout=30)\\\\n    return out.decode(\\\\\\\"utf-8\\\\\\\", errors=\\\\\\\"replace\\\\\\\").strip()\\\\\\\n    n\\\\n\\\\ndef is_git_repo(path: Path) -> bool:\\\\n    try:\\\\n        flag = _git([\\\\\\\n    \\\"rev-parse\\\\\\\", \\\\\\\"--is-inside-work-tree\\\\\\\"], cwd=path)\\\\n        return flag\\\n    \\ == \\\\\\\"true\\\\\\\"\\\\n    except Exception:\\\\n        return False\\\\n\\\\n\\\\ndef get_git_info(path:\\\n    \\ Path) -> Dict[str, Any]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Return info for the current\\\n    \\ HEAD of a repo rooted at `path`.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        commit\\\n    \\ = _git([\\\\\\\"rev-parse\\\\\\\", \\\\\\\"HEAD\\\\\\\"], cwd=path)\\\\n        branch = _git([\\\\\\\n    \\\"rev-parse\\\\\\\", \\\\\\\"--abbrev-ref\\\\\\\", \\\\\\\"HEAD\\\\\\\"], cwd=path)\\\\n        author\\\n    \\ = _git([\\\\\\\"show\\\\\\\", \\\\\\\"-s\\\\\\\", \\\\\\\"--format=%an <%ae>\\\\\\\"], cwd=path)\\\\n\\\n    \\        date = _git([\\\\\\\"show\\\\\\\", \\\\\\\"-s\\\\\\\", \\\\\\\"--date=local\\\\\\\", \\\\\\\"--format=%ad\\\\\\\n    \\\"], cwd=path)\\\\n        return {\\\\n            \\\\\\\"is_repo\\\\\\\": True,\\\\n    \\\n    \\        \\\\\\\"commit\\\\\\\": commit,\\\\n            \\\\\\\"branch\\\\\\\": branch,\\\\n    \\\n    \\        \\\\\\\"author\\\\\\\": author,\\\\n            \\\\\\\"date\\\\\\\": date,\\\\n        \\\n    \\    \\\\\\\"note\\\\\\\": None,\\\\n        }\\\\n    except Exception:\\\\n        # treat\\\n    \\ as not a repo if anything fails\\\\n        return {\\\\n            \\\\\\\"is_repo\\\\\\\n    \\\": False,\\\\n            \\\\\\\"commit\\\\\\\": None,\\\\n            \\\\\\\"branch\\\\\\\": None,\\\\\\\n    n            \\\\\\\"author\\\\\\\": None,\\\\n            \\\\\\\"date\\\\\\\": None,\\\\n      \\\n    \\      \\\\\\\"note\\\\\\\": \\\\\\\"Not a git repository\\\\\\\",\\\\n        }\\\\n\\\",\\n    \\\"src/rcpack/io_utils.py\\\"\\\n    : \\\"\\\\\\\"\\\\\\\"\\\\\\\"I/O utilities for file operations.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom pathlib\\\n    \\ import Path\\\\nfrom typing import Tuple\\\\n\\\\n\\\\ndef write_output(output_path:\\\n    \\ str, content: str) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Write content to output file.\\\\\\\n    \\\"\\\\\\\"\\\\\\\"\\\\n    output_file = Path(output_path)\\\\n    \\\\n    # Create parent\\\n    \\ directories if they don't exist\\\\n    output_file.parent.mkdir(parents=True,\\\n    \\ exist_ok=True)\\\\n    \\\\n    # Write content\\\\n    with open(output_file, 'w',\\\n    \\ encoding='utf-8') as f:\\\\n        f.write(content)\\\\n\\\\n\\\\ndef is_binary_file(path:\\\n    \\ Path, sniff_bytes: int = 2048) -> bool:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Heuristically determine\\\n    \\ if a file is binary by scanning for NUL bytes.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n   \\\n    \\     with open(path, 'rb') as fb:\\\\n            chunk = fb.read(sniff_bytes)\\\\\\\n    n        if b\\\\\\\"\\\\\\\\x00\\\\\\\" in chunk:\\\\n            return True\\\\n        # If\\\n    \\ the chunk has a lot of non-text bytes, consider it binary\\\\n        text_byte_count\\\n    \\ = sum(32 <= b <= 126 or b in (9, 10, 13) for b in chunk)\\\\n        return (len(chunk)\\\n    \\ - text_byte_count) > max(1, len(chunk) // 3)\\\\n    except Exception:\\\\n    \\\n    \\    # If we cannot read, treat as binary to avoid further processing\\\\n     \\\n    \\   return True\\\\n\\\\n\\\\ndef read_text_safely(path: Path, max_bytes: int = 16_384)\\\n    \\ -> Tuple[str, str, bool]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Read a text file safely with size\\\n    \\ limit and encoding fallbacks.\\\\n\\\\n    Returns (content, encoding_used, truncated).\\\\\\\n    n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    truncated = False\\\\n    raw: bytes\\\\n    with open(path,\\\n    \\ 'rb') as fb:\\\\n        raw = fb.read(max_bytes + 1)\\\\n    if len(raw) > max_bytes:\\\\\\\n    n        truncated = True\\\\n        raw = raw[:max_bytes]\\\\n\\\\n    for enc in\\\n    \\ (\\\\\\\"utf-8\\\\\\\", \\\\\\\"utf-16\\\\\\\", \\\\\\\"utf-16-le\\\\\\\", \\\\\\\"utf-16-be\\\\\\\", \\\\\\\"latin-1\\\\\\\n    \\\"):\\\\n        try:\\\\n            text = raw.decode(enc)\\\\n            return\\\n    \\ text, enc, truncated\\\\n        except Exception:\\\\n            continue\\\\n \\\n    \\   # Fallback: replace errors with utf-8\\\\n    text = raw.decode(\\\\\\\"utf-8\\\\\\\"\\\n    , errors=\\\\\\\"replace\\\\\\\")\\\\n    return text, \\\\\\\"utf-8\\\\\\\", truncated\\\",\\n   \\\n    \\ \\\"src/rcpack/packager.py\\\": \\\"from __future__ import annotations\\\\n\\\\nimport\\\n    \\ sys\\\\nfrom pathlib import Path\\\\nfrom typing import Iterable, Tuple\\\\n\\\\nfrom\\\n    \\ rcpack.discover import discover_files\\\\nfrom rcpack.gitinfo import get_git_info,\\\n    \\ is_git_repo\\\\nfrom rcpack.io_utils import read_text_safely, is_binary_file\\\\\\\n    nfrom rcpack.renderer import markdown as md_renderer\\\\nfrom rcpack.renderer.jsonyaml\\\n    \\ import render_json, render_yaml\\\\nfrom rcpack.treeview import render_tree\\\\\\\n    n\\\\n\\\\ndef _find_root(inputs: list[str]) -> Path:\\\\n    paths = [Path(p) for p\\\n    \\ in inputs]\\\\n    if len(paths) == 1 and Path(paths[0]).is_dir():\\\\n        return\\\n    \\ paths[0].resolve()\\\\n    parents = [p if p.is_dir() else p.parent for p in paths]\\\\\\\n    n    root = Path(*Path.commonpath([str(p.resolve()) for p in parents]).split(\\\\\\\n    \\\"/\\\\\\\"))\\\\n    return root.resolve()\\\\n\\\\n\\\\ndef build_package(\\\\n    inputs:\\\n    \\ list[str],\\\\n    include_patterns: list[str] | None,\\\\n    exclude_patterns:\\\n    \\ list[str] | None,\\\\n    max_file_bytes: int,\\\\n    fmt: str = \\\\\\\"markdown\\\\\\\n    \\\",\\\\n) -> Tuple[str, dict]:\\\\n    root = _find_root(inputs)\\\\n    root_abs =\\\n    \\ root.resolve()\\\\n\\\\n    repo_info = (\\\\n        get_git_info(root_abs) if is_git_repo(root_abs)\\\n    \\ else {\\\\n            \\\\\\\"is_repo\\\\\\\": False,\\\\n            \\\\\\\"commit\\\\\\\": None,\\\\\\\n    n            \\\\\\\"branch\\\\\\\": None,\\\\n            \\\\\\\"author\\\\\\\": None,\\\\n    \\\n    \\        \\\\\\\"date\\\\\\\": None,\\\\n            \\\\\\\"note\\\\\\\": \\\\\\\"Not a git repository\\\\\\\n    \\\",\\\\n        }\\\\n    )\\\\n\\\\n    files = discover_files(\\\\n        inputs=[Path(p)\\\n    \\ for p in inputs],\\\\n        root=root_abs,\\\\n        include_patterns=include_patterns\\\n    \\ or [],\\\\n        exclude_patterns=exclude_patterns or [],\\\\n    )\\\\n    rel_files\\\n    \\ = [f.relative_to(root_abs) for f in files]\\\\n\\\\n    project_tree = render_tree([p.as_posix()\\\n    \\ for p in rel_files])\\\\n\\\\n    file_sections: list[dict] = []\\\\n    total_lines\\\n    \\ = 0\\\\n    total_chars = 0\\\\n\\\\n    for f in files:\\\\n        rel = f.relative_to(root_abs).as_posix()\\\\\\\n    n        try:\\\\n            if is_binary_file(f):\\\\n                content =\\\n    \\ f\\\\\\\"[binary file skipped: {f.name}, {f.stat().st_size} bytes]\\\\\\\"\\\\n      \\\n    \\          file_sections.append({\\\\n                    \\\\\\\"path\\\\\\\": rel,\\\\n\\\n    \\                    \\\\\\\"language\\\\\\\": _language_from_ext(f.suffix),\\\\n      \\\n    \\              \\\\\\\"content\\\\\\\": content,\\\\n                    \\\\\\\"is_truncated\\\\\\\n    \\\": False,\\\\n                })\\\\n                total_chars += len(content)\\\\\\\n    n                continue\\\\n\\\\n            content, used_encoding, truncated =\\\n    \\ read_text_safely(f, max_bytes=max_file_bytes)\\\\n            total_lines += content.count(\\\\\\\n    \\\"\\\\\\\\n\\\\\\\") + (1 if content and not content.endswith(\\\\\\\"\\\\\\\\n\\\\\\\") else 0)\\\\\\\n    n            total_chars += len(content)\\\\n\\\\n            if truncated:\\\\n   \\\n    \\             note = f\\\\\\\"\\\\\\\\n\\\\\\\\n[... TRUNCATED to first {max_file_bytes} bytes\\\n    \\ ...]\\\\\\\"\\\\n                content = content + note\\\\n                total_chars\\\n    \\ += len(note)\\\\n\\\\n            file_sections.append({\\\\n                \\\\\\\"\\\n    path\\\\\\\": rel,\\\\n                \\\\\\\"language\\\\\\\": _language_from_ext(f.suffix),\\\\\\\n    n                \\\\\\\"content\\\\\\\": content,\\\\n                \\\\\\\"is_truncated\\\\\\\n    \\\": truncated,\\\\n            })\\\\n        except Exception as exc:\\\\n        \\\n    \\    print(f\\\\\\\"[rcpack] error reading {rel}: {exc}\\\\\\\", file=sys.stderr)\\\\n \\\n    \\           continue\\\\n\\\\n    # render in chosen format\\\\n    if fmt == \\\\\\\"markdown\\\\\\\n    \\\":\\\\n        out_text = md_renderer.render_markdown(\\\\n            root=str(root_abs),\\\\\\\n    n            repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n   \\\n    \\         files=file_sections,\\\\n            total_files=len(file_sections),\\\\\\\n    n            total_lines=total_lines,\\\\n        )\\\\n    elif fmt == \\\\\\\"json\\\\\\\n    \\\":\\\\n        out_text = render_json(\\\\n            root=str(root_abs),\\\\n   \\\n    \\         repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n      \\\n    \\      files=file_sections,\\\\n            total_files=len(file_sections),\\\\n \\\n    \\           total_lines=total_lines,\\\\n        )\\\\n    elif fmt == \\\\\\\"yaml\\\\\\\"\\\n    :\\\\n        out_text = render_yaml(\\\\n            root=str(root_abs),\\\\n     \\\n    \\       repo_info=repo_info,\\\\n            tree_text=project_tree,\\\\n        \\\n    \\    files=file_sections,\\\\n            total_files=len(file_sections),\\\\n   \\\n    \\         total_lines=total_lines,\\\\n        )\\\\n    else:\\\\n        raise ValueError(f\\\\\\\n    \\\"Unsupported format: {fmt}\\\\\\\")\\\\n\\\\n    stats = {\\\\\\\"files\\\\\\\": len(file_sections),\\\n    \\ \\\\\\\"lines\\\\\\\": total_lines, \\\\\\\"chars\\\\\\\": total_chars}\\\\n    return out_text,\\\n    \\ stats\\\\n\\\\n\\\\ndef _language_from_ext(ext: str) -> str:\\\\n    ext = ext.lower().lstrip(\\\\\\\n    \\\".\\\\\\\")\\\\n    mapping = {\\\\n        \\\\\\\"py\\\\\\\": \\\\\\\"python\\\\\\\", \\\\\\\"js\\\\\\\": \\\\\\\n    \\\"javascript\\\\\\\", \\\\\\\"ts\\\\\\\": \\\\\\\"typescript\\\\\\\",\\\\n        \\\\\\\"json\\\\\\\": \\\\\\\"\\\n    json\\\\\\\", \\\\\\\"md\\\\\\\": \\\\\\\"markdown\\\\\\\", \\\\\\\"yml\\\\\\\": \\\\\\\"yaml\\\\\\\", \\\\\\\"yaml\\\\\\\"\\\n    : \\\\\\\"yaml\\\\\\\",\\\\n        \\\\\\\"toml\\\\\\\": \\\\\\\"toml\\\\\\\", \\\\\\\"sh\\\\\\\": \\\\\\\"bash\\\\\\\"\\\n    , \\\\\\\"c\\\\\\\": \\\\\\\"c\\\\\\\", \\\\\\\"cpp\\\\\\\": \\\\\\\"cpp\\\\\\\",\\\\n        \\\\\\\"java\\\\\\\": \\\\\\\"\\\n    java\\\\\\\", \\\\\\\"go\\\\\\\": \\\\\\\"go\\\\\\\", \\\\\\\"rs\\\\\\\": \\\\\\\"rust\\\\\\\",\\\\n    }\\\\n    return\\\n    \\ mapping.get(ext, \\\\\\\"\\\\\\\")\\\\n\\\",\\n    \\\"src/rcpack/renderer/jsonyaml.py\\\": \\\"\\\n    from __future__ import annotations\\\\nimport json\\\\n\\\\ntry:\\\\n    import yaml\\\\\\\n    nexcept ImportError:\\\\n    yaml = None\\\\n\\\\n\\\\ndef render_json(root, repo_info,\\\n    \\ tree_text, files, total_files, total_lines,recent_files=None, file_sizes=None)\\\n    \\ -> str:\\\\n    data = {\\\\n        \\\\\\\"root\\\\\\\": root,\\\\n        \\\\\\\"repo_info\\\\\\\n    \\\": repo_info,\\\\n        \\\\\\\"structure\\\\\\\": tree_text,\\\\n        \\\\\\\"recent_changes\\\\\\\n    \\\": recent_files or [],\\\\n        \\\\\\\"files\\\\\\\": files,\\\\n        \\\\\\\"file_sizes\\\\\\\n    \\\": file_sizes or {},\\\\n        \\\\\\\"summary\\\\\\\": {\\\\\\\"total_files\\\\\\\": total_files,\\\n    \\ \\\\\\\"total_lines\\\\\\\": total_lines},\\\\n        \\\\n    }\\\\n    return json.dumps(data,\\\n    \\ indent=2, ensure_ascii=False)\\\\n\\\\n\\\\ndef render_yaml(root, repo_info, tree_text,\\\n    \\ files, total_files, total_lines,recent_files=None, file_sizes=None) -> str:\\\\\\\n    n    if yaml is None:\\\\n        raise RuntimeError(\\\\\\\"PyYAML not installed; run\\\n    \\ `pip install pyyaml`\\\\\\\")\\\\n    data = {\\\\n        \\\\\\\"root\\\\\\\": root,\\\\n  \\\n    \\      \\\\\\\"repo_info\\\\\\\": repo_info,\\\\n        \\\\\\\"structure\\\\\\\": tree_text,\\\\\\\n    n        \\\\\\\"recent_changes\\\\\\\": recent_files or [],\\\\n        \\\\\\\"files\\\\\\\":\\\n    \\ files,\\\\n        \\\\\\\"file_sizes\\\\\\\": file_sizes or {},\\\\n        \\\\\\\"summary\\\\\\\n    \\\": {\\\\\\\"total_files\\\\\\\": total_files, \\\\\\\"total_lines\\\\\\\": total_lines},\\\\n \\\n    \\       \\\\n    }\\\\n    return yaml.safe_dump(data, sort_keys=False, allow_unicode=True)\\\\\\\n    n\\\",\\n    \\\"src/rcpack/renderer/markdown.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Markdown renderer\\\n    \\ for repository context.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom typing import Dict, Any\\\\n\\\\n\\\\\\\n    ndef render_markdown(root: str, repo_info: Dict[str, Any], tree_text: str, \\\\\\\n    n                   files: Dict[str, str], total_files: int, total_lines: int,\\\n    \\ recent_files=None, file_sizes=None) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Render repository\\\n    \\ context as markdown.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    lines = []\\\\n    \\\\n    # Header\\\\\\\n    n    lines.append(f\\\\\\\"# Repository Context: {root}\\\\\\\")\\\\n    lines.append(\\\\\\\n    \\\"\\\\\\\")\\\\n    \\\\n    # Repository info\\\\n    if repo_info.get(\\\\\\\"is_repo\\\\\\\"\\\n    ):\\\\n        lines.append(\\\\\\\"## Git Repository Information\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Branch**: {repo_info.get('branch', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Commit**: {repo_info.get('commit', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Author**: {repo_info.get('author', 'N/A')}\\\\\\\")\\\\n        lines.append(f\\\\\\\n    \\\"- **Date**: {repo_info.get('date', 'N/A')}\\\\\\\")\\\\n    else:\\\\n        lines.append(\\\\\\\n    \\\"## Repository Information\\\\\\\")\\\\n        lines.append(f\\\\\\\"- **Note**: {repo_info.get('note',\\\n    \\ 'Not a git repository')}\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Summary\\\\\\\n    n    lines.append(\\\\\\\"## Summary\\\\\\\")\\\\n    lines.append(f\\\\\\\"- **Total Files**:\\\n    \\ {total_files}\\\\\\\")\\\\n    lines.append(f\\\\\\\"- **Total Lines**: {total_lines}\\\\\\\n    \\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    # Directory structure\\\\n    lines.append(\\\\\\\n    \\\"## Directory Structure\\\\\\\")\\\\n    lines.append(\\\\\\\"```\\\\\\\")\\\\n    lines.append(tree_text)\\\\\\\n    n    lines.append(\\\\\\\"```\\\\\\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n\\\\n    # will produce\\\n    \\ recent files \\\\n    # Recent files (fixed)\\\\n    if recent_files:\\\\n       \\\n    \\ lines.append(\\\\\\\"## Recent Changes\\\\\\\")\\\\n        for file, age in recent_files.items():\\\\\\\n    n            lines.append(f\\\\\\\"- {file} (modified {age})\\\\\\\")\\\\n        lines.append(\\\\\\\n    \\\"\\\\\\\")\\\\n    \\\\n    # File contents\\\\n    lines.append(\\\\\\\"## File Contents\\\\\\\n    \\\")\\\\n    lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    for file_path, content in sorted(files.items()):\\\\\\\n    n        if file_sizes and file_path in file_sizes:\\\\n            size_bytes =\\\n    \\ file_sizes[file_path]\\\\n            lines.append(f\\\\\\\"### {file_path} ({size_bytes}\\\n    \\ bytes)\\\\\\\")\\\\n        else:\\\\n            lines.append(f\\\\\\\"### {file_path}\\\\\\\n    \\\")\\\\n        lines.append(\\\\\\\"\\\\\\\")\\\\n        \\\\n        # Detect language for\\\n    \\ syntax highlighting\\\\n        ext = file_path.split('.')[-1].lower() if '.'\\\n    \\ in file_path else ''\\\\n        lang_map = {\\\\n            'py': 'python', 'js':\\\n    \\ 'javascript', 'ts': 'typescript',\\\\n            'java': 'java', 'cpp': 'cpp',\\\n    \\ 'c': 'c', 'h': 'c',\\\\n            'cs': 'csharp', 'php': 'php', 'rb': 'ruby',\\\\\\\n    n            'go': 'go', 'rs': 'rust', 'swift': 'swift',\\\\n            'html':\\\n    \\ 'html', 'css': 'css', 'scss': 'scss',\\\\n            'json': 'json', 'yaml':\\\n    \\ 'yaml', 'yml': 'yaml',\\\\n            'xml': 'xml', 'sql': 'sql', 'sh': 'bash',\\\\\\\n    n            'md': 'markdown', 'dockerfile': 'dockerfile'\\\\n        }\\\\n     \\\n    \\   \\\\n        language = lang_map.get(ext, '')\\\\n        lines.append(f\\\\\\\"```{language}\\\\\\\n    \\\")\\\\n        lines.append(content)\\\\n        lines.append(\\\\\\\"```\\\\\\\")\\\\n   \\\n    \\     lines.append(\\\\\\\"\\\\\\\")\\\\n    \\\\n    return \\\\\\\"\\\\\\\\n\\\\\\\".join(lines)\\\\n\\\"\\\n    ,\\n    \\\"src/rcpack/treeview.py\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Tree view generation for repository\\\n    \\ structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom pathlib import Path\\\\nfrom typing import Dict,\\\n    \\ List\\\\n\\\\n\\\\ndef create_tree_view(repo_path: Path, files_data: Dict[str, str])\\\n    \\ -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create a tree view of the repository structure.\\\\\\\"\\\n    \\\\\\\"\\\\\\\"\\\\n    paths = list(files_data.keys())\\\\n    return render_tree(paths)\\\\\\\n    n\\\\n\\\\ndef render_tree(paths: List[str]) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Render a tree\\\n    \\ view from a list of relative POSIX paths.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    tree_structure:\\\n    \\ dict = {}\\\\n\\\\n    for p in paths:\\\\n        parts = Path(p).parts\\\\n      \\\n    \\  current = tree_structure\\\\n        for part in parts[:-1]:\\\\n            if\\\n    \\ part not in current:\\\\n                current[part] = {}\\\\n            current\\\n    \\ = current[part]\\\\n        if parts:\\\\n            current[parts[-1]] = None\\\\\\\n    n\\\\n    def _render(structure: dict, prefix: str = \\\\\\\"\\\\\\\") -> str:\\\\n      \\\n    \\  lines = []\\\\n        items = sorted(structure.items(), key=lambda x: (x[1]\\\n    \\ is None, x[0]))\\\\n        for i, (name, subtree) in enumerate(items):\\\\n   \\\n    \\         is_last = i == len(items) - 1\\\\n            lines.append(f\\\\\\\"{prefix}{'└──\\\n    \\ ' if is_last else '├── '}{name}\\\\\\\")\\\\n            if subtree is not None:\\\\\\\n    n                extension = (\\\\\\\"    \\\\\\\" if is_last else \\\\\\\"│   \\\\\\\")\\\\n  \\\n    \\              lines.append(_render(subtree, prefix + extension))\\\\n        return\\\n    \\ \\\\\\\"\\\\\\\\n\\\\\\\".join(filter(None, lines))\\\\n\\\\n    if not tree_structure:\\\\n \\\n    \\       return \\\\\\\"No files found\\\\\\\"\\\\n    return _render(tree_structure)\\\"\\n\\\n    \\  },\\n  \\\"file_sizes\\\": {\\n    \\\"LICENSE\\\": \\\"1064\\\",\\n    \\\"README.md\\\": \\\"\\\n    11164\\\",\\n    \\\"pyproject.toml\\\": \\\"361\\\",\\n    \\\"src/rcpack/__init__.py\\\": \\\"\\\n    198\\\",\\n    \\\"src/rcpack/__main__.py\\\": \\\"197\\\",\\n    \\\"src/rcpack/cli.py\\\": \\\"\\\n    7087\\\",\\n    \\\"src/rcpack/config_loader.py\\\": \\\"2099\\\",\\n    \\\"src/rcpack/discover.py\\\"\\\n    : \\\"3067\\\",\\n    \\\"src/rcpack/gitinfo.py\\\": \\\"1653\\\",\\n    \\\"src/rcpack/io_utils.py\\\"\\\n    : \\\"1817\\\",\\n    \\\"src/rcpack/packager.py\\\": \\\"4430\\\",\\n    \\\"src/rcpack/renderer/jsonyaml.py\\\"\\\n    : \\\"1176\\\",\\n    \\\"src/rcpack/renderer/markdown.py\\\": \\\"2829\\\",\\n    \\\"src/rcpack/treeview.py\\\"\\\n    : \\\"1371\\\"\\n  },\\n  \\\"summary\\\": {\\n    \\\"total_files\\\": 14,\\n    \\\"total_lines\\\"\\\n    : 1180\\n  }\\n}\"\nfile_sizes:\n  LICENSE: '1064'\n  README.md: '11164'\n  pyproject.toml: '361'\n  src/rcpack/__init__.py: '198'\n  src/rcpack/__main__.py: '197'\n  src/rcpack/cli.py: '7087'\n  src/rcpack/config_loader.py: '2099'\n  src/rcpack/discover.py: '3067'\n  src/rcpack/gitinfo.py: '1653'\n  src/rcpack/io_utils.py: '1817'\n  src/rcpack/packager.py: '4430'\n  src/rcpack/renderer/jsonyaml.py: '1176'\n  src/rcpack/renderer/markdown.py: '2829'\n  src/rcpack/treeview.py: '1371'\n  test-output.json: '42249'\nsummary:\n  total_files: 15\n  total_lines: 1229\n"
  },
  "file_sizes": {
    "LICENSE": "1064",
    "README.md": "11164",
    "pyproject.toml": "361",
    "src/rcpack/__init__.py": "198",
    "src/rcpack/__main__.py": "197",
    "src/rcpack/cli.py": "7087",
    "src/rcpack/config_loader.py": "2099",
    "src/rcpack/discover.py": "3067",
    "src/rcpack/gitinfo.py": "1653",
    "src/rcpack/io_utils.py": "1817",
    "src/rcpack/packager.py": "4121",
    "src/rcpack/renderer/jsonyaml.py": "1154",
    "src/rcpack/renderer/markdown.py": "2318",
    "src/rcpack/treeview.py": "1371",
    "src/rcpack/utils.py": "3500",
    "test-output.json": "42249",
    "test-yaml.yaml": "93888"
  },
  "summary": {
    "total_files": 17,
    "total_lines": 2456
  }
}